Logistic loss:
lmda= 0.1 learning rate= 0.0001
CROSS VALIDATION 0
Iteration 1 Loss=  5.86298330746
Iteration 2 Loss=  0.0265021917269
Iteration 3 Loss=  0.0244868242127
Iteration 4 Loss=  0.0237498047161
Iteration 5 Loss=  0.0233067843371
Iteration 6 Loss=  0.0229924881833
Iteration 7 Loss=  0.0227489920404
Iteration 8 Loss=  0.0225496935935
Iteration 9 Loss=  0.0223803327132
Iteration 10 Loss=  0.0222324434412
Iteration 11 Loss=  0.022100619536
Iteration 12 Loss=  0.021981214321
Iteration 13 Loss=  0.0218716608394
Iteration 14 Loss=  0.0217700894196
Iteration 15 Loss=  0.021675099684
[ -1.85132182e-04   9.26818680e-04   3.73272866e-04 ...,   4.89534350e-04
  -4.24159246e-05   3.19411756e-04]
CROSS VALIDATION 1
Iteration 1 Loss=  9.09361796058
Iteration 2 Loss=  0.0363564042581
Iteration 3 Loss=  0.0288205529576
Iteration 4 Loss=  0.0268456765263
Iteration 5 Loss=  0.0256989989246
Iteration 6 Loss=  0.0249136273199
Iteration 7 Loss=  0.0243277137827
Iteration 8 Loss=  0.0238664367582
Iteration 9 Loss=  0.0234893921447
Iteration 10 Loss=  0.0231724697047
Iteration 11 Loss=  0.0229002333923
Iteration 12 Loss=  0.0226622675036
Iteration 13 Loss=  0.0224512507105
Iteration 14 Loss=  0.022261865308
Iteration 15 Loss=  0.0220901435242
Iteration 16 Loss=  0.0219330573852
Iteration 17 Loss=  0.0217882514349
Iteration 18 Loss=  0.0216538628889
Iteration 19 Loss=  0.0215283972626
Iteration 20 Loss=  0.0214106403044
Iteration 21 Loss=  0.0212995943292
Iteration 22 Loss=  0.0211944313446
Iteration 23 Loss=  0.0210944579748
[-0.00093265  0.0005723  -0.00040855 ...,  0.00024942 -0.00023272
  0.00037661]
CROSS VALIDATION 2
Iteration 1 Loss=  2.58219941905
Iteration 2 Loss=  0.0245814657898
Iteration 3 Loss=  0.0235002233336
Iteration 4 Loss=  0.022925916018
Iteration 5 Loss=  0.0225535534285
Iteration 6 Loss=  0.0222845548721
Iteration 7 Loss=  0.0220761858992
Iteration 8 Loss=  0.0219066508376
Iteration 9 Loss=  0.021763585936
Iteration 10 Loss=  0.0216394247508
Iteration 11 Loss=  0.0215292639495
Iteration 12 Loss=  0.0214297801739
[-0.0015093  -0.0005385  -0.00074727 ...,  0.00083707  0.00048505
  0.00029186]
CROSS VALIDATION 3
Iteration 1 Loss=  8.00484747411
Iteration 2 Loss=  0.0384605697345
Iteration 3 Loss=  0.024359941047
Iteration 4 Loss=  0.0236254146303
Iteration 5 Loss=  0.023111957315
Iteration 6 Loss=  0.0227242667344
Iteration 7 Loss=  0.0224161425731
Iteration 8 Loss=  0.0221620517355
Iteration 9 Loss=  0.0219465754112
Iteration 10 Loss=  0.0217597828913
Iteration 11 Loss=  0.0215949557903
Iteration 12 Loss=  0.0214473687918
Iteration 13 Loss=  0.0213135918189
Iteration 14 Loss=  0.0211910689689
Iteration 15 Loss=  0.0210778531987
Iteration 16 Loss=  0.0209724329881
Iteration 17 Loss=  0.020873615556
[-0.0009226   0.00065226 -0.00038165 ...,  0.00026069 -0.00019924
  0.00040005]
CROSS VALIDATION 4
Iteration 1 Loss=  7.85769000192
Iteration 2 Loss=  0.0374563739042
Iteration 3 Loss=  0.0244622291694
Iteration 4 Loss=  0.0236791167828
Iteration 5 Loss=  0.0231399404422
Iteration 6 Loss=  0.022736628209
Iteration 7 Loss=  0.0224181534985
Iteration 8 Loss=  0.0221567776233
Iteration 9 Loss=  0.0219359397478
Iteration 10 Loss=  0.0217450627288
Iteration 11 Loss=  0.0215770369137
Iteration 12 Loss=  0.0214268874485
Iteration 13 Loss=  0.0212910182827
Iteration 14 Loss=  0.0211667592468
Iteration 15 Loss=  0.021052082328
Iteration 16 Loss=  0.0209454172078
Iteration 17 Loss=  0.0208455274985
[-0.00090386  0.00066933 -0.00036564 ...,  0.00024581 -0.00019969
  0.00040082]
CROSS VALIDATION 5
Iteration 1 Loss=  6.63679171793
Iteration 2 Loss=  0.0237997710277
Iteration 3 Loss=  0.0232412297128
Iteration 4 Loss=  0.022861323834
Iteration 5 Loss=  0.0225762447295
Iteration 6 Loss=  0.0223488776
Iteration 7 Loss=  0.0221597667212
Iteration 8 Loss=  0.0219975632204
Iteration 9 Loss=  0.0218551334182
Iteration 10 Loss=  0.0217277367607
Iteration 11 Loss=  0.0216120838783
Iteration 12 Loss=  0.0215058118513
Iteration 13 Loss=  0.0214071742337
[ -6.17937732e-04   8.10348842e-04  -3.90494554e-04 ...,   6.57896974e-05
  -1.51828458e-04   5.13920976e-04]
CROSS VALIDATION 6
Iteration 1 Loss=  7.85167283369
Iteration 2 Loss=  0.0374005186864
Iteration 3 Loss=  0.0244666617827
Iteration 4 Loss=  0.0236813841142
Iteration 5 Loss=  0.0231411668854
Iteration 6 Loss=  0.022737270569
Iteration 7 Loss=  0.0224184363269
Iteration 8 Loss=  0.0221568255971
Iteration 9 Loss=  0.0219358282548
Iteration 10 Loss=  0.0217448403345
Iteration 11 Loss=  0.0215767364774
Iteration 12 Loss=  0.0214265320925
Iteration 13 Loss=  0.0212906248105
Iteration 14 Loss=  0.0211663402051
Iteration 15 Loss=  0.0210516473054
Iteration 16 Loss=  0.0209449736819
Iteration 17 Loss=  0.0208450814066
[-0.00090425  0.00066994 -0.00036529 ...,  0.00024529 -0.00019974
  0.00040092]
CROSS VALIDATION 7
Iteration 1 Loss=  7.87222247856
Iteration 2 Loss=  0.037524983527
Iteration 3 Loss=  0.0243901134446
Iteration 4 Loss=  0.0236164413972
Iteration 5 Loss=  0.0230815084365
Iteration 6 Loss=  0.0226803303729
Iteration 7 Loss=  0.0223629810363
Iteration 8 Loss=  0.0221021954657
Iteration 9 Loss=  0.0218816435281
Iteration 10 Loss=  0.0216908706969
Iteration 11 Loss=  0.0215228368814
Iteration 12 Loss=  0.0213726087257
Iteration 13 Loss=  0.0212366159357
Iteration 14 Loss=  0.0211122048405
Iteration 15 Loss=  0.020997358266
Iteration 16 Loss=  0.0208905131579
Iteration 17 Loss=  0.0207904380735
Iteration 18 Loss=  0.0206961486466
[-0.0009017   0.00066709 -0.00036637 ...,  0.00024554 -0.00020178
  0.00040024]
CROSS VALIDATION 8
Iteration 1 Loss=  7.85266698239
Iteration 2 Loss=  0.0377919166897
Iteration 3 Loss=  0.0244478994043
Iteration 4 Loss=  0.0236739535788
Iteration 5 Loss=  0.0231391134272
Iteration 6 Loss=  0.02273817823
Iteration 7 Loss=  0.0224211293481
Iteration 8 Loss=  0.0221606611858
Iteration 9 Loss=  0.0219404248404
Iteration 10 Loss=  0.0217499568901
Iteration 11 Loss=  0.0215822131029
Iteration 12 Loss=  0.0214322583877
Iteration 13 Loss=  0.0212965219753
Iteration 14 Loss=  0.0211723503901
Iteration 15 Loss=  0.021057727006
Iteration 16 Loss=  0.0209510894946
Iteration 17 Loss=  0.020851207217
[-0.00090252  0.00067254 -0.00035885 ...,  0.00024789 -0.00020319
  0.00040146]
CROSS VALIDATION 9
Iteration 1 Loss=  7.84551792552
Iteration 2 Loss=  0.0419736822558
Iteration 3 Loss=  0.0276076848986
Iteration 4 Loss=  0.026813448399
Iteration 5 Loss=  0.0262755927322
Iteration 6 Loss=  0.0258761480394
Iteration 7 Loss=  0.0255615299189
Iteration 8 Loss=  0.0253032792221
Iteration 9 Loss=  0.0250846730682
Iteration 10 Loss=  0.0248951552675
Iteration 11 Loss=  0.0247276943629
Iteration 12 Loss=  0.0245774059207
Iteration 13 Loss=  0.0244407803877
Iteration 14 Loss=  0.0243152249708
Iteration 15 Loss=  0.024198778951
Iteration 16 Loss=  0.0240899298426
Iteration 17 Loss=  0.0239874907576
Iteration 18 Loss=  0.0238905162911
[-0.00081241  0.0007358  -0.00025366 ...,  0.00059652 -0.00014973
  0.00040837]
CROSS VALIDATION 10
Iteration 1 Loss=  7.20309593006
Iteration 2 Loss=  0.0288433742401
Iteration 3 Loss=  0.0283203078829
Iteration 4 Loss=  0.0279525490131
Iteration 5 Loss=  0.0276704977827
Iteration 6 Loss=  0.027441743541
Iteration 7 Loss=  0.0272487948909
Iteration 8 Loss=  0.0270812551933
Iteration 9 Loss=  0.0269325038904
Iteration 10 Loss=  0.0267980999034
Iteration 11 Loss=  0.0266749399978
Iteration 12 Loss=  0.0265607830319
Iteration 13 Loss=  0.0264539657224
Iteration 14 Loss=  0.0263532249966
Iteration 15 Loss=  0.0262575827158
[-0.00084998  0.00063935 -0.00045519 ...,  0.00055539 -0.00010087
  0.00042779]
CROSS VALIDATION 11
Iteration 1 Loss=  7.85396597488
Iteration 2 Loss=  0.037406272203
Iteration 3 Loss=  0.0244686601843
Iteration 4 Loss=  0.0236847023526
Iteration 5 Loss=  0.0231451595356
Iteration 6 Loss=  0.0227416487421
Iteration 7 Loss=  0.0224230478544
Iteration 8 Loss=  0.0221615814457
Iteration 9 Loss=  0.0219406723445
Iteration 10 Loss=  0.0217497353527
Iteration 11 Loss=  0.0215816565207
Iteration 12 Loss=  0.0214314585532
Iteration 13 Loss=  0.0212955439388
Iteration 14 Loss=  0.0211712415933
Iteration 15 Loss=  0.0210565229088
Iteration 16 Loss=  0.0209498171651
Iteration 17 Loss=  0.0208498876949
[-0.0009023   0.00066985 -0.0003639  ...,  0.00024588 -0.00019969
  0.00040054]
CROSS VALIDATION 12
Iteration 1 Loss=  9.99471570438
Iteration 2 Loss=  0.0275255850732
Iteration 3 Loss=  0.0223910372042
Iteration 4 Loss=  0.0213984078276
Iteration 5 Loss=  0.0208199071502
Iteration 6 Loss=  0.0204183809433
Iteration 7 Loss=  0.0201138290624
Iteration 8 Loss=  0.0198697623372
Iteration 9 Loss=  0.0196666068465
Iteration 10 Loss=  0.0194927163605
Iteration 11 Loss=  0.0193406405187
Iteration 12 Loss=  0.0192053497242
Iteration 13 Loss=  0.0190833042933
Iteration 14 Loss=  0.0189719289453
Iteration 15 Loss=  0.0188692984263
Iteration 16 Loss=  0.0187739404267
[ -1.80598906e-03   6.52899703e-05  -5.70787174e-04 ...,   6.49928348e-05
  -2.05219260e-04   2.35703467e-04]
CROSS VALIDATION 13
Iteration 1 Loss=  7.96093282922
Iteration 2 Loss=  0.0331109088317
Iteration 3 Loss=  0.0293385769698
Iteration 4 Loss=  0.0280308553784
Iteration 5 Loss=  0.0272876826145
Iteration 6 Loss=  0.0267867370083
Iteration 7 Loss=  0.0264158335987
Iteration 8 Loss=  0.0261240515935
Iteration 9 Loss=  0.0258844910399
Iteration 10 Loss=  0.0256814419114
Iteration 11 Loss=  0.0255050456212
Iteration 12 Loss=  0.0253487706699
Iteration 13 Loss=  0.0252081019002
Iteration 14 Loss=  0.0250798092235
Iteration 15 Loss=  0.0249615156796
Iteration 16 Loss=  0.0248514301532
Iteration 17 Loss=  0.0247481754518
Iteration 18 Loss=  0.024650674041
[ -1.39017556e-03  -1.56664350e-04  -7.03054473e-04 ...,   7.16138767e-05
   5.29609458e-05   3.71684470e-04]
CROSS VALIDATION 14
Iteration 1 Loss=  7.83575363254
Iteration 2 Loss=  0.0358832536414
Iteration 3 Loss=  0.0230243764175
Iteration 4 Loss=  0.0225306524386
Iteration 5 Loss=  0.0221791667273
Iteration 6 Loss=  0.0219081497692
Iteration 7 Loss=  0.0216882140464
Iteration 8 Loss=  0.0215031989586
Iteration 9 Loss=  0.0213433340696
Iteration 10 Loss=  0.02120230089
Iteration 11 Loss=  0.0210758015433
Iteration 12 Loss=  0.020960795016
Iteration 13 Loss=  0.0208550602928
Iteration 14 Loss=  0.0207569323582
[-0.0008889   0.00068105 -0.00035907 ...,  0.0002347  -0.00021177
  0.00039969]
CROSS VALIDATION 15
Iteration 1 Loss=  7.88377336725
Iteration 2 Loss=  0.0377228577662
Iteration 3 Loss=  0.0244252459041
Iteration 4 Loss=  0.023659474883
Iteration 5 Loss=  0.0231288936709
Iteration 6 Loss=  0.0227305003572
Iteration 7 Loss=  0.0224151075285
Iteration 8 Loss=  0.0221557870896
Iteration 9 Loss=  0.0219363840234
Iteration 10 Loss=  0.0217465436983
Iteration 11 Loss=  0.0215792871221
Iteration 12 Loss=  0.0214297203997
Iteration 13 Loss=  0.0212942998657
Iteration 14 Loss=  0.0211703904803
Iteration 15 Loss=  0.0210559885081
Iteration 16 Loss=  0.0209495408435
Iteration 17 Loss=  0.0208498235764
[-0.00090474  0.00066848 -0.00036665 ...,  0.00024849 -0.00020175
  0.00039982]
CROSS VALIDATION 16
Iteration 1 Loss=  7.86086895294
Iteration 2 Loss=  0.0234797775135
Iteration 3 Loss=  0.0228228262937
Iteration 4 Loss=  0.0223890939051
Iteration 5 Loss=  0.0220695695575
Iteration 6 Loss=  0.0218182619037
Iteration 7 Loss=  0.0216116658214
Iteration 8 Loss=  0.0214362750751
Iteration 9 Loss=  0.0212836815876
Iteration 10 Loss=  0.0211483348495
Iteration 11 Loss=  0.0210264020579
Iteration 12 Loss=  0.020915140227
Iteration 13 Loss=  0.0208125282608
Iteration 14 Loss=  0.0207170404021
[-0.00089415  0.00067292 -0.00036339 ...,  0.00024446 -0.0002044
  0.00040503]
CROSS VALIDATION 17
Iteration 1 Loss=  7.85158290232
Iteration 2 Loss=  0.0373968779169
Iteration 3 Loss=  0.02446561417
Iteration 4 Loss=  0.0236802634749
Iteration 5 Loss=  0.0231400217696
Iteration 6 Loss=  0.0227361161622
Iteration 7 Loss=  0.0224172774616
Iteration 8 Loss=  0.0221556633666
Iteration 9 Loss=  0.0219346623099
Iteration 10 Loss=  0.0217436697781
Iteration 11 Loss=  0.021575560236
Iteration 12 Loss=  0.0214253490747
Iteration 13 Loss=  0.0212894339729
Iteration 14 Loss=  0.021165140577
Iteration 15 Loss=  0.0210504379942
Iteration 16 Loss=  0.0209437538705
Iteration 17 Loss=  0.0208438503469
[-0.00090422  0.00066996 -0.00036529 ...,  0.00024531 -0.00019972
  0.00040093]
CROSS VALIDATION 18
Iteration 1 Loss=  6.96272905819
Iteration 2 Loss=  0.0272570585857
Iteration 3 Loss=  0.0260775508399
Iteration 4 Loss=  0.0252773818923
Iteration 5 Loss=  0.0246820081491
Iteration 6 Loss=  0.0242137910492
Iteration 7 Loss=  0.0238312995348
Iteration 8 Loss=  0.0235099079187
Iteration 9 Loss=  0.023233873641
Iteration 10 Loss=  0.0229925831577
Iteration 11 Loss=  0.0227785820968
Iteration 12 Loss=  0.0225864612202
Iteration 13 Loss=  0.0224121888724
Iteration 14 Loss=  0.0222526920466
Iteration 15 Loss=  0.0221055833054
Iteration 16 Loss=  0.0219689770199
Iteration 17 Loss=  0.0218413623146
Iteration 18 Loss=  0.0217215131339
Iteration 19 Loss=  0.021608423268
Iteration 20 Loss=  0.0215012585525
Iteration 21 Loss=  0.021399321133
Iteration 22 Loss=  0.0213020223595
[-0.00086382 -0.00022298 -0.00165147 ...,  0.00093662 -0.00019793
  0.00032589]
CROSS VALIDATION 19
Iteration 1 Loss=  7.68265316565
Iteration 2 Loss=  0.0375257325322
Iteration 3 Loss=  0.0238877708011
Iteration 4 Loss=  0.0231362219481
Iteration 5 Loss=  0.0226080420826
Iteration 6 Loss=  0.0222085164333
Iteration 7 Loss=  0.0218910272304
Iteration 8 Loss=  0.0216295336627
Iteration 9 Loss=  0.0214081886236
Iteration 10 Loss=  0.0212167281446
Iteration 11 Loss=  0.0210481799718
Iteration 12 Loss=  0.0208976257447
Iteration 13 Loss=  0.0207614877651
Iteration 14 Loss=  0.0206370962739
Iteration 15 Loss=  0.020522415571
Iteration 16 Loss=  0.0204158644262
Iteration 17 Loss=  0.0203161947253
[-0.00108423  0.00067399 -0.00046384 ...,  0.00021521 -0.00022197
  0.00042256]
Accuracy (Logistic Loss):	0.95 for lmda= 0.1 learning rate= 0.0001
---------------------------------------------------------------------------------
lmda= 0.1 learning rate= 0.001
CROSS VALIDATION 0
Iteration 1 Loss=  84.6771384238
Iteration 2 Loss=  8.17347281837
Iteration 3 Loss=  4.86884688993
Iteration 4 Loss=  2.86775414818
Iteration 5 Loss=  2.80759171903
Iteration 6 Loss=  2.7486914336
Iteration 7 Loss=  2.69102681346
Iteration 8 Loss=  2.63457193567
Iteration 9 Loss=  2.57930142111
Iteration 10 Loss=  2.5251904231
Iteration 11 Loss=  2.47221461623
Iteration 12 Loss=  2.4203501854
Iteration 13 Loss=  2.36957381511
Iteration 14 Loss=  2.31986267901
Iteration 15 Loss=  2.27119442963
Iteration 16 Loss=  2.22354718831
Iteration 17 Loss=  2.1768995354
Iteration 18 Loss=  2.13123050058
Iteration 19 Loss=  2.0865195535
Iteration 20 Loss=  2.04274659449
Iteration 21 Loss=  1.99989194556
Iteration 22 Loss=  1.95793634155
Iteration 23 Loss=  1.91686092146
Iteration 24 Loss=  1.87664721995
Iteration 25 Loss=  1.83727715909
Iteration 26 Loss=  1.79873304021
Iteration 27 Loss=  1.76099753592
Iteration 28 Loss=  1.72405368234
Iteration 29 Loss=  1.6878848715
Iteration 30 Loss=  1.65247484382
Iteration 31 Loss=  1.61780768085
Iteration 32 Loss=  1.58386779807
Iteration 33 Loss=  1.55063993793
Iteration 34 Loss=  1.51810916296
Iteration 35 Loss=  1.48626084906
Iteration 36 Loss=  1.45508067893
Iteration 37 Loss=  1.42455463565
Iteration 38 Loss=  1.39466899634
Iteration 39 Loss=  1.36541032602
Iteration 40 Loss=  1.33676547157
Iteration 41 Loss=  1.30872155582
Iteration 42 Loss=  1.28126597173
Iteration 43 Loss=  1.25438637678
Iteration 44 Loss=  1.22807068736
Iteration 45 Loss=  1.20230707338
Iteration 46 Loss=  1.17708395295
Iteration 47 Loss=  1.15238998716
Iteration 48 Loss=  1.12821407498
Iteration 49 Loss=  1.1045453483
Iteration 50 Loss=  1.08137316702
Iteration 51 Loss=  1.05868711427
Iteration 52 Loss=  1.03647699176
Iteration 53 Loss=  1.01473281513
Iteration 54 Loss=  0.993444809568
Iteration 55 Loss=  0.972603405318
Iteration 56 Loss=  0.952199233442
Iteration 57 Loss=  0.932223121598
Iteration 58 Loss=  0.912666089916
Iteration 59 Loss=  0.893519346975
Iteration 60 Loss=  0.874774285855
Iteration 61 Loss=  0.856422480272
Iteration 62 Loss=  0.838455680805
Iteration 63 Loss=  0.82086581119
Iteration 64 Loss=  0.803644964706
Iteration 65 Loss=  0.786785400627
Iteration 66 Loss=  0.770279540756
Iteration 67 Loss=  0.754119966035
Iteration 68 Loss=  0.738299413222
Iteration 69 Loss=  0.722810771643
Iteration 70 Loss=  0.707647080014
Iteration 71 Loss=  0.692801523331
Iteration 72 Loss=  0.678267429827
Iteration 73 Loss=  0.664038267996
Iteration 74 Loss=  0.65010764368
Iteration 75 Loss=  0.636469297222
Iteration 76 Loss=  0.623117100678
Iteration 77 Loss=  0.61004505509
Iteration 78 Loss=  0.597247287818
Iteration 79 Loss=  0.584718049933
Iteration 80 Loss=  0.572451713658
Iteration 81 Loss=  0.560442769872
Iteration 82 Loss=  0.548685825661
Iteration 83 Loss=  0.537175601917
Iteration 84 Loss=  0.525906930994
Iteration 85 Loss=  0.514874754403
Iteration 86 Loss=  0.504074120547
Iteration 87 Loss=  0.493500182509
Iteration 88 Loss=  0.483148195861
Iteration 89 Loss=  0.473013516524
Iteration 90 Loss=  0.463091598642
Iteration 91 Loss=  0.453377992497
Iteration 92 Loss=  0.443868342437
Iteration 93 Loss=  0.434558384827
Iteration 94 Loss=  0.425443946014
Iteration 95 Loss=  0.416520940303
Iteration 96 Loss=  0.407785367944
Iteration 97 Loss=  0.399233313117
Iteration 98 Loss=  0.39086094193
Iteration 99 Loss=  0.382664500413
Iteration 100 Loss=  0.374640312527
[-0.00404072  0.00220376  0.00327653 ...,  0.00310454  0.00337861
  0.00062006]
CROSS VALIDATION 1
Iteration 1 Loss=  61.7684463657
Iteration 2 Loss=  2.59401399274
Iteration 3 Loss=  2.53959434065
Iteration 4 Loss=  2.48631635492
Iteration 5 Loss=  2.43415608462
Iteration 6 Loss=  2.38309008126
Iteration 7 Loss=  2.33309538829
Iteration 8 Loss=  2.28414953075
Iteration 9 Loss=  2.2362305052
Iteration 10 Loss=  2.18931676979
Iteration 11 Loss=  2.14338723461
Iteration 12 Loss=  2.09842125219
Iteration 13 Loss=  2.0543986082
Iteration 14 Loss=  2.01129951242
Iteration 15 Loss=  1.9691045898
Iteration 16 Loss=  1.92779487172
Iteration 17 Loss=  1.88735178756
Iteration 18 Loss=  1.84775715625
Iteration 19 Loss=  1.80899317815
Iteration 20 Loss=  1.77104242705
Iteration 21 Loss=  1.7338878423
Iteration 22 Loss=  1.69751272119
Iteration 23 Loss=  1.6619007114
Iteration 24 Loss=  1.62703580366
Iteration 25 Loss=  1.59290232457
Iteration 26 Loss=  1.55948492953
Iteration 27 Loss=  1.52676859587
Iteration 28 Loss=  1.49473861606
Iteration 29 Loss=  1.46338059113
Iteration 30 Loss=  1.43268042418
Iteration 31 Loss=  1.40262431405
Iteration 32 Loss=  1.37319874911
Iteration 33 Loss=  1.3443905012
Iteration 34 Loss=  1.31618661966
Iteration 35 Loss=  1.28857442554
Iteration 36 Loss=  1.26154150585
Iteration 37 Loss=  1.23507570804
Iteration 38 Loss=  1.20916513449
Iteration 39 Loss=  1.18379813719
Iteration 40 Loss=  1.15896331249
Iteration 41 Loss=  1.13464949598
Iteration 42 Loss=  1.11084575745
Iteration 43 Loss=  1.08754139602
Iteration 44 Loss=  1.06472593528
Iteration 45 Loss=  1.04238911862
Iteration 46 Loss=  1.02052090459
Iteration 47 Loss=  0.999111462413
Iteration 48 Loss=  0.978151167542
Iteration 49 Loss=  0.957630597344
Iteration 50 Loss=  0.937540526863
Iteration 51 Loss=  0.917871924674
Iteration 52 Loss=  0.89861594882
Iteration 53 Loss=  0.879763942841
Iteration 54 Loss=  0.861307431878
Iteration 55 Loss=  0.843238118867
Iteration 56 Loss=  0.825547880808
Iteration 57 Loss=  0.80822876511
Iteration 58 Loss=  0.791272986023
Iteration 59 Loss=  0.774672921131
Iteration 60 Loss=  0.758421107929
Iteration 61 Loss=  0.742510240466
Iteration 62 Loss=  0.726933166066
Iteration 63 Loss=  0.711682882103
Iteration 64 Loss=  0.696752532864
Iteration 65 Loss=  0.682135406458
Iteration 66 Loss=  0.667824931803
Iteration 67 Loss=  0.653814675673
Iteration 68 Loss=  0.640098339802
Iteration 69 Loss=  0.626669758057
Iteration 70 Loss=  0.613522893662
Iteration 71 Loss=  0.600651836489
Iteration 72 Loss=  0.588050800394
Iteration 73 Loss=  0.575714120624
Iteration 74 Loss=  0.563636251266
Iteration 75 Loss=  0.551811762752
Iteration 76 Loss=  0.540235339424
Iteration 77 Loss=  0.52890177714
Iteration 78 Loss=  0.517805980934
Iteration 79 Loss=  0.506942962729
Iteration 80 Loss=  0.496307839093
Iteration 81 Loss=  0.485895829044
Iteration 82 Loss=  0.475702251898
Iteration 83 Loss=  0.465722525171
Iteration 84 Loss=  0.455952162514
Iteration 85 Loss=  0.446386771698
Iteration 86 Loss=  0.43702205264
Iteration 87 Loss=  0.427853795469
Iteration 88 Loss=  0.418877878637
Iteration 89 Loss=  0.410090267062
Iteration 90 Loss=  0.401487010318
Iteration 91 Loss=  0.393064240857
Iteration 92 Loss=  0.384818172274
Iteration 93 Loss=  0.376745097604
Iteration 94 Loss=  0.368841387655
Iteration 95 Loss=  0.361103489379
Iteration 96 Loss=  0.353527924277
Iteration 97 Loss=  0.346111286835
Iteration 98 Loss=  0.338850242995
Iteration 99 Loss=  0.331741528657
Iteration 100 Loss=  0.324781948216
[-0.00199199  0.0029073  -0.0011481  ...,  0.00067383 -0.00022959
  0.0017726 ]
CROSS VALIDATION 2
Iteration 1 Loss=  355.264228726
Iteration 2 Loss=  65.162013481
Iteration 3 Loss=  2.83081556598
Iteration 4 Loss=  2.77142519396
Iteration 5 Loss=  2.71328166014
Iteration 6 Loss=  2.65635857454
Iteration 7 Loss=  2.60063017446
Iteration 8 Loss=  2.54607128427
Iteration 9 Loss=  2.49265728723
Iteration 10 Loss=  2.44036410393
Iteration 11 Loss=  2.38916817474
Iteration 12 Loss=  2.33904644476
Iteration 13 Loss=  2.28997635047
Iteration 14 Loss=  2.24193580741
Iteration 15 Loss=  2.19490319879
Iteration 16 Loss=  2.14885736466
Iteration 17 Loss=  2.10377759157
Iteration 18 Loss=  2.05964360271
Iteration 19 Loss=  2.01643554828
Iteration 20 Loss=  1.97413399624
Iteration 21 Loss=  1.93271992328
Iteration 22 Loss=  1.89217470606
Iteration 23 Loss=  1.85248011269
Iteration 24 Loss=  1.81361829435
Iteration 25 Loss=  1.77557177718
Iteration 26 Loss=  1.73832345435
Iteration 27 Loss=  1.70185657825
Iteration 28 Loss=  1.66615475294
Iteration 29 Loss=  1.63120192671
Iteration 30 Loss=  1.59698238482
Iteration 31 Loss=  1.5634807424
Iteration 32 Loss=  1.53068193752
Iteration 33 Loss=  1.49857122436
Iteration 34 Loss=  1.46713416658
Iteration 35 Loss=  1.43635663082
Iteration 36 Loss=  1.40622478031
Iteration 37 Loss=  1.37672506865
Iteration 38 Loss=  1.3478442337
Iteration 39 Loss=  1.31956929159
Iteration 40 Loss=  1.29188753093
Iteration 41 Loss=  1.26478650703
Iteration 42 Loss=  1.23825403632
Iteration 43 Loss=  1.21227819086
Iteration 44 Loss=  1.186847293
Iteration 45 Loss=  1.16194991009
Iteration 46 Loss=  1.13757484935
Iteration 47 Loss=  1.11371115284
Iteration 48 Loss=  1.09034809253
Iteration 49 Loss=  1.06747516546
Iteration 50 Loss=  1.04508208905
Iteration 51 Loss=  1.02315879643
Iteration 52 Loss=  1.00169543194
Iteration 53 Loss=  0.980682346701
Iteration 54 Loss=  0.960110094265
Iteration 55 Loss=  0.939969426367
Iteration 56 Loss=  0.920251288775
Iteration 57 Loss=  0.900946817213
Iteration 58 Loss=  0.882047333374
Iteration 59 Loss=  0.863544341025
Iteration 60 Loss=  0.84542952218
Iteration 61 Loss=  0.827694733366
Iteration 62 Loss=  0.81033200196
Iteration 63 Loss=  0.793333522604
Iteration 64 Loss=  0.7766916537
Iteration 65 Loss=  0.760398913973
Iteration 66 Loss=  0.744447979106
Iteration 67 Loss=  0.728831678455
Iteration 68 Loss=  0.713542991822
Iteration 69 Loss=  0.698575046301
Iteration 70 Loss=  0.683921113193
Iteration 71 Loss=  0.669574604977
Iteration 72 Loss=  0.65552907236
Iteration 73 Loss=  0.641778201373
Iteration 74 Loss=  0.628315810537
Iteration 75 Loss=  0.615135848093
Iteration 76 Loss=  0.602232389278
Iteration 77 Loss=  0.589599633673
Iteration 78 Loss=  0.577231902594
Iteration 79 Loss=  0.565123636551
Iteration 80 Loss=  0.553269392752
Iteration 81 Loss=  0.541663842664
Iteration 82 Loss=  0.530301769624
Iteration 83 Loss=  0.519178066506
Iteration 84 Loss=  0.508287733433
Iteration 85 Loss=  0.497625875539
Iteration 86 Loss=  0.487187700781
Iteration 87 Loss=  0.476968517798
Iteration 88 Loss=  0.466963733816
Iteration 89 Loss=  0.457168852597
Iteration 90 Loss=  0.447579472436
Iteration 91 Loss=  0.438191284196
Iteration 92 Loss=  0.429000069393
Iteration 93 Loss=  0.420001698318
Iteration 94 Loss=  0.4111921282
Iteration 95 Loss=  0.402567401411
Iteration 96 Loss=  0.394123643708
Iteration 97 Loss=  0.385857062516
Iteration 98 Loss=  0.377763945245
Iteration 99 Loss=  0.369840657641
Iteration 100 Loss=  0.362083642177
[-0.00639262 -0.00016253 -0.00330075 ...,  0.00635582  0.00034165
  0.00035797]
CROSS VALIDATION 3
Iteration 1 Loss=  61.7792608817
Iteration 2 Loss=  2.59409272201
Iteration 3 Loss=  2.53967141826
Iteration 4 Loss=  2.48639181553
Iteration 5 Loss=  2.43422996214
Iteration 6 Loss=  2.38316240891
Iteration 7 Loss=  2.33316619858
Iteration 8 Loss=  2.28421885552
Iteration 9 Loss=  2.23629837561
Iteration 10 Loss=  2.18938321635
Iteration 11 Loss=  2.1434522872
Iteration 12 Loss=  2.09848494004
Iteration 13 Loss=  2.05446095995
Iteration 14 Loss=  2.0113605561
Iteration 15 Loss=  1.96916435284
Iteration 16 Loss=  1.927853381
Iteration 17 Loss=  1.88740906937
Iteration 18 Loss=  1.84781323635
Iteration 19 Loss=  1.80904808175
Iteration 20 Loss=  1.77109617883
Iteration 21 Loss=  1.73394046643
Iteration 22 Loss=  1.69756424132
Iteration 23 Loss=  1.66195115069
Iteration 24 Loss=  1.62708518479
Iteration 25 Loss=  1.59295066974
Iteration 26 Loss=  1.55953226047
Iteration 27 Loss=  1.52681493385
Iteration 28 Loss=  1.49478398192
Iteration 29 Loss=  1.46342500526
Iteration 30 Loss=  1.43272390655
Iteration 31 Loss=  1.40266688421
Iteration 32 Loss=  1.37324042619
Iteration 33 Loss=  1.34443130394
Iteration 34 Loss=  1.31622656641
Iteration 35 Loss=  1.28861353424
Iteration 36 Loss=  1.26157979409
Iteration 37 Loss=  1.23511319304
Iteration 38 Loss=  1.20920183309
Iteration 39 Loss=  1.1838340659
Iteration 40 Loss=  1.15899848745
Iteration 41 Loss=  1.13468393301
Iteration 42 Loss=  1.11087947203
Iteration 43 Loss=  1.0875744033
Iteration 44 Loss=  1.0647582501
Iteration 45 Loss=  1.04242075551
Iteration 46 Loss=  1.02055187777
Iteration 47 Loss=  0.99914178581
Iteration 48 Loss=  0.978180854786
Iteration 49 Loss=  0.957659661781
Iteration 50 Loss=  0.937568981559
Iteration 51 Loss=  0.91789978242
Iteration 52 Loss=  0.898643222141
Iteration 53 Loss=  0.879790643997
Iteration 54 Loss=  0.861333572872
Iteration 55 Loss=  0.843263711451
Iteration 56 Loss=  0.825572936486
Iteration 57 Loss=  0.808253295147
Iteration 58 Loss=  0.791297001446
Iteration 59 Loss=  0.774696432736
Iteration 60 Loss=  0.758444126285
Iteration 61 Loss=  0.742532775922
Iteration 62 Loss=  0.726955228752
Iteration 63 Loss=  0.711704481938
Iteration 64 Loss=  0.696773679557
Iteration 65 Loss=  0.682156109515
Iteration 66 Loss=  0.667845200533
Iteration 67 Loss=  0.653834519186
Iteration 68 Loss=  0.64011776702
Iteration 69 Loss=  0.626688777712
Iteration 70 Loss=  0.613541514305
Iteration 71 Loss=  0.60067006649
Iteration 72 Loss=  0.588068647949
Iteration 73 Loss=  0.575731593757
Iteration 74 Loss=  0.56365335783
Iteration 75 Loss=  0.551828510439
Iteration 76 Loss=  0.540251735763
Iteration 77 Loss=  0.5289178295
Iteration 78 Loss=  0.517821696532
Iteration 79 Loss=  0.506958348631
Iteration 80 Loss=  0.496322902214
Iteration 81 Loss=  0.485910576156
Iteration 82 Loss=  0.47571668963
Iteration 83 Loss=  0.465736660014
Iteration 84 Loss=  0.455966000822
Iteration 85 Loss=  0.446400319691
Iteration 86 Loss=  0.437035316409
Iteration 87 Loss=  0.427866780976
Iteration 88 Loss=  0.418890591719
Iteration 89 Loss=  0.410102713433
Iteration 90 Loss=  0.401499195573
Iteration 91 Loss=  0.393076170474
Iteration 92 Loss=  0.384829851614
Iteration 93 Loss=  0.376756531917
Iteration 94 Loss=  0.368852582079
Iteration 95 Loss=  0.361114448945
Iteration 96 Loss=  0.353538653911
Iteration 97 Loss=  0.346121791358
Iteration 98 Loss=  0.338860527126
Iteration 99 Loss=  0.331751597018
Iteration 100 Loss=  0.324791805329
[-0.00199228  0.0029065  -0.00114889 ...,  0.00067359 -0.00022944
  0.00177238]
CROSS VALIDATION 4
Iteration 1 Loss=  61.7792608817
Iteration 2 Loss=  2.59409272201
Iteration 3 Loss=  2.53967141826
Iteration 4 Loss=  2.48639181553
Iteration 5 Loss=  2.43422996214
Iteration 6 Loss=  2.38316240891
Iteration 7 Loss=  2.33316619858
Iteration 8 Loss=  2.28421885552
Iteration 9 Loss=  2.23629837561
Iteration 10 Loss=  2.18938321635
Iteration 11 Loss=  2.1434522872
Iteration 12 Loss=  2.09848494004
Iteration 13 Loss=  2.05446095995
Iteration 14 Loss=  2.0113605561
Iteration 15 Loss=  1.96916435284
Iteration 16 Loss=  1.927853381
Iteration 17 Loss=  1.88740906937
Iteration 18 Loss=  1.84781323635
Iteration 19 Loss=  1.80904808175
Iteration 20 Loss=  1.77109617883
Iteration 21 Loss=  1.73394046643
Iteration 22 Loss=  1.69756424132
Iteration 23 Loss=  1.66195115069
Iteration 24 Loss=  1.62708518479
Iteration 25 Loss=  1.59295066974
Iteration 26 Loss=  1.55953226047
Iteration 27 Loss=  1.52681493385
Iteration 28 Loss=  1.49478398192
Iteration 29 Loss=  1.46342500526
Iteration 30 Loss=  1.43272390655
Iteration 31 Loss=  1.40266688421
Iteration 32 Loss=  1.37324042619
Iteration 33 Loss=  1.34443130394
Iteration 34 Loss=  1.31622656641
Iteration 35 Loss=  1.28861353424
Iteration 36 Loss=  1.26157979409
Iteration 37 Loss=  1.23511319304
Iteration 38 Loss=  1.20920183309
Iteration 39 Loss=  1.1838340659
Iteration 40 Loss=  1.15899848745
Iteration 41 Loss=  1.13468393301
Iteration 42 Loss=  1.11087947203
Iteration 43 Loss=  1.0875744033
Iteration 44 Loss=  1.0647582501
Iteration 45 Loss=  1.04242075551
Iteration 46 Loss=  1.02055187777
Iteration 47 Loss=  0.99914178581
Iteration 48 Loss=  0.978180854786
Iteration 49 Loss=  0.957659661781
Iteration 50 Loss=  0.937568981559
Iteration 51 Loss=  0.91789978242
Iteration 52 Loss=  0.898643222141
Iteration 53 Loss=  0.879790643997
Iteration 54 Loss=  0.861333572872
Iteration 55 Loss=  0.843263711451
Iteration 56 Loss=  0.825572936486
Iteration 57 Loss=  0.808253295147
Iteration 58 Loss=  0.791297001446
Iteration 59 Loss=  0.774696432736
Iteration 60 Loss=  0.758444126285
Iteration 61 Loss=  0.742532775922
Iteration 62 Loss=  0.726955228752
Iteration 63 Loss=  0.711704481938
Iteration 64 Loss=  0.696773679557
Iteration 65 Loss=  0.682156109515
Iteration 66 Loss=  0.667845200533
Iteration 67 Loss=  0.653834519186
Iteration 68 Loss=  0.64011776702
Iteration 69 Loss=  0.626688777712
Iteration 70 Loss=  0.613541514305
Iteration 71 Loss=  0.60067006649
Iteration 72 Loss=  0.588068647949
Iteration 73 Loss=  0.575731593757
Iteration 74 Loss=  0.56365335783
Iteration 75 Loss=  0.551828510439
Iteration 76 Loss=  0.540251735763
Iteration 77 Loss=  0.5289178295
Iteration 78 Loss=  0.517821696532
Iteration 79 Loss=  0.506958348631
Iteration 80 Loss=  0.496322902214
Iteration 81 Loss=  0.485910576156
Iteration 82 Loss=  0.47571668963
Iteration 83 Loss=  0.465736660014
Iteration 84 Loss=  0.455966000822
Iteration 85 Loss=  0.446400319691
Iteration 86 Loss=  0.437035316409
Iteration 87 Loss=  0.427866780976
Iteration 88 Loss=  0.418890591719
Iteration 89 Loss=  0.410102713433
Iteration 90 Loss=  0.401499195573
Iteration 91 Loss=  0.393076170474
Iteration 92 Loss=  0.384829851614
Iteration 93 Loss=  0.376756531917
Iteration 94 Loss=  0.368852582079
Iteration 95 Loss=  0.361114448945
Iteration 96 Loss=  0.353538653911
Iteration 97 Loss=  0.346121791358
Iteration 98 Loss=  0.338860527126
Iteration 99 Loss=  0.331751597018
Iteration 100 Loss=  0.324791805329
[-0.00199228  0.0029065  -0.00114889 ...,  0.00067359 -0.00022944
  0.00177238]
CROSS VALIDATION 5
Iteration 1 Loss=  61.7276158214
Iteration 2 Loss=  2.5946541916
Iteration 3 Loss=  2.54022110882
Iteration 4 Loss=  2.48692997416
Iteration 5 Loss=  2.43475683078
Iteration 6 Loss=  2.38367822441
Iteration 7 Loss=  2.33367119282
Iteration 8 Loss=  2.28471325552
Iteration 9 Loss=  2.23678240362
Iteration 10 Loss=  2.18985708997
Iteration 11 Loss=  2.14391621945
Iteration 12 Loss=  2.09893913949
Iteration 13 Loss=  2.05490563078
Iteration 14 Loss=  2.01179589821
Iteration 15 Loss=  1.96959056193
Iteration 16 Loss=  1.92827064868
Iteration 17 Loss=  1.88781758322
Iteration 18 Loss=  1.84821318002
Iteration 19 Loss=  1.80943963502
Iteration 20 Loss=  1.77147951773
Iteration 21 Loss=  1.73431576329
Iteration 22 Loss=  1.69793166485
Iteration 23 Loss=  1.66231086607
Iteration 24 Loss=  1.62743735372
Iteration 25 Loss=  1.59329545054
Iteration 26 Loss=  1.55986980814
Iteration 27 Loss=  1.52714540013
Iteration 28 Loss=  1.49510751537
Iteration 29 Loss=  1.46374175132
Iteration 30 Loss=  1.43303400761
Iteration 31 Loss=  1.40297047968
Iteration 32 Loss=  1.37353765256
Iteration 33 Loss=  1.34472229481
Iteration 34 Loss=  1.3165114526
Iteration 35 Loss=  1.28889244382
Iteration 36 Loss=  1.26185285245
Iteration 37 Loss=  1.23538052292
Iteration 38 Loss=  1.20946355468
Iteration 39 Loss=  1.18409029684
Iteration 40 Loss=  1.15924934295
Iteration 41 Loss=  1.13492952582
Iteration 42 Loss=  1.11111991256
Iteration 43 Loss=  1.08780979965
Iteration 44 Loss=  1.06498870808
Iteration 45 Loss=  1.04264637873
Iteration 46 Loss=  1.02077276766
Iteration 47 Loss=  0.999358041662
Iteration 48 Loss=  0.978392573821
Iteration 49 Loss=  0.957866939176
Iteration 50 Loss=  0.937771910495
Iteration 51 Loss=  0.918098454123
Iteration 52 Loss=  0.898837725923
Iteration 53 Loss=  0.879981067296
Iteration 54 Loss=  0.861520001294
Iteration 55 Loss=  0.843446228803
Iteration 56 Loss=  0.825751624818
Iteration 57 Loss=  0.808428234789
Iteration 58 Loss=  0.79146827104
Iteration 59 Loss=  0.774864109276
Iteration 60 Loss=  0.75860828515
Iteration 61 Loss=  0.742693490909
Iteration 62 Loss=  0.727112572109
Iteration 63 Loss=  0.711858524399
Iteration 64 Loss=  0.696924490371
Iteration 65 Loss=  0.682303756479
Iteration 66 Loss=  0.66798975002
Iteration 67 Loss=  0.653976036179
Iteration 68 Loss=  0.640256315137
Iteration 69 Loss=  0.626824419237
Iteration 70 Loss=  0.613674310216
Iteration 71 Loss=  0.600800076484
Iteration 72 Loss=  0.588195930472
Iteration 73 Loss=  0.575856206027
Iteration 74 Loss=  0.563775355868
Iteration 75 Loss=  0.551947949088
Iteration 76 Loss=  0.540368668715
Iteration 77 Loss=  0.529032309323
Iteration 78 Loss=  0.51793377469
Iteration 79 Loss=  0.507068075508
Iteration 80 Loss=  0.496430327138
Iteration 81 Loss=  0.486015747418
Iteration 82 Loss=  0.475819654511
Iteration 83 Loss=  0.4658374648
Iteration 84 Loss=  0.45606469083
Iteration 85 Loss=  0.446496939286
Iteration 86 Loss=  0.437129909026
Iteration 87 Loss=  0.427959389139
Iteration 88 Loss=  0.418981257058
Iteration 89 Loss=  0.410191476707
Iteration 90 Loss=  0.401586096684
Iteration 91 Loss=  0.393161248487
Iteration 92 Loss=  0.384913144776
Iteration 93 Loss=  0.376838077669
Iteration 94 Loss=  0.36893241708
Iteration 95 Loss=  0.361192609083
Iteration 96 Loss=  0.35361517432
Iteration 97 Loss=  0.346196706435
Iteration 98 Loss=  0.338933870547
Iteration 99 Loss=  0.33182340175
Iteration 100 Loss=  0.324862103648
[-0.00199345  0.00291651 -0.00114188 ...,  0.0006718  -0.00023105
  0.00177547]
CROSS VALIDATION 6
Iteration 1 Loss=  61.779310341
Iteration 2 Loss=  2.59409090944
Iteration 3 Loss=  2.53966964372
Iteration 4 Loss=  2.48639007821
Iteration 5 Loss=  2.43422826127
Iteration 6 Loss=  2.38316074372
Iteration 7 Loss=  2.33316456833
Iteration 8 Loss=  2.28421725947
Iteration 9 Loss=  2.23629681304
Iteration 10 Loss=  2.18938168657
Iteration 11 Loss=  2.1434507895
Iteration 12 Loss=  2.09848347376
Iteration 13 Loss=  2.05445952444
Iteration 14 Loss=  2.0113591507
Iteration 15 Loss=  1.96916297692
Iteration 16 Loss=  1.92785203395
Iteration 17 Loss=  1.88740775059
Iteration 18 Loss=  1.84781194523
Iteration 19 Loss=  1.80904681772
Iteration 20 Loss=  1.77109494131
Iteration 21 Loss=  1.73393925488
Iteration 22 Loss=  1.69756305518
Iteration 23 Loss=  1.66194998944
Iteration 24 Loss=  1.6270840479
Iteration 25 Loss=  1.59294955669
Iteration 26 Loss=  1.55953117078
Iteration 27 Loss=  1.52681386702
Iteration 28 Loss=  1.49478293747
Iteration 29 Loss=  1.46342398272
Iteration 30 Loss=  1.43272290546
Iteration 31 Loss=  1.40266590412
Iteration 32 Loss=  1.37323946667
Iteration 33 Loss=  1.34443036455
Iteration 34 Loss=  1.31622564672
Iteration 35 Loss=  1.28861263385
Iteration 36 Loss=  1.26157891259
Iteration 37 Loss=  1.23511233003
Iteration 38 Loss=  1.20920098819
Iteration 39 Loss=  1.18383323872
Iteration 40 Loss=  1.15899767763
Iteration 41 Loss=  1.13468314017
Iteration 42 Loss=  1.11087869582
Iteration 43 Loss=  1.08757364338
Iteration 44 Loss=  1.06475750612
Iteration 45 Loss=  1.04242002714
Iteration 46 Loss=  1.02055116468
Iteration 47 Loss=  0.999141087681
Iteration 48 Loss=  0.978180171303
Iteration 49 Loss=  0.957658992636
Iteration 50 Loss=  0.937568326452
Iteration 51 Loss=  0.917899141057
Iteration 52 Loss=  0.898642594233
Iteration 53 Loss=  0.879790029261
Iteration 54 Loss=  0.861332971033
Iteration 55 Loss=  0.843263122238
Iteration 56 Loss=  0.825572359635
Iteration 57 Loss=  0.808252730398
Iteration 58 Loss=  0.791296448544
Iteration 59 Loss=  0.774695891433
Iteration 60 Loss=  0.758443596339
Iteration 61 Loss=  0.742532257093
Iteration 62 Loss=  0.726954720807
Iteration 63 Loss=  0.711703984649
Iteration 64 Loss=  0.696773192701
Iteration 65 Loss=  0.682155632873
Iteration 66 Loss=  0.66784473389
Iteration 67 Loss=  0.653834062333
Iteration 68 Loss=  0.640117319751
Iteration 69 Loss=  0.626688339826
Iteration 70 Loss=  0.613541085606
Iteration 71 Loss=  0.600669646785
Iteration 72 Loss=  0.588068237049
Iteration 73 Loss=  0.575731191476
Iteration 74 Loss=  0.56365296399
Iteration 75 Loss=  0.551828124861
Iteration 76 Loss=  0.540251358273
Iteration 77 Loss=  0.52891745993
Iteration 78 Loss=  0.517821334715
Iteration 79 Loss=  0.506957994404
Iteration 80 Loss=  0.496322555419
Iteration 81 Loss=  0.485910236636
Iteration 82 Loss=  0.475716357234
Iteration 83 Loss=  0.465736334591
Iteration 84 Loss=  0.455965682225
Iteration 85 Loss=  0.446400007778
Iteration 86 Loss=  0.437035011039
Iteration 87 Loss=  0.427866482013
Iteration 88 Loss=  0.418890299028
Iteration 89 Loss=  0.410102426883
Iteration 90 Loss=  0.401498915034
Iteration 91 Loss=  0.39307589582
Iteration 92 Loss=  0.384829582723
Iteration 93 Loss=  0.376756268666
Iteration 94 Loss=  0.368852324351
Iteration 95 Loss=  0.361114196625
Iteration 96 Loss=  0.353538406884
Iteration 97 Loss=  0.346121549513
Iteration 98 Loss=  0.338860290355
Iteration 99 Loss=  0.331751365214
Iteration 100 Loss=  0.324791578389
[-0.00199227  0.00290648 -0.00114891 ...,  0.0006736  -0.00022944
  0.00177237]
CROSS VALIDATION 7
Iteration 1 Loss=  61.779310341
Iteration 2 Loss=  2.59409090944
Iteration 3 Loss=  2.53966964372
Iteration 4 Loss=  2.48639007821
Iteration 5 Loss=  2.43422826127
Iteration 6 Loss=  2.38316074372
Iteration 7 Loss=  2.33316456833
Iteration 8 Loss=  2.28421725947
Iteration 9 Loss=  2.23629681304
Iteration 10 Loss=  2.18938168657
Iteration 11 Loss=  2.1434507895
Iteration 12 Loss=  2.09848347376
Iteration 13 Loss=  2.05445952444
Iteration 14 Loss=  2.0113591507
Iteration 15 Loss=  1.96916297692
Iteration 16 Loss=  1.92785203395
Iteration 17 Loss=  1.88740775059
Iteration 18 Loss=  1.84781194523
Iteration 19 Loss=  1.80904681772
Iteration 20 Loss=  1.77109494131
Iteration 21 Loss=  1.73393925488
Iteration 22 Loss=  1.69756305518
Iteration 23 Loss=  1.66194998944
Iteration 24 Loss=  1.6270840479
Iteration 25 Loss=  1.59294955669
Iteration 26 Loss=  1.55953117078
Iteration 27 Loss=  1.52681386702
Iteration 28 Loss=  1.49478293747
Iteration 29 Loss=  1.46342398272
Iteration 30 Loss=  1.43272290546
Iteration 31 Loss=  1.40266590412
Iteration 32 Loss=  1.37323946667
Iteration 33 Loss=  1.34443036455
Iteration 34 Loss=  1.31622564672
Iteration 35 Loss=  1.28861263385
Iteration 36 Loss=  1.26157891259
Iteration 37 Loss=  1.23511233003
Iteration 38 Loss=  1.20920098819
Iteration 39 Loss=  1.18383323872
Iteration 40 Loss=  1.15899767763
Iteration 41 Loss=  1.13468314017
Iteration 42 Loss=  1.11087869582
Iteration 43 Loss=  1.08757364338
Iteration 44 Loss=  1.06475750612
Iteration 45 Loss=  1.04242002714
Iteration 46 Loss=  1.02055116468
Iteration 47 Loss=  0.999141087681
Iteration 48 Loss=  0.978180171303
Iteration 49 Loss=  0.957658992636
Iteration 50 Loss=  0.937568326452
Iteration 51 Loss=  0.917899141057
Iteration 52 Loss=  0.898642594233
Iteration 53 Loss=  0.879790029261
Iteration 54 Loss=  0.861332971033
Iteration 55 Loss=  0.843263122238
Iteration 56 Loss=  0.825572359635
Iteration 57 Loss=  0.808252730398
Iteration 58 Loss=  0.791296448544
Iteration 59 Loss=  0.774695891433
Iteration 60 Loss=  0.758443596339
Iteration 61 Loss=  0.742532257093
Iteration 62 Loss=  0.726954720807
Iteration 63 Loss=  0.711703984649
Iteration 64 Loss=  0.696773192701
Iteration 65 Loss=  0.682155632873
Iteration 66 Loss=  0.66784473389
Iteration 67 Loss=  0.653834062333
Iteration 68 Loss=  0.640117319751
Iteration 69 Loss=  0.626688339826
Iteration 70 Loss=  0.613541085606
Iteration 71 Loss=  0.600669646785
Iteration 72 Loss=  0.588068237049
Iteration 73 Loss=  0.575731191476
Iteration 74 Loss=  0.56365296399
Iteration 75 Loss=  0.551828124861
Iteration 76 Loss=  0.540251358273
Iteration 77 Loss=  0.52891745993
Iteration 78 Loss=  0.517821334715
Iteration 79 Loss=  0.506957994404
Iteration 80 Loss=  0.496322555419
Iteration 81 Loss=  0.485910236636
Iteration 82 Loss=  0.475716357234
Iteration 83 Loss=  0.465736334591
Iteration 84 Loss=  0.455965682225
Iteration 85 Loss=  0.446400007778
Iteration 86 Loss=  0.437035011039
Iteration 87 Loss=  0.427866482013
Iteration 88 Loss=  0.418890299028
Iteration 89 Loss=  0.410102426883
Iteration 90 Loss=  0.401498915034
Iteration 91 Loss=  0.39307589582
Iteration 92 Loss=  0.384829582723
Iteration 93 Loss=  0.376756268666
Iteration 94 Loss=  0.368852324351
Iteration 95 Loss=  0.361114196625
Iteration 96 Loss=  0.353538406884
Iteration 97 Loss=  0.346121549513
Iteration 98 Loss=  0.338860290355
Iteration 99 Loss=  0.331751365214
Iteration 100 Loss=  0.324791578389
[-0.00199227  0.00290648 -0.00114891 ...,  0.0006736  -0.00022944
  0.00177237]
CROSS VALIDATION 8
Iteration 1 Loss=  61.779310341
Iteration 2 Loss=  2.59409090944
Iteration 3 Loss=  2.53966964372
Iteration 4 Loss=  2.48639007821
Iteration 5 Loss=  2.43422826127
Iteration 6 Loss=  2.38316074372
Iteration 7 Loss=  2.33316456833
Iteration 8 Loss=  2.28421725947
Iteration 9 Loss=  2.23629681304
Iteration 10 Loss=  2.18938168657
Iteration 11 Loss=  2.1434507895
Iteration 12 Loss=  2.09848347376
Iteration 13 Loss=  2.05445952444
Iteration 14 Loss=  2.0113591507
Iteration 15 Loss=  1.96916297692
Iteration 16 Loss=  1.92785203395
Iteration 17 Loss=  1.88740775059
Iteration 18 Loss=  1.84781194523
Iteration 19 Loss=  1.80904681772
Iteration 20 Loss=  1.77109494131
Iteration 21 Loss=  1.73393925488
Iteration 22 Loss=  1.69756305518
Iteration 23 Loss=  1.66194998944
Iteration 24 Loss=  1.6270840479
Iteration 25 Loss=  1.59294955669
Iteration 26 Loss=  1.55953117078
Iteration 27 Loss=  1.52681386702
Iteration 28 Loss=  1.49478293747
Iteration 29 Loss=  1.46342398272
Iteration 30 Loss=  1.43272290546
Iteration 31 Loss=  1.40266590412
Iteration 32 Loss=  1.37323946667
Iteration 33 Loss=  1.34443036455
Iteration 34 Loss=  1.31622564672
Iteration 35 Loss=  1.28861263385
Iteration 36 Loss=  1.26157891259
Iteration 37 Loss=  1.23511233003
Iteration 38 Loss=  1.20920098819
Iteration 39 Loss=  1.18383323872
Iteration 40 Loss=  1.15899767763
Iteration 41 Loss=  1.13468314017
Iteration 42 Loss=  1.11087869582
Iteration 43 Loss=  1.08757364338
Iteration 44 Loss=  1.06475750612
Iteration 45 Loss=  1.04242002714
Iteration 46 Loss=  1.02055116468
Iteration 47 Loss=  0.999141087681
Iteration 48 Loss=  0.978180171303
Iteration 49 Loss=  0.957658992636
Iteration 50 Loss=  0.937568326452
Iteration 51 Loss=  0.917899141057
Iteration 52 Loss=  0.898642594233
Iteration 53 Loss=  0.879790029261
Iteration 54 Loss=  0.861332971033
Iteration 55 Loss=  0.843263122238
Iteration 56 Loss=  0.825572359635
Iteration 57 Loss=  0.808252730398
Iteration 58 Loss=  0.791296448544
Iteration 59 Loss=  0.774695891433
Iteration 60 Loss=  0.758443596339
Iteration 61 Loss=  0.742532257093
Iteration 62 Loss=  0.726954720807
Iteration 63 Loss=  0.711703984649
Iteration 64 Loss=  0.696773192701
Iteration 65 Loss=  0.682155632873
Iteration 66 Loss=  0.66784473389
Iteration 67 Loss=  0.653834062333
Iteration 68 Loss=  0.640117319751
Iteration 69 Loss=  0.626688339826
Iteration 70 Loss=  0.613541085606
Iteration 71 Loss=  0.600669646785
Iteration 72 Loss=  0.588068237049
Iteration 73 Loss=  0.575731191476
Iteration 74 Loss=  0.56365296399
Iteration 75 Loss=  0.551828124861
Iteration 76 Loss=  0.540251358273
Iteration 77 Loss=  0.52891745993
Iteration 78 Loss=  0.517821334715
Iteration 79 Loss=  0.506957994404
Iteration 80 Loss=  0.496322555419
Iteration 81 Loss=  0.485910236636
Iteration 82 Loss=  0.475716357234
Iteration 83 Loss=  0.465736334591
Iteration 84 Loss=  0.455965682225
Iteration 85 Loss=  0.446400007778
Iteration 86 Loss=  0.437035011039
Iteration 87 Loss=  0.427866482013
Iteration 88 Loss=  0.418890299028
Iteration 89 Loss=  0.410102426883
Iteration 90 Loss=  0.401498915034
Iteration 91 Loss=  0.39307589582
Iteration 92 Loss=  0.384829582723
Iteration 93 Loss=  0.376756268666
Iteration 94 Loss=  0.368852324351
Iteration 95 Loss=  0.361114196625
Iteration 96 Loss=  0.353538406884
Iteration 97 Loss=  0.346121549513
Iteration 98 Loss=  0.338860290355
Iteration 99 Loss=  0.331751365214
Iteration 100 Loss=  0.324791578389
[-0.00199227  0.00290648 -0.00114891 ...,  0.0006736  -0.00022944
  0.00177237]
CROSS VALIDATION 9
Iteration 1 Loss=  158.461629111
Iteration 2 Loss=  68.3467355739
Iteration 3 Loss=  3.0027405059
Iteration 4 Loss=  2.93974622876
Iteration 5 Loss=  2.8780735083
Iteration 6 Loss=  2.81769462025
Iteration 7 Loss=  2.75858242207
Iteration 8 Loss=  2.70071034073
Iteration 9 Loss=  2.64405236078
Iteration 10 Loss=  2.58858301267
Iteration 11 Loss=  2.53427736129
Iteration 12 Loss=  2.4811109948
Iteration 13 Loss=  2.42906001365
Iteration 14 Loss=  2.37810101984
Iteration 15 Loss=  2.32821110646
Iteration 16 Loss=  2.27936784733
Iteration 17 Loss=  2.231549287
Iteration 18 Loss=  2.18473393086
Iteration 19 Loss=  2.13890073548
Iteration 20 Loss=  2.0940290992
Iteration 21 Loss=  2.05009885282
Iteration 22 Loss=  2.00709025058
Iteration 23 Loss=  1.96498396129
Iteration 24 Loss=  1.92376105957
Iteration 25 Loss=  1.88340301742
Iteration 26 Loss=  1.84389169581
Iteration 27 Loss=  1.80520933652
Iteration 28 Loss=  1.76733855411
Iteration 29 Loss=  1.73026232806
Iteration 30 Loss=  1.69396399503
Iteration 31 Loss=  1.65842724131
Iteration 32 Loss=  1.62363609538
Iteration 33 Loss=  1.58957492062
Iteration 34 Loss=  1.55622840812
Iteration 35 Loss=  1.52358156967
Iteration 36 Loss=  1.49161973088
Iteration 37 Loss=  1.4603285244
Iteration 38 Loss=  1.4296938833
Iteration 39 Loss=  1.3997020346
Iteration 40 Loss=  1.37033949296
Iteration 41 Loss=  1.34159305447
Iteration 42 Loss=  1.31344979069
Iteration 43 Loss=  1.28589704282
Iteration 44 Loss=  1.25892241603
Iteration 45 Loss=  1.23251377402
Iteration 46 Loss=  1.20665923371
Iteration 47 Loss=  1.18134716016
Iteration 48 Loss=  1.15656616158
Iteration 49 Loss=  1.13230508456
Iteration 50 Loss=  1.10855300938
Iteration 51 Loss=  1.08529924546
Iteration 52 Loss=  1.06253332685
Iteration 53 Loss=  1.04024500784
Iteration 54 Loss=  1.01842425861
Iteration 55 Loss=  0.997061260875
Iteration 56 Loss=  0.976146403608
Iteration 57 Loss=  0.95567027878
Iteration 58 Loss=  0.935623677129
Iteration 59 Loss=  0.915997583957
Iteration 60 Loss=  0.896783174988
Iteration 61 Loss=  0.877971812272
Iteration 62 Loss=  0.859555040153
Iteration 63 Loss=  0.841524581309
Iteration 64 Loss=  0.823872332877
Iteration 65 Loss=  0.806590362658
Iteration 66 Loss=  0.789670905409
Iteration 67 Loss=  0.773106359231
Iteration 68 Loss=  0.756889282043
Iteration 69 Loss=  0.741012388153
Iteration 70 Loss=  0.725468544904
Iteration 71 Loss=  0.710250769422
Iteration 72 Loss=  0.695352225436
Iteration 73 Loss=  0.680766220177
Iteration 74 Loss=  0.66648620136
Iteration 75 Loss=  0.652505754232
Iteration 76 Loss=  0.638818598695
Iteration 77 Loss=  0.62541858649
Iteration 78 Loss=  0.61229969845
Iteration 79 Loss=  0.599456041809
Iteration 80 Loss=  0.58688184757
Iteration 81 Loss=  0.574571467932
Iteration 82 Loss=  0.562519373765
Iteration 83 Loss=  0.550720152136
Iteration 84 Loss=  0.539168503883
Iteration 85 Loss=  0.527859241238
Iteration 86 Loss=  0.516787285485
Iteration 87 Loss=  0.505947664662
Iteration 88 Loss=  0.495335511302
Iteration 89 Loss=  0.484946060205
Iteration 90 Loss=  0.474774646247
Iteration 91 Loss=  0.464816702219
Iteration 92 Loss=  0.455067756693
Iteration 93 Loss=  0.445523431923
Iteration 94 Loss=  0.436179441774
Iteration 95 Loss=  0.427031589682
Iteration 96 Loss=  0.418075766644
Iteration 97 Loss=  0.409307949259
Iteration 98 Loss=  0.400724197796
Iteration 99 Loss=  0.392320654324
Iteration 100 Loss=  0.384093540896
[-0.00526566  0.00260645 -0.00075184 ...,  0.00708569  0.00279972
  0.00138353]
CROSS VALIDATION 10
Iteration 1 Loss=  61.7766995079
Iteration 2 Loss=  2.59403139159
Iteration 3 Loss=  2.53961137448
Iteration 4 Loss=  2.4863330314
Iteration 5 Loss=  2.43417241125
Iteration 6 Loss=  2.38310606537
Iteration 7 Loss=  2.33311103707
Iteration 8 Loss=  2.28416485124
Iteration 9 Loss=  2.23624550428
Iteration 10 Loss=  2.18933145421
Iteration 11 Loss=  2.14340161097
Iteration 12 Loss=  2.09843532694
Iteration 13 Loss=  2.05441238768
Iteration 14 Loss=  2.01131300282
Iteration 15 Loss=  1.96911779718
Iteration 16 Loss=  1.92780780203
Iteration 17 Loss=  1.8873644466
Iteration 18 Loss=  1.84776954972
Iteration 19 Loss=  1.80900531162
Iteration 20 Loss=  1.77105430597
Iteration 21 Loss=  1.73389947202
Iteration 22 Loss=  1.69752410693
Iteration 23 Loss=  1.66191185827
Iteration 24 Loss=  1.62704671669
Iteration 25 Loss=  1.59291300865
Iteration 26 Loss=  1.55949538948
Iteration 27 Loss=  1.52677883637
Iteration 28 Loss=  1.49474864173
Iteration 29 Loss=  1.46339040647
Iteration 30 Loss=  1.4326900336
Iteration 31 Loss=  1.40263372188
Iteration 32 Loss=  1.37320795957
Iteration 33 Loss=  1.34439951844
Iteration 34 Loss=  1.31619544773
Iteration 35 Loss=  1.2885830684
Iteration 36 Loss=  1.26154996739
Iteration 37 Loss=  1.23508399207
Iteration 38 Loss=  1.20917324473
Iteration 39 Loss=  1.18380607729
Iteration 40 Loss=  1.15897108602
Iteration 41 Loss=  1.13465710642
Iteration 42 Loss=  1.11085320823
Iteration 43 Loss=  1.08754869049
Iteration 44 Loss=  1.06473307672
Iteration 45 Loss=  1.04239611024
Iteration 46 Loss=  1.02052774954
Iteration 47 Loss=  0.999118163759
Iteration 48 Loss=  0.9781577283
Iteration 49 Loss=  0.957637020464
Iteration 50 Loss=  0.937546815233
Iteration 51 Loss=  0.917878081121
Iteration 52 Loss=  0.898621976111
Iteration 53 Loss=  0.879769843686
Iteration 54 Loss=  0.86131320893
Iteration 55 Loss=  0.843243774723
Iteration 56 Loss=  0.825553418009
Iteration 57 Loss=  0.808234186147
Iteration 58 Loss=  0.791278293333
Iteration 59 Loss=  0.774678117099
Iteration 60 Loss=  0.758426194891
Iteration 61 Loss=  0.742515220709
Iteration 62 Loss=  0.726938041828
Iteration 63 Loss=  0.711687655578
Iteration 64 Loss=  0.696757206196
Iteration 65 Loss=  0.682139981748
Iteration 66 Loss=  0.667829411109
Iteration 67 Loss=  0.653819061007
Iteration 68 Loss=  0.640102633137
Iteration 69 Loss=  0.626673961322
Iteration 70 Loss=  0.613527008748
Iteration 71 Loss=  0.600655865244
Iteration 72 Loss=  0.58805474463
Iteration 73 Loss=  0.575717982114
Iteration 74 Loss=  0.563640031746
Iteration 75 Loss=  0.551815463922
Iteration 76 Loss=  0.540238962947
Iteration 77 Loss=  0.528905324645
Iteration 78 Loss=  0.517809454016
Iteration 79 Loss=  0.506946362949
Iteration 80 Loss=  0.49631116798
Iteration 81 Loss=  0.485899088094
Iteration 82 Loss=  0.475705442576
Iteration 83 Loss=  0.465725648912
Iteration 84 Loss=  0.455955220721
Iteration 85 Loss=  0.446389765746
Iteration 86 Loss=  0.437024983875
Iteration 87 Loss=  0.427856665209
Iteration 88 Loss=  0.418880688171
Iteration 89 Loss=  0.410093017653
Iteration 90 Loss=  0.401489703202
Iteration 91 Loss=  0.393066877245
Iteration 92 Loss=  0.384820753351
Iteration 93 Loss=  0.376747624529
Iteration 94 Loss=  0.368843861563
Iteration 95 Loss=  0.361105911382
Iteration 96 Loss=  0.353530295463
Iteration 97 Loss=  0.346113608269
Iteration 98 Loss=  0.338852515719
Iteration 99 Loss=  0.331743753692
Iteration 100 Loss=  0.324784126561
[-0.00199188  0.00290549 -0.00114959 ...,  0.00067362 -0.00022945
  0.0017722 ]
CROSS VALIDATION 11
Iteration 1 Loss=  61.7766801365
Iteration 2 Loss=  2.59403196836
Iteration 3 Loss=  2.53961193915
Iteration 4 Loss=  2.48633358423
Iteration 5 Loss=  2.43417295247
Iteration 6 Loss=  2.38310659524
Iteration 7 Loss=  2.33311155583
Iteration 8 Loss=  2.28416535911
Iteration 9 Loss=  2.2362460015
Iteration 10 Loss=  2.189331941
Iteration 11 Loss=  2.14340208754
Iteration 12 Loss=  2.09843579352
Iteration 13 Loss=  2.05441284447
Iteration 14 Loss=  2.01131345003
Iteration 15 Loss=  1.96911823501
Iteration 16 Loss=  1.92780823067
Iteration 17 Loss=  1.88736486625
Iteration 18 Loss=  1.84776996056
Iteration 19 Loss=  1.80900571385
Iteration 20 Loss=  1.77105469976
Iteration 21 Loss=  1.73389985754
Iteration 22 Loss=  1.69752448437
Iteration 23 Loss=  1.66191222779
Iteration 24 Loss=  1.62704707845
Iteration 25 Loss=  1.59291336283
Iteration 26 Loss=  1.55949573622
Iteration 27 Loss=  1.52677917585
Iteration 28 Loss=  1.49474897408
Iteration 29 Loss=  1.46339073185
Iteration 30 Loss=  1.43269035216
Iteration 31 Loss=  1.40263403375
Iteration 32 Loss=  1.3732082649
Iteration 33 Loss=  1.34439981736
Iteration 34 Loss=  1.31619574038
Iteration 35 Loss=  1.28858335491
Iteration 36 Loss=  1.2615502479
Iteration 37 Loss=  1.23508426669
Iteration 38 Loss=  1.20917351359
Iteration 39 Loss=  1.1838063405
Iteration 40 Loss=  1.15897134371
Iteration 41 Loss=  1.13465735871
Iteration 42 Loss=  1.11085345523
Iteration 43 Loss=  1.0875489323
Iteration 44 Loss=  1.06473331346
Iteration 45 Loss=  1.04239634201
Iteration 46 Loss=  1.02052797645
Iteration 47 Loss=  0.999118385909
Iteration 48 Loss=  0.97815794579
Iteration 49 Loss=  0.957637233391
Iteration 50 Loss=  0.937547023693
Iteration 51 Loss=  0.917878285208
Iteration 52 Loss=  0.898622175917
Iteration 53 Loss=  0.8797700393
Iteration 54 Loss=  0.86131340044
Iteration 55 Loss=  0.843243962215
Iteration 56 Loss=  0.825553601568
Iteration 57 Loss=  0.808234365855
Iteration 58 Loss=  0.791278469271
Iteration 59 Loss=  0.774678289346
Iteration 60 Loss=  0.758426363524
Iteration 61 Loss=  0.742515385805
Iteration 62 Loss=  0.72693820346
Iteration 63 Loss=  0.711687813819
Iteration 64 Loss=  0.696757361117
Iteration 65 Loss=  0.682140133419
Iteration 66 Loss=  0.667829559598
Iteration 67 Loss=  0.653819206382
Iteration 68 Loss=  0.640102775462
Iteration 69 Loss=  0.626674100661
Iteration 70 Loss=  0.613527145163
Iteration 71 Loss=  0.600655998797
Iteration 72 Loss=  0.588054875382
Iteration 73 Loss=  0.575718110123
Iteration 74 Loss=  0.563640157069
Iteration 75 Loss=  0.551815586616
Iteration 76 Loss=  0.540239083067
Iteration 77 Loss=  0.528905442245
Iteration 78 Loss=  0.517809569149
Iteration 79 Loss=  0.506946475667
Iteration 80 Loss=  0.496311278333
Iteration 81 Loss=  0.485899196131
Iteration 82 Loss=  0.475705548347
Iteration 83 Loss=  0.465725752464
Iteration 84 Loss=  0.455955322101
Iteration 85 Loss=  0.446389864999
Iteration 86 Loss=  0.437025081046
Iteration 87 Loss=  0.427856760341
Iteration 88 Loss=  0.418880781308
Iteration 89 Loss=  0.410093108836
Iteration 90 Loss=  0.401489792472
Iteration 91 Loss=  0.393066964642
Iteration 92 Loss=  0.384820838914
Iteration 93 Loss=  0.376747708297
Iteration 94 Loss=  0.368843943574
Iteration 95 Loss=  0.361105991672
Iteration 96 Loss=  0.353530374069
Iteration 97 Loss=  0.346113685226
Iteration 98 Loss=  0.338852591061
Iteration 99 Loss=  0.331743827454
Iteration 100 Loss=  0.324784198776
[-0.00199188  0.0029055  -0.00114959 ...,  0.00067362 -0.00022945
  0.0017722 ]
CROSS VALIDATION 12
Iteration 1 Loss=  165.707031682
Iteration 2 Loss=  36.4039249988
Iteration 3 Loss=  2.9032708494
Iteration 4 Loss=  2.84236502439
Iteration 5 Loss=  2.78273690353
Iteration 6 Loss=  2.72435968469
Iteration 7 Loss=  2.66720712797
Iteration 8 Loss=  2.6112535438
Iteration 9 Loss=  2.55647378143
Iteration 10 Loss=  2.50284321761
Iteration 11 Loss=  2.45033774547
Iteration 12 Loss=  2.39893376376
Iteration 13 Loss=  2.34860816619
Iteration 14 Loss=  2.29933833106
Iteration 15 Loss=  2.25110211112
Iteration 16 Loss=  2.2038778236
Iteration 17 Loss=  2.15764424049
Iteration 18 Loss=  2.11238057899
Iteration 19 Loss=  2.06806649221
Iteration 20 Loss=  2.02468206002
Iteration 21 Loss=  1.98220778006
Iteration 22 Loss=  1.94062455908
Iteration 23 Loss=  1.89991370427
Iteration 24 Loss=  1.86005691491
Iteration 25 Loss=  1.82103627417
Iteration 26 Loss=  1.78283424101
Iteration 27 Loss=  1.74543364235
Iteration 28 Loss=  1.70881766533
Iteration 29 Loss=  1.67296984977
Iteration 30 Loss=  1.63787408075
Iteration 31 Loss=  1.60351458143
Iteration 32 Loss=  1.56987590588
Iteration 33 Loss=  1.53694293221
Iteration 34 Loss=  1.50470085573
Iteration 35 Loss=  1.47313518233
Iteration 36 Loss=  1.44223172194
Iteration 37 Loss=  1.41197658218
Iteration 38 Loss=  1.38235616209
Iteration 39 Loss=  1.35335714603
Iteration 40 Loss=  1.3249664977
Iteration 41 Loss=  1.29717145429
Iteration 42 Loss=  1.2699595207
Iteration 43 Loss=  1.24331846399
Iteration 44 Loss=  1.21723630782
Iteration 45 Loss=  1.19170132711
Iteration 46 Loss=  1.16670204275
Iteration 47 Loss=  1.14222721645
Iteration 48 Loss=  1.11826584566
Iteration 49 Loss=  1.09480715868
Iteration 50 Loss=  1.07184060977
Iteration 51 Loss=  1.04935587442
Iteration 52 Loss=  1.02734284472
Iteration 53 Loss=  1.00579162482
Iteration 54 Loss=  0.984692526459
Iteration 55 Loss=  0.96403606464
Iteration 56 Loss=  0.943812953338
Iteration 57 Loss=  0.924014101345
Iteration 58 Loss=  0.904630608176
Iteration 59 Loss=  0.885653760069
Iteration 60 Loss=  0.867075026072
Iteration 61 Loss=  0.848886054202
Iteration 62 Loss=  0.831078667697
Iteration 63 Loss=  0.813644861338
Iteration 64 Loss=  0.796576797851
Iteration 65 Loss=  0.779866804386
Iteration 66 Loss=  0.763507369066
Iteration 67 Loss=  0.747491137615
Iteration 68 Loss=  0.731810910048
Iteration 69 Loss=  0.716459637442
Iteration 70 Loss=  0.70143041876
Iteration 71 Loss=  0.686716497761
Iteration 72 Loss=  0.672311259953
Iteration 73 Loss=  0.658208229631
Iteration 74 Loss=  0.644401066963
Iteration 75 Loss=  0.630883565143
Iteration 76 Loss=  0.617649647604
Iteration 77 Loss=  0.604693365292
Iteration 78 Loss=  0.592008893989
Iteration 79 Loss=  0.579590531703
Iteration 80 Loss=  0.567432696108
Iteration 81 Loss=  0.555529922039
Iteration 82 Loss=  0.543876859039
Iteration 83 Loss=  0.53246826896
Iteration 84 Loss=  0.521299023613
Iteration 85 Loss=  0.510364102471
Iteration 86 Loss=  0.499658590416
Iteration 87 Loss=  0.489177675539
Iteration 88 Loss=  0.478916646984
Iteration 89 Loss=  0.468870892837
Iteration 90 Loss=  0.459035898063
Iteration 91 Loss=  0.449407242485
Iteration 92 Loss=  0.439980598804
Iteration 93 Loss=  0.430751730665
Iteration 94 Loss=  0.421716490761
Iteration 95 Loss=  0.412870818975
Iteration 96 Loss=  0.404210740567
Iteration 97 Loss=  0.395732364391
Iteration 98 Loss=  0.387431881152
Iteration 99 Loss=  0.379305561697
Iteration 100 Loss=  0.371349755341
[-0.0139635  -0.00262841 -0.00501502 ...,  0.00452852  0.00294831
  0.00035248]
CROSS VALIDATION 13
Iteration 1 Loss=  233.32084818
Iteration 2 Loss=  65.4390968119
Iteration 3 Loss=  2.87336074734
Iteration 4 Loss=  2.81308069771
Iteration 5 Loss=  2.75406525935
Iteration 6 Loss=  2.69628790207
Iteration 7 Loss=  2.63972265223
Iteration 8 Loss=  2.58434408112
Iteration 9 Loss=  2.53012729348
Iteration 10 Loss=  2.47704791632
Iteration 11 Loss=  2.425082088
Iteration 12 Loss=  2.37420644742
Iteration 13 Loss=  2.32439812363
Iteration 14 Loss=  2.27563472545
Iteration 15 Loss=  2.22789433145
Iteration 16 Loss=  2.1811554801
Iteration 17 Loss=  2.13539716009
Iteration 18 Loss=  2.09059880092
Iteration 19 Loss=  2.04674026363
Iteration 20 Loss=  2.00380183177
Iteration 21 Loss=  1.9617642025
Iteration 22 Loss=  1.92060847794
Iteration 23 Loss=  1.88031615667
Iteration 24 Loss=  1.8408691254
Iteration 25 Loss=  1.80224965086
Iteration 26 Loss=  1.76444037178
Iteration 27 Loss=  1.72742429113
Iteration 28 Loss=  1.69118476844
Iteration 29 Loss=  1.65570551236
Iteration 30 Loss=  1.6209705733
Iteration 31 Loss=  1.58696433629
Iteration 32 Loss=  1.55367151392
Iteration 33 Loss=  1.52107713953
Iteration 34 Loss=  1.48916656042
Iteration 35 Loss=  1.45792543128
Iteration 36 Loss=  1.42733970778
Iteration 37 Loss=  1.39739564019
Iteration 38 Loss=  1.36807976727
Iteration 39 Loss=  1.33937891015
Iteration 40 Loss=  1.31128016646
Iteration 41 Loss=  1.2837709045
Iteration 42 Loss=  1.25683875757
Iteration 43 Loss=  1.23047161842
Iteration 44 Loss=  1.20465763377
Iteration 45 Loss=  1.17938519905
Iteration 46 Loss=  1.1546429531
Iteration 47 Loss=  1.13041977314
Iteration 48 Loss=  1.1067047697
Iteration 49 Loss=  1.0834872818
Iteration 50 Loss=  1.06075687208
Iteration 51 Loss=  1.03850332216
Iteration 52 Loss=  1.01671662804
Iteration 53 Loss=  0.995386995579
Iteration 54 Loss=  0.974504836107
Iteration 55 Loss=  0.954060762124
Iteration 56 Loss=  0.934045583065
Iteration 57 Loss=  0.914450301176
Iteration 58 Loss=  0.895266107464
Iteration 59 Loss=  0.876484377743
Iteration 60 Loss=  0.858096668755
Iteration 61 Loss=  0.84009471437
Iteration 62 Loss=  0.82247042188
Iteration 63 Loss=  0.80521586835
Iteration 64 Loss=  0.788323297066
Iteration 65 Loss=  0.771785114042
Iteration 66 Loss=  0.755593884611
Iteration 67 Loss=  0.739742330079
Iteration 68 Loss=  0.72422332446
Iteration 69 Loss=  0.709029891264
Iteration 70 Loss=  0.694155200371
Iteration 71 Loss=  0.679592564955
Iteration 72 Loss=  0.665335438483
Iteration 73 Loss=  0.651377411769
Iteration 74 Loss=  0.6377122101
Iteration 75 Loss=  0.624333690412
Iteration 76 Loss=  0.611235838532
Iteration 77 Loss=  0.598412766477
Iteration 78 Loss=  0.585858709809
Iteration 79 Loss=  0.573568025048
Iteration 80 Loss=  0.561535187133
Iteration 81 Loss=  0.549754786949
Iteration 82 Loss=  0.538221528894
Iteration 83 Loss=  0.526930228504
Iteration 84 Loss=  0.51587581013
Iteration 85 Loss=  0.505053304656
Iteration 86 Loss=  0.494457847278
Iteration 87 Loss=  0.484084675318
Iteration 88 Loss=  0.473929126094
Iteration 89 Loss=  0.463986634832
Iteration 90 Loss=  0.454252732617
Iteration 91 Loss=  0.444723044403
Iteration 92 Loss=  0.435393287047
Iteration 93 Loss=  0.426259267403
Iteration 94 Loss=  0.417316880441
Iteration 95 Loss=  0.408562107417
Iteration 96 Loss=  0.399991014081
Iteration 97 Loss=  0.391599748916
Iteration 98 Loss=  0.383384541424
Iteration 99 Loss=  0.375341700439
Iteration 100 Loss=  0.367467612482
[-0.00872243 -0.00331092 -0.00477011 ...,  0.00374864 -0.00105407
  0.00104626]
CROSS VALIDATION 14
Iteration 1 Loss=  61.7746984389
Iteration 2 Loss=  2.59431980626
Iteration 3 Loss=  2.53989373853
Iteration 4 Loss=  2.48660947175
Iteration 5 Loss=  2.43444305217
Iteration 6 Loss=  2.38337102853
Iteration 7 Loss=  2.33337044159
Iteration 8 Loss=  2.28441881373
Iteration 9 Loss=  2.23649413891
Iteration 10 Loss=  2.18957487274
Iteration 11 Loss=  2.14363992284
Iteration 12 Loss=  2.09866863928
Iteration 13 Loss=  2.05464080538
Iteration 14 Loss=  2.01153662856
Iteration 15 Loss=  1.96933673149
Iteration 16 Loss=  1.92802214333
Iteration 17 Loss=  1.88757429125
Iteration 18 Loss=  1.84797499205
Iteration 19 Loss=  1.80920644399
Iteration 20 Loss=  1.7712512188
Iteration 21 Loss=  1.73409225382
Iteration 22 Loss=  1.69771284438
Iteration 23 Loss=  1.66209663621
Iteration 24 Loss=  1.62722761818
Iteration 25 Loss=  1.59309011502
Iteration 26 Loss=  1.55966878035
Iteration 27 Loss=  1.52694858969
Iteration 28 Loss=  1.4949148338
Iteration 29 Loss=  1.46355311201
Iteration 30 Loss=  1.43284932575
Iteration 31 Loss=  1.40278967224
Iteration 32 Loss=  1.37336063827
Iteration 33 Loss=  1.3445489941
Iteration 34 Loss=  1.31634178755
Iteration 35 Loss=  1.28872633817
Iteration 36 Loss=  1.26169023151
Iteration 37 Loss=  1.2352213136
Iteration 38 Loss=  1.2093076854
Iteration 39 Loss=  1.18393769753
Iteration 40 Loss=  1.15909994501
Iteration 41 Loss=  1.13478326209
Iteration 42 Loss=  1.11097671729
Iteration 43 Loss=  1.08766960846
Iteration 44 Loss=  1.06485145796
Iteration 45 Loss=  1.04251200796
Iteration 46 Loss=  1.02064121585
Iteration 47 Loss=  0.999229249671
Iteration 48 Loss=  0.978266483748
Iteration 49 Loss=  0.957743494338
Iteration 50 Loss=  0.937651055399
Iteration 51 Loss=  0.917980134438
Iteration 52 Loss=  0.898721888459
Iteration 53 Loss=  0.879867659979
Iteration 54 Loss=  0.861408973141
Iteration 55 Loss=  0.843337529903
Iteration 56 Loss=  0.825645206306
Iteration 57 Loss=  0.808324048823
Iteration 58 Loss=  0.791366270785
Iteration 59 Loss=  0.774764248878
Iteration 60 Loss=  0.758510519716
Iteration 61 Loss=  0.74259777649
Iteration 62 Loss=  0.727018865676
Iteration 63 Loss=  0.711766783827
Iteration 64 Loss=  0.696834674419
Iteration 65 Loss=  0.68221582477
Iteration 66 Loss=  0.667903663025
Iteration 67 Loss=  0.653891755197
Iteration 68 Loss=  0.640173802279
Iteration 69 Loss=  0.626743637411
Iteration 70 Loss=  0.613595223105
Iteration 71 Loss=  0.600722648535
Iteration 72 Loss=  0.588120126877
Iteration 73 Loss=  0.57578199271
Iteration 74 Loss=  0.563702699464
Iteration 75 Loss=  0.551876816935
Iteration 76 Loss=  0.540299028835
Iteration 77 Loss=  0.528964130408
Iteration 78 Loss=  0.517867026089
Iteration 79 Loss=  0.507002727212
Iteration 80 Loss=  0.496366349769
Iteration 81 Loss=  0.485953112211
Iteration 82 Loss=  0.475758333305
Iteration 83 Loss=  0.465777430024
Iteration 84 Loss=  0.456005915489
Iteration 85 Loss=  0.446439396952
Iteration 86 Loss=  0.437073573821
Iteration 87 Loss=  0.427904235727
Iteration 88 Loss=  0.418927260631
Iteration 89 Loss=  0.410138612974
Iteration 90 Loss=  0.40153434186
Iteration 91 Loss=  0.393110579279
Iteration 92 Loss=  0.384863538375
Iteration 93 Loss=  0.376789511736
Iteration 94 Loss=  0.368884869735
Iteration 95 Loss=  0.361146058894
Iteration 96 Loss=  0.353569600291
Iteration 97 Loss=  0.346152087995
Iteration 98 Loss=  0.338890187535
Iteration 99 Loss=  0.331780634406
Iteration 100 Loss=  0.3248202326
[-0.0019921   0.00290748 -0.00114857 ...,  0.00067367 -0.00022937
  0.00177268]
CROSS VALIDATION 15
Iteration 1 Loss=  61.7746984389
Iteration 2 Loss=  2.59431980626
Iteration 3 Loss=  2.53989373853
Iteration 4 Loss=  2.48660947175
Iteration 5 Loss=  2.43444305217
Iteration 6 Loss=  2.38337102853
Iteration 7 Loss=  2.33337044159
Iteration 8 Loss=  2.28441881373
Iteration 9 Loss=  2.23649413891
Iteration 10 Loss=  2.18957487274
Iteration 11 Loss=  2.14363992284
Iteration 12 Loss=  2.09866863928
Iteration 13 Loss=  2.05464080538
Iteration 14 Loss=  2.01153662856
Iteration 15 Loss=  1.96933673149
Iteration 16 Loss=  1.92802214333
Iteration 17 Loss=  1.88757429125
Iteration 18 Loss=  1.84797499205
Iteration 19 Loss=  1.80920644399
Iteration 20 Loss=  1.7712512188
Iteration 21 Loss=  1.73409225382
Iteration 22 Loss=  1.69771284438
Iteration 23 Loss=  1.66209663621
Iteration 24 Loss=  1.62722761818
Iteration 25 Loss=  1.59309011502
Iteration 26 Loss=  1.55966878035
Iteration 27 Loss=  1.52694858969
Iteration 28 Loss=  1.4949148338
Iteration 29 Loss=  1.46355311201
Iteration 30 Loss=  1.43284932575
Iteration 31 Loss=  1.40278967224
Iteration 32 Loss=  1.37336063827
Iteration 33 Loss=  1.3445489941
Iteration 34 Loss=  1.31634178755
Iteration 35 Loss=  1.28872633817
Iteration 36 Loss=  1.26169023151
Iteration 37 Loss=  1.2352213136
Iteration 38 Loss=  1.2093076854
Iteration 39 Loss=  1.18393769753
Iteration 40 Loss=  1.15909994501
Iteration 41 Loss=  1.13478326209
Iteration 42 Loss=  1.11097671729
Iteration 43 Loss=  1.08766960846
Iteration 44 Loss=  1.06485145796
Iteration 45 Loss=  1.04251200796
Iteration 46 Loss=  1.02064121585
Iteration 47 Loss=  0.999229249671
Iteration 48 Loss=  0.978266483748
Iteration 49 Loss=  0.957743494338
Iteration 50 Loss=  0.937651055399
Iteration 51 Loss=  0.917980134438
Iteration 52 Loss=  0.898721888459
Iteration 53 Loss=  0.879867659979
Iteration 54 Loss=  0.861408973141
Iteration 55 Loss=  0.843337529903
Iteration 56 Loss=  0.825645206306
Iteration 57 Loss=  0.808324048823
Iteration 58 Loss=  0.791366270785
Iteration 59 Loss=  0.774764248878
Iteration 60 Loss=  0.758510519717
Iteration 61 Loss=  0.74259777649
Iteration 62 Loss=  0.727018865677
Iteration 63 Loss=  0.711766783828
Iteration 64 Loss=  0.69683467442
Iteration 65 Loss=  0.682215824771
Iteration 66 Loss=  0.667903663026
Iteration 67 Loss=  0.653891755198
Iteration 68 Loss=  0.640173802281
Iteration 69 Loss=  0.626743637413
Iteration 70 Loss=  0.613595223108
Iteration 71 Loss=  0.60072264854
Iteration 72 Loss=  0.588120126884
Iteration 73 Loss=  0.575781992718
Iteration 74 Loss=  0.563702699475
Iteration 75 Loss=  0.551876816948
Iteration 76 Loss=  0.540299028853
Iteration 77 Loss=  0.528964130431
Iteration 78 Loss=  0.517867026119
Iteration 79 Loss=  0.507002727251
Iteration 80 Loss=  0.496366349818
Iteration 81 Loss=  0.485953112275
Iteration 82 Loss=  0.475758333387
Iteration 83 Loss=  0.465777430129
Iteration 84 Loss=  0.456005915622
Iteration 85 Loss=  0.446439397121
Iteration 86 Loss=  0.437073574035
Iteration 87 Loss=  0.427904235998
Iteration 88 Loss=  0.418927260973
Iteration 89 Loss=  0.410138613405
Iteration 90 Loss=  0.4015343424
Iteration 91 Loss=  0.393110579956
Iteration 92 Loss=  0.38486353922
Iteration 93 Loss=  0.37678951279
Iteration 94 Loss=  0.368884871046
Iteration 95 Loss=  0.361146060521
Iteration 96 Loss=  0.353569602305
Iteration 97 Loss=  0.346152090483
Iteration 98 Loss=  0.338890190602
Iteration 99 Loss=  0.331780638178
Iteration 100 Loss=  0.324820237228
[-0.0019921   0.00290748 -0.00114857 ...,  0.00067367 -0.00022937
  0.00177268]
CROSS VALIDATION 16
Iteration 1 Loss=  134.623771838
Iteration 2 Loss=  2.52360585715
Iteration 3 Loss=  2.46331618388
Iteration 4 Loss=  2.41163844278
Iteration 5 Loss=  2.36104484752
Iteration 6 Loss=  2.31151265419
Iteration 7 Loss=  2.26301959604
Iteration 8 Loss=  2.21554387356
Iteration 9 Loss=  2.16906414458
Iteration 10 Loss=  2.12355951477
Iteration 11 Loss=  2.07900952819
Iteration 12 Loss=  2.03539415816
Iteration 13 Loss=  1.9926937982
Iteration 14 Loss=  1.9508892533
Iteration 15 Loss=  1.90996173124
Iteration 16 Loss=  1.86989283418
Iteration 17 Loss=  1.83066455038
Iteration 18 Loss=  1.79225924616
Iteration 19 Loss=  1.75465965795
Iteration 20 Loss=  1.71784888453
Iteration 21 Loss=  1.68181037948
Iteration 22 Loss=  1.64652794373
Iteration 23 Loss=  1.61198571832
Iteration 24 Loss=  1.57816817725
Iteration 25 Loss=  1.54506012051
Iteration 26 Loss=  1.5126466673
Iteration 27 Loss=  1.48091324929
Iteration 28 Loss=  1.44984560412
Iteration 29 Loss=  1.41942976894
Iteration 30 Loss=  1.38965207417
Iteration 31 Loss=  1.36049913731
Iteration 32 Loss=  1.33195785687
Iteration 33 Loss=  1.30401540653
Iteration 34 Loss=  1.27665922922
Iteration 35 Loss=  1.24987703148
Iteration 36 Loss=  1.22365677781
Iteration 37 Loss=  1.19798668519
Iteration 38 Loss=  1.17285521766
Iteration 39 Loss=  1.14825108098
Iteration 40 Loss=  1.12416321744
Iteration 41 Loss=  1.10058080068
Iteration 42 Loss=  1.07749323072
Iteration 43 Loss=  1.05489012898
Iteration 44 Loss=  1.03276133343
Iteration 45 Loss=  1.01109689397
Iteration 46 Loss=  0.989887067738
Iteration 47 Loss=  0.969122314715
Iteration 48 Loss=  0.948793293388
Iteration 49 Loss=  0.928890856586
Iteration 50 Loss=  0.909406047462
Iteration 51 Loss=  0.890330095632
Iteration 52 Loss=  0.871654413464
Iteration 53 Loss=  0.853370592498
Iteration 54 Loss=  0.835470400006
Iteration 55 Loss=  0.817945775647
Iteration 56 Loss=  0.800788828218
Iteration 57 Loss=  0.783991832469
Iteration 58 Loss=  0.767547225964
Iteration 59 Loss=  0.751447605968
Iteration 60 Loss=  0.735685726352
Iteration 61 Loss=  0.7202544945
Iteration 62 Loss=  0.705146968223
Iteration 63 Loss=  0.690356352672
Iteration 64 Loss=  0.675875997263
Iteration 65 Loss=  0.661699392622
Iteration 66 Loss=  0.647820167547
Iteration 67 Loss=  0.634232086023
Iteration 68 Loss=  0.620929044269
Iteration 69 Loss=  0.607905067846
Iteration 70 Loss=  0.595154308829
Iteration 71 Loss=  0.582671043039
Iteration 72 Loss=  0.570449667341
Iteration 73 Loss=  0.558484697011
Iteration 74 Loss=  0.546770763169
Iteration 75 Loss=  0.535302610272
Iteration 76 Loss=  0.52407509366
Iteration 77 Loss=  0.513083177167
Iteration 78 Loss=  0.502321930762
Iteration 79 Loss=  0.491786528247
Iteration 80 Loss=  0.481472244981
Iteration 81 Loss=  0.471374455643
Iteration 82 Loss=  0.461488632013
Iteration 83 Loss=  0.451810340789
Iteration 84 Loss=  0.442335241414
Iteration 85 Loss=  0.433059083941
Iteration 86 Loss=  0.423977706912
Iteration 87 Loss=  0.415087035274
Iteration 88 Loss=  0.406383078335
Iteration 89 Loss=  0.397861927768
Iteration 90 Loss=  0.389519755667
Iteration 91 Loss=  0.381352812688
Iteration 92 Loss=  0.373357426258
Iteration 93 Loss=  0.365529998879
Iteration 94 Loss=  0.357867006531
Iteration 95 Loss=  0.350364997172
Iteration 96 Loss=  0.343020589322
Iteration 97 Loss=  0.335830470747
Iteration 98 Loss=  0.328791397196
Iteration 99 Loss=  0.321900191204
Iteration 100 Loss=  0.315153740923
[-0.00539114  0.00194729 -0.00301885 ...,  0.00361488 -0.00202585
  0.00122987]
CROSS VALIDATION 17
Iteration 1 Loss=  61.7755272035
Iteration 2 Loss=  2.59429768622
Iteration 3 Loss=  2.53987208254
Iteration 4 Loss=  2.48658827008
Iteration 5 Loss=  2.43442229529
Iteration 6 Loss=  2.38335070711
Iteration 7 Loss=  2.33335054649
Iteration 8 Loss=  2.28439933601
Iteration 9 Loss=  2.23647506981
Iteration 10 Loss=  2.1895562037
Iteration 11 Loss=  2.14362164545
Iteration 12 Loss=  2.09865074533
Iteration 13 Loss=  2.05462328683
Iteration 14 Loss=  2.01151947753
Iteration 15 Loss=  1.96931994027
Iteration 16 Loss=  1.92800570437
Iteration 17 Loss=  1.88755819716
Iteration 18 Loss=  1.8479592356
Iteration 19 Loss=  1.80919101809
Iteration 20 Loss=  1.77123611652
Iteration 21 Loss=  1.73407746837
Iteration 22 Loss=  1.69769836911
Iteration 23 Loss=  1.66208246462
Iteration 24 Loss=  1.62721374389
Iteration 25 Loss=  1.5930765318
Iteration 26 Loss=  1.55965548209
Iteration 27 Loss=  1.52693557041
Iteration 28 Loss=  1.49490208765
Iteration 29 Loss=  1.46354063326
Iteration 30 Loss=  1.4328371088
Iteration 31 Loss=  1.40277771159
Iteration 32 Loss=  1.37334892854
Iteration 33 Loss=  1.34453753002
Iteration 34 Loss=  1.31633056398
Iteration 35 Loss=  1.28871535005
Iteration 36 Loss=  1.26167947392
Iteration 37 Loss=  1.23521078168
Iteration 38 Loss=  1.20929737444
Iteration 39 Loss=  1.18392760288
Iteration 40 Loss=  1.15909006213
Iteration 41 Loss=  1.13477358655
Iteration 42 Loss=  1.11096724473
Iteration 43 Loss=  1.08766033462
Iteration 44 Loss=  1.06484237868
Iteration 45 Loss=  1.04250311916
Iteration 46 Loss=  1.02063251352
Iteration 47 Loss=  0.999220729907
Iteration 48 Loss=  0.97825814272
Iteration 49 Loss=  0.957735328296
Iteration 50 Loss=  0.937643060672
Iteration 51 Loss=  0.917972307432
Iteration 52 Loss=  0.898714225655
Iteration 53 Loss=  0.879860157933
Iteration 54 Loss=  0.86140162848
Iteration 55 Loss=  0.843330339324
Iteration 56 Loss=  0.825638166578
Iteration 57 Loss=  0.808317156781
Iteration 58 Loss=  0.791359523331
Iteration 59 Loss=  0.774757642978
Iteration 60 Loss=  0.758504052402
Iteration 61 Loss=  0.742591444853
Iteration 62 Loss=  0.72701266687
Iteration 63 Loss=  0.711760715066
Iteration 64 Loss=  0.696828732974
Iteration 65 Loss=  0.68221000797
Iteration 66 Loss=  0.667897968255
Iteration 67 Loss=  0.653886179898
Iteration 68 Loss=  0.640168343945
Iteration 69 Loss=  0.626738293587
Iteration 70 Loss=  0.61358999139
Iteration 71 Loss=  0.600717526577
Iteration 72 Loss=  0.588115112374
Iteration 73 Loss=  0.575777083408
Iteration 74 Loss=  0.563697893157
Iteration 75 Loss=  0.551872111462
Iteration 76 Loss=  0.540294422082
Iteration 77 Loss=  0.528959620306
Iteration 78 Loss=  0.517862610611
Iteration 79 Loss=  0.506998404376
Iteration 80 Loss=  0.496362117633
Iteration 81 Loss=  0.485948968876
Iteration 82 Loss=  0.475754276912
Iteration 83 Loss=  0.465773458755
Iteration 84 Loss=  0.456002027564
Iteration 85 Loss=  0.44643559063
Iteration 86 Loss=  0.4370698474
Iteration 87 Loss=  0.427900587543
Iteration 88 Loss=  0.41892368906
Iteration 89 Loss=  0.410135116427
Iteration 90 Loss=  0.401530918785
Iteration 91 Loss=  0.393107228165
Iteration 92 Loss=  0.384860257747
Iteration 93 Loss=  0.376786300159
Iteration 94 Loss=  0.368881725813
Iteration 95 Loss=  0.361142981273
Iteration 96 Loss=  0.353566587658
Iteration 97 Loss=  0.34614913908
Iteration 98 Loss=  0.338887301118
Iteration 99 Loss=  0.331777809314
Iteration 100 Loss=  0.324817467713
[-0.00199199  0.00290725 -0.0011487  ...,  0.00067367 -0.00022937
  0.00177263]
CROSS VALIDATION 18
Iteration 1 Loss=  129.72406955
Iteration 2 Loss=  117.626725907
Iteration 3 Loss=  2.84112844616
Iteration 4 Loss=  2.78152471769
Iteration 5 Loss=  2.72317142995
Iteration 6 Loss=  2.66604235234
Iteration 7 Loss=  2.61011180483
Iteration 8 Loss=  2.55535464636
Iteration 9 Loss=  2.50174626362
Iteration 10 Loss=  2.44926255992
Iteration 11 Loss=  2.3978799444
Iteration 12 Loss=  2.3475753214
Iteration 13 Loss=  2.2983260801
Iteration 14 Loss=  2.25011008428
Iteration 15 Loss=  2.20290566243
Iteration 16 Loss=  2.15669159788
Iteration 17 Loss=  2.11144711927
Iteration 18 Loss=  2.06715189116
Iteration 19 Loss=  2.02378600475
Iteration 20 Loss=  1.9813299689
Iteration 21 Loss=  1.9397647012
Iteration 22 Loss=  1.89907151935
Iteration 23 Loss=  1.85923213251
Iteration 24 Loss=  1.82022863303
Iteration 25 Loss=  1.78204348817
Iteration 26 Loss=  1.7446595321
Iteration 27 Loss=  1.70805995801
Iteration 28 Loss=  1.67222831043
Iteration 29 Loss=  1.63714847771
Iteration 30 Loss=  1.60280468474
Iteration 31 Loss=  1.56918148578
Iteration 32 Loss=  1.5362637576
Iteration 33 Loss=  1.50403669274
Iteration 34 Loss=  1.472485793
Iteration 35 Loss=  1.44159686316
Iteration 36 Loss=  1.41135600486
Iteration 37 Loss=  1.38174961062
Iteration 38 Loss=  1.3527643581
Iteration 39 Loss=  1.3243872044
Iteration 40 Loss=  1.29660538055
Iteration 41 Loss=  1.26940638604
Iteration 42 Loss=  1.24277798346
Iteration 43 Loss=  1.21670819315
Iteration 44 Loss=  1.19118528801
Iteration 45 Loss=  1.16619778823
Iteration 46 Loss=  1.14173445616
Iteration 47 Loss=  1.11778429119
Iteration 48 Loss=  1.09433652475
Iteration 49 Loss=  1.07138061532
Iteration 50 Loss=  1.04890624353
Iteration 51 Loss=  1.0269033074
Iteration 52 Loss=  1.00536191761
Iteration 53 Loss=  0.98427239291
Iteration 54 Loss=  0.963625255617
Iteration 55 Loss=  0.943411227233
Iteration 56 Loss=  0.923621224152
Iteration 57 Loss=  0.90424635348
Iteration 58 Loss=  0.885277908958
Iteration 59 Loss=  0.866707366979
Iteration 60 Loss=  0.848526382709
Iteration 61 Loss=  0.830726786297
Iteration 62 Loss=  0.813300579174
Iteration 63 Loss=  0.796239930442
Iteration 64 Loss=  0.779537173342
Iteration 65 Loss=  0.763184801804
Iteration 66 Loss=  0.747175467075
Iteration 67 Loss=  0.731501974417
Iteration 68 Loss=  0.716157279882
Iteration 69 Loss=  0.701134487155
Iteration 70 Loss=  0.686426844464
Iteration 71 Loss=  0.672027741553
Iteration 72 Loss=  0.657930706725
Iteration 73 Loss=  0.644129403942
Iteration 74 Loss=  0.630617629988
Iteration 75 Loss=  0.617389311693
Iteration 76 Loss=  0.604438503207
Iteration 77 Loss=  0.591759383345
Iteration 78 Loss=  0.579346252971
Iteration 79 Loss=  0.56719353245
Iteration 80 Loss=  0.555295759142
Iteration 81 Loss=  0.543647584959
Iteration 82 Loss=  0.532243773961
Iteration 83 Loss=  0.521079200014
Iteration 84 Loss=  0.510148844485
Iteration 85 Loss=  0.499447793995
Iteration 86 Loss=  0.488971238212
Iteration 87 Loss=  0.478714467693
Iteration 88 Loss=  0.468672871772
Iteration 89 Loss=  0.458841936486
Iteration 90 Loss=  0.449217242555
Iteration 91 Loss=  0.439794463392
Iteration 92 Loss=  0.430569363163
Iteration 93 Loss=  0.421537794885
Iteration 94 Loss=  0.412695698563
Iteration 95 Loss=  0.404039099366
Iteration 96 Loss=  0.395564105843
Iteration 97 Loss=  0.387266908176
Iteration 98 Loss=  0.379143776463
Iteration 99 Loss=  0.371191059049
Iteration 100 Loss=  0.363405180885
[-0.00343158 -0.00136791 -0.00269135 ...,  0.00447703  0.00175876
  0.00135852]
CROSS VALIDATION 19
Iteration 1 Loss=  115.663745727
Iteration 2 Loss=  2.56791344916
Iteration 3 Loss=  2.46123470703
Iteration 4 Loss=  2.40960062534
Iteration 5 Loss=  2.3590497722
Iteration 6 Loss=  2.3095594227
Iteration 7 Loss=  2.26110732872
Iteration 8 Loss=  2.21367170888
Iteration 9 Loss=  2.16723123877
Iteration 10 Loss=  2.12176504138
Iteration 11 Loss=  2.0772526777
Iteration 12 Loss=  2.03367413753
Iteration 13 Loss=  1.99100983051
Iteration 14 Loss=  1.9492405773
Iteration 15 Loss=  1.90834760096
Iteration 16 Loss=  1.86831251854
Iteration 17 Loss=  1.82911733279
Iteration 18 Loss=  1.79074442408
Iteration 19 Loss=  1.75317654252
Iteration 20 Loss=  1.71639680017
Iteration 21 Loss=  1.68038866349
Iteration 22 Loss=  1.64513594588
Iteration 23 Loss=  1.61062280045
Iteration 24 Loss=  1.57683371289
Iteration 25 Loss=  1.54375349451
Iteration 26 Loss=  1.51136727542
Iteration 27 Loss=  1.47966049785
Iteration 28 Loss=  1.44861890964
Iteration 29 Loss=  1.41822855784
Iteration 30 Loss=  1.38847578243
Iteration 31 Loss=  1.35934721021
Iteration 32 Loss=  1.3308297488
Iteration 33 Loss=  1.30291058077
Iteration 34 Loss=  1.27557715787
Iteration 35 Loss=  1.2488171954
Iteration 36 Loss=  1.2226186667
Iteration 37 Loss=  1.19696979773
Iteration 38 Loss=  1.17185906177
Iteration 39 Loss=  1.14727517422
Iteration 40 Loss=  1.12320708752
Iteration 41 Loss=  1.0996439861
Iteration 42 Loss=  1.07657528152
Iteration 43 Loss=  1.05399060763
Iteration 44 Loss=  1.0318798158
Iteration 45 Loss=  1.01023297031
Iteration 46 Loss=  0.989040343727
Iteration 47 Loss=  0.96829241244
Iteration 48 Loss=  0.947979852196
Iteration 49 Loss=  0.928093533776
Iteration 50 Loss=  0.908624518716
Iteration 51 Loss=  0.889564055122
Iteration 52 Loss=  0.870903573574
Iteration 53 Loss=  0.852634683129
Iteration 54 Loss=  0.834749167428
Iteration 55 Loss=  0.817238980921
Iteration 56 Loss=  0.800096245213
Iteration 57 Loss=  0.783313245544
Iteration 58 Loss=  0.766882427403
Iteration 59 Loss=  0.750796393283
Iteration 60 Loss=  0.735047899566
Iteration 61 Loss=  0.719629853534
Iteration 62 Loss=  0.704535310493
Iteration 63 Loss=  0.689757470995
Iteration 64 Loss=  0.675289678129
Iteration 65 Loss=  0.661125414877
Iteration 66 Loss=  0.647258301492
Iteration 67 Loss=  0.633682092907
Iteration 68 Loss=  0.620390676138
Iteration 69 Loss=  0.607378067686
Iteration 70 Loss=  0.594638410933
Iteration 71 Loss=  0.582165973528
Iteration 72 Loss=  0.569955144772
Iteration 73 Loss=  0.55800043301
Iteration 74 Loss=  0.54629646304
Iteration 75 Loss=  0.534837973548
Iteration 76 Loss=  0.523619814578
Iteration 77 Loss=  0.51263694505
Iteration 78 Loss=  0.501884430329
Iteration 79 Loss=  0.491357439847
Iteration 80 Loss=  0.481051244797
Iteration 81 Loss=  0.470961215877
Iteration 82 Loss=  0.461082821104
Iteration 83 Loss=  0.451411623686
Iteration 84 Loss=  0.441943279958
Iteration 85 Loss=  0.432673537372
Iteration 86 Loss=  0.423598232547
Iteration 87 Loss=  0.414713289365
Iteration 88 Loss=  0.406014717125
Iteration 89 Loss=  0.397498608734
Iteration 90 Loss=  0.38916113896
Iteration 91 Loss=  0.380998562704
Iteration 92 Loss=  0.373007213338
Iteration 93 Loss=  0.365183501061
Iteration 94 Loss=  0.357523911309
Iteration 95 Loss=  0.350025003186
Iteration 96 Loss=  0.342683407945
Iteration 97 Loss=  0.335495827488
Iteration 98 Loss=  0.32845903291
Iteration 99 Loss=  0.32156986307
Iteration 100 Loss=  0.314825223189
[-0.00389047  0.00016309 -0.00236424 ...,  0.00057896  0.000639    0.00175967]
Accuracy (Logistic Loss):	0.85 for lmda= 0.1 learning rate= 0.001
---------------------------------------------------------------------------------
lmda= 0.1 learning rate= 0.01
CROSS VALIDATION 0
Iteration 1 Loss=  1708.86859499
Iteration 2 Loss=  184.599981888
Iteration 3 Loss=  149.30317062
Iteration 4 Loss=  120.755357253
Iteration 5 Loss=  97.6660861556
Iteration 6 Loss=  78.9916461971
Iteration 7 Loss=  63.8878922306
Iteration 8 Loss=  51.6720884899
Iteration 9 Loss=  41.7920483289
Iteration 10 Loss=  33.8011676798
Iteration 11 Loss=  27.3382127785
Iteration 12 Loss=  22.1110017028
Iteration 13 Loss=  17.8832562733
Iteration 14 Loss=  14.4638837905
Iteration 15 Loss=  11.6983192522
Iteration 16 Loss=  9.46155004899
Iteration 17 Loss=  7.65246680548
Iteration 18 Loss=  6.18929296656
Iteration 19 Loss=  5.00588822795
Iteration 20 Loss=  4.04875877544
Iteration 21 Loss=  3.27463918731
Iteration 22 Loss=  2.64853669395
Iteration 23 Loss=  2.1421493891
Iteration 24 Loss=  1.73258689244
Iteration 25 Loss=  1.40133564259
Iteration 26 Loss=  1.13342208691
Iteration 27 Loss=  0.916736061229
Iteration 28 Loss=  0.74148403166
Iteration 29 Loss=  0.599747504492
Iteration 30 Loss=  0.485123744704
Iteration 31 Loss=  0.392425978476
Iteration 32 Loss=  0.317449345502
Iteration 33 Loss=  0.256802146286
Iteration 34 Loss=  0.207748632647
Iteration 35 Loss=  0.168077735461
Iteration 36 Loss=  0.13600271381
Iteration 37 Loss=  0.110080628527
Iteration 38 Loss=  0.0891284169354
Iteration 39 Loss=  0.0721764905499
Iteration 40 Loss=  0.0584686451428
Iteration 41 Loss=  0.0474046453565
Iteration 42 Loss=  0.0384930843613
Iteration 43 Loss=  0.031321629886
Iteration 44 Loss=  0.0255314769072
Iteration 45 Loss=  0.0208521224396
Iteration 46 Loss=  0.0170868407604
Iteration 47 Loss=  0.0140418639726
Iteration 48 Loss=  0.011592345622
Iteration 49 Loss=  0.00961718664622
Iteration 50 Loss=  0.00804611661006
Iteration 51 Loss=  0.00679953150816
Iteration 52 Loss=  0.00578564934709
Iteration 53 Loss=  0.00495233349225
Iteration 54 Loss=  0.00427926189351
Iteration 55 Loss=  0.00375404175677
Iteration 56 Loss=  0.003378450339
Iteration 57 Loss=  0.00313315157023
Iteration 58 Loss=  0.00295125250139
Iteration 59 Loss=  0.00278136933272
Iteration 60 Loss=  0.00258502592308
Iteration 61 Loss=  0.00243387531934
Iteration 62 Loss=  0.00232475114175
Iteration 63 Loss=  0.00224491807206
[ -4.06654045e-04  -1.73971185e-04   3.58173324e-05 ...,   2.16481634e-04
   1.35100281e-04   3.35596855e-05]
CROSS VALIDATION 1
Iteration 1 Loss=  1093.88718713
Iteration 2 Loss=  201.717594879
Iteration 3 Loss=  163.147775945
Iteration 4 Loss=  131.952776909
Iteration 5 Loss=  106.722480482
Iteration 6 Loss=  86.3163936911
Iteration 7 Loss=  69.8120938172
Iteration 8 Loss=  56.4635318359
Iteration 9 Loss=  45.667308529
Iteration 10 Loss=  36.9353988428
Iteration 11 Loss=  29.873091549
Iteration 12 Loss=  24.1611470375
Iteration 13 Loss=  19.5413668087
Iteration 14 Loss=  15.8049225715
Iteration 15 Loss=  12.7829173673
Iteration 16 Loss=  10.3387491746
Iteration 17 Loss=  8.3619260293
Iteration 18 Loss=  6.76307806374
Iteration 19 Loss=  5.46993858401
Iteration 20 Loss=  4.42405652927
Iteration 21 Loss=  3.57815445306
Iteration 22 Loss=  2.89399478715
Iteration 23 Loss=  2.34065124785
Iteration 24 Loss=  1.89311087428
Iteration 25 Loss=  1.5311433592
Iteration 26 Loss=  1.23838657309
Iteration 27 Loss=  1.00160694781
Iteration 28 Loss=  0.810101308034
Iteration 29 Loss=  0.655213191274
Iteration 30 Loss=  0.529942026656
Iteration 31 Loss=  0.428627942448
Iteration 32 Loss=  0.346697448923
Iteration 33 Loss=  0.280450987655
Iteration 34 Loss=  0.226876495415
Iteration 35 Loss=  0.183536100428
Iteration 36 Loss=  0.148483482172
Iteration 37 Loss=  0.120134730994
Iteration 38 Loss=  0.0972024040203
Iteration 39 Loss=  0.0786558709257
Iteration 40 Loss=  0.0636631131875
Iteration 41 Loss=  0.0515489734828
Iteration 42 Loss=  0.0417582741712
Iteration 43 Loss=  0.0338482269141
Iteration 44 Loss=  0.0274723417346
Iteration 45 Loss=  0.0223348548161
Iteration 46 Loss=  0.0182014308305
Iteration 47 Loss=  0.0148945545558
Iteration 48 Loss=  0.0122579062737
Iteration 49 Loss=  0.0101214973786
Iteration 50 Loss=  0.00838741127128
Iteration 51 Loss=  0.00699020859513
Iteration 52 Loss=  0.00587522485294
Iteration 53 Loss=  0.00500619294859
Iteration 54 Loss=  0.00433566854894
Iteration 55 Loss=  0.00381957116865
Iteration 56 Loss=  0.00341313502512
Iteration 57 Loss=  0.0030765909315
Iteration 58 Loss=  0.00280299983231
Iteration 59 Loss=  0.00261147985213
Iteration 60 Loss=  0.00251884550855
[ -3.42307827e-04  -1.09596419e-04  -1.10026327e-04 ...,   1.96668066e-04
   5.27003614e-05   7.52234901e-05]
CROSS VALIDATION 2
Iteration 1 Loss=  5012.25047459
Iteration 2 Loss=  1552.58458939
Iteration 3 Loss=  204.669140392
Iteration 4 Loss=  165.534965255
Iteration 5 Loss=  133.88351888
Iteration 6 Loss=  108.284051046
Iteration 7 Loss=  87.5793810109
Iteration 8 Loss=  70.8335891031
Iteration 9 Loss=  57.2897100586
Iteration 10 Loss=  46.3355156807
Iteration 11 Loss=  37.4758400975
Iteration 12 Loss=  30.3101966253
Iteration 13 Loss=  24.5146744429
Iteration 14 Loss=  19.82729675
Iteration 15 Loss=  16.036178548
Iteration 16 Loss=  12.9699487362
Iteration 17 Loss=  10.49000357
Iteration 18 Loss=  8.48424131335
Iteration 19 Loss=  6.86199486802
Iteration 20 Loss=  5.54993332105
Iteration 21 Loss=  4.48874714431
Iteration 22 Loss=  3.63046720744
Iteration 23 Loss=  2.93629641425
Iteration 24 Loss=  2.37485594544
Iteration 25 Loss=  1.9207668321
Iteration 26 Loss=  1.55350274239
Iteration 27 Loss=  1.25646212515
Iteration 28 Loss=  1.01621777503
Iteration 29 Loss=  0.821909927227
Iteration 30 Loss=  0.66475554505
Iteration 31 Loss=  0.537651825902
Iteration 32 Loss=  0.43485587725
Iteration 33 Loss=  0.351722869387
Iteration 34 Loss=  0.284487742708
Iteration 35 Loss=  0.230107431223
Iteration 36 Loss=  0.186133025475
Iteration 37 Loss=  0.150569265836
Iteration 38 Loss=  0.121797162275
Iteration 39 Loss=  0.0985247834916
Iteration 40 Loss=  0.0797031909088
Iteration 41 Loss=  0.064483449615
Iteration 42 Loss=  0.0521838236266
Iteration 43 Loss=  0.0422623034478
Iteration 44 Loss=  0.0342846912126
Iteration 45 Loss=  0.0278686460619
Iteration 46 Loss=  0.0226848435842
Iteration 47 Loss=  0.0185042006253
Iteration 48 Loss=  0.0151198827329
Iteration 49 Loss=  0.0123679486205
Iteration 50 Loss=  0.0101442809342
Iteration 51 Loss=  0.0083734000756
Iteration 52 Loss=  0.00698757724688
Iteration 53 Loss=  0.0059102560207
Iteration 54 Loss=  0.00506186114396
Iteration 55 Loss=  0.00439802919652
Iteration 56 Loss=  0.00387601637497
Iteration 57 Loss=  0.00345170409537
Iteration 58 Loss=  0.00310846168228
Iteration 59 Loss=  0.00285075078067
Iteration 60 Loss=  0.00266583406622
Iteration 61 Loss=  0.00247121089883
Iteration 62 Loss=  0.00229508448013
Iteration 63 Loss=  0.00216494399922
Iteration 64 Loss=  0.00207033567859
[ -4.29607696e-04  -2.40065967e-04  -6.62205125e-06 ...,   3.62121659e-04
   1.40693864e-04   3.36938309e-05]
CROSS VALIDATION 3
Iteration 1 Loss=  1435.43600428
Iteration 2 Loss=  828.37214988
Iteration 3 Loss=  186.420820636
Iteration 4 Loss=  150.775852224
Iteration 5 Loss=  121.946451777
Iteration 6 Loss=  98.6294348975
Iteration 7 Loss=  79.7707951844
Iteration 8 Loss=  64.518059654
Iteration 9 Loss=  52.1817541357
Iteration 10 Loss=  42.204236756
Iteration 11 Loss=  34.134490679
Iteration 12 Loss=  27.6077366509
Iteration 13 Loss=  22.3289437699
Iteration 14 Loss=  18.0594931119
Iteration 15 Loss=  14.6063913644
Iteration 16 Loss=  11.8135468902
Iteration 17 Loss=  9.5547138677
Iteration 18 Loss=  7.72778556197
Iteration 19 Loss=  6.25017876189
Iteration 20 Loss=  5.05510074553
Iteration 21 Loss=  4.08853002785
Iteration 22 Loss=  3.30677441066
Iteration 23 Loss=  2.67449595051
Iteration 24 Loss=  2.16311356657
Iteration 25 Loss=  1.74951108114
Iteration 26 Loss=  1.41499229182
Iteration 27 Loss=  1.14443584127
Iteration 28 Loss=  0.925611681917
Iteration 29 Loss=  0.748628238743
Iteration 30 Loss=  0.605485286
Iteration 31 Loss=  0.489712352926
Iteration 32 Loss=  0.396076403449
Iteration 33 Loss=  0.32034580407
Iteration 34 Loss=  0.259100144533
Iteration 35 Loss=  0.209575622348
Iteration 36 Loss=  0.169531148166
Iteration 37 Loss=  0.137141491819
Iteration 38 Loss=  0.110943473274
Iteration 39 Loss=  0.0897542688801
Iteration 40 Loss=  0.0726216337967
Iteration 41 Loss=  0.0587790209954
Iteration 42 Loss=  0.0475913517693
Iteration 43 Loss=  0.0385421102981
Iteration 44 Loss=  0.0312350543006
Iteration 45 Loss=  0.0253476902153
Iteration 46 Loss=  0.0206082845626
Iteration 47 Loss=  0.0167790652734
Iteration 48 Loss=  0.0136937106742
Iteration 49 Loss=  0.0112281058915
Iteration 50 Loss=  0.00925773805214
Iteration 51 Loss=  0.00768843944994
Iteration 52 Loss=  0.00645321672729
Iteration 53 Loss=  0.00548635464455
Iteration 54 Loss=  0.0047329287434
Iteration 55 Loss=  0.00412366907388
Iteration 56 Loss=  0.00363131454755
Iteration 57 Loss=  0.00323079561378
Iteration 58 Loss=  0.00289745318624
Iteration 59 Loss=  0.00263176881402
Iteration 60 Loss=  0.0024491058611
Iteration 61 Loss=  0.00237389647256
[ -4.84498022e-04  -6.26025730e-05  -1.22303846e-04 ...,   3.40382051e-04
   6.58049239e-05   5.39026195e-05]
CROSS VALIDATION 4
Iteration 1 Loss=  1435.43600428
Iteration 2 Loss=  828.37214988
Iteration 3 Loss=  186.420820636
Iteration 4 Loss=  150.775852224
Iteration 5 Loss=  121.946451777
Iteration 6 Loss=  98.6294348975
Iteration 7 Loss=  79.7707951844
Iteration 8 Loss=  64.518059654
Iteration 9 Loss=  52.1817541357
Iteration 10 Loss=  42.204236756
Iteration 11 Loss=  34.134490679
Iteration 12 Loss=  27.6077366509
Iteration 13 Loss=  22.3289437699
Iteration 14 Loss=  18.0594931119
Iteration 15 Loss=  14.6063913644
Iteration 16 Loss=  11.8135468902
Iteration 17 Loss=  9.5547138677
Iteration 18 Loss=  7.72778556197
Iteration 19 Loss=  6.25017876189
Iteration 20 Loss=  5.05510074553
Iteration 21 Loss=  4.08853002785
Iteration 22 Loss=  3.30677441066
Iteration 23 Loss=  2.67449595051
Iteration 24 Loss=  2.16311356657
Iteration 25 Loss=  1.74951108114
Iteration 26 Loss=  1.41499229182
Iteration 27 Loss=  1.14443584127
Iteration 28 Loss=  0.925611681917
Iteration 29 Loss=  0.748628238743
Iteration 30 Loss=  0.605485286
Iteration 31 Loss=  0.489712352926
Iteration 32 Loss=  0.396076403449
Iteration 33 Loss=  0.32034580407
Iteration 34 Loss=  0.259100144533
Iteration 35 Loss=  0.209575622348
Iteration 36 Loss=  0.169531148166
Iteration 37 Loss=  0.137141491819
Iteration 38 Loss=  0.110943473274
Iteration 39 Loss=  0.0897542688801
Iteration 40 Loss=  0.0726216337968
Iteration 41 Loss=  0.0587790209981
Iteration 42 Loss=  0.0475913518089
Iteration 43 Loss=  0.0385421107409
Iteration 44 Loss=  0.0312350581797
Iteration 45 Loss=  0.0253477175611
Iteration 46 Loss=  0.0206084424492
Iteration 47 Loss=  0.0167798115436
Iteration 48 Loss=  0.0136965785708
Iteration 49 Loss=  0.0112369742115
Iteration 50 Loss=  0.00927807262821
Iteration 51 Loss=  0.00771784616695
Iteration 52 Loss=  0.00647766974138
Iteration 53 Loss=  0.0054982244471
Iteration 54 Loss=  0.004733323155
Iteration 55 Loss=  0.00411705858258
Iteration 56 Loss=  0.00362198467889
Iteration 57 Loss=  0.00322104904741
Iteration 58 Loss=  0.00288857494127
Iteration 59 Loss=  0.00262376350279
Iteration 60 Loss=  0.0024426517639
Iteration 61 Loss=  0.00237056000873
[ -4.73761617e-04  -6.06376127e-05  -1.19901699e-04 ...,   3.38083649e-04
   7.27584950e-05   5.44915752e-05]
CROSS VALIDATION 5
Iteration 1 Loss=  1435.43600428
Iteration 2 Loss=  828.37214988
Iteration 3 Loss=  186.420820636
Iteration 4 Loss=  150.775852224
Iteration 5 Loss=  121.946451777
Iteration 6 Loss=  98.6294348975
Iteration 7 Loss=  79.7707951844
Iteration 8 Loss=  64.518059654
Iteration 9 Loss=  52.1817541357
Iteration 10 Loss=  42.204236756
Iteration 11 Loss=  34.134490679
Iteration 12 Loss=  27.6077366509
Iteration 13 Loss=  22.3289437699
Iteration 14 Loss=  18.0594931119
Iteration 15 Loss=  14.6063913644
Iteration 16 Loss=  11.8135468902
Iteration 17 Loss=  9.5547138677
Iteration 18 Loss=  7.72778556197
Iteration 19 Loss=  6.25017876189
Iteration 20 Loss=  5.05510074553
Iteration 21 Loss=  4.08853002785
Iteration 22 Loss=  3.30677441066
Iteration 23 Loss=  2.67449595051
Iteration 24 Loss=  2.16311356657
Iteration 25 Loss=  1.74951108114
Iteration 26 Loss=  1.41499229182
Iteration 27 Loss=  1.14443584127
Iteration 28 Loss=  0.925611681917
Iteration 29 Loss=  0.748628238743
Iteration 30 Loss=  0.605485285999
Iteration 31 Loss=  0.489712352925
Iteration 32 Loss=  0.396076403441
Iteration 33 Loss=  0.320345803957
Iteration 34 Loss=  0.259100143396
Iteration 35 Loss=  0.209575613309
Iteration 36 Loss=  0.16953108997
Iteration 37 Loss=  0.137141182624
Iteration 38 Loss=  0.110942097609
Iteration 39 Loss=  0.0897491175555
Iteration 40 Loss=  0.0726057504318
Iteration 41 Loss=  0.05874195187
Iteration 42 Loss=  0.0475337076482
Iteration 43 Loss=  0.0384786820819
Iteration 44 Loss=  0.0311696972013
Iteration 45 Loss=  0.0252782492908
Iteration 46 Loss=  0.0205360753236
Iteration 47 Loss=  0.0167074443
Iteration 48 Loss=  0.0136232477057
Iteration 49 Loss=  0.0111612946116
Iteration 50 Loss=  0.00920352847701
Iteration 51 Loss=  0.00765271131167
Iteration 52 Loss=  0.00642675624248
Iteration 53 Loss=  0.00546268857612
Iteration 54 Loss=  0.00470534105168
Iteration 55 Loss=  0.00409264733607
Iteration 56 Loss=  0.00359842729699
Iteration 57 Loss=  0.00319772291854
Iteration 58 Loss=  0.00286523452543
Iteration 59 Loss=  0.00260055458766
Iteration 60 Loss=  0.00242034663755
Iteration 61 Loss=  0.00234870294992
[ -4.52712584e-04  -5.91324819e-05  -1.09583081e-04 ...,   3.08711010e-04
   3.62558120e-05   5.91987288e-05]
CROSS VALIDATION 6
Iteration 1 Loss=  1435.43600428
Iteration 2 Loss=  828.37214988
Iteration 3 Loss=  186.420820636
Iteration 4 Loss=  150.775852224
Iteration 5 Loss=  121.946451777
Iteration 6 Loss=  98.6294348975
Iteration 7 Loss=  79.7707951844
Iteration 8 Loss=  64.518059654
Iteration 9 Loss=  52.1817541357
Iteration 10 Loss=  42.204236756
Iteration 11 Loss=  34.134490679
Iteration 12 Loss=  27.6077366509
Iteration 13 Loss=  22.3289437699
Iteration 14 Loss=  18.0594931119
Iteration 15 Loss=  14.6063913644
Iteration 16 Loss=  11.8135468902
Iteration 17 Loss=  9.5547138677
Iteration 18 Loss=  7.72778556197
Iteration 19 Loss=  6.25017876189
Iteration 20 Loss=  5.05510074553
Iteration 21 Loss=  4.08853002785
Iteration 22 Loss=  3.30677441066
Iteration 23 Loss=  2.67449595051
Iteration 24 Loss=  2.16311356657
Iteration 25 Loss=  1.74951108114
Iteration 26 Loss=  1.41499229182
Iteration 27 Loss=  1.14443584127
Iteration 28 Loss=  0.925611681917
Iteration 29 Loss=  0.748628238743
Iteration 30 Loss=  0.605485286
Iteration 31 Loss=  0.489712352926
Iteration 32 Loss=  0.396076403449
Iteration 33 Loss=  0.32034580407
Iteration 34 Loss=  0.259100144534
Iteration 35 Loss=  0.20957562235
Iteration 36 Loss=  0.169531148178
Iteration 37 Loss=  0.137141491875
Iteration 38 Loss=  0.110943473307
Iteration 39 Loss=  0.0897542659524
Iteration 40 Loss=  0.0726215936304
Iteration 41 Loss=  0.0587787461248
Iteration 42 Loss=  0.0475905057345
Iteration 43 Loss=  0.0385409602409
Iteration 44 Loss=  0.0312339095012
Iteration 45 Loss=  0.0253465706174
Iteration 46 Loss=  0.0206072585553
Iteration 47 Loss=  0.0167785950138
Iteration 48 Loss=  0.0136954691296
Iteration 49 Loss=  0.0112363982337
Iteration 50 Loss=  0.00927920008375
Iteration 51 Loss=  0.00772312291638
Iteration 52 Loss=  0.0064901059158
Iteration 53 Loss=  0.00551778132703
Iteration 54 Loss=  0.00475419365667
Iteration 55 Loss=  0.0041333272712
Iteration 56 Loss=  0.00363413548428
Iteration 57 Loss=  0.00323078992177
Iteration 58 Loss=  0.00289591699089
Iteration 59 Loss=  0.00263032702633
Iteration 60 Loss=  0.00244851436006
Iteration 61 Loss=  0.00237241451909
[ -4.86917486e-04  -6.82344219e-05  -1.18397063e-04 ...,   3.30450405e-04
   6.57280192e-05   5.17451021e-05]
CROSS VALIDATION 7
Iteration 1 Loss=  1435.43600428
Iteration 2 Loss=  828.37214988
Iteration 3 Loss=  186.420820636
Iteration 4 Loss=  150.775852224
Iteration 5 Loss=  121.946451777
Iteration 6 Loss=  98.6294348975
Iteration 7 Loss=  79.7707951844
Iteration 8 Loss=  64.518059654
Iteration 9 Loss=  52.1817541357
Iteration 10 Loss=  42.204236756
Iteration 11 Loss=  34.134490679
Iteration 12 Loss=  27.6077366509
Iteration 13 Loss=  22.3289437699
Iteration 14 Loss=  18.0594931119
Iteration 15 Loss=  14.6063913644
Iteration 16 Loss=  11.8135468902
Iteration 17 Loss=  9.5547138677
Iteration 18 Loss=  7.72778556197
Iteration 19 Loss=  6.25017876189
Iteration 20 Loss=  5.05510074553
Iteration 21 Loss=  4.08853002785
Iteration 22 Loss=  3.30677441066
Iteration 23 Loss=  2.67449595051
Iteration 24 Loss=  2.16311356657
Iteration 25 Loss=  1.74951108114
Iteration 26 Loss=  1.41499229182
Iteration 27 Loss=  1.14443584127
Iteration 28 Loss=  0.925611681917
Iteration 29 Loss=  0.748628238743
Iteration 30 Loss=  0.605485286
Iteration 31 Loss=  0.489712352926
Iteration 32 Loss=  0.396076403449
Iteration 33 Loss=  0.32034580407
Iteration 34 Loss=  0.259100144534
Iteration 35 Loss=  0.20957562235
Iteration 36 Loss=  0.169531148178
Iteration 37 Loss=  0.137141491875
Iteration 38 Loss=  0.110943473306
Iteration 39 Loss=  0.0897542659519
Iteration 40 Loss=  0.0726215936218
Iteration 41 Loss=  0.0587787460078
Iteration 42 Loss=  0.0475905045113
Iteration 43 Loss=  0.0385409500761
Iteration 44 Loss=  0.0312338406706
Iteration 45 Loss=  0.025346182624
Iteration 46 Loss=  0.0206054165426
Iteration 47 Loss=  0.0167712833823
Iteration 48 Loss=  0.0136725302381
Iteration 49 Loss=  0.0111878469694
Iteration 50 Loss=  0.00922140920462
Iteration 51 Loss=  0.00767358826652
Iteration 52 Loss=  0.00644675918772
Iteration 53 Loss=  0.00548070111997
Iteration 54 Loss=  0.00472465328236
Iteration 55 Loss=  0.00411254821815
Iteration 56 Loss=  0.00361963208997
Iteration 57 Loss=  0.00321970418134
Iteration 58 Loss=  0.00288715293569
Iteration 59 Loss=  0.00262130386717
Iteration 60 Loss=  0.00243748388557
Iteration 61 Loss=  0.00236120992685
[ -4.95308096e-04  -6.73907692e-05  -1.24963998e-04 ...,   3.27186357e-04
   6.32693148e-05   5.50592200e-05]
CROSS VALIDATION 8
Iteration 1 Loss=  1435.43600428
Iteration 2 Loss=  828.37214988
Iteration 3 Loss=  186.420820636
Iteration 4 Loss=  150.775852224
Iteration 5 Loss=  121.946451777
Iteration 6 Loss=  98.6294348975
Iteration 7 Loss=  79.7707951844
Iteration 8 Loss=  64.518059654
Iteration 9 Loss=  52.1817541357
Iteration 10 Loss=  42.204236756
Iteration 11 Loss=  34.134490679
Iteration 12 Loss=  27.6077366509
Iteration 13 Loss=  22.3289437699
Iteration 14 Loss=  18.0594931119
Iteration 15 Loss=  14.6063913644
Iteration 16 Loss=  11.8135468902
Iteration 17 Loss=  9.5547138677
Iteration 18 Loss=  7.72778556197
Iteration 19 Loss=  6.25017876189
Iteration 20 Loss=  5.05510074553
Iteration 21 Loss=  4.08853002785
Iteration 22 Loss=  3.30677441066
Iteration 23 Loss=  2.67449595051
Iteration 24 Loss=  2.16311356657
Iteration 25 Loss=  1.74951108114
Iteration 26 Loss=  1.41499229182
Iteration 27 Loss=  1.14443584127
Iteration 28 Loss=  0.925611681917
Iteration 29 Loss=  0.748628238743
Iteration 30 Loss=  0.605485286
Iteration 31 Loss=  0.489712352926
Iteration 32 Loss=  0.396076403449
Iteration 33 Loss=  0.32034580407
Iteration 34 Loss=  0.259100144534
Iteration 35 Loss=  0.20957562235
Iteration 36 Loss=  0.169531148178
Iteration 37 Loss=  0.137141491874
Iteration 38 Loss=  0.110943473297
Iteration 39 Loss=  0.0897542658359
Iteration 40 Loss=  0.0726215925529
Iteration 41 Loss=  0.0587787381705
Iteration 42 Loss=  0.0475904578797
Iteration 43 Loss=  0.0385407219332
Iteration 44 Loss=  0.0312329181228
Iteration 45 Loss=  0.0253431269055
Iteration 46 Loss=  0.0205974134076
Iteration 47 Loss=  0.0167563148922
Iteration 48 Loss=  0.013657871956
Iteration 49 Loss=  0.0111886330726
Iteration 50 Loss=  0.00922757423085
Iteration 51 Loss=  0.00767195354563
Iteration 52 Loss=  0.006443084486
Iteration 53 Loss=  0.00547936857372
Iteration 54 Loss=  0.00472796316083
Iteration 55 Loss=  0.00411795159917
Iteration 56 Loss=  0.00362363391427
Iteration 57 Loss=  0.00322164780738
Iteration 58 Loss=  0.00288742217627
Iteration 59 Loss=  0.0026211522255
Iteration 60 Loss=  0.00243613926422
Iteration 61 Loss=  0.00235589653809
[ -4.70782838e-04  -5.93143376e-05  -9.54618351e-05 ...,   3.34022226e-04
   5.68064715e-05   5.05125637e-05]
CROSS VALIDATION 9
Iteration 1 Loss=  1859.95844877
Iteration 2 Loss=  1006.69971367
Iteration 3 Loss=  198.2384944
Iteration 4 Loss=  160.333903878
Iteration 5 Loss=  129.676936918
Iteration 6 Loss=  104.881797059
Iteration 7 Loss=  84.8276618486
Iteration 8 Loss=  68.6080179445
Iteration 9 Loss=  55.4896837151
Iteration 10 Loss=  44.8796669989
Iteration 11 Loss=  36.2983598947
Iteration 12 Loss=  29.3578588958
Iteration 13 Loss=  23.7444303667
Iteration 14 Loss=  19.2043287435
Iteration 15 Loss=  15.5323263937
Iteration 16 Loss=  12.5624366476
Iteration 17 Loss=  10.160410651
Iteration 18 Loss=  8.21766887214
Iteration 19 Loss=  6.64639294766
Iteration 20 Loss=  5.37555600366
Iteration 21 Loss=  4.34771201805
Iteration 22 Loss=  3.51639912805
Iteration 23 Loss=  2.84403961852
Iteration 24 Loss=  2.30024190569
Iteration 25 Loss=  1.86042759755
Iteration 26 Loss=  1.50471799562
Iteration 27 Loss=  1.2170276789
Iteration 28 Loss=  0.984349179333
Iteration 29 Loss=  0.796162434282
Iteration 30 Loss=  0.643953525177
Iteration 31 Loss=  0.520854325274
Iteration 32 Loss=  0.421308079833
Iteration 33 Loss=  0.340806229547
Iteration 34 Loss=  0.275695089003
Iteration 35 Loss=  0.223037693073
Iteration 36 Loss=  0.180455132149
Iteration 37 Loss=  0.146016398842
Iteration 38 Loss=  0.118163996484
Iteration 39 Loss=  0.0956391213515
Iteration 40 Loss=  0.0774240401734
Iteration 41 Loss=  0.0626964131988
Iteration 42 Loss=  0.0507942567774
Iteration 43 Loss=  0.0411751490961
Iteration 44 Loss=  0.0334034269227
Iteration 45 Loss=  0.0271356865752
Iteration 46 Loss=  0.022084734858
Iteration 47 Loss=  0.0180059234607
Iteration 48 Loss=  0.0147118970055
Iteration 49 Loss=  0.0120463934522
Iteration 50 Loss=  0.00990292334597
Iteration 51 Loss=  0.0081879215218
Iteration 52 Loss=  0.00681118682255
Iteration 53 Loss=  0.00571667652308
Iteration 54 Loss=  0.00485670493737
Iteration 55 Loss=  0.00417843988136
Iteration 56 Loss=  0.00365971445873
Iteration 57 Loss=  0.0032789836384
Iteration 58 Loss=  0.00297766210197
Iteration 59 Loss=  0.00274798138541
Iteration 60 Loss=  0.00257586442117
Iteration 61 Loss=  0.00237591262276
Iteration 62 Loss=  0.00220909735193
Iteration 63 Loss=  0.00208824475754
Iteration 64 Loss=  0.00201127710148
[ -4.71165628e-04  -1.08549142e-04  -4.28422702e-05 ...,   3.21904018e-04
   1.77780374e-04   4.02466463e-05]
CROSS VALIDATION 10
Iteration 1 Loss=  1434.20083289
Iteration 2 Loss=  827.389220291
Iteration 3 Loss=  186.434137385
Iteration 4 Loss=  150.786622718
Iteration 5 Loss=  121.955162877
Iteration 6 Loss=  98.6364803737
Iteration 7 Loss=  79.7764935162
Iteration 8 Loss=  64.5226684248
Iteration 9 Loss=  52.1854816772
Iteration 10 Loss=  42.2072515654
Iteration 11 Loss=  34.1369290357
Iteration 12 Loss=  27.6097087767
Iteration 13 Loss=  22.3305388115
Iteration 14 Loss=  18.0607831702
Iteration 15 Loss=  14.6074347546
Iteration 16 Loss=  11.8143907768
Iteration 17 Loss=  9.55539639731
Iteration 18 Loss=  7.72833758713
Iteration 19 Loss=  6.25062523597
Iteration 20 Loss=  5.05546185063
Iteration 21 Loss=  4.08882208713
Iteration 22 Loss=  3.30701062616
Iteration 23 Loss=  2.67468699994
Iteration 24 Loss=  2.16326808601
Iteration 25 Loss=  1.74963605538
Iteration 26 Loss=  1.41509337011
Iteration 27 Loss=  1.14451759268
Iteration 28 Loss=  0.925677801888
Iteration 29 Loss=  0.748681716126
Iteration 30 Loss=  0.605528538228
Iteration 31 Loss=  0.489747335525
Iteration 32 Loss=  0.396104699292
Iteration 33 Loss=  0.320368697277
Iteration 34 Loss=  0.259118681948
Iteration 35 Loss=  0.209590651623
Iteration 36 Loss=  0.169543310319
Iteration 37 Loss=  0.13715129792
Iteration 38 Loss=  0.110951391749
Iteration 39 Loss=  0.0897606366102
Iteration 40 Loss=  0.0726266633775
Iteration 41 Loss=  0.0587826518027
Iteration 42 Loss=  0.0475930717445
Iteration 43 Loss=  0.0385405712715
Iteration 44 Loss=  0.0312253028039
Iteration 45 Loss=  0.025319362069
Iteration 46 Loss=  0.0205571932454
Iteration 47 Loss=  0.0167199999434
Iteration 48 Loss=  0.0136353849431
Iteration 49 Loss=  0.0111743960517
Iteration 50 Loss=  0.00921656438531
Iteration 51 Loss=  0.00765976318544
Iteration 52 Loss=  0.00642659268377
Iteration 53 Loss=  0.00545802646406
Iteration 54 Loss=  0.00470661194354
Iteration 55 Loss=  0.0040987127861
Iteration 56 Loss=  0.00360576151369
Iteration 57 Loss=  0.00320437769521
Iteration 58 Loss=  0.00287019761754
Iteration 59 Loss=  0.0026042889931
Iteration 60 Loss=  0.00242157246773
Iteration 61 Loss=  0.00234572905291
[ -4.63669845e-04  -5.57983142e-05  -1.16606644e-04 ...,   3.30356407e-04
   5.65543800e-05   5.80410134e-05]
CROSS VALIDATION 11
Iteration 1 Loss=  1434.20083289
Iteration 2 Loss=  827.389220291
Iteration 3 Loss=  186.434137385
Iteration 4 Loss=  150.786622718
Iteration 5 Loss=  121.955162877
Iteration 6 Loss=  98.6364803737
Iteration 7 Loss=  79.7764935162
Iteration 8 Loss=  64.5226684248
Iteration 9 Loss=  52.1854816772
Iteration 10 Loss=  42.2072515654
Iteration 11 Loss=  34.1369290357
Iteration 12 Loss=  27.6097087767
Iteration 13 Loss=  22.3305388115
Iteration 14 Loss=  18.0607831702
Iteration 15 Loss=  14.6074347546
Iteration 16 Loss=  11.8143907768
Iteration 17 Loss=  9.55539639731
Iteration 18 Loss=  7.72833758713
Iteration 19 Loss=  6.25062523597
Iteration 20 Loss=  5.05546185063
Iteration 21 Loss=  4.08882208713
Iteration 22 Loss=  3.30701062616
Iteration 23 Loss=  2.67468699994
Iteration 24 Loss=  2.16326808601
Iteration 25 Loss=  1.74963605538
Iteration 26 Loss=  1.41509337011
Iteration 27 Loss=  1.14451759268
Iteration 28 Loss=  0.925677801888
Iteration 29 Loss=  0.748681716126
Iteration 30 Loss=  0.605528538228
Iteration 31 Loss=  0.489747335525
Iteration 32 Loss=  0.396104699292
Iteration 33 Loss=  0.320368697277
Iteration 34 Loss=  0.259118681948
Iteration 35 Loss=  0.209590651623
Iteration 36 Loss=  0.169543310321
Iteration 37 Loss=  0.137151297954
Iteration 38 Loss=  0.110951392141
Iteration 39 Loss=  0.0897606400891
Iteration 40 Loss=  0.072626688189
Iteration 41 Loss=  0.058782798051
Iteration 42 Loss=  0.0475937996713
Iteration 43 Loss=  0.0385436448678
Iteration 44 Loss=  0.031236055644
Iteration 45 Loss=  0.0253481551637
Iteration 46 Loss=  0.0206080007256
Iteration 47 Loss=  0.0167785893656
Iteration 48 Loss=  0.0136947751778
Iteration 49 Loss=  0.0112344215391
Iteration 50 Loss=  0.00927507166031
Iteration 51 Loss=  0.00771479824299
Iteration 52 Loss=  0.00647207708828
Iteration 53 Loss=  0.00548641556742
Iteration 54 Loss=  0.00471967344135
Iteration 55 Loss=  0.0041073684229
Iteration 56 Loss=  0.00361354433223
Iteration 57 Loss=  0.00321233833835
Iteration 58 Loss=  0.00287967634155
Iteration 59 Loss=  0.00261436411577
Iteration 60 Loss=  0.00243278453354
Iteration 61 Loss=  0.00236050210384
[ -4.83389466e-04  -5.64506351e-05  -1.03675840e-04 ...,   3.33849737e-04
   6.68475290e-05   5.15055845e-05]
CROSS VALIDATION 12
Iteration 1 Loss=  1310.24303339
Iteration 2 Loss=  441.614233547
Iteration 3 Loss=  169.427049064
Iteration 4 Loss=  137.031408967
Iteration 5 Loss=  110.83004247
Iteration 6 Loss=  89.6385610176
Iteration 7 Loss=  72.49903945
Iteration 8 Loss=  58.6367146182
Iteration 9 Loss=  47.4249635209
Iteration 10 Loss=  38.3569778696
Iteration 11 Loss=  31.0228546753
Iteration 12 Loss=  25.0910672753
Iteration 13 Loss=  20.2934792302
Iteration 14 Loss=  16.4132236683
Iteration 15 Loss=  13.274900185
Iteration 16 Loss=  10.736646163
Iteration 17 Loss=  8.68372411264
Iteration 18 Loss=  7.02333515697
Iteration 19 Loss=  5.68042421516
Iteration 20 Loss=  4.59428726423
Iteration 21 Loss=  3.7158273162
Iteration 22 Loss=  3.00533507152
Iteration 23 Loss=  2.43069392723
Iteration 24 Loss=  1.9659282001
Iteration 25 Loss=  1.59002893974
Iteration 26 Loss=  1.28600425442
Iteration 27 Loss=  1.04011122129
Iteration 28 Loss=  0.841234660713
Iteration 29 Loss=  0.680384693389
Iteration 30 Loss=  0.550290367977
Iteration 31 Loss=  0.445070990046
Iteration 32 Loss=  0.359970295353
Iteration 33 Loss=  0.291141452208
Iteration 34 Loss=  0.23547318049
Iteration 35 Loss=  0.190449157089
Iteration 36 Loss=  0.154034466582
Iteration 37 Loss=  0.124584304029
Iteration 38 Loss=  0.100771456883
Iteration 39 Loss=  0.0815286826704
Iteration 40 Loss=  0.0659929419026
Iteration 41 Loss=  0.0534402038926
Iteration 42 Loss=  0.0432852414441
Iteration 43 Loss=  0.0350828084759
Iteration 44 Loss=  0.0284733382621
Iteration 45 Loss=  0.0231573545749
Iteration 46 Loss=  0.0188546102503
Iteration 47 Loss=  0.0153762743516
Iteration 48 Loss=  0.0125918118057
Iteration 49 Loss=  0.0103727357802
Iteration 50 Loss=  0.00861136414447
Iteration 51 Loss=  0.00721971413151
Iteration 52 Loss=  0.00611914201838
Iteration 53 Loss=  0.0052428597428
Iteration 54 Loss=  0.00452377824727
Iteration 55 Loss=  0.00393880841355
Iteration 56 Loss=  0.00348049771794
Iteration 57 Loss=  0.00311289532949
Iteration 58 Loss=  0.00280589173284
Iteration 59 Loss=  0.00256021533694
Iteration 60 Loss=  0.00238765084314
Iteration 61 Loss=  0.0023148656631
[ -7.92121401e-04  -2.19550915e-04  -2.03490969e-04 ...,   2.63768435e-04
   5.90430229e-05   1.91127673e-05]
CROSS VALIDATION 13
Iteration 1 Loss=  2008.64768025
Iteration 2 Loss=  1202.99897152
Iteration 3 Loss=  184.673730822
Iteration 4 Loss=  149.362818236
Iteration 5 Loss=  120.803599799
Iteration 6 Loss=  97.7051042327
Iteration 7 Loss=  79.0232030258
Iteration 8 Loss=  63.9134123596
Iteration 9 Loss=  51.6927196447
Iteration 10 Loss=  41.8087090897
Iteration 11 Loss=  33.8145906766
Iteration 12 Loss=  27.3490037727
Iteration 13 Loss=  22.1196824327
Iteration 14 Loss=  17.89024401
Iteration 15 Loss=  14.4695038779
Iteration 16 Loss=  11.7028332512
Iteration 17 Loss=  9.46516945299
Iteration 18 Loss=  7.6553626674
Iteration 19 Loss=  6.19160363272
Iteration 20 Loss=  5.00772559188
Iteration 21 Loss=  4.05021333586
Iteration 22 Loss=  3.27578413892
Iteration 23 Loss=  2.64943123608
Iteration 24 Loss=  2.14284140134
Iteration 25 Loss=  1.73311509608
Iteration 26 Loss=  1.4017313341
Iteration 27 Loss=  1.13371047165
Iteration 28 Loss=  0.916937077929
Iteration 29 Loss=  0.741612277479
Iteration 30 Loss=  0.599810808596
Iteration 31 Loss=  0.485122775536
Iteration 32 Loss=  0.392363902227
Iteration 33 Loss=  0.317341198893
Iteration 34 Loss=  0.256663486322
Iteration 35 Loss=  0.207588336119
Iteration 36 Loss=  0.167898807832
Iteration 37 Loss=  0.135804675785
Iteration 38 Loss=  0.10986127763
Iteration 39 Loss=  0.0888920978097
Iteration 40 Loss=  0.0719281172497
Iteration 41 Loss=  0.058205343435
Iteration 42 Loss=  0.0471271180621
Iteration 43 Loss=  0.038208948723
Iteration 44 Loss=  0.0310395392799
Iteration 45 Loss=  0.0252699884845
Iteration 46 Loss=  0.020612701653
Iteration 47 Loss=  0.0168517984735
Iteration 48 Loss=  0.0138194655228
Iteration 49 Loss=  0.011383639829
Iteration 50 Loss=  0.00942271959401
Iteration 51 Loss=  0.00783164921201
Iteration 52 Loss=  0.00654946436334
Iteration 53 Loss=  0.00552348959052
Iteration 54 Loss=  0.00471343709236
Iteration 55 Loss=  0.00409669578237
Iteration 56 Loss=  0.00362262925133
Iteration 57 Loss=  0.00322065910162
Iteration 58 Loss=  0.00287930999567
Iteration 59 Loss=  0.00260990440875
Iteration 60 Loss=  0.00243689072518
Iteration 61 Loss=  0.0023707546099
[ -5.96120745e-04  -2.83452225e-04  -1.55790103e-04 ...,   2.80681256e-04
   6.92655642e-05   5.18920241e-05]
CROSS VALIDATION 14
Iteration 1 Loss=  1435.53751046
Iteration 2 Loss=  828.076736734
Iteration 3 Loss=  186.501231329
Iteration 4 Loss=  150.840887829
Iteration 5 Loss=  121.999052118
Iteration 6 Loss=  98.6719776845
Iteration 7 Loss=  79.8052034922
Iteration 8 Loss=  64.545888852
Iteration 9 Loss=  52.2042621958
Iteration 10 Loss=  42.2224411172
Iteration 11 Loss=  34.1492142386
Iteration 12 Loss=  27.6196449627
Iteration 13 Loss=  22.338575129
Iteration 14 Loss=  18.0672828875
Iteration 15 Loss=  14.6126916803
Iteration 16 Loss=  11.8186425415
Iteration 17 Loss=  9.55883519474
Iteration 18 Loss=  7.73111886238
Iteration 19 Loss=  6.25287471188
Iteration 20 Loss=  5.05728121097
Iteration 21 Loss=  4.09029357301
Iteration 22 Loss=  3.30820075362
Iteration 23 Loss=  2.67564956669
Iteration 24 Loss=  2.16404660324
Iteration 25 Loss=  1.75026571466
Iteration 26 Loss=  1.41560263411
Iteration 27 Loss=  1.14492948181
Iteration 28 Loss=  0.926010934659
Iteration 29 Loss=  0.748951149163
Iteration 30 Loss=  0.605746436563
Iteration 31 Loss=  0.489923470019
Iteration 32 Loss=  0.396246671833
Iteration 33 Loss=  0.320481564944
Iteration 34 Loss=  0.259203435667
Iteration 35 Loss=  0.209642787279
Iteration 36 Loss=  0.169560776322
Iteration 37 Loss=  0.13714814094
Iteration 38 Loss=  0.1109384428
Iteration 39 Loss=  0.0897395270121
Iteration 40 Loss=  0.0725991000814
Iteration 41 Loss=  0.0587501671514
Iteration 42 Loss=  0.0475569363544
Iteration 43 Loss=  0.0385033878026
Iteration 44 Loss=  0.0311934969562
Iteration 45 Loss=  0.0253036567226
Iteration 46 Loss=  0.0205608505713
Iteration 47 Loss=  0.0167306109246
Iteration 48 Loss=  0.0136473620098
Iteration 49 Loss=  0.0111846723057
Iteration 50 Loss=  0.00922239687605
Iteration 51 Loss=  0.0076659302017
Iteration 52 Loss=  0.00643894255914
Iteration 53 Loss=  0.00547387039802
Iteration 54 Loss=  0.00471507984148
Iteration 55 Loss=  0.00410038641369
Iteration 56 Loss=  0.00360597531935
Iteration 57 Loss=  0.00320685060205
Iteration 58 Loss=  0.00287574399918
Iteration 59 Loss=  0.00261053625863
Iteration 60 Loss=  0.00242695907182
Iteration 61 Loss=  0.00234928193773
[ -4.43414898e-04  -4.34461191e-05  -9.78559243e-05 ...,   3.09298586e-04
   4.40461866e-05   4.80784219e-05]
CROSS VALIDATION 15
Iteration 1 Loss=  1435.53751046
Iteration 2 Loss=  828.076736734
Iteration 3 Loss=  186.501231329
Iteration 4 Loss=  150.840887829
Iteration 5 Loss=  121.999052118
Iteration 6 Loss=  98.6719776845
Iteration 7 Loss=  79.8052034922
Iteration 8 Loss=  64.545888852
Iteration 9 Loss=  52.2042621958
Iteration 10 Loss=  42.2224411172
Iteration 11 Loss=  34.1492142386
Iteration 12 Loss=  27.6196449627
Iteration 13 Loss=  22.338575129
Iteration 14 Loss=  18.0672828875
Iteration 15 Loss=  14.6126916803
Iteration 16 Loss=  11.8186425415
Iteration 17 Loss=  9.55883519474
Iteration 18 Loss=  7.73111886238
Iteration 19 Loss=  6.25287471188
Iteration 20 Loss=  5.05728121097
Iteration 21 Loss=  4.09029357301
Iteration 22 Loss=  3.30820075362
Iteration 23 Loss=  2.67564956669
Iteration 24 Loss=  2.16404660324
Iteration 25 Loss=  1.75026571466
Iteration 26 Loss=  1.41560263412
Iteration 27 Loss=  1.14492948183
Iteration 28 Loss=  0.926010934924
Iteration 29 Loss=  0.748951151605
Iteration 30 Loss=  0.605746454571
Iteration 31 Loss=  0.489923578548
Iteration 32 Loss=  0.396247216599
Iteration 33 Loss=  0.320483867549
Iteration 34 Loss=  0.259211550791
Iteration 35 Loss=  0.209665205566
Iteration 36 Loss=  0.169603112765
Iteration 37 Loss=  0.137199556651
Iteration 38 Loss=  0.110990270772
Iteration 39 Loss=  0.0897919272621
Iteration 40 Loss=  0.0726518309013
Iteration 41 Loss=  0.0588029731643
Iteration 42 Loss=  0.0476099452369
Iteration 43 Loss=  0.0385565234942
Iteration 44 Loss=  0.031246244396
Iteration 45 Loss=  0.0253561430497
Iteration 46 Loss=  0.02061426522
Iteration 47 Loss=  0.0167832449579
Iteration 48 Loss=  0.0136972529852
Iteration 49 Loss=  0.0112325175599
Iteration 50 Loss=  0.00926371259319
Iteration 51 Loss=  0.00769122913123
Iteration 52 Loss=  0.00645012243825
Iteration 53 Loss=  0.00548316619883
Iteration 54 Loss=  0.00472948187744
Iteration 55 Loss=  0.00411831470146
Iteration 56 Loss=  0.00362465071837
Iteration 57 Loss=  0.00322379375427
Iteration 58 Loss=  0.00289061243423
Iteration 59 Loss=  0.00262439444183
Iteration 60 Loss=  0.0024400187236
Iteration 61 Loss=  0.00236267113485
[ -4.82363098e-04  -4.44104806e-05  -1.15260752e-04 ...,   3.34288154e-04
   6.53293869e-05   5.12315537e-05]
CROSS VALIDATION 16
Iteration 1 Loss=  2057.06379668
Iteration 2 Loss=  191.610266872
Iteration 3 Loss=  154.973039943
Iteration 4 Loss=  125.341107766
Iteration 5 Loss=  101.375008852
Iteration 6 Loss=  81.9913961421
Iteration 7 Loss=  66.3140661339
Iteration 8 Loss=  53.6343515799
Iteration 9 Loss=  43.3790873807
Iteration 10 Loss=  35.0847016242
Iteration 11 Loss=  28.3762605989
Iteration 12 Loss=  22.9505205488
Iteration 13 Loss=  18.562220051
Iteration 14 Loss=  15.0129933868
Iteration 15 Loss=  12.1424037541
Iteration 16 Loss=  9.82069099273
Iteration 17 Loss=  7.94290599521
Iteration 18 Loss=  6.42416665954
Iteration 19 Loss=  5.19582093725
Iteration 20 Loss=  4.2023435355
Iteration 21 Loss=  3.39882600174
Iteration 22 Loss=  2.74894676834
Iteration 23 Loss=  2.22332950416
Iteration 24 Loss=  1.79821581145
Iteration 25 Loss=  1.45439237921
Iteration 26 Loss=  1.17632148013
Iteration 27 Loss=  0.951426926757
Iteration 28 Loss=  0.769524771794
Iteration 29 Loss=  0.622397867732
Iteration 30 Loss=  0.503402696933
Iteration 31 Loss=  0.407160235211
Iteration 32 Loss=  0.329320010624
Iteration 33 Loss=  0.266363405292
Iteration 34 Loss=  0.215444669258
Iteration 35 Loss=  0.174262528781
Iteration 36 Loss=  0.140956916431
Iteration 37 Loss=  0.114026413579
Iteration 38 Loss=  0.0922596799594
Iteration 39 Loss=  0.0746668747206
Iteration 40 Loss=  0.0604359069633
Iteration 41 Loss=  0.0489370242859
Iteration 42 Loss=  0.0396609005688
Iteration 43 Loss=  0.0321796916786
Iteration 44 Loss=  0.0261351809714
Iteration 45 Loss=  0.0212731869114
Iteration 46 Loss=  0.0173712592148
Iteration 47 Loss=  0.0142397725705
Iteration 48 Loss=  0.0117298528675
Iteration 49 Loss=  0.00970447704784
Iteration 50 Loss=  0.00807268962094
Iteration 51 Loss=  0.00677021618382
Iteration 52 Loss=  0.00573011915457
Iteration 53 Loss=  0.00489453243987
Iteration 54 Loss=  0.0042395214637
Iteration 55 Loss=  0.00373936033051
Iteration 56 Loss=  0.00334543635063
Iteration 57 Loss=  0.00302247472115
Iteration 58 Loss=  0.00275805330479
Iteration 59 Loss=  0.00256601016234
Iteration 60 Loss=  0.00246972182171
[ -4.40561594e-04  -4.21836914e-05  -1.82346894e-04 ...,   3.07738234e-04
   2.59752925e-05   7.44525473e-05]
CROSS VALIDATION 17
Iteration 1 Loss=  1438.03806812
Iteration 2 Loss=  828.748720193
Iteration 3 Loss=  186.532545028
Iteration 4 Loss=  150.866214129
Iteration 5 Loss=  122.019535852
Iteration 6 Loss=  98.6885447847
Iteration 7 Loss=  79.8186028466
Iteration 8 Loss=  64.5567261559
Iteration 9 Loss=  52.2130273312
Iteration 10 Loss=  42.2295302972
Iteration 11 Loss=  34.1549479177
Iteration 12 Loss=  27.6242823221
Iteration 13 Loss=  22.3423257928
Iteration 14 Loss=  18.070316398
Iteration 15 Loss=  14.6151451624
Iteration 16 Loss=  11.8206269006
Iteration 17 Loss=  9.56044013045
Iteration 18 Loss=  7.73241692312
Iteration 19 Loss=  6.25392457431
Iteration 20 Loss=  5.05813033234
Iteration 21 Loss=  4.09098033641
Iteration 22 Loss=  3.30875620304
Iteration 23 Loss=  2.67609881029
Iteration 24 Loss=  2.16440994831
Iteration 25 Loss=  1.7505595856
Iteration 26 Loss=  1.41584031488
Iteration 27 Loss=  1.14512171637
Iteration 28 Loss=  0.926166412874
Iteration 29 Loss=  0.749076901147
Iteration 30 Loss=  0.605848160348
Iteration 31 Loss=  0.490005839723
Iteration 32 Loss=  0.39631375866
Iteration 33 Loss=  0.320537721515
Iteration 34 Loss=  0.259255206366
Iteration 35 Loss=  0.209700682966
Iteration 36 Loss=  0.169631844279
Iteration 37 Loss=  0.137222671497
Iteration 38 Loss=  0.111008985214
Iteration 39 Loss=  0.0898071639469
Iteration 40 Loss=  0.0726644235827
Iteration 41 Loss=  0.058813438317
Iteration 42 Loss=  0.0476182274365
Iteration 43 Loss=  0.0385629552933
Iteration 44 Loss=  0.0312512889293
Iteration 45 Loss=  0.0253599744057
Iteration 46 Loss=  0.0206174036673
Iteration 47 Loss=  0.0167862461525
Iteration 48 Loss=  0.0137008189608
Iteration 49 Loss=  0.0112393872279
Iteration 50 Loss=  0.00928029648427
Iteration 51 Loss=  0.00772346863967
Iteration 52 Loss=  0.00649053386972
Iteration 53 Loss=  0.00552002216556
Iteration 54 Loss=  0.00476018489113
Iteration 55 Loss=  0.00414319805124
Iteration 56 Loss=  0.00364445918825
Iteration 57 Loss=  0.00323982750787
Iteration 58 Loss=  0.00290424966822
Iteration 59 Loss=  0.0026382550461
Iteration 60 Loss=  0.00245622267564
Iteration 61 Loss=  0.00238041854074
[ -4.78423656e-04  -5.83489513e-05  -1.08900248e-04 ...,   3.37699771e-04
   6.22259012e-05   5.19824586e-05]
CROSS VALIDATION 18
Iteration 1 Loss=  1842.94013686
Iteration 2 Loss=  1612.24983251
Iteration 3 Loss=  166.762648211
Iteration 4 Loss=  134.876460244
Iteration 5 Loss=  109.087135058
Iteration 6 Loss=  88.2289097267
Iteration 7 Loss=  71.3589233729
Iteration 8 Loss=  57.7145967315
Iteration 9 Loss=  46.6791610422
Iteration 10 Loss=  37.7537780602
Iteration 11 Loss=  30.5349909305
Iteration 12 Loss=  24.6964866661
Iteration 13 Loss=  19.974345953
Iteration 14 Loss=  16.1551136946
Iteration 15 Loss=  13.0661503637
Iteration 16 Loss=  10.5678235871
Iteration 17 Loss=  8.5471915231
Iteration 18 Loss=  6.91291483042
Iteration 19 Loss=  5.59112324256
Iteration 20 Loss=  4.52206767414
Iteration 21 Loss=  3.65742381944
Iteration 22 Loss=  2.9581085711
Iteration 23 Loss=  2.39251338018
Iteration 24 Loss=  1.93506944924
Iteration 25 Loss=  1.56508773474
Iteration 26 Loss=  1.26584514813
Iteration 27 Loss=  1.023819839
Iteration 28 Loss=  0.828071468793
Iteration 29 Loss=  0.66975157373
Iteration 30 Loss=  0.541703631143
Iteration 31 Loss=  0.438139717334
Iteration 32 Loss=  0.3543793636
Iteration 33 Loss=  0.286639036422
Iteration 34 Loss=  0.231861228842
Iteration 35 Loss=  0.187568060466
Iteration 36 Loss=  0.151742660332
Iteration 37 Loss=  0.122766931912
Iteration 38 Loss=  0.0993395422166
Iteration 39 Loss=  0.0804051528641
Iteration 40 Loss=  0.0651022934533
Iteration 41 Loss=  0.0527331482158
Iteration 42 Loss=  0.0427529750797
Iteration 43 Loss=  0.0347170461942
Iteration 44 Loss=  0.0282325794584
Iteration 45 Loss=  0.0229982629624
Iteration 46 Loss=  0.0187719983581
Iteration 47 Loss=  0.0153540105091
Iteration 48 Loss=  0.0126074151286
Iteration 49 Loss=  0.0104116002353
Iteration 50 Loss=  0.00865231390259
Iteration 51 Loss=  0.00722931350729
Iteration 52 Loss=  0.0060747947496
Iteration 53 Loss=  0.00513784164367
Iteration 54 Loss=  0.00439427137633
Iteration 55 Loss=  0.00383165783972
Iteration 56 Loss=  0.00342095444886
Iteration 57 Loss=  0.00308372594501
Iteration 58 Loss=  0.0027814110206
Iteration 59 Loss=  0.00254105403728
Iteration 60 Loss=  0.0023955434401
Iteration 61 Loss=  0.0023443402324
[ -4.02093692e-04  -2.20869121e-04  -1.33398378e-04 ...,   2.72069236e-04
   1.18974371e-04   6.21416385e-05]
CROSS VALIDATION 19
Iteration 1 Loss=  1815.08537467
Iteration 2 Loss=  472.921367901
Iteration 3 Loss=  198.924266367
Iteration 4 Loss=  160.888551436
Iteration 5 Loss=  130.125531972
Iteration 6 Loss=  105.244617593
Iteration 7 Loss=  85.1211085514
Iteration 8 Loss=  68.8453555795
Iteration 9 Loss=  55.6816407297
Iteration 10 Loss=  45.034920486
Iteration 11 Loss=  36.4239278261
Iteration 12 Loss=  29.459417358
Iteration 13 Loss=  23.8265701387
Iteration 14 Loss=  19.2707628149
Iteration 15 Loss=  15.5860578047
Iteration 16 Loss=  12.605894236
Iteration 17 Loss=  10.1955588437
Iteration 18 Loss=  8.24609648383
Iteration 19 Loss=  6.66938500019
Iteration 20 Loss=  5.39415181086
Iteration 21 Loss=  4.36275215148
Iteration 22 Loss=  3.52856334093
Iteration 23 Loss=  2.85387728174
Iteration 24 Loss=  2.30819592914
Iteration 25 Loss=  1.86685267841
Iteration 26 Loss=  1.50989735269
Iteration 27 Loss=  1.22119438884
Iteration 28 Loss=  0.987693456562
Iteration 29 Loss=  0.798839540248
Iteration 30 Loss=  0.646095817309
Iteration 31 Loss=  0.522557765561
Iteration 32 Loss=  0.422641056408
Iteration 33 Loss=  0.341829128114
Iteration 34 Loss=  0.276469042266
Iteration 35 Loss=  0.223606452523
Iteration 36 Loss=  0.180852411681
Iteration 37 Loss=  0.14627642914
Iteration 38 Loss=  0.1183211633
Iteration 39 Loss=  0.0957306815171
Iteration 40 Loss=  0.0774766643628
Iteration 41 Loss=  0.0627109255156
Iteration 42 Loss=  0.0507794694865
Iteration 43 Loss=  0.0411628887205
Iteration 44 Loss=  0.0334040747422
Iteration 45 Loss=  0.0271309967527
Iteration 46 Loss=  0.022065927725
Iteration 47 Loss=  0.0179912038223
Iteration 48 Loss=  0.0147174142915
Iteration 49 Loss=  0.0120774982383
Iteration 50 Loss=  0.00994333952508
Iteration 51 Loss=  0.00822861850802
Iteration 52 Loss=  0.00686615674557
Iteration 53 Loss=  0.00578676013941
Iteration 54 Loss=  0.00493340475253
Iteration 55 Loss=  0.00426606277828
Iteration 56 Loss=  0.00374931692127
Iteration 57 Loss=  0.00333502764093
Iteration 58 Loss=  0.00300874031199
Iteration 59 Loss=  0.00278340147163
Iteration 60 Loss=  0.00265021515724
Iteration 61 Loss=  0.0025041576576
Iteration 62 Loss=  0.0023638788076
Iteration 63 Loss=  0.00224911805833
Iteration 64 Loss=  0.00216478950789
[ -4.30611516e-04  -1.98506202e-04  -1.28167489e-04 ...,   2.86547680e-04
   9.72896256e-05   3.36829017e-05]
Accuracy (Logistic Loss):	0.85 for lmda= 0.1 learning rate= 0.01
---------------------------------------------------------------------------------
lmda= 0.1 learning rate= 0.1
CROSS VALIDATION 0
Iteration 1 Loss=  21903.2048031
Iteration 2 Loss=  3948.16783656
Iteration 3 Loss=  5645.01123795
Iteration 4 Loss=  340.64237968
Iteration 5 Loss=  40.0186746483
Iteration 6 Loss=  4.70139482383
Iteration 7 Loss=  0.552393499368
Iteration 8 Loss=  53749.7355425
Iteration 9 Loss=  13506.0833224
Iteration 10 Loss=  2848.08296687
Iteration 11 Loss=  19364.7357178
Iteration 12 Loss=  24902.1919255
Iteration 13 Loss=  6996.78720542
Iteration 14 Loss=  15122.4787395
Iteration 15 Loss=  42647.0418835
Iteration 16 Loss=  7794.31815895
Iteration 17 Loss=  6868.78872401
Iteration 18 Loss=  18908.4348371
Iteration 19 Loss=  1473.59523365
Iteration 20 Loss=  173.118002152
Iteration 21 Loss=  20.3379068993
Iteration 22 Loss=  2.38929778883
Iteration 23 Loss=  0.280734112328
Iteration 24 Loss=  0.0639341016818
Iteration 25 Loss=  31414.2569112
Iteration 26 Loss=  20405.7417377
Iteration 27 Loss=  7980.66002341
Iteration 28 Loss=  12997.429791
Iteration 29 Loss=  23187.8712225
Iteration 30 Loss=  29400.753768
Iteration 31 Loss=  9015.20284679
Iteration 32 Loss=  21214.2110049
Iteration 33 Loss=  22405.6232368
Iteration 34 Loss=  26220.8254089
Iteration 35 Loss=  6980.13510531
Iteration 36 Loss=  1570.98723513
Iteration 37 Loss=  38767.8184152
Iteration 38 Loss=  29554.6709855
Iteration 39 Loss=  16833.6733083
Iteration 40 Loss=  3553.262716
Iteration 41 Loss=  34117.3800462
Iteration 42 Loss=  7117.9996167
Iteration 43 Loss=  18613.893292
Iteration 44 Loss=  26310.771019
Iteration 45 Loss=  5597.62254554
Iteration 46 Loss=  13583.8306311
Iteration 47 Loss=  27804.2867627
Iteration 48 Loss=  7600.78153632
Iteration 49 Loss=  20903.0978104
Iteration 50 Loss=  4956.53991968
Iteration 51 Loss=  11365.7952296
Iteration 52 Loss=  13555.2725156
Iteration 53 Loss=  18943.0237703
Iteration 54 Loss=  5623.32655569
Iteration 55 Loss=  26769.6228684
Iteration 56 Loss=  33508.9135038
Iteration 57 Loss=  13672.4389834
Iteration 58 Loss=  34054.7250839
Iteration 59 Loss=  13809.0592266
Iteration 60 Loss=  38393.0223359
Iteration 61 Loss=  2508.59718046
Iteration 62 Loss=  17255.9373452
Iteration 63 Loss=  41013.4971471
Iteration 64 Loss=  20514.3012251
Iteration 65 Loss=  5476.88813224
Iteration 66 Loss=  24818.2385099
Iteration 67 Loss=  38779.6375803
Iteration 68 Loss=  4333.47962132
Iteration 69 Loss=  35610.8295262
Iteration 70 Loss=  5106.5144259
Iteration 71 Loss=  23283.1945634
Iteration 72 Loss=  5185.19094697
Iteration 73 Loss=  10405.1711964
Iteration 74 Loss=  1377.24787589
Iteration 75 Loss=  30877.3043189
Iteration 76 Loss=  17041.2827689
Iteration 77 Loss=  27065.5361844
Iteration 78 Loss=  14120.4666211
Iteration 79 Loss=  19671.6032486
Iteration 80 Loss=  23686.8725936
Iteration 81 Loss=  9014.06562165
Iteration 82 Loss=  13825.8877753
Iteration 83 Loss=  37907.7163672
Iteration 84 Loss=  30864.6475697
Iteration 85 Loss=  25249.2189722
Iteration 86 Loss=  30416.9008896
Iteration 87 Loss=  4888.61919648
Iteration 88 Loss=  9947.09377798
Iteration 89 Loss=  26410.1129072
Iteration 90 Loss=  10472.7286633
Iteration 91 Loss=  24445.8963697
Iteration 92 Loss=  21187.4702265
Iteration 93 Loss=  22959.5653218
Iteration 94 Loss=  13238.5869456
Iteration 95 Loss=  32952.3487786
Iteration 96 Loss=  12059.1562841
Iteration 97 Loss=  18582.3890531
Iteration 98 Loss=  22936.9945369
Iteration 99 Loss=  32339.3181872
Iteration 100 Loss=  21241.5011514
[-0.32580029 -0.02868749  0.20528355 ...,  0.11413497  0.06986788
 -0.12600736]
CROSS VALIDATION 1
Iteration 1 Loss=  27361.1104953
Iteration 2 Loss=  11998.6409383
Iteration 3 Loss=  4744.23782992
Iteration 4 Loss=  42653.1936036
Iteration 5 Loss=  14388.8160878
Iteration 6 Loss=  7401.21030452
Iteration 7 Loss=  31302.666742
Iteration 8 Loss=  23977.2989861
Iteration 9 Loss=  3641.66735094
Iteration 10 Loss=  21648.4237758
Iteration 11 Loss=  3745.25736836
Iteration 12 Loss=  439.992922311
Iteration 13 Loss=  51.6903786958
Iteration 14 Loss=  6.07259674732
Iteration 15 Loss=  0.77568959897
Iteration 16 Loss=  0.0921498760713
Iteration 17 Loss=  2.81978304033
Iteration 18 Loss=  29580.0406511
Iteration 19 Loss=  17820.8704279
Iteration 20 Loss=  46493.7036606
Iteration 21 Loss=  9737.12305806
Iteration 22 Loss=  22084.0478654
Iteration 23 Loss=  22589.4029871
Iteration 24 Loss=  11895.2295091
Iteration 25 Loss=  14289.1671158
Iteration 26 Loss=  40388.3366035
Iteration 27 Loss=  16437.8608729
Iteration 28 Loss=  4485.95035642
Iteration 29 Loss=  5052.01514554
Iteration 30 Loss=  24623.645136
Iteration 31 Loss=  24473.4091988
Iteration 32 Loss=  2692.9561822
Iteration 33 Loss=  20656.9655372
Iteration 34 Loss=  12095.788299
Iteration 35 Loss=  7554.28321603
Iteration 36 Loss=  28058.3981709
Iteration 37 Loss=  5430.02945878
Iteration 38 Loss=  637.919986484
Iteration 39 Loss=  74.9428547755
Iteration 40 Loss=  8.80428831342
Iteration 41 Loss=  1.03439330967
Iteration 42 Loss=  0.122790597122
Iteration 43 Loss=  124172.749918
Iteration 44 Loss=  41084.4464274
Iteration 45 Loss=  33517.5636268
Iteration 46 Loss=  8040.69894546
Iteration 47 Loss=  2105.96583806
Iteration 48 Loss=  247.408915393
Iteration 49 Loss=  29.0656051061
Iteration 50 Loss=  3.41462796054
Iteration 51 Loss=  0.401242784608
Iteration 52 Loss=  0.0506221005196
Iteration 53 Loss=  98380.003458
Iteration 54 Loss=  21793.3870392
Iteration 55 Loss=  5097.0115705
Iteration 56 Loss=  598.797037262
Iteration 57 Loss=  70.3466897954
Iteration 58 Loss=  8.26433074519
Iteration 59 Loss=  0.970893883995
Iteration 60 Loss=  0.114643748025
Iteration 61 Loss=  0.0310394623038
Iteration 62 Loss=  16368.8910045
Iteration 63 Loss=  7888.34252234
Iteration 64 Loss=  16277.3068705
Iteration 65 Loss=  67453.1952517
Iteration 66 Loss=  3311.54969561
Iteration 67 Loss=  389.040934879
Iteration 68 Loss=  45.7045380331
Iteration 69 Loss=  5.36937225987
Iteration 70 Loss=  11.8105907143
Iteration 71 Loss=  28974.6121556
Iteration 72 Loss=  17616.3505529
Iteration 73 Loss=  40854.4245719
Iteration 74 Loss=  4712.38193139
Iteration 75 Loss=  553.610738358
Iteration 76 Loss=  65.0382024464
Iteration 77 Loss=  7.64126641432
Iteration 78 Loss=  0.897730174734
Iteration 79 Loss=  0.120160171251
Iteration 80 Loss=  36339.0155894
Iteration 81 Loss=  10687.1474109
Iteration 82 Loss=  1298.86938293
Iteration 83 Loss=  152.591938665
Iteration 84 Loss=  17.9348586371
Iteration 85 Loss=  2.10698760775
Iteration 86 Loss=  0.24752944788
Iteration 87 Loss=  16.1454486243
Iteration 88 Loss=  27726.9097224
Iteration 89 Loss=  7830.47849068
Iteration 90 Loss=  2327.03897353
Iteration 91 Loss=  11943.6052073
Iteration 92 Loss=  33672.4836118
Iteration 93 Loss=  5934.17942884
Iteration 94 Loss=  697.147536634
Iteration 95 Loss=  81.9009087378
Iteration 96 Loss=  9.62172067262
Iteration 97 Loss=  1.1305036617
Iteration 98 Loss=  69199.4864661
Iteration 99 Loss=  20336.3295041
Iteration 100 Loss=  17957.4320228
[-0.77883448 -0.36918599  0.41686376 ...,  0.11852862  0.11809526
  0.01691384]
CROSS VALIDATION 2
Iteration 1 Loss=  20143.9402097
Iteration 2 Loss=  10018.8057925
Iteration 3 Loss=  10478.4799712
Iteration 4 Loss=  20543.4586046
Iteration 5 Loss=  19094.3613361
Iteration 6 Loss=  1081.59148473
Iteration 7 Loss=  7627.57993813
Iteration 8 Loss=  51173.0781854
Iteration 9 Loss=  52959.0850066
Iteration 10 Loss=  16440.0432065
Iteration 11 Loss=  17267.2508957
Iteration 12 Loss=  12405.8038262
Iteration 13 Loss=  17200.8073946
Iteration 14 Loss=  15243.7764883
Iteration 15 Loss=  11823.8908891
Iteration 16 Loss=  12095.6653747
Iteration 17 Loss=  1901.91881613
Iteration 18 Loss=  36569.3679199
Iteration 19 Loss=  41014.6866865
Iteration 20 Loss=  32178.318738
Iteration 21 Loss=  2920.77510496
Iteration 22 Loss=  21319.415531
Iteration 23 Loss=  16536.7029445
Iteration 24 Loss=  4840.37877578
Iteration 25 Loss=  568.647810599
Iteration 26 Loss=  66.8047579494
Iteration 27 Loss=  7.84822450995
Iteration 28 Loss=  0.922048768487
Iteration 29 Loss=  0.111654290154
Iteration 30 Loss=  4355.17297295
Iteration 31 Loss=  22800.12811
Iteration 32 Loss=  21754.6216346
Iteration 33 Loss=  14431.584643
Iteration 34 Loss=  6882.42144077
Iteration 35 Loss=  1244.40487558
Iteration 36 Loss=  84858.9511378
Iteration 37 Loss=  45484.9680188
Iteration 38 Loss=  10627.9258618
Iteration 39 Loss=  23349.1196185
Iteration 40 Loss=  31135.2784861
Iteration 41 Loss=  4024.63074519
Iteration 42 Loss=  23325.7373438
Iteration 43 Loss=  34035.453962
Iteration 44 Loss=  3313.15254653
Iteration 45 Loss=  389.229237842
Iteration 46 Loss=  45.7266598696
Iteration 47 Loss=  5.37196905973
Iteration 48 Loss=  0.631127782066
Iteration 49 Loss=  101335.970178
Iteration 50 Loss=  37026.6748406
Iteration 51 Loss=  2377.94253952
Iteration 52 Loss=  279.360744576
Iteration 53 Loss=  32.819306738
Iteration 54 Loss=  3.85561291512
Iteration 55 Loss=  0.453132114517
Iteration 56 Loss=  49.9641230468
Iteration 57 Loss=  35131.9845942
Iteration 58 Loss=  7165.33216302
Iteration 59 Loss=  3868.07872126
Iteration 60 Loss=  33721.7681133
Iteration 61 Loss=  18534.9425782
Iteration 62 Loss=  12734.8967708
Iteration 63 Loss=  23699.5988147
Iteration 64 Loss=  3409.2583578
Iteration 65 Loss=  21016.5863479
Iteration 66 Loss=  32133.1337781
Iteration 67 Loss=  9350.10654926
Iteration 68 Loss=  908.293510084
Iteration 69 Loss=  106.706342586
Iteration 70 Loss=  12.5367284139
Iteration 71 Loss=  1.47577834762
Iteration 72 Loss=  0.173466764676
Iteration 73 Loss=  98016.0186304
Iteration 74 Loss=  20087.7165471
Iteration 75 Loss=  15737.5893729
Iteration 76 Loss=  1612.13202092
Iteration 77 Loss=  22739.8260515
Iteration 78 Loss=  35734.3218049
Iteration 79 Loss=  18830.9210143
Iteration 80 Loss=  5221.94749237
Iteration 81 Loss=  23137.4552265
Iteration 82 Loss=  15299.3874365
Iteration 83 Loss=  13809.0354858
Iteration 84 Loss=  34624.4609741
Iteration 85 Loss=  2338.60286476
Iteration 86 Loss=  274.739195188
Iteration 87 Loss=  32.2812470418
Iteration 88 Loss=  3.79240164955
Iteration 89 Loss=  0.445556495324
Iteration 90 Loss=  97393.5517744
Iteration 91 Loss=  19979.3500741
Iteration 92 Loss=  15802.4344875
Iteration 93 Loss=  1610.15560146
Iteration 94 Loss=  22733.4689705
Iteration 95 Loss=  35728.3059543
Iteration 96 Loss=  18802.2816647
Iteration 97 Loss=  5219.48484022
Iteration 98 Loss=  23124.9145004
Iteration 99 Loss=  15298.5387056
Iteration 100 Loss=  13808.9851987
[-0.47295908 -0.37998241  0.46932359 ...,  0.16779999  0.02170876
  0.14521541]
CROSS VALIDATION 3
Iteration 1 Loss=  27407.4260099
Iteration 2 Loss=  17018.6386903
Iteration 3 Loss=  6618.83740939
Iteration 4 Loss=  16291.5595006
Iteration 5 Loss=  17018.9725273
Iteration 6 Loss=  5052.24624167
Iteration 7 Loss=  40580.4712612
Iteration 8 Loss=  11969.7093113
Iteration 9 Loss=  25125.6665705
Iteration 10 Loss=  13532.2295981
Iteration 11 Loss=  23817.9277899
Iteration 12 Loss=  21477.8462572
Iteration 13 Loss=  29914.1856818
Iteration 14 Loss=  7892.22671487
Iteration 15 Loss=  25412.9447126
Iteration 16 Loss=  28370.5165942
Iteration 17 Loss=  21977.3003007
Iteration 18 Loss=  1240.12331478
Iteration 19 Loss=  145.689715721
Iteration 20 Loss=  17.1156311746
Iteration 21 Loss=  2.01074482784
Iteration 22 Loss=  0.241627063235
Iteration 23 Loss=  36625.3653124
Iteration 24 Loss=  10726.9019416
Iteration 25 Loss=  1298.73818875
Iteration 26 Loss=  152.577520836
Iteration 27 Loss=  17.9541007436
Iteration 28 Loss=  2.10924817086
Iteration 29 Loss=  0.247794871608
Iteration 30 Loss=  0.0903446050578
Iteration 31 Loss=  37768.0310812
Iteration 32 Loss=  19340.6068067
Iteration 33 Loss=  3450.79528328
Iteration 34 Loss=  50069.7940267
Iteration 35 Loss=  13156.8587758
Iteration 36 Loss=  16237.5341594
Iteration 37 Loss=  20403.0483097
Iteration 38 Loss=  30777.5437071
Iteration 39 Loss=  3947.59056483
Iteration 40 Loss=  28696.2974164
Iteration 41 Loss=  17543.397994
Iteration 42 Loss=  1190.20855162
Iteration 43 Loss=  18593.0669126
Iteration 44 Loss=  18127.7611749
Iteration 45 Loss=  19523.9344381
Iteration 46 Loss=  33230.3236532
Iteration 47 Loss=  3463.89511255
Iteration 48 Loss=  1387.81239543
Iteration 49 Loss=  48576.6113051
Iteration 50 Loss=  19128.7534549
Iteration 51 Loss=  43075.6502253
Iteration 52 Loss=  5822.57174143
Iteration 53 Loss=  31290.9661217
Iteration 54 Loss=  6454.37563841
Iteration 55 Loss=  25362.5307859
Iteration 56 Loss=  48579.9003642
Iteration 57 Loss=  7959.93756679
Iteration 58 Loss=  8845.9658034
Iteration 59 Loss=  9478.39439183
Iteration 60 Loss=  5840.85607426
Iteration 61 Loss=  6401.07810342
Iteration 62 Loss=  20200.5442256
Iteration 63 Loss=  8313.54829288
Iteration 64 Loss=  37978.8547545
Iteration 65 Loss=  55228.0437382
Iteration 66 Loss=  12295.467929
Iteration 67 Loss=  14121.6282141
Iteration 68 Loss=  4329.5077196
Iteration 69 Loss=  20999.739721
Iteration 70 Loss=  47599.2580634
Iteration 71 Loss=  6215.44698788
Iteration 72 Loss=  6859.67002577
Iteration 73 Loss=  25826.5752576
Iteration 74 Loss=  8909.0114512
Iteration 75 Loss=  26382.8857781
Iteration 76 Loss=  37923.0060941
Iteration 77 Loss=  26784.9660515
Iteration 78 Loss=  14984.6909511
Iteration 79 Loss=  1732.5836682
Iteration 80 Loss=  67051.5389911
Iteration 81 Loss=  13256.7620755
Iteration 82 Loss=  6758.89120618
Iteration 83 Loss=  25163.9800881
Iteration 84 Loss=  6212.97015447
Iteration 85 Loss=  28815.6359532
Iteration 86 Loss=  18186.3729913
Iteration 87 Loss=  1961.1117922
Iteration 88 Loss=  230.391458734
Iteration 89 Loss=  27.066393904
Iteration 90 Loss=  3.17979023181
Iteration 91 Loss=  0.373737419709
Iteration 92 Loss=  0.0455245738629
Iteration 93 Loss=  33589.7547154
Iteration 94 Loss=  24759.4737688
Iteration 95 Loss=  3827.95456631
Iteration 96 Loss=  33744.7861153
Iteration 97 Loss=  14222.4893338
Iteration 98 Loss=  4372.25339299
Iteration 99 Loss=  38109.1776211
Iteration 100 Loss=  20551.3495437
[-0.26359922  0.22257267 -0.52909713 ...,  0.58177967  0.13502155
  0.17862518]
CROSS VALIDATION 4
Iteration 1 Loss=  27407.4260099
Iteration 2 Loss=  17018.6386903
Iteration 3 Loss=  6245.02021553
Iteration 4 Loss=  23669.2149392
Iteration 5 Loss=  29720.4312507
Iteration 6 Loss=  14759.6329849
Iteration 7 Loss=  21217.7174974
Iteration 8 Loss=  15263.1804948
Iteration 9 Loss=  5033.0520396
Iteration 10 Loss=  16317.593847
Iteration 11 Loss=  15551.2058216
Iteration 12 Loss=  10247.7467632
Iteration 13 Loss=  13960.4910142
Iteration 14 Loss=  9066.73254027
Iteration 15 Loss=  19997.0200742
Iteration 16 Loss=  30306.8064069
Iteration 17 Loss=  10202.9298661
Iteration 18 Loss=  34502.9450788
Iteration 19 Loss=  25416.4727157
Iteration 20 Loss=  12213.1814242
Iteration 21 Loss=  14448.9660655
Iteration 22 Loss=  40497.8464229
Iteration 23 Loss=  3506.54929153
Iteration 24 Loss=  16721.8892329
Iteration 25 Loss=  51208.6188816
Iteration 26 Loss=  21872.7063658
Iteration 27 Loss=  4394.11386935
Iteration 28 Loss=  28876.0216073
Iteration 29 Loss=  25409.232835
Iteration 30 Loss=  3822.44980907
Iteration 31 Loss=  14792.7141973
Iteration 32 Loss=  22683.3619229
Iteration 33 Loss=  11116.0781979
Iteration 34 Loss=  14527.2930689
Iteration 35 Loss=  2403.06067193
Iteration 36 Loss=  42118.4565822
Iteration 37 Loss=  37351.6134921
Iteration 38 Loss=  7917.34377946
Iteration 39 Loss=  19986.7563164
Iteration 40 Loss=  21969.2524132
Iteration 41 Loss=  3594.88963111
Iteration 42 Loss=  422.327717059
Iteration 43 Loss=  49.6150699739
Iteration 44 Loss=  5.82877956914
Iteration 45 Loss=  0.68534747236
Iteration 46 Loss=  0.0822746471645
Iteration 47 Loss=  0.0119259055893
Iteration 48 Loss=  19124.5021098
Iteration 49 Loss=  33062.0607772
Iteration 50 Loss=  11767.4276623
Iteration 51 Loss=  28699.7873982
Iteration 52 Loss=  4704.25671598
Iteration 53 Loss=  9990.84213546
Iteration 54 Loss=  9897.3473878
Iteration 55 Loss=  3586.6614427
Iteration 56 Loss=  7933.51785438
Iteration 57 Loss=  20819.2805134
Iteration 58 Loss=  3485.12563919
Iteration 59 Loss=  15315.5175709
Iteration 60 Loss=  27598.1223
Iteration 61 Loss=  4967.64934019
Iteration 62 Loss=  583.599559451
Iteration 63 Loss=  68.5612897505
Iteration 64 Loss=  8.05458192203
Iteration 65 Loss=  0.946358502506
Iteration 66 Loss=  12.9351235291
Iteration 67 Loss=  30239.2095617
Iteration 68 Loss=  16557.8685965
Iteration 69 Loss=  24667.4856083
Iteration 70 Loss=  2521.74481992
Iteration 71 Loss=  5335.11845711
Iteration 72 Loss=  57790.6551271
Iteration 73 Loss=  5704.91493002
Iteration 74 Loss=  670.213538008
Iteration 75 Loss=  78.7367019559
Iteration 76 Loss=  9.24998956868
Iteration 77 Loss=  1.08671810109
Iteration 78 Loss=  105595.682809
Iteration 79 Loss=  37080.850773
Iteration 80 Loss=  2378.53262215
Iteration 81 Loss=  279.430067496
Iteration 82 Loss=  32.8274507963
Iteration 83 Loss=  3.85656967927
Iteration 84 Loss=  0.453171782606
Iteration 85 Loss=  33.5119177701
Iteration 86 Loss=  32024.415529
Iteration 87 Loss=  12362.6535775
Iteration 88 Loss=  20523.5164221
Iteration 89 Loss=  18567.8710736
Iteration 90 Loss=  4067.32622132
Iteration 91 Loss=  6472.12611321
Iteration 92 Loss=  942.68153279
Iteration 93 Loss=  30426.8877591
Iteration 94 Loss=  4396.15318232
Iteration 95 Loss=  516.460177599
Iteration 96 Loss=  60.6737536167
Iteration 97 Loss=  7.12795397906
Iteration 98 Loss=  0.837392946975
Iteration 99 Loss=  0.11991091939
Iteration 100 Loss=  29486.1321131
[-1.3884826   0.06340174 -0.37011376 ...,  0.10605739 -0.54691191
  0.10520479]
CROSS VALIDATION 5
Iteration 1 Loss=  23826.4791247
Iteration 2 Loss=  16527.5980148
Iteration 3 Loss=  2354.96729682
Iteration 4 Loss=  276.661612531
Iteration 5 Loss=  32.5022126429
Iteration 6 Loss=  3.8183606935
Iteration 7 Loss=  0.448744858026
Iteration 8 Loss=  0.0542112258361
Iteration 9 Loss=  136925.443812
Iteration 10 Loss=  78770.6872025
Iteration 11 Loss=  18436.2864505
Iteration 12 Loss=  8015.69615897
Iteration 13 Loss=  15617.233567
Iteration 14 Loss=  13710.0555696
Iteration 15 Loss=  13378.2288226
Iteration 16 Loss=  57113.7102559
Iteration 17 Loss=  22137.1985207
Iteration 18 Loss=  18675.6034987
Iteration 19 Loss=  19534.4438424
Iteration 20 Loss=  10936.0786064
Iteration 21 Loss=  32870.5663713
Iteration 22 Loss=  16415.4255736
Iteration 23 Loss=  41391.3459653
Iteration 24 Loss=  6833.93881903
Iteration 25 Loss=  27456.1474504
Iteration 26 Loss=  9255.88051227
Iteration 27 Loss=  14686.6159425
Iteration 28 Loss=  35005.1692928
Iteration 29 Loss=  41326.5101837
Iteration 30 Loss=  2562.27992582
Iteration 31 Loss=  301.016704984
Iteration 32 Loss=  35.3634494679
Iteration 33 Loss=  4.15450415606
Iteration 34 Loss=  0.491198869687
Iteration 35 Loss=  41534.0403513
Iteration 36 Loss=  7242.13893251
Iteration 37 Loss=  26740.8552315
Iteration 38 Loss=  52469.6559488
Iteration 39 Loss=  11995.9905335
Iteration 40 Loss=  13802.863212
Iteration 41 Loss=  13244.3233163
Iteration 42 Loss=  5374.92750236
Iteration 43 Loss=  12887.3928028
Iteration 44 Loss=  8547.06879286
Iteration 45 Loss=  6771.52669535
Iteration 46 Loss=  3222.90852874
Iteration 47 Loss=  33266.767045
Iteration 48 Loss=  27756.5051639
Iteration 49 Loss=  14777.1601853
Iteration 50 Loss=  8975.67132247
Iteration 51 Loss=  35678.9773523
Iteration 52 Loss=  19288.8877656
Iteration 53 Loss=  21754.1541143
Iteration 54 Loss=  12315.031132
Iteration 55 Loss=  8081.34635655
Iteration 56 Loss=  18262.5254355
Iteration 57 Loss=  22928.4403974
Iteration 58 Loss=  15863.276625
Iteration 59 Loss=  15029.7424248
Iteration 60 Loss=  9565.66925378
Iteration 61 Loss=  15994.9747466
Iteration 62 Loss=  4915.54313828
Iteration 63 Loss=  577.478121646
Iteration 64 Loss=  67.8421430955
Iteration 65 Loss=  7.97009654092
Iteration 66 Loss=  0.936327126081
Iteration 67 Loss=  0.110157357179
Iteration 68 Loss=  137969.104415
Iteration 69 Loss=  78858.4676232
Iteration 70 Loss=  18457.8856361
Iteration 71 Loss=  8016.27696937
Iteration 72 Loss=  15619.009962
Iteration 73 Loss=  13709.6738117
Iteration 74 Loss=  13377.876273
Iteration 75 Loss=  57114.0376425
Iteration 76 Loss=  22137.1823201
Iteration 77 Loss=  18675.5892929
Iteration 78 Loss=  19534.4427429
Iteration 79 Loss=  10936.0826615
Iteration 80 Loss=  32870.5664999
Iteration 81 Loss=  16415.4255177
Iteration 82 Loss=  41391.3459141
Iteration 83 Loss=  6833.93880427
Iteration 84 Loss=  27456.147459
Iteration 85 Loss=  9255.88051425
Iteration 86 Loss=  14686.6159435
Iteration 87 Loss=  35005.1692924
Iteration 88 Loss=  41326.5101836
Iteration 89 Loss=  2562.27992582
Iteration 90 Loss=  301.016704984
Iteration 91 Loss=  35.3634494679
Iteration 92 Loss=  4.15450415606
Iteration 93 Loss=  0.491198869687
Iteration 94 Loss=  41534.0403499
Iteration 95 Loss=  7242.13893292
Iteration 96 Loss=  26740.855232
Iteration 97 Loss=  52469.6559486
Iteration 98 Loss=  11995.9905335
Iteration 99 Loss=  13802.863212
Iteration 100 Loss=  13244.3233163
[-0.79224076 -0.35947002 -1.05929347 ...,  0.49862977 -0.27113056
  0.26840643]
CROSS VALIDATION 6
Iteration 1 Loss=  27407.4260099
Iteration 2 Loss=  16915.7400903
Iteration 3 Loss=  6580.02583276
Iteration 4 Loss=  23898.9849916
Iteration 5 Loss=  31678.8923095
Iteration 6 Loss=  5407.73657525
Iteration 7 Loss=  635.301018012
Iteration 8 Loss=  74.6351782987
Iteration 9 Loss=  8.76814248664
Iteration 10 Loss=  1.03204342683
Iteration 11 Loss=  17671.8219878
Iteration 12 Loss=  32880.0517387
Iteration 13 Loss=  4222.00705116
Iteration 14 Loss=  27042.7070836
Iteration 15 Loss=  21438.6200003
Iteration 16 Loss=  18683.2026282
Iteration 17 Loss=  9798.22311914
Iteration 18 Loss=  14120.3812407
Iteration 19 Loss=  6924.73766526
Iteration 20 Loss=  43391.4874485
Iteration 21 Loss=  24261.765662
Iteration 22 Loss=  11474.5301706
Iteration 23 Loss=  19189.8359448
Iteration 24 Loss=  13414.3285598
Iteration 25 Loss=  15790.1709595
Iteration 26 Loss=  8828.52668711
Iteration 27 Loss=  33677.476259
Iteration 28 Loss=  39297.1443743
Iteration 29 Loss=  3713.4193366
Iteration 30 Loss=  436.252589604
Iteration 31 Loss=  51.2509643228
Iteration 32 Loss=  6.02096447474
Iteration 33 Loss=  0.707383942075
Iteration 34 Loss=  103704.643191
Iteration 35 Loss=  33888.7554829
Iteration 36 Loss=  23165.3229997
Iteration 37 Loss=  8513.90622772
Iteration 38 Loss=  34092.9770972
Iteration 39 Loss=  6650.80369132
Iteration 40 Loss=  5319.25833653
Iteration 41 Loss=  31372.5577441
Iteration 42 Loss=  8917.69705492
Iteration 43 Loss=  33620.4233138
Iteration 44 Loss=  13846.8594952
Iteration 45 Loss=  70426.7723838
Iteration 46 Loss=  25732.562143
Iteration 47 Loss=  15405.1643274
Iteration 48 Loss=  14273.8207217
Iteration 49 Loss=  9034.26568022
Iteration 50 Loss=  37818.4121424
Iteration 51 Loss=  57859.9840717
Iteration 52 Loss=  4156.45731898
Iteration 53 Loss=  488.301346738
Iteration 54 Loss=  57.3708433939
Iteration 55 Loss=  6.73992800964
Iteration 56 Loss=  0.791808734393
Iteration 57 Loss=  0.103786068861
Iteration 58 Loss=  31336.565315
Iteration 59 Loss=  5765.23225306
Iteration 60 Loss=  7667.09250511
Iteration 61 Loss=  19828.064623
Iteration 62 Loss=  31776.8524142
Iteration 63 Loss=  13924.9335567
Iteration 64 Loss=  45363.8011688
Iteration 65 Loss=  19489.8386256
Iteration 66 Loss=  33882.498584
Iteration 67 Loss=  9306.44058409
Iteration 68 Loss=  477.496055022
Iteration 69 Loss=  56.0962475947
Iteration 70 Loss=  6.59018846566
Iteration 71 Loss=  0.774215558891
Iteration 72 Loss=  10.5466535401
Iteration 73 Loss=  34627.2915917
Iteration 74 Loss=  8112.2962076
Iteration 75 Loss=  4425.1639578
Iteration 76 Loss=  1723.24694678
Iteration 77 Loss=  24725.1901624
Iteration 78 Loss=  21129.9304795
Iteration 79 Loss=  6317.83288026
Iteration 80 Loss=  7456.44608678
Iteration 81 Loss=  28998.0196199
Iteration 82 Loss=  2266.05873568
Iteration 83 Loss=  35028.5118448
Iteration 84 Loss=  7646.52363905
Iteration 85 Loss=  898.313774078
Iteration 86 Loss=  105.533922968
Iteration 87 Loss=  12.3981277141
Iteration 88 Loss=  1.45751561014
Iteration 89 Loss=  51157.0976883
Iteration 90 Loss=  17102.9669066
Iteration 91 Loss=  5719.69867472
Iteration 92 Loss=  14094.9198271
Iteration 93 Loss=  27614.4561501
Iteration 94 Loss=  22107.9122018
Iteration 95 Loss=  21884.9394287
Iteration 96 Loss=  15064.6889228
Iteration 97 Loss=  29336.8214335
Iteration 98 Loss=  9912.670275
Iteration 99 Loss=  4726.45932406
Iteration 100 Loss=  33163.9193611
[-1.15992492 -0.4923409  -1.22028558 ...,  0.61728672 -0.70701219
  0.12267738]
CROSS VALIDATION 7
Iteration 1 Loss=  27407.4260099
Iteration 2 Loss=  16915.7400903
Iteration 3 Loss=  6580.02583276
Iteration 4 Loss=  16370.1190211
Iteration 5 Loss=  16931.8423116
Iteration 6 Loss=  5040.51343827
Iteration 7 Loss=  40523.4144995
Iteration 8 Loss=  11961.7414854
Iteration 9 Loss=  25148.2522064
Iteration 10 Loss=  13388.9240332
Iteration 11 Loss=  22402.3615427
Iteration 12 Loss=  16061.9557334
Iteration 13 Loss=  25406.4763293
Iteration 14 Loss=  9628.5448707
Iteration 15 Loss=  62989.3200459
Iteration 16 Loss=  20038.8301106
Iteration 17 Loss=  20143.8242446
Iteration 18 Loss=  18153.3052288
Iteration 19 Loss=  3054.06548732
Iteration 20 Loss=  2585.16229843
Iteration 21 Loss=  40709.7672496
Iteration 22 Loss=  41400.120323
Iteration 23 Loss=  15893.4094362
Iteration 24 Loss=  18352.3331188
Iteration 25 Loss=  4596.62949344
Iteration 26 Loss=  17875.6021845
Iteration 27 Loss=  43881.1426932
Iteration 28 Loss=  7610.0475826
Iteration 29 Loss=  36727.9062175
Iteration 30 Loss=  24642.1007667
Iteration 31 Loss=  2994.12705896
Iteration 32 Loss=  23531.5927171
Iteration 33 Loss=  17244.3387215
Iteration 34 Loss=  9324.09821034
Iteration 35 Loss=  11452.0548009
Iteration 36 Loss=  13615.5215571
Iteration 37 Loss=  10512.8277612
Iteration 38 Loss=  3892.47219913
Iteration 39 Loss=  30236.1436712
Iteration 40 Loss=  28976.8706776
Iteration 41 Loss=  8045.70665558
Iteration 42 Loss=  32723.3332957
Iteration 43 Loss=  25317.346329
Iteration 44 Loss=  8597.22348337
Iteration 45 Loss=  9900.82290717
Iteration 46 Loss=  18356.4843784
Iteration 47 Loss=  8931.0096329
Iteration 48 Loss=  30977.8766905
Iteration 49 Loss=  14675.886049
Iteration 50 Loss=  2988.66333912
Iteration 51 Loss=  22119.1828842
Iteration 52 Loss=  15566.8118114
Iteration 53 Loss=  14972.2548163
Iteration 54 Loss=  27773.9345359
Iteration 55 Loss=  4503.60233571
Iteration 56 Loss=  2914.81149151
Iteration 57 Loss=  342.432121479
Iteration 58 Loss=  40.2289335563
Iteration 59 Loss=  4.72609604521
Iteration 60 Loss=  0.55525428752
Iteration 61 Loss=  91213.4058519
Iteration 62 Loss=  56664.7225208
Iteration 63 Loss=  21636.8149854
Iteration 64 Loss=  1985.73181917
Iteration 65 Loss=  19072.8767129
Iteration 66 Loss=  14550.2368337
Iteration 67 Loss=  14695.1072092
Iteration 68 Loss=  1694.73178634
Iteration 69 Loss=  199.09712948
Iteration 70 Loss=  23.389935379
Iteration 71 Loss=  2.74792844618
Iteration 72 Loss=  0.323172546646
Iteration 73 Loss=  0.201822616332
Iteration 74 Loss=  40886.0345132
Iteration 75 Loss=  2910.75769743
Iteration 76 Loss=  11478.2700097
Iteration 77 Loss=  25675.7908078
Iteration 78 Loss=  18233.027684
Iteration 79 Loss=  8466.87572482
Iteration 80 Loss=  9833.78702501
Iteration 81 Loss=  4204.51637174
Iteration 82 Loss=  22416.333127
Iteration 83 Loss=  60278.7288701
Iteration 84 Loss=  10125.9078555
Iteration 85 Loss=  9906.3926394
Iteration 86 Loss=  17853.6735898
Iteration 87 Loss=  2382.88486176
Iteration 88 Loss=  19375.3268738
Iteration 89 Loss=  24784.165413
Iteration 90 Loss=  5955.20142198
Iteration 91 Loss=  24680.5641968
Iteration 92 Loss=  22113.0822278
Iteration 93 Loss=  10205.7512357
Iteration 94 Loss=  20864.366168
Iteration 95 Loss=  8042.47177863
Iteration 96 Loss=  2683.58513195
Iteration 97 Loss=  315.267643408
Iteration 98 Loss=  37.0376500438
Iteration 99 Loss=  4.35118398649
Iteration 100 Loss=  0.511669580536
[-0.00853684 -0.00608484 -0.00025368 ...,  0.00516658  0.00225367
 -0.00079081]
CROSS VALIDATION 8
Iteration 1 Loss=  27407.4260099
Iteration 2 Loss=  16915.7400903
Iteration 3 Loss=  6580.02583276
Iteration 4 Loss=  16370.1190211
Iteration 5 Loss=  16931.8423116
Iteration 6 Loss=  5040.51343827
Iteration 7 Loss=  40523.4144995
Iteration 8 Loss=  11961.7414854
Iteration 9 Loss=  25148.2522064
Iteration 10 Loss=  13388.9240332
Iteration 11 Loss=  23699.2264204
Iteration 12 Loss=  16061.9704643
Iteration 13 Loss=  26274.3108391
Iteration 14 Loss=  9628.54922149
Iteration 15 Loss=  60054.7078849
Iteration 16 Loss=  16271.4825824
Iteration 17 Loss=  10421.3719951
Iteration 18 Loss=  11419.816
Iteration 19 Loss=  13035.9245724
Iteration 20 Loss=  3997.47069708
Iteration 21 Loss=  4047.14998662
Iteration 22 Loss=  29964.4718256
Iteration 23 Loss=  28258.074521
Iteration 24 Loss=  2365.7330083
Iteration 25 Loss=  25360.6813137
Iteration 26 Loss=  3649.38088427
Iteration 27 Loss=  428.729350741
Iteration 28 Loss=  50.3671340472
Iteration 29 Loss=  5.91713207351
Iteration 30 Loss=  0.69526563185
Iteration 31 Loss=  62.2947644779
Iteration 32 Loss=  31336.0853987
Iteration 33 Loss=  5784.5708451
Iteration 34 Loss=  7657.89360141
Iteration 35 Loss=  19848.5432634
Iteration 36 Loss=  31778.8293158
Iteration 37 Loss=  13931.3502769
Iteration 38 Loss=  44747.8624306
Iteration 39 Loss=  19488.4545959
Iteration 40 Loss=  34585.012865
Iteration 41 Loss=  9306.40266118
Iteration 42 Loss=  477.495958921
Iteration 43 Loss=  56.0962363047
Iteration 44 Loss=  6.59018713931
Iteration 45 Loss=  0.774215403077
Iteration 46 Loss=  10.5474893784
Iteration 47 Loss=  34627.2997204
Iteration 48 Loss=  23764.3231528
Iteration 49 Loss=  9642.63899528
Iteration 50 Loss=  21814.4779248
Iteration 51 Loss=  11883.2059731
Iteration 52 Loss=  5384.31735946
Iteration 53 Loss=  6985.12702665
Iteration 54 Loss=  27079.7981191
Iteration 55 Loss=  38697.3756607
Iteration 56 Loss=  21013.342298
Iteration 57 Loss=  9002.4522376
Iteration 58 Loss=  11135.7313057
Iteration 59 Loss=  11279.4995028
Iteration 60 Loss=  10617.0693698
Iteration 61 Loss=  30009.8074616
Iteration 62 Loss=  8944.24920487
Iteration 63 Loss=  16613.7561456
Iteration 64 Loss=  14612.5920766
Iteration 65 Loss=  19258.6797826
Iteration 66 Loss=  21139.1435557
Iteration 67 Loss=  33157.6442767
Iteration 68 Loss=  11292.6196427
Iteration 69 Loss=  1585.56231459
Iteration 70 Loss=  64455.5133849
Iteration 71 Loss=  14640.7183791
Iteration 72 Loss=  18019.1182416
Iteration 73 Loss=  19875.0121316
Iteration 74 Loss=  11061.6922917
Iteration 75 Loss=  13976.8760649
Iteration 76 Loss=  64342.2898145
Iteration 77 Loss=  21984.648493
Iteration 78 Loss=  21489.4591305
Iteration 79 Loss=  24378.8006534
Iteration 80 Loss=  21574.1762734
Iteration 81 Loss=  19516.6028817
Iteration 82 Loss=  20118.908186
Iteration 83 Loss=  36879.3542908
Iteration 84 Loss=  18042.1454415
Iteration 85 Loss=  47584.1958164
Iteration 86 Loss=  15571.0241745
Iteration 87 Loss=  2902.83383128
Iteration 88 Loss=  50688.9384181
Iteration 89 Loss=  11023.8152114
Iteration 90 Loss=  24510.8874524
Iteration 91 Loss=  42427.2763661
Iteration 92 Loss=  3856.20719083
Iteration 93 Loss=  24730.5489318
Iteration 94 Loss=  73891.152795
Iteration 95 Loss=  4338.64314907
Iteration 96 Loss=  30818.1258783
Iteration 97 Loss=  12983.2906545
Iteration 98 Loss=  14469.7080296
Iteration 99 Loss=  14347.4438522
Iteration 100 Loss=  4050.21649453
[-0.32771562 -0.52068423  0.01635836 ..., -0.04009854 -0.01402441
  0.02235863]
CROSS VALIDATION 9
Iteration 1 Loss=  34968.5690306
Iteration 2 Loss=  5352.85106136
Iteration 3 Loss=  628.85306657
Iteration 4 Loss=  73.8776728141
Iteration 5 Loss=  8.67916342444
Iteration 6 Loss=  1.0277018911
Iteration 7 Loss=  20718.3602936
Iteration 8 Loss=  18649.8876201
Iteration 9 Loss=  7210.65810264
Iteration 10 Loss=  2037.07293777
Iteration 11 Loss=  239.315375879
Iteration 12 Loss=  28.1147879197
Iteration 13 Loss=  3.3060649782
Iteration 14 Loss=  0.388482540201
Iteration 15 Loss=  70630.407418
Iteration 16 Loss=  21763.200424
Iteration 17 Loss=  1123.49746682
Iteration 18 Loss=  131.988508403
Iteration 19 Loss=  15.5060513999
Iteration 20 Loss=  1.82931642349
Iteration 21 Loss=  0.21560251047
Iteration 22 Loss=  67272.4386087
Iteration 23 Loss=  10554.7090344
Iteration 24 Loss=  25906.2023832
Iteration 25 Loss=  16061.2798046
Iteration 26 Loss=  14818.3301295
Iteration 27 Loss=  6077.94610217
Iteration 28 Loss=  23228.6968606
Iteration 29 Loss=  19301.2886846
Iteration 30 Loss=  40950.8099563
Iteration 31 Loss=  6311.33841916
Iteration 32 Loss=  1490.10348354
Iteration 33 Loss=  175.057391731
Iteration 34 Loss=  20.565746432
Iteration 35 Loss=  2.41618130889
Iteration 36 Loss=  127395.869883
Iteration 37 Loss=  51272.8403006
Iteration 38 Loss=  14694.6293155
Iteration 39 Loss=  28515.8273741
Iteration 40 Loss=  2909.38813795
Iteration 41 Loss=  24861.7410614
Iteration 42 Loss=  6270.47250418
Iteration 43 Loss=  22821.7015786
Iteration 44 Loss=  11276.7267991
Iteration 45 Loss=  10761.6645416
Iteration 46 Loss=  33271.9536761
Iteration 47 Loss=  15650.3210191
Iteration 48 Loss=  1402.54165197
Iteration 49 Loss=  164.770625732
Iteration 50 Loss=  19.3572569243
Iteration 51 Loss=  2.27410215996
Iteration 52 Loss=  88204.4221577
Iteration 53 Loss=  70729.2297512
Iteration 54 Loss=  4209.46918793
Iteration 55 Loss=  494.528537617
Iteration 56 Loss=  58.0972241401
Iteration 57 Loss=  6.82915618715
Iteration 58 Loss=  0.805903979318
Iteration 59 Loss=  0.0948922306474
Iteration 60 Loss=  34401.5726361
Iteration 61 Loss=  33214.7810588
Iteration 62 Loss=  23456.457527
Iteration 63 Loss=  33065.6891561
Iteration 64 Loss=  18701.5841195
Iteration 65 Loss=  5840.87286179
Iteration 66 Loss=  12857.7817656
Iteration 67 Loss=  30523.7145833
Iteration 68 Loss=  30383.6568931
Iteration 69 Loss=  3719.79171897
Iteration 70 Loss=  27725.0120285
Iteration 71 Loss=  12263.4704071
Iteration 72 Loss=  33925.246085
Iteration 73 Loss=  13639.6494229
Iteration 74 Loss=  25624.2027902
Iteration 75 Loss=  42931.3483653
Iteration 76 Loss=  12742.6741216
Iteration 77 Loss=  6411.61403606
Iteration 78 Loss=  15465.7740266
Iteration 79 Loss=  18831.3932824
Iteration 80 Loss=  16650.222467
Iteration 81 Loss=  57226.0401526
Iteration 82 Loss=  3403.41370467
Iteration 83 Loss=  35670.6775261
Iteration 84 Loss=  13838.1144579
Iteration 85 Loss=  7447.24371014
Iteration 86 Loss=  8670.40261874
Iteration 87 Loss=  13917.1334622
Iteration 88 Loss=  16989.6911258
Iteration 89 Loss=  38740.5452582
Iteration 90 Loss=  5661.0017463
Iteration 91 Loss=  35664.1444408
Iteration 92 Loss=  3550.52880415
Iteration 93 Loss=  4834.88323897
Iteration 94 Loss=  34371.6933848
Iteration 95 Loss=  19955.1919859
Iteration 96 Loss=  5618.68185135
Iteration 97 Loss=  73156.591272
Iteration 98 Loss=  31671.6138045
Iteration 99 Loss=  26236.1528746
Iteration 100 Loss=  11980.4756122
[-1.05404258 -0.85629305 -0.49249582 ...,  0.41310739  0.04345014
 -0.02153756]
CROSS VALIDATION 10
Iteration 1 Loss=  27396.3021008
Iteration 2 Loss=  10877.6633329
Iteration 3 Loss=  875.974473805
Iteration 4 Loss=  102.909501455
Iteration 5 Loss=  12.0898106126
Iteration 6 Loss=  1.42031123056
Iteration 7 Loss=  0.166907266672
Iteration 8 Loss=  98074.7687416
Iteration 9 Loss=  24946.1832339
Iteration 10 Loss=  4535.81275654
Iteration 11 Loss=  6825.1094309
Iteration 12 Loss=  22500.6143968
Iteration 13 Loss=  19326.3237676
Iteration 14 Loss=  4033.10135673
Iteration 15 Loss=  473.808840726
Iteration 16 Loss=  55.6630735739
Iteration 17 Loss=  6.53929928193
Iteration 18 Loss=  0.78242365729
Iteration 19 Loss=  0.0926765424071
Iteration 20 Loss=  61357.5020966
Iteration 21 Loss=  27303.5167166
Iteration 22 Loss=  4475.0238367
Iteration 23 Loss=  25555.3522673
Iteration 24 Loss=  20108.3052873
Iteration 25 Loss=  16925.6613319
Iteration 26 Loss=  34268.1438363
Iteration 27 Loss=  3841.44240298
Iteration 28 Loss=  37844.0997549
Iteration 29 Loss=  17233.2191687
Iteration 30 Loss=  1846.83387789
Iteration 31 Loss=  216.966086716
Iteration 32 Loss=  25.4891808886
Iteration 33 Loss=  2.99446964486
Iteration 34 Loss=  0.355274467703
Iteration 35 Loss=  46039.0283088
Iteration 36 Loss=  17243.5754124
Iteration 37 Loss=  3338.8702728
Iteration 38 Loss=  20808.4573944
Iteration 39 Loss=  16727.6280911
Iteration 40 Loss=  16353.2306848
Iteration 41 Loss=  7623.86270325
Iteration 42 Loss=  32525.0492922
Iteration 43 Loss=  30638.4707354
Iteration 44 Loss=  24763.9359752
Iteration 45 Loss=  21957.0153977
Iteration 46 Loss=  20235.0357571
Iteration 47 Loss=  18007.1959468
Iteration 48 Loss=  15173.1155416
Iteration 49 Loss=  971.162861174
Iteration 50 Loss=  37107.9278109
Iteration 51 Loss=  19632.1160031
Iteration 52 Loss=  7618.99191409
Iteration 53 Loss=  5917.80098917
Iteration 54 Loss=  13128.8228918
Iteration 55 Loss=  53096.7888916
Iteration 56 Loss=  3314.66448349
Iteration 57 Loss=  33601.78208
Iteration 58 Loss=  6706.69331112
Iteration 59 Loss=  18527.6168153
Iteration 60 Loss=  21931.3456115
Iteration 61 Loss=  80722.025047
Iteration 62 Loss=  13600.1485072
Iteration 63 Loss=  6423.42283631
Iteration 64 Loss=  23940.9660228
Iteration 65 Loss=  10311.5596934
Iteration 66 Loss=  21881.3553296
Iteration 67 Loss=  51182.3831505
Iteration 68 Loss=  8640.76300877
Iteration 69 Loss=  26980.3048943
Iteration 70 Loss=  54245.9737529
Iteration 71 Loss=  3922.77366979
Iteration 72 Loss=  5171.31819697
Iteration 73 Loss=  13718.46716
Iteration 74 Loss=  54644.9089672
Iteration 75 Loss=  3216.22834775
Iteration 76 Loss=  753.201381465
Iteration 77 Loss=  88.4861157258
Iteration 78 Loss=  10.3953509234
Iteration 79 Loss=  1.22127381855
Iteration 80 Loss=  109.874144417
Iteration 81 Loss=  33637.4849378
Iteration 82 Loss=  21798.9437806
Iteration 83 Loss=  10785.4482193
Iteration 84 Loss=  75092.5278178
Iteration 85 Loss=  3863.51312034
Iteration 86 Loss=  22391.8085903
Iteration 87 Loss=  24481.900854
Iteration 88 Loss=  5489.44572642
Iteration 89 Loss=  7223.64382612
Iteration 90 Loss=  26370.7793363
Iteration 91 Loss=  23831.1800725
Iteration 92 Loss=  25027.5680077
Iteration 93 Loss=  24986.1297662
Iteration 94 Loss=  21345.9610228
Iteration 95 Loss=  4901.69857687
Iteration 96 Loss=  22711.1881942
Iteration 97 Loss=  15949.9472619
Iteration 98 Loss=  17277.0842743
Iteration 99 Loss=  17163.6863448
Iteration 100 Loss=  34928.3533962
[-0.24553863 -0.53486867 -1.14361237 ...,  0.58100564 -0.09123346
  0.26736217]
CROSS VALIDATION 11
Iteration 1 Loss=  27396.3021008
Iteration 2 Loss=  14169.0163029
Iteration 3 Loss=  4430.06568583
Iteration 4 Loss=  16351.1121299
Iteration 5 Loss=  16783.37897
Iteration 6 Loss=  5032.57339908
Iteration 7 Loss=  29975.7303817
Iteration 8 Loss=  17809.1228398
Iteration 9 Loss=  8888.48195723
Iteration 10 Loss=  18499.5985476
Iteration 11 Loss=  10475.0526539
Iteration 12 Loss=  14849.4895202
Iteration 13 Loss=  35247.5310446
Iteration 14 Loss=  2896.07663658
Iteration 15 Loss=  340.231150289
Iteration 16 Loss=  39.9703634099
Iteration 17 Loss=  4.69571921842
Iteration 18 Loss=  0.551660883825
Iteration 19 Loss=  0.0738587116478
Iteration 20 Loss=  20193.4152405
Iteration 21 Loss=  17277.2712311
Iteration 22 Loss=  26975.1132653
Iteration 23 Loss=  31362.4209461
Iteration 24 Loss=  14103.0009434
Iteration 25 Loss=  1488.99681252
Iteration 26 Loss=  18565.9117373
Iteration 27 Loss=  29651.8704942
Iteration 28 Loss=  10212.5556608
Iteration 29 Loss=  35765.1134062
Iteration 30 Loss=  13111.9583923
Iteration 31 Loss=  23141.2377432
Iteration 32 Loss=  15434.7793765
Iteration 33 Loss=  12561.8749034
Iteration 34 Loss=  24568.4378008
Iteration 35 Loss=  1671.88625932
Iteration 36 Loss=  26932.6552296
Iteration 37 Loss=  7404.07408258
Iteration 38 Loss=  20468.7766293
Iteration 39 Loss=  6957.40226837
Iteration 40 Loss=  20494.2332984
Iteration 41 Loss=  40653.6793249
Iteration 42 Loss=  7852.087193
Iteration 43 Loss=  11034.6165345
Iteration 44 Loss=  24639.6687013
Iteration 45 Loss=  8617.30130912
Iteration 46 Loss=  24012.2696452
Iteration 47 Loss=  14619.8001628
Iteration 48 Loss=  8682.08458974
Iteration 49 Loss=  6658.65670563
Iteration 50 Loss=  28086.5382161
Iteration 51 Loss=  24642.7130002
Iteration 52 Loss=  1150.6995264
Iteration 53 Loss=  135.184206992
Iteration 54 Loss=  15.881443766
Iteration 55 Loss=  1.86575238158
Iteration 56 Loss=  0.220013320951
Iteration 57 Loss=  52858.7304415
Iteration 58 Loss=  14862.144282
Iteration 59 Loss=  8796.07706343
Iteration 60 Loss=  9412.17342491
Iteration 61 Loss=  35891.2268853
Iteration 62 Loss=  24762.2938538
Iteration 63 Loss=  15438.498921
Iteration 64 Loss=  7830.17327267
Iteration 65 Loss=  66434.7939243
Iteration 66 Loss=  50936.9028046
Iteration 67 Loss=  5242.29159201
Iteration 68 Loss=  20352.0105453
Iteration 69 Loss=  10537.5434362
Iteration 70 Loss=  8008.62420606
Iteration 71 Loss=  11317.5048021
Iteration 72 Loss=  35488.1499464
Iteration 73 Loss=  22888.9368762
Iteration 74 Loss=  15515.8929747
Iteration 75 Loss=  10735.2351379
Iteration 76 Loss=  21769.3421361
Iteration 77 Loss=  24464.4439083
Iteration 78 Loss=  17591.8148958
Iteration 79 Loss=  50987.3855648
Iteration 80 Loss=  17775.2308937
Iteration 81 Loss=  12950.0185297
Iteration 82 Loss=  32471.6451262
Iteration 83 Loss=  29465.8658461
Iteration 84 Loss=  21257.1388857
Iteration 85 Loss=  7920.49060502
Iteration 86 Loss=  17776.7854885
Iteration 87 Loss=  9076.62177775
Iteration 88 Loss=  3115.58056901
Iteration 89 Loss=  366.018477351
Iteration 90 Loss=  42.9998591899
Iteration 91 Loss=  5.05162445277
Iteration 92 Loss=  0.593530175988
Iteration 93 Loss=  105749.501507
Iteration 94 Loss=  26944.3031385
Iteration 95 Loss=  5904.11618926
Iteration 96 Loss=  6929.63891639
Iteration 97 Loss=  36613.203412
Iteration 98 Loss=  19366.9643982
Iteration 99 Loss=  1296.05329644
Iteration 100 Loss=  152.26037126
[-0.19694469 -0.14638977 -0.01077358 ...,  0.05406069  0.0056074
 -0.00588313]
CROSS VALIDATION 12
Iteration 1 Loss=  28534.8756222
Iteration 2 Loss=  8381.88190035
Iteration 3 Loss=  10220.6485833
Iteration 4 Loss=  12048.7214261
Iteration 5 Loss=  12085.8421679
Iteration 6 Loss=  15199.3716995
Iteration 7 Loss=  4316.90471685
Iteration 8 Loss=  507.150066041
Iteration 9 Loss=  59.5800242572
Iteration 10 Loss=  7.08162816509
Iteration 11 Loss=  0.83197593207
Iteration 12 Loss=  0.0978186924008
Iteration 13 Loss=  0.0578347746328
Iteration 14 Loss=  24305.95252
Iteration 15 Loss=  4645.13247799
Iteration 16 Loss=  545.710271017
Iteration 17 Loss=  64.1100552684
Iteration 18 Loss=  7.53165077663
Iteration 19 Loss=  0.884819111334
Iteration 20 Loss=  0.107387259605
Iteration 21 Loss=  33947.9212654
Iteration 22 Loss=  17230.0750886
Iteration 23 Loss=  68982.3649572
Iteration 24 Loss=  14226.8226147
Iteration 25 Loss=  4914.19119954
Iteration 26 Loss=  31327.2517322
Iteration 27 Loss=  19018.1633928
Iteration 28 Loss=  4732.94682452
Iteration 29 Loss=  28150.1957862
Iteration 30 Loss=  21012.0202963
Iteration 31 Loss=  13954.2187992
Iteration 32 Loss=  11901.6576241
Iteration 33 Loss=  61922.9212746
Iteration 34 Loss=  15376.9730141
Iteration 35 Loss=  8606.52114879
Iteration 36 Loss=  9770.08023091
Iteration 37 Loss=  26777.8888263
Iteration 38 Loss=  19510.7772321
Iteration 39 Loss=  14309.592193
Iteration 40 Loss=  36455.3828313
Iteration 41 Loss=  4872.44716051
Iteration 42 Loss=  26258.7443812
Iteration 43 Loss=  41243.8785231
Iteration 44 Loss=  1754.23518828
Iteration 45 Loss=  206.087590517
Iteration 46 Loss=  24.2111749034
Iteration 47 Loss=  2.84432939718
Iteration 48 Loss=  0.335940639735
Iteration 49 Loss=  49165.2803478
Iteration 50 Loss=  24832.0298736
Iteration 51 Loss=  3258.12741682
Iteration 52 Loss=  382.765484746
Iteration 53 Loss=  44.9688943432
Iteration 54 Loss=  5.30077706297
Iteration 55 Loss=  0.623020113227
Iteration 56 Loss=  0.0752006879338
Iteration 57 Loss=  0.0206928618393
Iteration 58 Loss=  25539.6428524
Iteration 59 Loss=  7684.20457731
Iteration 60 Loss=  8877.86274917
Iteration 61 Loss=  34207.0734167
Iteration 62 Loss=  28347.3485428
Iteration 63 Loss=  7191.29350398
Iteration 64 Loss=  64766.7433821
Iteration 65 Loss=  26663.9420074
Iteration 66 Loss=  3000.24946117
Iteration 67 Loss=  29907.4035988
Iteration 68 Loss=  6120.95756017
Iteration 69 Loss=  15064.5287899
Iteration 70 Loss=  32942.3732957
Iteration 71 Loss=  13538.9892076
Iteration 72 Loss=  19278.383034
Iteration 73 Loss=  22878.7583395
Iteration 74 Loss=  9137.58646901
Iteration 75 Loss=  598.318886228
Iteration 76 Loss=  70.2905261218
Iteration 77 Loss=  8.25826047276
Iteration 78 Loss=  0.970180631461
Iteration 79 Loss=  0.113993178846
Iteration 80 Loss=  0.0174295083609
Iteration 81 Loss=  22442.8836703
Iteration 82 Loss=  35030.5825857
Iteration 83 Loss=  9043.99018482
Iteration 84 Loss=  31722.5451981
Iteration 85 Loss=  30346.2719869
Iteration 86 Loss=  22007.0781303
Iteration 87 Loss=  3865.87009162
Iteration 88 Loss=  53053.8844367
Iteration 89 Loss=  18326.5240908
Iteration 90 Loss=  11919.8193179
Iteration 91 Loss=  2083.75888164
Iteration 92 Loss=  244.80004164
Iteration 93 Loss=  28.7591145572
Iteration 94 Loss=  3.37862164782
Iteration 95 Loss=  0.398987618798
Iteration 96 Loss=  68932.5594495
Iteration 97 Loss=  12447.292994
Iteration 98 Loss=  4269.7472682
Iteration 99 Loss=  501.610007883
Iteration 100 Loss=  58.9291553348
[-0.10165875  0.04459065 -0.07697009 ...,  0.07631969  0.00020931
  0.01010691]
CROSS VALIDATION 13
Iteration 1 Loss=  42095.7436006
Iteration 2 Loss=  7104.16127695
Iteration 3 Loss=  19637.6565677
Iteration 4 Loss=  19432.0391478
Iteration 5 Loss=  17395.7352396
Iteration 6 Loss=  5670.13890611
Iteration 7 Loss=  13497.8833585
Iteration 8 Loss=  33612.7651852
Iteration 9 Loss=  23288.2977635
Iteration 10 Loss=  14327.9168237
Iteration 11 Loss=  27841.8875641
Iteration 12 Loss=  10604.9624577
Iteration 13 Loss=  13268.1990145
Iteration 14 Loss=  15312.6339503
Iteration 15 Loss=  10636.4128746
Iteration 16 Loss=  17857.1406233
Iteration 17 Loss=  2964.56753052
Iteration 18 Loss=  19437.1713754
Iteration 19 Loss=  3906.1810358
Iteration 20 Loss=  41763.5282702
Iteration 21 Loss=  16413.3091295
Iteration 22 Loss=  17889.2765175
Iteration 23 Loss=  30218.918951
Iteration 24 Loss=  1170.49206505
Iteration 25 Loss=  137.509434891
Iteration 26 Loss=  16.1546348786
Iteration 27 Loss=  90.494274655
Iteration 28 Loss=  66523.6197668
Iteration 29 Loss=  12740.3413014
Iteration 30 Loss=  6722.66059869
Iteration 31 Loss=  12712.8434341
Iteration 32 Loss=  14101.599035
Iteration 33 Loss=  8097.94953277
Iteration 34 Loss=  30568.7880867
Iteration 35 Loss=  11458.3063432
Iteration 36 Loss=  13423.1062279
Iteration 37 Loss=  26492.1274798
Iteration 38 Loss=  46959.2565675
Iteration 39 Loss=  27093.4926844
Iteration 40 Loss=  12525.451916
Iteration 41 Loss=  55849.3217763
Iteration 42 Loss=  1845.63739147
Iteration 43 Loss=  216.825523463
Iteration 44 Loss=  25.4726901109
Iteration 45 Loss=  2.99850789805
Iteration 46 Loss=  0.352705896169
Iteration 47 Loss=  0.0428809388944
Iteration 48 Loss=  68874.2361873
Iteration 49 Loss=  13115.2926018
Iteration 50 Loss=  18165.4129446
Iteration 51 Loss=  23248.6213642
Iteration 52 Loss=  9971.06502362
Iteration 53 Loss=  32716.1971405
Iteration 54 Loss=  50491.8472107
Iteration 55 Loss=  11318.1047144
Iteration 56 Loss=  23754.0360248
Iteration 57 Loss=  19345.5753496
Iteration 58 Loss=  36378.6958971
Iteration 59 Loss=  18206.2225522
Iteration 60 Loss=  18739.7177465
Iteration 61 Loss=  9340.051033
Iteration 62 Loss=  41302.1644415
Iteration 63 Loss=  37821.5877262
Iteration 64 Loss=  19065.2137467
Iteration 65 Loss=  21357.2026745
Iteration 66 Loss=  20405.3184936
Iteration 67 Loss=  21114.3463161
Iteration 68 Loss=  8822.97285215
Iteration 69 Loss=  25828.6967495
Iteration 70 Loss=  21707.2484288
Iteration 71 Loss=  10209.6052352
Iteration 72 Loss=  16320.1085397
Iteration 73 Loss=  20812.0176569
Iteration 74 Loss=  21785.2317889
Iteration 75 Loss=  13821.7699029
Iteration 76 Loss=  7207.53952845
Iteration 77 Loss=  15087.3468881
Iteration 78 Loss=  23081.4473308
Iteration 79 Loss=  14757.3660886
Iteration 80 Loss=  16554.8834759
Iteration 81 Loss=  5269.39694234
Iteration 82 Loss=  37302.2601163
Iteration 83 Loss=  15925.0243049
Iteration 84 Loss=  4126.99762631
Iteration 85 Loss=  484.83977665
Iteration 86 Loss=  56.9589881814
Iteration 87 Loss=  6.69154324975
Iteration 88 Loss=  0.786122783228
Iteration 89 Loss=  0.094176201517
Iteration 90 Loss=  55043.34914
Iteration 91 Loss=  24667.4926365
Iteration 92 Loss=  36732.9147537
Iteration 93 Loss=  8323.20185925
Iteration 94 Loss=  40221.8768635
Iteration 95 Loss=  20592.8882717
Iteration 96 Loss=  16103.7187653
Iteration 97 Loss=  27915.9331908
Iteration 98 Loss=  6859.55589404
Iteration 99 Loss=  15881.7484429
Iteration 100 Loss=  35426.7652226
[-1.40751488 -1.08589333 -0.61657973 ...,  0.64455991  0.04563254
  0.1274558 ]
CROSS VALIDATION 14
Iteration 1 Loss=  27391.1406951
Iteration 2 Loss=  17030.7918966
Iteration 3 Loss=  6613.49308328
Iteration 4 Loss=  15816.6169269
Iteration 5 Loss=  11854.6868028
Iteration 6 Loss=  16905.6734204
Iteration 7 Loss=  16396.2377142
Iteration 8 Loss=  16510.4804258
Iteration 9 Loss=  28486.6586976
Iteration 10 Loss=  17384.0260995
Iteration 11 Loss=  34195.0654805
Iteration 12 Loss=  24247.1732379
Iteration 13 Loss=  23119.6417274
Iteration 14 Loss=  6282.06996098
Iteration 15 Loss=  23006.2162357
Iteration 16 Loss=  3411.33702852
Iteration 17 Loss=  25916.164131
Iteration 18 Loss=  29893.5338808
Iteration 19 Loss=  3480.41723135
Iteration 20 Loss=  16677.892494
Iteration 21 Loss=  15708.2550508
Iteration 22 Loss=  20808.7026442
Iteration 23 Loss=  6052.82646164
Iteration 24 Loss=  2483.7059641
Iteration 25 Loss=  291.785834142
Iteration 26 Loss=  34.2790065478
Iteration 27 Loss=  4.02709848255
Iteration 28 Loss=  0.473105831602
Iteration 29 Loss=  0.0597428644027
Iteration 30 Loss=  32225.2087382
Iteration 31 Loss=  7953.60554253
Iteration 32 Loss=  3150.23785054
Iteration 33 Loss=  370.090015588
Iteration 34 Loss=  43.4781836958
Iteration 35 Loss=  5.11094363257
Iteration 36 Loss=  8.32634877689
Iteration 37 Loss=  43964.7436683
Iteration 38 Loss=  67878.186068
Iteration 39 Loss=  2777.68721346
Iteration 40 Loss=  24633.8720426
Iteration 41 Loss=  17403.0979765
Iteration 42 Loss=  1644.16667212
Iteration 43 Loss=  20068.5662465
Iteration 44 Loss=  34161.4388285
Iteration 45 Loss=  1581.91685838
Iteration 46 Loss=  185.843629133
Iteration 47 Loss=  21.8329138515
Iteration 48 Loss=  2.56493122455
Iteration 49 Loss=  0.30132834874
Iteration 50 Loss=  0.0402719967605
Iteration 51 Loss=  37702.0326196
Iteration 52 Loss=  20741.1258504
Iteration 53 Loss=  1347.4709604
Iteration 54 Loss=  158.300919612
Iteration 55 Loss=  18.5971956996
Iteration 56 Loss=  2.18479898118
Iteration 57 Loss=  0.256671617178
Iteration 58 Loss=  0.0350729057909
Iteration 59 Loss=  32214.8465726
Iteration 60 Loss=  7923.68987863
Iteration 61 Loss=  3150.21638316
Iteration 62 Loss=  370.087493599
Iteration 63 Loss=  43.477887449
Iteration 64 Loss=  5.11103674019
Iteration 65 Loss=  8.52195685349
Iteration 66 Loss=  43963.858493
Iteration 67 Loss=  67877.8435409
Iteration 68 Loss=  2776.71087253
Iteration 69 Loss=  24633.87672
Iteration 70 Loss=  17403.013018
Iteration 71 Loss=  1644.16792924
Iteration 72 Loss=  20068.5680424
Iteration 73 Loss=  34161.4351888
Iteration 74 Loss=  1581.91685935
Iteration 75 Loss=  185.843629247
Iteration 76 Loss=  21.8329138649
Iteration 77 Loss=  2.56493122612
Iteration 78 Loss=  0.301328348923
Iteration 79 Loss=  0.0402719904919
Iteration 80 Loss=  37702.03283
Iteration 81 Loss=  20741.1252664
Iteration 82 Loss=  1347.47096205
Iteration 83 Loss=  158.300919806
Iteration 84 Loss=  18.5971957223
Iteration 85 Loss=  2.18479898385
Iteration 86 Loss=  0.256671617492
Iteration 87 Loss=  0.0350729055681
Iteration 88 Loss=  32214.8465711
Iteration 89 Loss=  7923.68987848
Iteration 90 Loss=  3150.21638316
Iteration 91 Loss=  370.087493599
Iteration 92 Loss=  43.477887449
Iteration 93 Loss=  5.11103674016
Iteration 94 Loss=  8.52195672733
Iteration 95 Loss=  43963.8584939
Iteration 96 Loss=  67877.8435412
Iteration 97 Loss=  2776.7108728
Iteration 98 Loss=  24633.87672
Iteration 99 Loss=  17403.013018
Iteration 100 Loss=  1644.16792924
[-0.70792046 -0.26396635 -0.40150026 ...,  0.1812147   0.1022395
 -0.03396788]
CROSS VALIDATION 15
Iteration 1 Loss=  27391.1406951
Iteration 2 Loss=  17030.7918966
Iteration 3 Loss=  6613.49308328
Iteration 4 Loss=  16302.1562928
Iteration 5 Loss=  16853.5325242
Iteration 6 Loss=  4766.08447974
Iteration 7 Loss=  21554.0065958
Iteration 8 Loss=  23097.1615962
Iteration 9 Loss=  26867.4553653
Iteration 10 Loss=  31294.1628776
Iteration 11 Loss=  5630.84736191
Iteration 12 Loss=  21516.4504033
Iteration 13 Loss=  63766.0788713
Iteration 14 Loss=  6740.77853247
Iteration 15 Loss=  19377.4463968
Iteration 16 Loss=  2377.61190575
Iteration 17 Loss=  279.321901862
Iteration 18 Loss=  32.8161273688
Iteration 19 Loss=  3.85523940454
Iteration 20 Loss=  0.453117440197
Iteration 21 Loss=  110136.713322
Iteration 22 Loss=  75815.3213852
Iteration 23 Loss=  11237.4818742
Iteration 24 Loss=  2132.07386802
Iteration 25 Loss=  16464.934336
Iteration 26 Loss=  41400.1594768
Iteration 27 Loss=  34335.7030807
Iteration 28 Loss=  3970.20058542
Iteration 29 Loss=  3828.7397549
Iteration 30 Loss=  8031.03761286
Iteration 31 Loss=  56436.8377584
Iteration 32 Loss=  22411.8823678
Iteration 33 Loss=  4006.73133333
Iteration 34 Loss=  3737.89901407
Iteration 35 Loss=  30358.5844623
Iteration 36 Loss=  9901.91830631
Iteration 37 Loss=  10718.0691026
Iteration 38 Loss=  16128.2277637
Iteration 39 Loss=  15136.4581319
Iteration 40 Loss=  25785.7450551
Iteration 41 Loss=  3104.20881709
Iteration 42 Loss=  364.682523673
Iteration 43 Loss=  42.8429113209
Iteration 44 Loss=  5.03318621349
Iteration 45 Loss=  0.591298843772
Iteration 46 Loss=  0.137925176349
Iteration 47 Loss=  32339.2057562
Iteration 48 Loss=  3444.4872936
Iteration 49 Loss=  404.658446968
Iteration 50 Loss=  47.5392837148
Iteration 51 Loss=  5.58491615101
Iteration 52 Loss=  0.656167764557
Iteration 53 Loss=  0.0774526292388
Iteration 54 Loss=  48475.9674211
Iteration 55 Loss=  14767.6796261
Iteration 56 Loss=  21182.0145678
Iteration 57 Loss=  44291.4430445
Iteration 58 Loss=  16565.4894848
Iteration 59 Loss=  7468.53512559
Iteration 60 Loss=  54782.3436386
Iteration 61 Loss=  18423.7853272
Iteration 62 Loss=  11128.2418986
Iteration 63 Loss=  23591.384474
Iteration 64 Loss=  64436.569543
Iteration 65 Loss=  34225.8751411
Iteration 66 Loss=  14430.0489584
Iteration 67 Loss=  21852.9093564
Iteration 68 Loss=  13966.2191846
Iteration 69 Loss=  17879.0103633
Iteration 70 Loss=  37631.0976067
Iteration 71 Loss=  7319.76534852
Iteration 72 Loss=  18996.8445643
Iteration 73 Loss=  18721.9978815
Iteration 74 Loss=  12595.0086604
Iteration 75 Loss=  24638.6014187
Iteration 76 Loss=  23305.8501647
Iteration 77 Loss=  53033.0180645
Iteration 78 Loss=  7815.15444199
Iteration 79 Loss=  32678.4319866
Iteration 80 Loss=  21300.7664748
Iteration 81 Loss=  8362.82562295
Iteration 82 Loss=  2792.41974032
Iteration 83 Loss=  12135.2220505
Iteration 84 Loss=  20352.0498625
Iteration 85 Loss=  2693.72222407
Iteration 86 Loss=  11078.1255827
Iteration 87 Loss=  16893.0187677
Iteration 88 Loss=  9374.95010413
Iteration 89 Loss=  11521.687165
Iteration 90 Loss=  11994.6439464
Iteration 91 Loss=  19959.3347285
Iteration 92 Loss=  9551.05273606
Iteration 93 Loss=  11989.132057
Iteration 94 Loss=  1674.49337393
Iteration 95 Loss=  196.719520322
Iteration 96 Loss=  23.1106138005
Iteration 97 Loss=  2.71567938522
Iteration 98 Loss=  95861.7024402
Iteration 99 Loss=  39975.2878502
Iteration 100 Loss=  9874.83212346
[-0.51698375 -0.29066737 -0.04820444 ...,  0.45852994  0.33523113
  0.10035771]
CROSS VALIDATION 16
Iteration 1 Loss=  27391.1406951
Iteration 2 Loss=  17030.7918966
Iteration 3 Loss=  771.520559378
Iteration 4 Loss=  90.638253171
Iteration 5 Loss=  10.6481840802
Iteration 6 Loss=  1.25124092921
Iteration 7 Loss=  100558.483732
Iteration 8 Loss=  37365.4768995
Iteration 9 Loss=  5231.0723512
Iteration 10 Loss=  13763.9675006
Iteration 11 Loss=  28989.3062948
Iteration 12 Loss=  4908.32638727
Iteration 13 Loss=  7708.79624334
Iteration 14 Loss=  24648.479393
Iteration 15 Loss=  4718.99306411
Iteration 16 Loss=  15837.3423634
Iteration 17 Loss=  36175.6779145
Iteration 18 Loss=  6331.91260136
Iteration 19 Loss=  37315.027779
Iteration 20 Loss=  40061.1516599
Iteration 21 Loss=  8150.73135435
Iteration 22 Loss=  8354.9868582
Iteration 23 Loss=  28421.7978904
Iteration 24 Loss=  7957.47426947
Iteration 25 Loss=  21547.0573351
Iteration 26 Loss=  24834.2872867
Iteration 27 Loss=  48124.9757341
Iteration 28 Loss=  3619.42564094
Iteration 29 Loss=  610.116615636
Iteration 30 Loss=  71.6765142879
Iteration 31 Loss=  8.42080959448
Iteration 32 Loss=  0.989587439421
Iteration 33 Loss=  0.121962671476
Iteration 34 Loss=  57308.5994118
Iteration 35 Loss=  23167.5528552
Iteration 36 Loss=  6263.74575862
Iteration 37 Loss=  2367.45687462
Iteration 38 Loss=  278.128888421
Iteration 39 Loss=  32.6745882511
Iteration 40 Loss=  3.83973715753
Iteration 41 Loss=  72878.2782661
Iteration 42 Loss=  28324.269568
Iteration 43 Loss=  5035.4024314
Iteration 44 Loss=  26564.4799254
Iteration 45 Loss=  2788.7462548
Iteration 46 Loss=  17427.6100268
Iteration 47 Loss=  37436.7971222
Iteration 48 Loss=  1708.34094057
Iteration 49 Loss=  200.695933234
Iteration 50 Loss=  23.5777628824
Iteration 51 Loss=  2.77085877526
Iteration 52 Loss=  0.326261638206
Iteration 53 Loss=  61733.2184199
Iteration 54 Loss=  15166.1010075
Iteration 55 Loss=  3605.73639728
Iteration 56 Loss=  9296.73908947
Iteration 57 Loss=  40638.4023163
Iteration 58 Loss=  9320.95398112
Iteration 59 Loss=  3564.18590833
Iteration 60 Loss=  17292.4632027
Iteration 61 Loss=  18001.2886671
Iteration 62 Loss=  3326.66144318
Iteration 63 Loss=  19013.8155625
Iteration 64 Loss=  34267.646574
Iteration 65 Loss=  14834.1598804
Iteration 66 Loss=  8873.43307606
Iteration 67 Loss=  27008.0676263
Iteration 68 Loss=  27429.132624
Iteration 69 Loss=  3924.3461342
Iteration 70 Loss=  13238.1163921
Iteration 71 Loss=  20464.8862525
Iteration 72 Loss=  4685.13827021
Iteration 73 Loss=  17848.340541
Iteration 74 Loss=  29811.743468
Iteration 75 Loss=  21475.0659379
Iteration 76 Loss=  5168.88050941
Iteration 77 Loss=  29754.7702722
Iteration 78 Loss=  28287.4971904
Iteration 79 Loss=  34691.9219165
Iteration 80 Loss=  5177.96130083
Iteration 81 Loss=  8896.34971754
Iteration 82 Loss=  27084.9493579
Iteration 83 Loss=  65251.9301179
Iteration 84 Loss=  8572.24127467
Iteration 85 Loss=  21933.0250477
Iteration 86 Loss=  17228.6704473
Iteration 87 Loss=  15303.0958208
Iteration 88 Loss=  12516.2912778
Iteration 89 Loss=  12292.480905
Iteration 90 Loss=  702.138258507
Iteration 91 Loss=  82.487218859
Iteration 92 Loss=  9.69060038055
Iteration 93 Loss=  1.13845928052
Iteration 94 Loss=  0.135691122298
Iteration 95 Loss=  106412.914742
Iteration 96 Loss=  37380.3872147
Iteration 97 Loss=  5241.54405627
Iteration 98 Loss=  13756.7963642
Iteration 99 Loss=  29006.1461944
Iteration 100 Loss=  4910.15161786
[-0.38459657 -0.24287248  0.36036077 ...,  0.68391409  0.19616834
 -0.06343638]
CROSS VALIDATION 17
Iteration 1 Loss=  27391.1406951
Iteration 2 Loss=  17030.7918966
Iteration 3 Loss=  6836.0267989
Iteration 4 Loss=  16339.2441797
Iteration 5 Loss=  16876.8622307
Iteration 6 Loss=  5022.86319086
Iteration 7 Loss=  40226.7768975
Iteration 8 Loss=  7242.57814213
Iteration 9 Loss=  20373.5483779
Iteration 10 Loss=  30240.491234
Iteration 11 Loss=  6882.57286883
Iteration 12 Loss=  13050.3213003
Iteration 13 Loss=  19135.2374114
Iteration 14 Loss=  37576.4399068
Iteration 15 Loss=  8053.60824287
Iteration 16 Loss=  17241.2276435
Iteration 17 Loss=  11570.4452783
Iteration 18 Loss=  15479.7489358
Iteration 19 Loss=  20362.6673333
Iteration 20 Loss=  2861.99628164
Iteration 21 Loss=  336.227389403
Iteration 22 Loss=  39.5000014883
Iteration 23 Loss=  4.64069716184
Iteration 24 Loss=  0.554309420061
Iteration 25 Loss=  47505.1944058
Iteration 26 Loss=  26857.1036311
Iteration 27 Loss=  10627.302384
Iteration 28 Loss=  12674.0553412
Iteration 29 Loss=  18914.3570019
Iteration 30 Loss=  44131.9814519
Iteration 31 Loss=  10633.42896
Iteration 32 Loss=  3541.29962604
Iteration 33 Loss=  3893.49444883
Iteration 34 Loss=  40048.508365
Iteration 35 Loss=  23360.670232
Iteration 36 Loss=  2639.47058562
Iteration 37 Loss=  310.085065483
Iteration 38 Loss=  36.4288006693
Iteration 39 Loss=  4.2796563457
Iteration 40 Loss=  0.502899596079
Iteration 41 Loss=  0.0598343614017
Iteration 42 Loss=  75130.020259
Iteration 43 Loss=  28435.6069887
Iteration 44 Loss=  43743.11731
Iteration 45 Loss=  6539.53970276
Iteration 46 Loss=  5748.31432175
Iteration 47 Loss=  33640.0975129
Iteration 48 Loss=  52557.1722321
Iteration 49 Loss=  5275.01331095
Iteration 50 Loss=  21509.5787834
Iteration 51 Loss=  51581.6661782
Iteration 52 Loss=  7294.36513556
Iteration 53 Loss=  20663.9330279
Iteration 54 Loss=  20845.5308054
Iteration 55 Loss=  16105.9068678
Iteration 56 Loss=  13630.7826867
Iteration 57 Loss=  8329.97515159
Iteration 58 Loss=  24544.8658378
Iteration 59 Loss=  5524.11518563
Iteration 60 Loss=  20714.812877
Iteration 61 Loss=  11595.3758075
Iteration 62 Loss=  5945.86461946
Iteration 63 Loss=  20962.7857207
Iteration 64 Loss=  46057.2796046
Iteration 65 Loss=  6861.70298794
Iteration 66 Loss=  16320.6323323
Iteration 67 Loss=  19050.8741814
Iteration 68 Loss=  19184.5104091
Iteration 69 Loss=  26317.9280142
Iteration 70 Loss=  6833.18069836
Iteration 71 Loss=  7371.42769273
Iteration 72 Loss=  18493.2712119
Iteration 73 Loss=  23887.2828596
Iteration 74 Loss=  25546.0742497
Iteration 75 Loss=  12657.8531886
Iteration 76 Loss=  3771.47539203
Iteration 77 Loss=  21312.5374382
Iteration 78 Loss=  18379.8328588
Iteration 79 Loss=  28871.2886354
Iteration 80 Loss=  30457.4585503
Iteration 81 Loss=  4986.57049678
Iteration 82 Loss=  40440.5832594
Iteration 83 Loss=  33298.123768
Iteration 84 Loss=  8884.24529104
Iteration 85 Loss=  8181.96308202
Iteration 86 Loss=  15377.1349823
Iteration 87 Loss=  1566.03493032
Iteration 88 Loss=  183.977819857
Iteration 89 Loss=  21.6137185346
Iteration 90 Loss=  2.53918015364
Iteration 91 Loss=  0.298302959712
Iteration 92 Loss=  4.79005177954
Iteration 93 Loss=  47977.0156367
Iteration 94 Loss=  23962.0957278
Iteration 95 Loss=  8874.91607363
Iteration 96 Loss=  26792.1795945
Iteration 97 Loss=  8789.87167893
Iteration 98 Loss=  20307.5893475
Iteration 99 Loss=  23931.0334666
Iteration 100 Loss=  7005.87889245
[-0.87935972 -0.28516296 -0.22662746 ...,  0.32312508 -0.05205885
  0.0918771 ]
CROSS VALIDATION 18
Iteration 1 Loss=  23685.4557517
Iteration 2 Loss=  4596.25185245
Iteration 3 Loss=  3330.01107936
Iteration 4 Loss=  11162.0076112
Iteration 5 Loss=  10515.8652737
Iteration 6 Loss=  20975.8043818
Iteration 7 Loss=  9282.08471225
Iteration 8 Loss=  6774.38543127
Iteration 9 Loss=  24181.7114021
Iteration 10 Loss=  51226.5920437
Iteration 11 Loss=  5532.82323518
Iteration 12 Loss=  14634.9423497
Iteration 13 Loss=  36685.7227179
Iteration 14 Loss=  7705.31851967
Iteration 15 Loss=  3091.46592599
Iteration 16 Loss=  363.185488531
Iteration 17 Loss=  42.6670395978
Iteration 18 Loss=  5.01252479939
Iteration 19 Loss=  0.588871529438
Iteration 20 Loss=  0.0692259570064
Iteration 21 Loss=  92220.3292715
Iteration 22 Loss=  33245.3607313
Iteration 23 Loss=  46531.9559283
Iteration 24 Loss=  8495.46213268
Iteration 25 Loss=  14999.5700967
Iteration 26 Loss=  1166.88775156
Iteration 27 Loss=  41211.4248269
Iteration 28 Loss=  6838.07346416
Iteration 29 Loss=  2740.88610973
Iteration 30 Loss=  321.999363603
Iteration 31 Loss=  37.8284926881
Iteration 32 Loss=  4.44409219647
Iteration 33 Loss=  0.522092090154
Iteration 34 Loss=  0.0619310699315
Iteration 35 Loss=  77531.6342868
Iteration 36 Loss=  34511.4861649
Iteration 37 Loss=  20192.5325006
Iteration 38 Loss=  2170.46350694
Iteration 39 Loss=  25638.2811046
Iteration 40 Loss=  18425.5575739
Iteration 41 Loss=  11830.8007699
Iteration 42 Loss=  29020.0303829
Iteration 43 Loss=  51943.6320363
Iteration 44 Loss=  20000.2526687
Iteration 45 Loss=  864.09057283
Iteration 46 Loss=  101.513380494
Iteration 47 Loss=  11.9258522321
Iteration 48 Loss=  196.812127278
Iteration 49 Loss=  26454.1115501
Iteration 50 Loss=  12602.5868345
Iteration 51 Loss=  20871.5728517
Iteration 52 Loss=  35902.4342308
Iteration 53 Loss=  19099.4459551
Iteration 54 Loss=  4210.43674778
Iteration 55 Loss=  52640.8509328
Iteration 56 Loss=  2916.9405098
Iteration 57 Loss=  342.682239249
Iteration 58 Loss=  40.2584202486
Iteration 59 Loss=  4.72956104416
Iteration 60 Loss=  0.555827134442
Iteration 61 Loss=  84178.0603584
Iteration 62 Loss=  33298.5935189
Iteration 63 Loss=  5146.60135753
Iteration 64 Loss=  13316.6300674
Iteration 65 Loss=  15921.6383304
Iteration 66 Loss=  23182.5273115
Iteration 67 Loss=  2450.98672546
Iteration 68 Loss=  16842.1860882
Iteration 69 Loss=  7024.97005869
Iteration 70 Loss=  14889.1386679
Iteration 71 Loss=  31637.4961618
Iteration 72 Loss=  4293.49950909
Iteration 73 Loss=  48346.1192035
Iteration 74 Loss=  19151.0040428
Iteration 75 Loss=  20646.2963379
Iteration 76 Loss=  20063.5043363
Iteration 77 Loss=  60977.6188373
Iteration 78 Loss=  17809.2322949
Iteration 79 Loss=  27790.8065983
Iteration 80 Loss=  4305.21068204
Iteration 81 Loss=  37642.6563897
Iteration 82 Loss=  3865.49084977
Iteration 83 Loss=  20727.7915158
Iteration 84 Loss=  30483.3646639
Iteration 85 Loss=  16241.8658905
Iteration 86 Loss=  32906.5315682
Iteration 87 Loss=  16693.4518244
Iteration 88 Loss=  7283.49623232
Iteration 89 Loss=  21902.5023678
Iteration 90 Loss=  2969.75127777
Iteration 91 Loss=  348.886448842
Iteration 92 Loss=  40.9871880842
Iteration 93 Loss=  4.81517880924
Iteration 94 Loss=  0.572522857779
Iteration 95 Loss=  24333.9227528
Iteration 96 Loss=  13981.150918
Iteration 97 Loss=  5509.44283474
Iteration 98 Loss=  19728.7263641
Iteration 99 Loss=  19993.1807095
Iteration 100 Loss=  21707.3747049
[ 0.13625699 -0.31914932  0.19164285 ...,  0.22788439 -0.04223641
  0.03726494]
CROSS VALIDATION 19
Iteration 1 Loss=  27316.9490482
Iteration 2 Loss=  16998.963985
Iteration 3 Loss=  4928.00499673
Iteration 4 Loss=  13662.9888492
Iteration 5 Loss=  13960.0265998
Iteration 6 Loss=  10503.9086232
Iteration 7 Loss=  32503.4894658
Iteration 8 Loss=  15367.6724912
Iteration 9 Loss=  3612.52641133
Iteration 10 Loss=  27453.1526352
Iteration 11 Loss=  2693.84083379
Iteration 12 Loss=  18827.5704935
Iteration 13 Loss=  46337.9635144
Iteration 14 Loss=  3340.99795989
Iteration 15 Loss=  392.500517648
Iteration 16 Loss=  46.110969897
Iteration 17 Loss=  5.41733250284
Iteration 18 Loss=  0.639898929697
Iteration 19 Loss=  58561.6014987
Iteration 20 Loss=  14932.7267596
Iteration 21 Loss=  13028.7973808
Iteration 22 Loss=  8685.5608919
Iteration 23 Loss=  35639.6778037
Iteration 24 Loss=  29914.5639715
Iteration 25 Loss=  4816.63558874
Iteration 26 Loss=  33124.7954877
Iteration 27 Loss=  26541.085755
Iteration 28 Loss=  24244.9353821
Iteration 29 Loss=  16458.2861633
Iteration 30 Loss=  39200.1105985
Iteration 31 Loss=  13236.8486239
Iteration 32 Loss=  8702.73013912
Iteration 33 Loss=  26295.3750858
Iteration 34 Loss=  4308.76053723
Iteration 35 Loss=  42491.5469716
Iteration 36 Loss=  23479.3677876
Iteration 37 Loss=  582.198188747
Iteration 38 Loss=  68.3971657671
Iteration 39 Loss=  8.03530061723
Iteration 40 Loss=  0.94399244009
Iteration 41 Loss=  0.114708856792
Iteration 42 Loss=  20109.7835557
Iteration 43 Loss=  27396.5958706
Iteration 44 Loss=  11898.1042996
Iteration 45 Loss=  3297.06936774
Iteration 46 Loss=  27210.7048792
Iteration 47 Loss=  16802.207054
Iteration 48 Loss=  2636.27650412
Iteration 49 Loss=  24675.1167428
Iteration 50 Loss=  5951.76639398
Iteration 51 Loss=  38617.7747325
Iteration 52 Loss=  56450.9236859
Iteration 53 Loss=  11285.2970877
Iteration 54 Loss=  5106.23240099
Iteration 55 Loss=  23605.8005712
Iteration 56 Loss=  32538.1030445
Iteration 57 Loss=  16537.2629007
Iteration 58 Loss=  5172.58649049
Iteration 59 Loss=  26064.1305938
Iteration 60 Loss=  14823.6428139
Iteration 61 Loss=  18853.5840232
Iteration 62 Loss=  41989.1042366
Iteration 63 Loss=  2828.43674363
Iteration 64 Loss=  28195.8167667
Iteration 65 Loss=  26479.1245231
Iteration 66 Loss=  18271.0059421
Iteration 67 Loss=  622.136587717
Iteration 68 Loss=  73.0886207231
Iteration 69 Loss=  8.58645285403
Iteration 70 Loss=  1.00873669746
Iteration 71 Loss=  0.122556245499
Iteration 72 Loss=  66873.7468398
Iteration 73 Loss=  13468.9295755
Iteration 74 Loss=  13448.8323966
Iteration 75 Loss=  23601.9614853
Iteration 76 Loss=  17632.641436
Iteration 77 Loss=  27646.820292
Iteration 78 Loss=  18205.1270937
Iteration 79 Loss=  24893.1684531
Iteration 80 Loss=  6470.24160795
Iteration 81 Loss=  29767.66829
Iteration 82 Loss=  54641.6890208
Iteration 83 Loss=  13772.4170094
Iteration 84 Loss=  26037.7829634
Iteration 85 Loss=  3468.14013575
Iteration 86 Loss=  407.437183411
Iteration 87 Loss=  47.8657297478
Iteration 88 Loss=  5.62514614966
Iteration 89 Loss=  0.663525025446
Iteration 90 Loss=  0.0846603280204
Iteration 91 Loss=  33578.5793048
Iteration 92 Loss=  11554.2013968
Iteration 93 Loss=  5845.75809842
Iteration 94 Loss=  12219.8221636
Iteration 95 Loss=  29667.994613
Iteration 96 Loss=  10369.0437186
Iteration 97 Loss=  25640.0272855
Iteration 98 Loss=  28120.3678813
Iteration 99 Loss=  7530.38409575
Iteration 100 Loss=  884.669697843
[-0.39997532 -0.02629364 -0.46583586 ...,  0.15745239 -0.03657423
  0.10663795]
Accuracy (Logistic Loss):	0.8 for lmda= 0.1 learning rate= 0.1
---------------------------------------------------------------------------------
lmda= 0.3 learning rate= 0.0001
CROSS VALIDATION 0
Iteration 1 Loss=  5.91796378255
Iteration 2 Loss=  0.067543321922
Iteration 3 Loss=  0.0651755499715
Iteration 4 Loss=  0.0641187012722
Iteration 5 Loss=  0.06335723809
Iteration 6 Loss=  0.0627250942134
Iteration 7 Loss=  0.0621645817001
Iteration 8 Loss=  0.0616493779881
Iteration 9 Loss=  0.0611654470942
Iteration 10 Loss=  0.0607044920378
Iteration 11 Loss=  0.0602612327184
Iteration 12 Loss=  0.0598321168361
Iteration 13 Loss=  0.0594146483518
Iteration 14 Loss=  0.0590070110393
Iteration 15 Loss=  0.058607844793
Iteration 16 Loss=  0.0582161062357
Iteration 17 Loss=  0.0578309783586
Iteration 18 Loss=  0.057451809959
Iteration 19 Loss=  0.0570780738746
Iteration 20 Loss=  0.0567093374603
Iteration 21 Loss=  0.056345241265
Iteration 22 Loss=  0.0559854833342
Iteration 23 Loss=  0.0556298074598
Iteration 24 Loss=  0.0552779942492
Iteration 25 Loss=  0.0549298542467
Iteration 26 Loss=  0.0545852225691
Iteration 27 Loss=  0.0542439546765
Iteration 28 Loss=  0.0539059230033
Iteration 29 Loss=  0.0535710142508
Iteration 30 Loss=  0.0532391271914
Iteration 31 Loss=  0.0529101708745
Iteration 32 Loss=  0.0525840631501
Iteration 33 Loss=  0.052260729445
Iteration 34 Loss=  0.0519401017424
Iteration 35 Loss=  0.0516221177259
Iteration 36 Loss=  0.0513067200577
Iteration 37 Loss=  0.0509938557662
Iteration 38 Loss=  0.0506834757248
Iteration 39 Loss=  0.0503755342057
Iteration 40 Loss=  0.0500699884957
Iteration 41 Loss=  0.0497667985659
Iteration 42 Loss=  0.0494659267839
Iteration 43 Loss=  0.0491673376651
Iteration 44 Loss=  0.0488709976543
Iteration 45 Loss=  0.0485768749351
Iteration 46 Loss=  0.0482849392627
Iteration 47 Loss=  0.047995161816
Iteration 48 Loss=  0.0477075150668
Iteration 49 Loss=  0.0474219726648
Iteration 50 Loss=  0.0471385093343
Iteration 51 Loss=  0.0468571007828
Iteration 52 Loss=  0.0465777236192
Iteration 53 Loss=  0.0463003552807
Iteration 54 Loss=  0.0460249739665
Iteration 55 Loss=  0.0457515585797
Iteration 56 Loss=  0.045480088673
Iteration 57 Loss=  0.0452105444011
Iteration 58 Loss=  0.0449429064773
Iteration 59 Loss=  0.0446771561335
Iteration 60 Loss=  0.0444132750849
Iteration 61 Loss=  0.044151245497
Iteration 62 Loss=  0.0438910499559
Iteration 63 Loss=  0.0436326714415
Iteration 64 Loss=  0.043376093302
Iteration 65 Loss=  0.0431212992319
Iteration 66 Loss=  0.0428682732506
Iteration 67 Loss=  0.0426169996836
Iteration 68 Loss=  0.0423674631445
Iteration 69 Loss=  0.0421196485193
Iteration 70 Loss=  0.0418735409507
Iteration 71 Loss=  0.0416291258251
Iteration 72 Loss=  0.041386388759
Iteration 73 Loss=  0.0411453155879
Iteration 74 Loss=  0.0409058923548
Iteration 75 Loss=  0.0406681053003
Iteration 76 Loss=  0.040431940853
Iteration 77 Loss=  0.040197385621
Iteration 78 Loss=  0.0399644263836
Iteration 79 Loss=  0.0397330500835
Iteration 80 Loss=  0.0395032438202
Iteration 81 Loss=  0.039274994843
Iteration 82 Loss=  0.0390482905454
Iteration 83 Loss=  0.038823118459
Iteration 84 Loss=  0.0385994662484
Iteration 85 Loss=  0.0383773217064
Iteration 86 Loss=  0.0381566727493
Iteration 87 Loss=  0.0379375074131
Iteration 88 Loss=  0.037719813849
Iteration 89 Loss=  0.0375035803205
Iteration 90 Loss=  0.0372887951998
Iteration 91 Loss=  0.0370754469648
Iteration 92 Loss=  0.0368635241968
Iteration 93 Loss=  0.0366530155775
Iteration 94 Loss=  0.0364439098872
Iteration 95 Loss=  0.0362361960028
Iteration 96 Loss=  0.0360298628959
Iteration 97 Loss=  0.0358248996318
Iteration 98 Loss=  0.0356212953677
Iteration 99 Loss=  0.0354190393521
Iteration 100 Loss=  0.0352181209235
[ -1.71654170e-04   6.56685465e-04   2.59922089e-04 ...,   3.83543216e-04
  -1.20577890e-05   2.33649388e-04]
CROSS VALIDATION 1
Iteration 1 Loss=  9.11320823913
Iteration 2 Loss=  0.0764046255333
Iteration 3 Loss=  0.0684680056582
Iteration 4 Loss=  0.0662143333673
Iteration 5 Loss=  0.0647748754496
Iteration 6 Loss=  0.0636902390881
Iteration 7 Loss=  0.0628017886955
Iteration 8 Loss=  0.0620364221501
Iteration 9 Loss=  0.0613547696387
Iteration 10 Loss=  0.0607333903227
Iteration 11 Loss=  0.0601573038797
Iteration 12 Loss=  0.0596164165745
Iteration 13 Loss=  0.0591036410371
Iteration 14 Loss=  0.0586138333034
Iteration 15 Loss=  0.0581431568205
Iteration 16 Loss=  0.0576886840123
Iteration 17 Loss=  0.0572481369818
Iteration 18 Loss=  0.0568197132562
Iteration 19 Loss=  0.0564019654241
Iteration 20 Loss=  0.0559937159958
Iteration 21 Loss=  0.0555939959167
Iteration 22 Loss=  0.0552019993379
Iteration 23 Loss=  0.0548170498
Iteration 24 Loss=  0.0544385745778
Iteration 25 Loss=  0.0540660849578
Iteration 26 Loss=  0.0536991608954
Iteration 27 Loss=  0.0533374389491
Iteration 28 Loss=  0.0529806026965
Iteration 29 Loss=  0.0526283750524
Iteration 30 Loss=  0.0522805120594
Iteration 31 Loss=  0.0519367978298
Iteration 32 Loss=  0.0515970403957
Iteration 33 Loss=  0.0512610682806
Iteration 34 Loss=  0.0509287276505
Iteration 35 Loss=  0.0505998799312
Iteration 36 Loss=  0.0502743998065
Iteration 37 Loss=  0.0499521735257
Iteration 38 Loss=  0.0496330974669
Iteration 39 Loss=  0.049317076912
Iteration 40 Loss=  0.0490040249968
Iteration 41 Loss=  0.0486938618082
Iteration 42 Loss=  0.0483865136046
Iteration 43 Loss=  0.0480819121405
Iteration 44 Loss=  0.0477799940789
Iteration 45 Loss=  0.0474807004787
Iteration 46 Loss=  0.047183976346
Iteration 47 Loss=  0.0468897702407
Iteration 48 Loss=  0.0465980339289
Iteration 49 Loss=  0.0463087220775
Iteration 50 Loss=  0.0460217919831
Iteration 51 Loss=  0.0457372033309
Iteration 52 Loss=  0.0454549179818
Iteration 53 Loss=  0.0451748997809
Iteration 54 Loss=  0.0448971143876
Iteration 55 Loss=  0.0446215291226
Iteration 56 Loss=  0.0443481128313
Iteration 57 Loss=  0.0440768357605
Iteration 58 Loss=  0.0438076694478
Iteration 59 Loss=  0.043540586621
Iteration 60 Loss=  0.043275561108
Iteration 61 Loss=  0.0430125677547
Iteration 62 Loss=  0.0427515823508
Iteration 63 Loss=  0.0424925815619
Iteration 64 Loss=  0.0422355428682
Iteration 65 Loss=  0.041980444508
Iteration 66 Loss=  0.041727265427
Iteration 67 Loss=  0.0414759852309
Iteration 68 Loss=  0.0412265841427
Iteration 69 Loss=  0.0409790429627
Iteration 70 Loss=  0.0407333430329
Iteration 71 Loss=  0.0404894662028
Iteration 72 Loss=  0.040247394799
Iteration 73 Loss=  0.0400071115962
Iteration 74 Loss=  0.0397685997911
Iteration 75 Loss=  0.0395318429773
Iteration 76 Loss=  0.0392968251228
Iteration 77 Loss=  0.0390635305484
Iteration 78 Loss=  0.0388319439079
Iteration 79 Loss=  0.0386020501693
Iteration 80 Loss=  0.0383738345971
Iteration 81 Loss=  0.0381472827362
Iteration 82 Loss=  0.0379223803961
Iteration 83 Loss=  0.0376991136362
Iteration 84 Loss=  0.0374774687521
Iteration 85 Loss=  0.0372574322624
Iteration 86 Loss=  0.0370389908962
Iteration 87 Loss=  0.0368221315815
Iteration 88 Loss=  0.0366068414337
Iteration 89 Loss=  0.0363931077451
Iteration 90 Loss=  0.0361809179747
Iteration 91 Loss=  0.0359702597386
Iteration 92 Loss=  0.0357611208009
Iteration 93 Loss=  0.0355534890645
Iteration 94 Loss=  0.0353473525636
Iteration 95 Loss=  0.0351426994552
Iteration 96 Loss=  0.0349395180121
Iteration 97 Loss=  0.0347377966154
Iteration 98 Loss=  0.0345375237485
Iteration 99 Loss=  0.0343386879906
Iteration 100 Loss=  0.0341412780109
[-0.00073073  0.00040558 -0.00031539 ...,  0.00019841 -0.00015625
  0.00028769]
CROSS VALIDATION 2
Iteration 1 Loss=  2.62520205364
Iteration 2 Loss=  0.066234467482
Iteration 3 Loss=  0.0648007874606
Iteration 4 Loss=  0.0638825586856
Iteration 5 Loss=  0.0631694875855
Iteration 6 Loss=  0.0625621600604
Iteration 7 Loss=  0.0620176769398
Iteration 8 Loss=  0.061514221268
Iteration 9 Loss=  0.0610394405834
Iteration 10 Loss=  0.0605857842847
Iteration 11 Loss=  0.0601483621681
Iteration 12 Loss=  0.0597238598453
Iteration 13 Loss=  0.0593099468112
Iteration 14 Loss=  0.0589049336687
Iteration 15 Loss=  0.0585075638234
Iteration 16 Loss=  0.0581168817104
Iteration 17 Loss=  0.0577321465573
Iteration 18 Loss=  0.0573527742779
Iteration 19 Loss=  0.0569782973179
Iteration 20 Loss=  0.056608336284
Iteration 21 Loss=  0.0562425795017
Iteration 22 Loss=  0.0558807680261
Iteration 23 Loss=  0.0555226844779
Iteration 24 Loss=  0.0551681446093
Iteration 25 Loss=  0.0548169908505
Iteration 26 Loss=  0.0544690873136
Iteration 27 Loss=  0.0541243158831
Iteration 28 Loss=  0.053782573126
Iteration 29 Loss=  0.0534437678279
Iteration 30 Loss=  0.0531078190117
Iteration 31 Loss=  0.0527746543318
Iteration 32 Loss=  0.0524442087625
Iteration 33 Loss=  0.0521164235208
Iteration 34 Loss=  0.0517912451745
Iteration 35 Loss=  0.0514686249007
Iteration 36 Loss=  0.0511485178648
Iteration 37 Loss=  0.050830882698
Iteration 38 Loss=  0.0505156810561
Iteration 39 Loss=  0.0502028772444
Iteration 40 Loss=  0.0498924378968
Iteration 41 Loss=  0.0495843317024
Iteration 42 Loss=  0.0492785291689
Iteration 43 Loss=  0.0489750024185
Iteration 44 Loss=  0.0486737250115
Iteration 45 Loss=  0.0483746717921
Iteration 46 Loss=  0.0480778187542
Iteration 47 Loss=  0.0477831429235
Iteration 48 Loss=  0.0474906222541
Iteration 49 Loss=  0.0472002355376
Iteration 50 Loss=  0.0469119623221
Iteration 51 Loss=  0.0466257828409
Iteration 52 Loss=  0.0463416779491
Iteration 53 Loss=  0.0460596290666
Iteration 54 Loss=  0.0457796181278
Iteration 55 Loss=  0.0455016275364
Iteration 56 Loss=  0.0452256401242
Iteration 57 Loss=  0.0449516391149
Iteration 58 Loss=  0.044679608091
Iteration 59 Loss=  0.0444095309638
Iteration 60 Loss=  0.0441413919464
Iteration 61 Loss=  0.0438751755294
Iteration 62 Loss=  0.0436108664584
Iteration 63 Loss=  0.0433484497138
Iteration 64 Loss=  0.0430879104925
Iteration 65 Loss=  0.0428292341907
Iteration 66 Loss=  0.042572406389
Iteration 67 Loss=  0.042317412838
Iteration 68 Loss=  0.0420642394456
Iteration 69 Loss=  0.0418128722651
Iteration 70 Loss=  0.0415632974847
Iteration 71 Loss=  0.0413155014176
Iteration 72 Loss=  0.0410694704929
Iteration 73 Loss=  0.0408251912476
Iteration 74 Loss=  0.0405826503191
Iteration 75 Loss=  0.0403418344384
Iteration 76 Loss=  0.0401027304238
Iteration 77 Loss=  0.0398653251756
Iteration 78 Loss=  0.0396296056711
Iteration 79 Loss=  0.03939555896
Iteration 80 Loss=  0.0391631721602
Iteration 81 Loss=  0.0389324324548
Iteration 82 Loss=  0.0387033270886
Iteration 83 Loss=  0.0384758433655
Iteration 84 Loss=  0.0382499686465
Iteration 85 Loss=  0.0380256903475
Iteration 86 Loss=  0.0378029959377
Iteration 87 Loss=  0.0375818729387
Iteration 88 Loss=  0.0373623089237
Iteration 89 Loss=  0.0371442915163
Iteration 90 Loss=  0.0369278083908
Iteration 91 Loss=  0.0367128472721
Iteration 92 Loss=  0.0364993959358
Iteration 93 Loss=  0.0362874422085
Iteration 94 Loss=  0.0360769739692
Iteration 95 Loss=  0.0358679791494
Iteration 96 Loss=  0.0356604457347
Iteration 97 Loss=  0.0354543617662
Iteration 98 Loss=  0.0352497153414
Iteration 99 Loss=  0.0350464946165
Iteration 100 Loss=  0.0348446878079
[-0.0011281  -0.00040691 -0.00055763 ...,  0.00062165  0.00037108
  0.00021915]
CROSS VALIDATION 3
Iteration 1 Loss=  8.03924449999
Iteration 2 Loss=  0.0780982478121
Iteration 3 Loss=  0.0636816149442
Iteration 4 Loss=  0.0626607553337
Iteration 5 Loss=  0.061848717507
Iteration 6 Loss=  0.0611573786155
Iteration 7 Loss=  0.0605435646677
Iteration 8 Loss=  0.0599832577459
Iteration 9 Loss=  0.0594618880936
Iteration 10 Loss=  0.0589700398519
Iteration 11 Loss=  0.0585013253184
Iteration 12 Loss=  0.0580512408719
Iteration 13 Loss=  0.0576165099121
Iteration 14 Loss=  0.0571946853369
Iteration 15 Loss=  0.0567838985369
Iteration 16 Loss=  0.0563826951309
Iteration 17 Loss=  0.0559899241469
Iteration 18 Loss=  0.0556046612738
Iteration 19 Loss=  0.0552261544828
Iteration 20 Loss=  0.0548537847162
Iteration 21 Loss=  0.05448703696
Iteration 22 Loss=  0.0541254786154
Iteration 23 Loss=  0.0537687430958
Iteration 24 Loss=  0.0534165172255
Iteration 25 Loss=  0.0530685314438
Iteration 26 Loss=  0.0527245521093
Iteration 27 Loss=  0.0523843753936
Iteration 28 Loss=  0.0520478223929
Iteration 29 Loss=  0.0517147351814
Iteration 30 Loss=  0.0513849736003
Iteration 31 Loss=  0.0510584126275
Iteration 32 Loss=  0.0507349402064
Iteration 33 Loss=  0.0504144554451
Iteration 34 Loss=  0.0500968671117
Iteration 35 Loss=  0.0497820923713
Iteration 36 Loss=  0.04947005572
Iteration 37 Loss=  0.0491606880807
Iteration 38 Loss=  0.0488539260329
Iteration 39 Loss=  0.0485497111528
Iteration 40 Loss=  0.0482479894468
Iteration 41 Loss=  0.0479487108622
Iteration 42 Loss=  0.0476518288631
Iteration 43 Loss=  0.0473573000621
Iteration 44 Loss=  0.0470650838986
Iteration 45 Loss=  0.0467751423566
Iteration 46 Loss=  0.0464874397176
Iteration 47 Loss=  0.046201942342
Iteration 48 Loss=  0.0459186184764
Iteration 49 Loss=  0.0456374380817
Iteration 50 Loss=  0.0453583726814
Iteration 51 Loss=  0.045081395225
Iteration 52 Loss=  0.0448064799667
Iteration 53 Loss=  0.0445336023559
Iteration 54 Loss=  0.0442627389389
Iteration 55 Loss=  0.0439938672703
Iteration 56 Loss=  0.0437269658324
Iteration 57 Loss=  0.0434620139626
Iteration 58 Loss=  0.0431989917871
Iteration 59 Loss=  0.0429378801607
Iteration 60 Loss=  0.0426786606112
Iteration 61 Loss=  0.0424213152892
Iteration 62 Loss=  0.0421658269217
Iteration 63 Loss=  0.0419121787694
Iteration 64 Loss=  0.0416603545873
Iteration 65 Loss=  0.0414103385888
Iteration 66 Loss=  0.0411621154116
Iteration 67 Loss=  0.040915670087
Iteration 68 Loss=  0.0406709880109
Iteration 69 Loss=  0.0404280549174
Iteration 70 Loss=  0.0401868568532
Iteration 71 Loss=  0.0399473801552
Iteration 72 Loss=  0.0397096114283
Iteration 73 Loss=  0.0394735375257
Iteration 74 Loss=  0.0392391455301
Iteration 75 Loss=  0.0390064227358
Iteration 76 Loss=  0.0387753566331
Iteration 77 Loss=  0.0385459348924
Iteration 78 Loss=  0.0383181453505
Iteration 79 Loss=  0.0380919759974
Iteration 80 Loss=  0.0378674149637
Iteration 81 Loss=  0.0376444505097
Iteration 82 Loss=  0.0374230710144
Iteration 83 Loss=  0.0372032649662
Iteration 84 Loss=  0.0369850209535
Iteration 85 Loss=  0.0367683276568
Iteration 86 Loss=  0.036553173841
Iteration 87 Loss=  0.0363395483483
Iteration 88 Loss=  0.0361274400923
Iteration 89 Loss=  0.0359168380523
Iteration 90 Loss=  0.0357077312678
Iteration 91 Loss=  0.0355001088348
Iteration 92 Loss=  0.0352939599011
Iteration 93 Loss=  0.0350892736634
Iteration 94 Loss=  0.0348860393643
Iteration 95 Loss=  0.0346842462898
Iteration 96 Loss=  0.0344838837674
Iteration 97 Loss=  0.0342849411644
Iteration 98 Loss=  0.0340874078872
Iteration 99 Loss=  0.0338912733802
Iteration 100 Loss=  0.0336965271259
[-0.00072517  0.00045773 -0.00029296 ...,  0.0002082  -0.00013761
  0.0002996 ]
CROSS VALIDATION 4
Iteration 1 Loss=  7.89334121332
Iteration 2 Loss=  0.0769184169017
Iteration 3 Loss=  0.0636810994791
Iteration 4 Loss=  0.0626101136016
Iteration 5 Loss=  0.0617719122463
Iteration 6 Loss=  0.0610650890035
Iteration 7 Loss=  0.0604413898018
Iteration 8 Loss=  0.0598744587233
Iteration 9 Loss=  0.059348509622
Iteration 10 Loss=  0.0588534356458
Iteration 11 Loss=  0.0583824296532
Iteration 12 Loss=  0.057930719871
Iteration 13 Loss=  0.0574948509745
Iteration 14 Loss=  0.0570722525989
Iteration 15 Loss=  0.0566609686631
Iteration 16 Loss=  0.0562594811968
Iteration 17 Loss=  0.055866592036
Iteration 18 Loss=  0.0554813412174
Iteration 19 Loss=  0.0551029493562
Iteration 20 Loss=  0.0547307761184
Iteration 21 Loss=  0.0543642897432
Iteration 22 Loss=  0.054003044311
Iteration 23 Loss=  0.0536466625406
Iteration 24 Loss=  0.0532948225988
Iteration 25 Loss=  0.0529472478655
Iteration 26 Loss=  0.0526036989058
Iteration 27 Loss=  0.0522639671092
Iteration 28 Loss=  0.051927869605
Iteration 29 Loss=  0.0515952451623
Iteration 30 Loss=  0.0512659508577
Iteration 31 Loss=  0.0509398593487
Iteration 32 Loss=  0.050616856626
Iteration 33 Loss=  0.0502968401495
Iteration 34 Loss=  0.0499797172935
Iteration 35 Loss=  0.0496654040418
Iteration 36 Loss=  0.0493538238877
Iteration 37 Loss=  0.0490449069017
Iteration 38 Loss=  0.0487385889366
Iteration 39 Loss=  0.0484348109492
Iteration 40 Loss=  0.048133518416
Iteration 41 Loss=  0.0478346608302
Iteration 42 Loss=  0.0475381912658
Iteration 43 Loss=  0.0472440659989
Iteration 44 Loss=  0.0469522441771
Iteration 45 Loss=  0.0466626875304
Iteration 46 Loss=  0.0463753601175
Iteration 47 Loss=  0.0460902281014
Iteration 48 Loss=  0.0458072595523
Iteration 49 Loss=  0.0455264242722
Iteration 50 Loss=  0.0452476936387
Iteration 51 Loss=  0.0449710404664
Iteration 52 Loss=  0.0446964388828
Iteration 53 Loss=  0.0444238642169
Iteration 54 Loss=  0.0441532928987
Iteration 55 Loss=  0.04388470237
Iteration 56 Loss=  0.0436180710022
Iteration 57 Loss=  0.0433533780228
Iteration 58 Loss=  0.043090603449
Iteration 59 Loss=  0.0428297280261
Iteration 60 Loss=  0.042570733173
Iteration 61 Loss=  0.042313600931
Iteration 62 Loss=  0.0420583139176
Iteration 63 Loss=  0.0418048552845
Iteration 64 Loss=  0.0415532086782
Iteration 65 Loss=  0.0413033582048
Iteration 66 Loss=  0.0410552883964
Iteration 67 Loss=  0.0408089841812
Iteration 68 Loss=  0.0405644308554
Iteration 69 Loss=  0.0403216140572
Iteration 70 Loss=  0.0400805197429
Iteration 71 Loss=  0.0398411341648
Iteration 72 Loss=  0.0396034438505
Iteration 73 Loss=  0.0393674355842
Iteration 74 Loss=  0.0391330963887
Iteration 75 Loss=  0.0389004135094
Iteration 76 Loss=  0.0386693743991
Iteration 77 Loss=  0.0384399667038
Iteration 78 Loss=  0.0382121782499
Iteration 79 Loss=  0.0379859970323
Iteration 80 Loss=  0.037761411203
Iteration 81 Loss=  0.0375384090612
Iteration 82 Loss=  0.0373169790437
Iteration 83 Loss=  0.0370971097162
Iteration 84 Loss=  0.0368787897656
Iteration 85 Loss=  0.0366620079924
Iteration 86 Loss=  0.0364467533044
Iteration 87 Loss=  0.0362330147101
Iteration 88 Loss=  0.0360207813141
Iteration 89 Loss=  0.0358100423113
Iteration 90 Loss=  0.0356007869833
Iteration 91 Loss=  0.0353930046936
Iteration 92 Loss=  0.0351866848849
Iteration 93 Loss=  0.0349818170757
Iteration 94 Loss=  0.0347783908579
Iteration 95 Loss=  0.0345763958939
Iteration 96 Loss=  0.0343758219159
Iteration 97 Loss=  0.034176658723
Iteration 98 Loss=  0.0339788961811
Iteration 99 Loss=  0.0337825242213
Iteration 100 Loss=  0.0335875328394
[-0.00071109  0.00046967 -0.00028137 ...,  0.00019742 -0.00013764
  0.00030023]
CROSS VALIDATION 5
Iteration 1 Loss=  6.68745163129
Iteration 2 Loss=  0.0643948459395
Iteration 3 Loss=  0.063542893551
Iteration 4 Loss=  0.0628547642151
Iteration 5 Loss=  0.0622561101218
Iteration 6 Loss=  0.0617132620769
Iteration 7 Loss=  0.0612083413556
Iteration 8 Loss=  0.0607308312238
Iteration 9 Loss=  0.0602740821539
Iteration 10 Loss=  0.059833655921
Iteration 11 Loss=  0.0594064621534
Iteration 12 Loss=  0.0589902742073
Iteration 13 Loss=  0.0585834417591
Iteration 14 Loss=  0.0581847120917
Iteration 15 Loss=  0.0577931146194
Iteration 16 Loss=  0.0574078838182
Iteration 17 Loss=  0.0570284063395
Iteration 18 Loss=  0.0566541838369
Iteration 19 Loss=  0.0562848062806
Iteration 20 Loss=  0.0559199324401
Iteration 21 Loss=  0.0555592753711
Iteration 22 Loss=  0.0552025914615
Iteration 23 Loss=  0.0548496720521
Iteration 24 Loss=  0.0545003369479
Iteration 25 Loss=  0.0541544293381
Iteration 26 Loss=  0.0538118117769
Iteration 27 Loss=  0.0534723629756
Iteration 28 Loss=  0.0531359752186
Iteration 29 Loss=  0.0528025522661
Iteration 30 Loss=  0.0524720076384
Iteration 31 Loss=  0.0521442632044
Iteration 32 Loss=  0.0518192480106
Iteration 33 Loss=  0.051496897306
Iteration 34 Loss=  0.0511771517234
Iteration 35 Loss=  0.0508599565909
Iteration 36 Loss=  0.0505452613475
Iteration 37 Loss=  0.0502330190467
Iteration 38 Loss=  0.049923185932
Iteration 39 Loss=  0.0496157210724
Iteration 40 Loss=  0.0493105860491
Iteration 41 Loss=  0.0490077446838
Iteration 42 Loss=  0.0487071628037
Iteration 43 Loss=  0.0484088080361
Iteration 44 Loss=  0.04811264963
Iteration 45 Loss=  0.0478186582992
Iteration 46 Loss=  0.0475268060845
Iteration 47 Loss=  0.0472370662329
Iteration 48 Loss=  0.04694941309
Iteration 49 Loss=  0.0466638220057
Iteration 50 Loss=  0.0463802692499
Iteration 51 Loss=  0.0460987319376
Iteration 52 Loss=  0.0458191879625
Iteration 53 Loss=  0.0455416159375
Iteration 54 Loss=  0.0452659951408
Iteration 55 Loss=  0.0449923054686
Iteration 56 Loss=  0.0447205273921
Iteration 57 Loss=  0.0444506419184
Iteration 58 Loss=  0.0441826305557
Iteration 59 Loss=  0.0439164752817
Iteration 60 Loss=  0.0436521585151
Iteration 61 Loss=  0.0433896630891
Iteration 62 Loss=  0.0431289722283
Iteration 63 Loss=  0.0428700695268
Iteration 64 Loss=  0.0426129389285
Iteration 65 Loss=  0.0423575647092
Iteration 66 Loss=  0.0421039314601
Iteration 67 Loss=  0.0418520240725
Iteration 68 Loss=  0.041601827724
Iteration 69 Loss=  0.0413533278655
Iteration 70 Loss=  0.0411065102095
Iteration 71 Loss=  0.0408613607188
Iteration 72 Loss=  0.040617865597
Iteration 73 Loss=  0.0403760112784
Iteration 74 Loss=  0.0401357844195
Iteration 75 Loss=  0.0398971718911
Iteration 76 Loss=  0.0396601607703
Iteration 77 Loss=  0.0394247383339
Iteration 78 Loss=  0.0391908920515
Iteration 79 Loss=  0.0389586095796
Iteration 80 Loss=  0.0387278787555
Iteration 81 Loss=  0.0384986875924
Iteration 82 Loss=  0.0382710242743
Iteration 83 Loss=  0.0380448771511
Iteration 84 Loss=  0.0378202347343
Iteration 85 Loss=  0.0375970856932
Iteration 86 Loss=  0.0373754188507
Iteration 87 Loss=  0.0371552231802
Iteration 88 Loss=  0.0369364878017
Iteration 89 Loss=  0.0367192019791
Iteration 90 Loss=  0.0365033551173
Iteration 91 Loss=  0.0362889367595
Iteration 92 Loss=  0.0360759365842
Iteration 93 Loss=  0.0358643444038
Iteration 94 Loss=  0.0356541501613
Iteration 95 Loss=  0.0354453439294
Iteration 96 Loss=  0.0352379159076
Iteration 97 Loss=  0.0350318564211
Iteration 98 Loss=  0.0348271559187
Iteration 99 Loss=  0.0346238049718
Iteration 100 Loss=  0.0344217942722
[ -4.92676196e-04   5.71615241e-04  -2.95210888e-04 ...,   6.45900602e-05
  -1.06430194e-04   3.77868650e-04]
CROSS VALIDATION 6
Iteration 1 Loss=  7.88757219792
Iteration 2 Loss=  0.076858512448
Iteration 3 Loss=  0.0636799861314
Iteration 4 Loss=  0.0626069945415
Iteration 5 Loss=  0.0617678689885
Iteration 6 Loss=  0.0610605670514
Iteration 7 Loss=  0.0604366111548
Iteration 8 Loss=  0.0598695485948
Iteration 9 Loss=  0.059343545196
Iteration 10 Loss=  0.0588484678528
Iteration 11 Loss=  0.0583774939994
Iteration 12 Loss=  0.0579258422816
Iteration 13 Loss=  0.0574900511573
Iteration 14 Loss=  0.0570675460836
Iteration 15 Loss=  0.0566563680927
Iteration 16 Loss=  0.0562549971757
Iteration 17 Loss=  0.0558622337045
Iteration 18 Loss=  0.0554771166513
Iteration 19 Loss=  0.0550988658516
Iteration 20 Loss=  0.0547268403988
Iteration 21 Loss=  0.0543605081131
Iteration 22 Loss=  0.0539994227712
Iteration 23 Loss=  0.0536432068765
Iteration 24 Loss=  0.053291538449
Iteration 25 Loss=  0.0529441407753
Iteration 26 Loss=  0.0526007743697
Iteration 27 Loss=  0.0522612306049
Iteration 28 Loss=  0.0519253266208
Iteration 29 Loss=  0.0515929012193
Iteration 30 Loss=  0.0512638115281
Iteration 31 Loss=  0.0509379302707
Iteration 32 Loss=  0.0506151435162
Iteration 33 Loss=  0.0502953488128
Iteration 34 Loss=  0.0499784536316
Iteration 35 Loss=  0.0496643740601
Iteration 36 Loss=  0.0493530337007
Iteration 37 Loss=  0.0490443627374
Iteration 38 Loss=  0.0487382971403
Iteration 39 Loss=  0.0484347779856
Iteration 40 Loss=  0.0481337508713
Iteration 41 Loss=  0.0478351654133
Iteration 42 Loss=  0.0475389748089
Iteration 43 Loss=  0.0472451354571
Iteration 44 Loss=  0.0469536066281
Iteration 45 Loss=  0.0466643501732
Iteration 46 Loss=  0.0463773302704
Iteration 47 Loss=  0.0460925132005
Iteration 48 Loss=  0.0458098671483
Iteration 49 Loss=  0.0455293620273
Iteration 50 Loss=  0.0452509693233
Iteration 51 Loss=  0.044974661955
Iteration 52 Loss=  0.0447004141491
Iteration 53 Loss=  0.044428201329
Iteration 54 Loss=  0.0441580000142
Iteration 55 Loss=  0.0438897877293
Iteration 56 Loss=  0.0436235429226
Iteration 57 Loss=  0.0433592448918
Iteration 58 Loss=  0.0430968737165
Iteration 59 Loss=  0.0428364101974
Iteration 60 Loss=  0.0425778358001
Iteration 61 Loss=  0.0423211326041
Iteration 62 Loss=  0.042066283256
Iteration 63 Loss=  0.0418132709272
Iteration 64 Loss=  0.0415620792738
Iteration 65 Loss=  0.0413126924008
Iteration 66 Loss=  0.0410650948287
Iteration 67 Loss=  0.0408192714627
Iteration 68 Loss=  0.040575207564
Iteration 69 Loss=  0.0403328887239
Iteration 70 Loss=  0.0400923008391
Iteration 71 Loss=  0.0398534300893
Iteration 72 Loss=  0.0396162629165
Iteration 73 Loss=  0.0393807860051
Iteration 74 Loss=  0.0391469862646
Iteration 75 Loss=  0.0389148508125
Iteration 76 Loss=  0.0386843669589
Iteration 77 Loss=  0.0384555221926
Iteration 78 Loss=  0.0382283041675
Iteration 79 Loss=  0.0380027006905
Iteration 80 Loss=  0.0377786997105
Iteration 81 Loss=  0.0375562893076
Iteration 82 Loss=  0.0373354576839
Iteration 83 Loss=  0.0371161931547
Iteration 84 Loss=  0.0368984841404
Iteration 85 Loss=  0.0366823191595
Iteration 86 Loss=  0.0364676868217
Iteration 87 Loss=  0.0362545758222
Iteration 88 Loss=  0.0360429749363
Iteration 89 Loss=  0.0358328730149
Iteration 90 Loss=  0.0356242589799
Iteration 91 Loss=  0.0354171218209
Iteration 92 Loss=  0.0352114505921
Iteration 93 Loss=  0.0350072344094
Iteration 94 Loss=  0.0348044624486
Iteration 95 Loss=  0.0346031239434
Iteration 96 Loss=  0.0344032081839
Iteration 97 Loss=  0.034204704516
Iteration 98 Loss=  0.0340076023408
Iteration 99 Loss=  0.0338118911141
Iteration 100 Loss=  0.0336175603466
[-0.00071209  0.00046979 -0.00028093 ...,  0.00019677 -0.0001381
  0.00030011]
CROSS VALIDATION 7
Iteration 1 Loss=  7.90782251533
Iteration 2 Loss=  0.0770070546074
Iteration 3 Loss=  0.0636187302182
Iteration 4 Loss=  0.0625562010591
Iteration 5 Loss=  0.0617210736258
Iteration 6 Loss=  0.0610150978366
Iteration 7 Loss=  0.0603911616818
Iteration 8 Loss=  0.0598234067912
Iteration 9 Loss=  0.0592962920962
Iteration 10 Loss=  0.0587998426527
Iteration 11 Loss=  0.0583273273106
Iteration 12 Loss=  0.0578740205363
Iteration 13 Loss=  0.0574364964642
Iteration 14 Loss=  0.0570122042658
Iteration 15 Loss=  0.0565992012965
Iteration 16 Loss=  0.0561959791477
Iteration 17 Loss=  0.0558013466869
Iteration 18 Loss=  0.0554143492895
Iteration 19 Loss=  0.0550342117535
Iteration 20 Loss=  0.0546602971228
Iteration 21 Loss=  0.0542920764454
Iteration 22 Loss=  0.0539291062009
Iteration 23 Loss=  0.0535710112086
Iteration 24 Loss=  0.0532174715145
Iteration 25 Loss=  0.0528682122108
Iteration 26 Loss=  0.0525229954469
Iteration 27 Loss=  0.0521816140976
Iteration 28 Loss=  0.0518438866974
Iteration 29 Loss=  0.0515096533558
Iteration 30 Loss=  0.0511787724357
Iteration 31 Loss=  0.050851117834
Iteration 32 Loss=  0.0505265767392
Iteration 33 Loss=  0.0502050477718
Iteration 34 Loss=  0.0498864394313
Iteration 35 Loss=  0.0495706687939
Iteration 36 Loss=  0.0492576604133
Iteration 37 Loss=  0.0489473453885
Iteration 38 Loss=  0.0486396605702
Iteration 39 Loss=  0.0483345478816
Iteration 40 Loss=  0.0480319537346
Iteration 41 Loss=  0.0477318285263
Iteration 42 Loss=  0.047434126203
Iteration 43 Loss=  0.0471388038806
Iteration 44 Loss=  0.0468458215145
Iteration 45 Loss=  0.0465551416091
Iteration 46 Loss=  0.0462667289645
Iteration 47 Loss=  0.0459805504513
Iteration 48 Loss=  0.0456965748134
Iteration 49 Loss=  0.0454147724919
Iteration 50 Loss=  0.045135115469
Iteration 51 Loss=  0.0448575771291
Iteration 52 Loss=  0.044582132134
Iteration 53 Loss=  0.0443087563115
Iteration 54 Loss=  0.0440374265554
Iteration 55 Loss=  0.0437681207346
Iteration 56 Loss=  0.043500817612
Iteration 57 Loss=  0.0432354967705
Iteration 58 Loss=  0.0429721385461
Iteration 59 Loss=  0.0427107239665
Iteration 60 Loss=  0.0424512346964
Iteration 61 Loss=  0.042193652986
Iteration 62 Loss=  0.0419379616252
Iteration 63 Loss=  0.0416841439007
Iteration 64 Loss=  0.0414321835573
Iteration 65 Loss=  0.0411820647616
Iteration 66 Loss=  0.0409337720695
Iteration 67 Loss=  0.0406872903955
Iteration 68 Loss=  0.0404426049845
Iteration 69 Loss=  0.0401997013859
Iteration 70 Loss=  0.0399585654298
Iteration 71 Loss=  0.0397191832045
Iteration 72 Loss=  0.0394815410362
Iteration 73 Loss=  0.03924562547
Iteration 74 Loss=  0.0390114232523
Iteration 75 Loss=  0.0387789213143
Iteration 76 Loss=  0.0385481067574
Iteration 77 Loss=  0.0383189668391
Iteration 78 Loss=  0.0380914889602
Iteration 79 Loss=  0.0378656606533
Iteration 80 Loss=  0.0376414695717
Iteration 81 Loss=  0.0374189034797
Iteration 82 Loss=  0.0371979502438
Iteration 83 Loss=  0.0369785978239
Iteration 84 Loss=  0.0367608342666
Iteration 85 Loss=  0.0365446476981
Iteration 86 Loss=  0.0363300263185
Iteration 87 Loss=  0.0361169583964
Iteration 88 Loss=  0.0359054322642
Iteration 89 Loss=  0.0356954363144
Iteration 90 Loss=  0.035486958996
Iteration 91 Loss=  0.0352799888116
Iteration 92 Loss=  0.0350745143151
Iteration 93 Loss=  0.0348705241101
Iteration 94 Loss=  0.0346680068485
Iteration 95 Loss=  0.0344669512295
Iteration 96 Loss=  0.0342673459993
Iteration 97 Loss=  0.0340691799508
Iteration 98 Loss=  0.0338724419247
Iteration 99 Loss=  0.0336771208092
Iteration 100 Loss=  0.0334832055417
[-0.00071381  0.00046722 -0.00028523 ...,  0.0001949  -0.00014029
  0.00030093]
CROSS VALIDATION 8
Iteration 1 Loss=  7.88957028887
Iteration 2 Loss=  0.0773009550462
Iteration 3 Loss=  0.0636814623484
Iteration 4 Loss=  0.062620806153
Iteration 5 Loss=  0.0617874155692
Iteration 6 Loss=  0.061083137457
Iteration 7 Loss=  0.0604608734826
Iteration 8 Loss=  0.0598947680047
Iteration 9 Loss=  0.0593692809558
Iteration 10 Loss=  0.0588744380273
Iteration 11 Loss=  0.0584035085397
Iteration 12 Loss=  0.0579517672943
Iteration 13 Loss=  0.0575157886343
Iteration 14 Loss=  0.0570930218252
Iteration 15 Loss=  0.0566815242135
Iteration 16 Loss=  0.0562797872907
Iteration 17 Loss=  0.0558866197444
Iteration 18 Loss=  0.0555010666994
Iteration 19 Loss=  0.0551223526413
Iteration 20 Loss=  0.0547498402479
Iteration 21 Loss=  0.0543830001533
Iteration 22 Loss=  0.0540213883827
Iteration 23 Loss=  0.0536646292654
Iteration 24 Loss=  0.0533124023273
Iteration 25 Loss=  0.0529644321151
Iteration 26 Loss=  0.0526204802119
Iteration 27 Loss=  0.0522803389088
Iteration 28 Loss=  0.0519438261437
Iteration 29 Loss=  0.0516107814197
Iteration 30 Loss=  0.0512810624867
Iteration 31 Loss=  0.0509545426249
Iteration 32 Loss=  0.0506311084058
Iteration 33 Loss=  0.0503106578342
Iteration 34 Loss=  0.0499930987986
Iteration 35 Loss=  0.0496783477704
Iteration 36 Loss=  0.0493663287069
Iteration 37 Loss=  0.0490569721215
Iteration 38 Loss=  0.0487502142912
Iteration 39 Loss=  0.0484459965794
Iteration 40 Loss=  0.0481442648538
Iteration 41 Loss=  0.0478449689838
Iteration 42 Loss=  0.0475480624063
Iteration 43 Loss=  0.0472535017469
Iteration 44 Loss=  0.0469612464911
Iteration 45 Loss=  0.046671258695
Iteration 46 Loss=  0.0463835027326
Iteration 47 Loss=  0.0460979450716
Iteration 48 Loss=  0.0458145540771
Iteration 49 Loss=  0.045533299836
Iteration 50 Loss=  0.045254154002
Iteration 51 Loss=  0.0449770896569
Iteration 52 Loss=  0.0447020811864
Iteration 53 Loss=  0.0444291041697
Iteration 54 Loss=  0.0441581352793
Iteration 55 Loss=  0.0438891521912
Iteration 56 Loss=  0.0436221335037
Iteration 57 Loss=  0.0433570586643
Iteration 58 Loss=  0.0430939079024
Iteration 59 Loss=  0.0428326621695
Iteration 60 Loss=  0.0425733030832
Iteration 61 Loss=  0.0423158128774
Iteration 62 Loss=  0.0420601743555
Iteration 63 Loss=  0.0418063708491
Iteration 64 Loss=  0.0415543861781
Iteration 65 Loss=  0.0413042046158
Iteration 66 Loss=  0.0410558108557
Iteration 67 Loss=  0.0408091899811
Iteration 68 Loss=  0.0405643274374
Iteration 69 Loss=  0.0403212090059
Iteration 70 Loss=  0.0400798207798
Iteration 71 Loss=  0.0398401491425
Iteration 72 Loss=  0.0396021807464
Iteration 73 Loss=  0.0393659024943
Iteration 74 Loss=  0.0391313015214
Iteration 75 Loss=  0.0388983651789
Iteration 76 Loss=  0.0386670810191
Iteration 77 Loss=  0.0384374367809
Iteration 78 Loss=  0.0382094203767
Iteration 79 Loss=  0.0379830198807
Iteration 80 Loss=  0.0377582235172
Iteration 81 Loss=  0.0375350196504
Iteration 82 Loss=  0.0373133967747
Iteration 83 Loss=  0.0370933435063
Iteration 84 Loss=  0.0368748485746
Iteration 85 Loss=  0.036657900815
Iteration 86 Loss=  0.036442489162
Iteration 87 Loss=  0.036228602643
Iteration 88 Loss=  0.0360162303731
Iteration 89 Loss=  0.0358053615493
Iteration 90 Loss=  0.0355959854465
Iteration 91 Loss=  0.0353880914134
Iteration 92 Loss=  0.0351816688685
Iteration 93 Loss=  0.0349767072976
Iteration 94 Loss=  0.0347731962504
Iteration 95 Loss=  0.0345711253386
Iteration 96 Loss=  0.0343704842339
Iteration 97 Loss=  0.0341712626661
Iteration 98 Loss=  0.0339734504223
Iteration 99 Loss=  0.0337770373453
Iteration 100 Loss=  0.0335820133336
[-0.00071019  0.00047187 -0.00027479 ...,  0.00019889 -0.00014184
  0.00030016]
CROSS VALIDATION 9
Iteration 1 Loss=  7.89852584459
Iteration 2 Loss=  0.088551304983
Iteration 3 Loss=  0.0736918999265
Iteration 4 Loss=  0.0725366619117
Iteration 5 Loss=  0.0716328552124
Iteration 6 Loss=  0.0708656847704
Iteration 7 Loss=  0.0701831814585
Iteration 8 Loss=  0.0695577789818
Iteration 9 Loss=  0.0689732862569
Iteration 10 Loss=  0.0684194825185
Iteration 11 Loss=  0.0678895571225
Iteration 12 Loss=  0.0673787756211
Iteration 13 Loss=  0.0668837325941
Iteration 14 Loss=  0.066401908537
Iteration 15 Loss=  0.0659313945988
Iteration 16 Loss=  0.06547071488
Iteration 17 Loss=  0.0650187079255
Iteration 18 Loss=  0.0645744454618
Iteration 19 Loss=  0.0641371753151
Iteration 20 Loss=  0.0637062804565
Iteration 21 Loss=  0.0632812490661
Iteration 22 Loss=  0.062861652284
Iteration 23 Loss=  0.0624471274266
Iteration 24 Loss=  0.0620373651536
Iteration 25 Loss=  0.0616320995373
Iteration 26 Loss=  0.0612311002903
Iteration 27 Loss=  0.0608341666217
Iteration 28 Loss=  0.0604411223344
Iteration 29 Loss=  0.0600518118793
Iteration 30 Loss=  0.0596660971546
Iteration 31 Loss=  0.0592838548895
Iteration 32 Loss=  0.0589049744914
Iteration 33 Loss=  0.0585293562629
Iteration 34 Loss=  0.0581569099163
Iteration 35 Loss=  0.0577875533292
Iteration 36 Loss=  0.0574212114953
Iteration 37 Loss=  0.0570578156372
Iteration 38 Loss=  0.0566973024512
Iteration 39 Loss=  0.056339613462
Iteration 40 Loss=  0.0559846944695
Iteration 41 Loss=  0.055632495071
Iteration 42 Loss=  0.0552829682496
Iteration 43 Loss=  0.0549360700152
Iteration 44 Loss=  0.054591759093
Iteration 45 Loss=  0.0542499966505
Iteration 46 Loss=  0.0539107460583
Iteration 47 Loss=  0.0535739726795
Iteration 48 Loss=  0.053239643684
Iteration 49 Loss=  0.052907727884
Iteration 50 Loss=  0.0525781955881
Iteration 51 Loss=  0.0522510184712
Iteration 52 Loss=  0.0519261694588
Iteration 53 Loss=  0.0516036226229
Iteration 54 Loss=  0.0512833530891
Iteration 55 Loss=  0.0509653369528
Iteration 56 Loss=  0.0506495512036
Iteration 57 Loss=  0.0503359736575
Iteration 58 Loss=  0.0500245828946
Iteration 59 Loss=  0.0497153582032
Iteration 60 Loss=  0.0494082795292
Iteration 61 Loss=  0.0491033274289
Iteration 62 Loss=  0.0488004830274
Iteration 63 Loss=  0.0484997279791
Iteration 64 Loss=  0.0482010444323
Iteration 65 Loss=  0.0479044149968
Iteration 66 Loss=  0.0476098227137
Iteration 67 Loss=  0.0473172510275
Iteration 68 Loss=  0.047026683761
Iteration 69 Loss=  0.0467381050915
Iteration 70 Loss=  0.046451499529
Iteration 71 Loss=  0.0461668518961
Iteration 72 Loss=  0.0458841473096
Iteration 73 Loss=  0.0456033711625
Iteration 74 Loss=  0.0453245091087
Iteration 75 Loss=  0.0450475470476
Iteration 76 Loss=  0.0447724711101
Iteration 77 Loss=  0.0444992676465
Iteration 78 Loss=  0.0442279232135
Iteration 79 Loss=  0.0439584245638
Iteration 80 Loss=  0.0436907586354
Iteration 81 Loss=  0.0434249125421
Iteration 82 Loss=  0.0431608735645
Iteration 83 Loss=  0.0428986291417
Iteration 84 Loss=  0.0426381668636
Iteration 85 Loss=  0.0423794744634
Iteration 86 Loss=  0.0421225398117
Iteration 87 Loss=  0.0418673509094
Iteration 88 Loss=  0.0416138958828
Iteration 89 Loss=  0.0413621629776
Iteration 90 Loss=  0.0411121405545
Iteration 91 Loss=  0.0408638170844
Iteration 92 Loss=  0.0406171811443
Iteration 93 Loss=  0.0403722214136
Iteration 94 Loss=  0.0401289266699
Iteration 95 Loss=  0.0398872857866
Iteration 96 Loss=  0.0396472877292
Iteration 97 Loss=  0.0394089215525
Iteration 98 Loss=  0.0391721763985
Iteration 99 Loss=  0.0389370414935
Iteration 100 Loss=  0.0387035061463
[-0.00064306  0.00052601 -0.00019531 ...,  0.00046055 -0.000104    0.00030342]
CROSS VALIDATION 10
Iteration 1 Loss=  7.2648143187
Iteration 2 Loss=  0.0800817892407
Iteration 3 Loss=  0.0791462624405
Iteration 4 Loss=  0.0783662484712
Iteration 5 Loss=  0.0776727041286
Iteration 6 Loss=  0.0770337455341
Iteration 7 Loss=  0.0764322566404
Iteration 8 Loss=  0.0758581005515
Iteration 9 Loss=  0.0753048381183
Iteration 10 Loss=  0.0747681569173
Iteration 11 Loss=  0.0742450461811
Iteration 12 Loss=  0.0737333318097
Iteration 13 Loss=  0.0732313992658
Iteration 14 Loss=  0.0727380207636
Iteration 15 Loss=  0.0722522433518
Iteration 16 Loss=  0.0717733140802
Iteration 17 Loss=  0.0713006285728
Iteration 18 Loss=  0.070833694835
Iteration 19 Loss=  0.0703721072452
Iteration 20 Loss=  0.0699155275163
Iteration 21 Loss=  0.0694636705281
Iteration 22 Loss=  0.0690162936278
Iteration 23 Loss=  0.068573188441
Iteration 24 Loss=  0.0681341745265
Iteration 25 Loss=  0.0676990944082
Iteration 26 Loss=  0.067267809642
Iteration 27 Loss=  0.0668401976763
Iteration 28 Loss=  0.0664161493221
Iteration 29 Loss=  0.0659955666993
Iteration 30 Loss=  0.065578361557
Iteration 31 Loss=  0.06516445389
Iteration 32 Loss=  0.0647537707922
Iteration 33 Loss=  0.0643462455008
Iteration 34 Loss=  0.0639418165941
Iteration 35 Loss=  0.0635404273166
Iteration 36 Loss=  0.063142025006
Iteration 37 Loss=  0.0627465606065
Iteration 38 Loss=  0.062353988252
Iteration 39 Loss=  0.0619642649089
Iteration 40 Loss=  0.0615773500681
Iteration 41 Loss=  0.0611932054782
Iteration 42 Loss=  0.0608117949141
Iteration 43 Loss=  0.0604330839757
Iteration 44 Loss=  0.0600570399111
Iteration 45 Loss=  0.0596836314627
Iteration 46 Loss=  0.0593128287304
Iteration 47 Loss=  0.0589446030522
Iteration 48 Loss=  0.0585789268981
Iteration 49 Loss=  0.0582157737753
Iteration 50 Loss=  0.0578551181449
Iteration 51 Loss=  0.0574969353468
Iteration 52 Loss=  0.057141201533
Iteration 53 Loss=  0.0567878936072
Iteration 54 Loss=  0.0564369891712
Iteration 55 Loss=  0.0560884664761
Iteration 56 Loss=  0.055742304378
Iteration 57 Loss=  0.0553984822984
Iteration 58 Loss=  0.055056980188
Iteration 59 Loss=  0.0547177784933
Iteration 60 Loss=  0.054380858127
Iteration 61 Loss=  0.0540462004399
Iteration 62 Loss=  0.0537137871957
Iteration 63 Loss=  0.0533836005479
Iteration 64 Loss=  0.0530556230181
Iteration 65 Loss=  0.0527298374762
Iteration 66 Loss=  0.0524062271219
Iteration 67 Loss=  0.0520847754678
Iteration 68 Loss=  0.0517654663233
Iteration 69 Loss=  0.05144828378
Iteration 70 Loss=  0.0511332121976
Iteration 71 Loss=  0.050820236191
Iteration 72 Loss=  0.0505093406184
Iteration 73 Loss=  0.0502005105694
Iteration 74 Loss=  0.0498937313548
Iteration 75 Loss=  0.049588988496
Iteration 76 Loss=  0.0492862677159
Iteration 77 Loss=  0.0489855549294
Iteration 78 Loss=  0.0486868362354
Iteration 79 Loss=  0.0483900979084
Iteration 80 Loss=  0.0480953263911
Iteration 81 Loss=  0.047802508287
Iteration 82 Loss=  0.0475116303537
Iteration 83 Loss=  0.0472226794963
Iteration 84 Loss=  0.0469356427615
Iteration 85 Loss=  0.0466505073315
Iteration 86 Loss=  0.0463672605186
Iteration 87 Loss=  0.0460858897601
Iteration 88 Loss=  0.0458063826133
Iteration 89 Loss=  0.0455287267504
Iteration 90 Loss=  0.0452529099549
Iteration 91 Loss=  0.0449789201166
Iteration 92 Loss=  0.0447067452281
Iteration 93 Loss=  0.0444363733808
Iteration 94 Loss=  0.0441677927618
Iteration 95 Loss=  0.0439009916499
Iteration 96 Loss=  0.043635958413
Iteration 97 Loss=  0.043372681505
Iteration 98 Loss=  0.0431111494629
Iteration 99 Loss=  0.0428513509044
Iteration 100 Loss=  0.0425932745253
[ -6.65867862e-04   4.50054948e-04  -3.43359947e-04 ...,   4.31516617e-04
  -6.40818669e-05   3.20159730e-04]
CROSS VALIDATION 11
Iteration 1 Loss=  7.88987107874
Iteration 2 Loss=  0.0768811791455
Iteration 3 Loss=  0.0636981411961
Iteration 4 Loss=  0.0626263212869
Iteration 5 Loss=  0.061787696481
Iteration 6 Loss=  0.061080589419
Iteration 7 Loss=  0.0604566643551
Iteration 8 Loss=  0.0598895345772
Iteration 9 Loss=  0.0593634005079
Iteration 10 Loss=  0.0588681487856
Iteration 11 Loss=  0.0583969688422
Iteration 12 Loss=  0.0579450869711
Iteration 13 Loss=  0.0575090466864
Iteration 14 Loss=  0.0570862768831
Iteration 15 Loss=  0.0566748209801
Iteration 16 Loss=  0.0562731606487
Iteration 17 Loss=  0.0558800974534
Iteration 18 Loss=  0.0554946712128
Iteration 19 Loss=  0.0551161023595
Iteration 20 Loss=  0.0547437503987
Iteration 21 Loss=  0.0543770834237
Iteration 22 Loss=  0.054015655379
Iteration 23 Loss=  0.0536590888535
Iteration 24 Loss=  0.0533070618887
Iteration 25 Loss=  0.0529592977417
Iteration 26 Loss=  0.0526155568562
Iteration 27 Loss=  0.0522756305013
Iteration 28 Loss=  0.0519393356862
Iteration 29 Loss=  0.0516065110595
Iteration 30 Loss=  0.0512770135772
Iteration 31 Loss=  0.0509507157756
Iteration 32 Loss=  0.0506275035234
Iteration 33 Loss=  0.0503072741579
Iteration 34 Loss=  0.04998993493
Iteration 35 Loss=  0.0496754016995
Iteration 36 Loss=  0.0493635978349
Iteration 37 Loss=  0.0490544532812
Iteration 38 Loss=  0.0487479037655
Iteration 39 Loss=  0.0484438901184
Iteration 40 Loss=  0.04814235769
Iteration 41 Loss=  0.047843255847
Iteration 42 Loss=  0.0475465375373
Iteration 43 Loss=  0.047252158911
Iteration 44 Loss=  0.0469600789908
Iteration 45 Loss=  0.0466702593823
Iteration 46 Loss=  0.0463826640209
Iteration 47 Loss=  0.0460972589484
Iteration 48 Loss=  0.0458140121151
Iteration 49 Loss=  0.0455328932052
Iteration 50 Loss=  0.0452538734815
Iteration 51 Loss=  0.0449769256464
Iteration 52 Loss=  0.0447020237184
Iteration 53 Loss=  0.0444291429213
Iteration 54 Loss=  0.0441582595843
Iteration 55 Loss=  0.0438893510525
Iteration 56 Loss=  0.0436223956061
Iteration 57 Loss=  0.0433573723868
Iteration 58 Loss=  0.0430942613317
Iteration 59 Loss=  0.0428330431129
Iteration 60 Loss=  0.0425736990828
Iteration 61 Loss=  0.0423162112237
Iteration 62 Loss=  0.0420605621024
Iteration 63 Loss=  0.0418067348279
Iteration 64 Loss=  0.0415547130136
Iteration 65 Loss=  0.0413044807414
Iteration 66 Loss=  0.0410560225296
Iteration 67 Loss=  0.0408093233032
Iteration 68 Loss=  0.0405643683658
Iteration 69 Loss=  0.0403211433747
Iteration 70 Loss=  0.0400796343172
Iteration 71 Loss=  0.0398398274888
Iteration 72 Loss=  0.0396017094732
Iteration 73 Loss=  0.0393652671237
Iteration 74 Loss=  0.0391304875456
Iteration 75 Loss=  0.0388973580808
Iteration 76 Loss=  0.0386658662921
Iteration 77 Loss=  0.0384359999503
Iteration 78 Loss=  0.0382077470209
Iteration 79 Loss=  0.0379810956523
Iteration 80 Loss=  0.0377560341649
Iteration 81 Loss=  0.0375325510409
Iteration 82 Loss=  0.0373106349148
Iteration 83 Loss=  0.0370902745647
Iteration 84 Loss=  0.0368714589042
Iteration 85 Loss=  0.0366541769749
Iteration 86 Loss=  0.0364384179394
Iteration 87 Loss=  0.0362241710753
Iteration 88 Loss=  0.0360114257688
Iteration 89 Loss=  0.0358001715097
Iteration 90 Loss=  0.0355903978863
Iteration 91 Loss=  0.0353820945808
Iteration 92 Loss=  0.0351752513655
Iteration 93 Loss=  0.0349698580985
Iteration 94 Loss=  0.0347659047206
Iteration 95 Loss=  0.0345633812522
Iteration 96 Loss=  0.0343622777904
Iteration 97 Loss=  0.0341625845064
Iteration 98 Loss=  0.0339642916435
Iteration 99 Loss=  0.0337673895148
Iteration 100 Loss=  0.0335718685015
[-0.00071057  0.00047027 -0.00027911 ...,  0.0001973  -0.00013802
  0.00029985]
CROSS VALIDATION 12
Iteration 1 Loss=  10.0299560515
Iteration 2 Loss=  0.0628245863739
Iteration 3 Loss=  0.0573655166049
Iteration 4 Loss=  0.0561160264364
Iteration 5 Loss=  0.0552719532969
Iteration 6 Loss=  0.0546016216039
Iteration 7 Loss=  0.0540270814478
Iteration 8 Loss=  0.0535128768372
Iteration 9 Loss=  0.0530400328433
Iteration 10 Loss=  0.0525972805508
Iteration 11 Loss=  0.0521774207271
Iteration 12 Loss=  0.0517755975356
Iteration 13 Loss=  0.051388394956
Iteration 14 Loss=  0.0510133275379
Iteration 15 Loss=  0.0506485362264
Iteration 16 Loss=  0.0502925979441
Iteration 17 Loss=  0.0499444016736
Iteration 18 Loss=  0.0496030651436
Iteration 19 Loss=  0.0492678772348
Iteration 20 Loss=  0.0489382571967
Iteration 21 Loss=  0.0486137251581
Iteration 22 Loss=  0.0482938804041
Iteration 23 Loss=  0.0479783851112
Iteration 24 Loss=  0.0476669519881
Iteration 25 Loss=  0.0473593347594
Iteration 26 Loss=  0.0470553207504
Iteration 27 Loss=  0.0467547250454
Iteration 28 Loss=  0.0464573858403
Iteration 29 Loss=  0.0461631607099
Iteration 30 Loss=  0.0458719235863
Iteration 31 Loss=  0.0455835622922
Iteration 32 Loss=  0.0452979765134
Iteration 33 Loss=  0.0450150761205
Iteration 34 Loss=  0.0447347797715
Iteration 35 Loss=  0.0444570137405
Iteration 36 Loss=  0.0441817109309
Iteration 37 Loss=  0.0439088100403
Iteration 38 Loss=  0.0436382548486
Iteration 39 Loss=  0.0433699936103
Iteration 40 Loss=  0.0431039785317
Iteration 41 Loss=  0.0428401653204
Iteration 42 Loss=  0.0425785127951
Iteration 43 Loss=  0.0423189825461
Iteration 44 Loss=  0.0420615386394
Iteration 45 Loss=  0.0418061473579
Iteration 46 Loss=  0.0415527769731
Iteration 47 Loss=  0.0413013975452
Iteration 48 Loss=  0.0410519807454
Iteration 49 Loss=  0.0408044996991
Iteration 50 Loss=  0.0405589288461
Iteration 51 Loss=  0.0403152438167
Iteration 52 Loss=  0.0400734213201
Iteration 53 Loss=  0.0398334390454
Iteration 54 Loss=  0.0395952755725
Iteration 55 Loss=  0.0393589102919
Iteration 56 Loss=  0.0391243233326
Iteration 57 Loss=  0.0388914954973
Iteration 58 Loss=  0.0386604082034
Iteration 59 Loss=  0.0384310434301
Iteration 60 Loss=  0.0382033836704
Iteration 61 Loss=  0.0379774118875
Iteration 62 Loss=  0.037753111475
Iteration 63 Loss=  0.0375304662217
Iteration 64 Loss=  0.0373094602783
Iteration 65 Loss=  0.0370900781284
Iteration 66 Loss=  0.0368723045613
Iteration 67 Loss=  0.0366561246476
Iteration 68 Loss=  0.0364415237173
Iteration 69 Loss=  0.0362284873394
Iteration 70 Loss=  0.036017001304
Iteration 71 Loss=  0.0358070516052
Iteration 72 Loss=  0.035598624427
Iteration 73 Loss=  0.0353917061292
Iteration 74 Loss=  0.0351862832351
Iteration 75 Loss=  0.0349823424215
Iteration 76 Loss=  0.0347798705079
Iteration 77 Loss=  0.0345788544483
Iteration 78 Loss=  0.0343792813233
Iteration 79 Loss=  0.0341811383335
Iteration 80 Loss=  0.0339844127929
Iteration 81 Loss=  0.0337890921241
Iteration 82 Loss=  0.0335951638535
Iteration 83 Loss=  0.0334026156074
Iteration 84 Loss=  0.0332114351088
Iteration 85 Loss=  0.0330216101743
Iteration 86 Loss=  0.0328331287122
Iteration 87 Loss=  0.0326459787204
Iteration 88 Loss=  0.0324601482852
Iteration 89 Loss=  0.0322756255802
Iteration 90 Loss=  0.0320923988656
Iteration 91 Loss=  0.0319104564882
Iteration 92 Loss=  0.031729786881
Iteration 93 Loss=  0.0315503785635
Iteration 94 Loss=  0.0313722201424
Iteration 95 Loss=  0.0311953003123
Iteration 96 Loss=  0.0310196078562
Iteration 97 Loss=  0.0308451316468
Iteration 98 Loss=  0.030671860648
Iteration 99 Loss=  0.0304997839154
Iteration 100 Loss=  0.0303288905988
[ -1.37345008e-03   2.53638443e-05  -4.30910299e-04 ...,   6.33200650e-05
  -1.53597605e-04   1.72073530e-04]
CROSS VALIDATION 13
Iteration 1 Loss=  7.99391818482
Iteration 2 Loss=  0.0814325038111
Iteration 3 Loss=  0.0772085009093
Iteration 4 Loss=  0.0755072930162
Iteration 5 Loss=  0.0743746067933
Iteration 6 Loss=  0.0734859437201
Iteration 7 Loss=  0.0727290578443
Iteration 8 Loss=  0.0720531932805
Iteration 9 Loss=  0.0714316083073
Iteration 10 Loss=  0.0708487150484
Iteration 11 Loss=  0.0702947444185
Iteration 12 Loss=  0.0697632293552
Iteration 13 Loss=  0.0692497006055
Iteration 14 Loss=  0.0687509603373
Iteration 15 Loss=  0.0682646537233
Iteration 16 Loss=  0.0677890041861
Iteration 17 Loss=  0.067322643301
Iteration 18 Loss=  0.0668644978643
Iteration 19 Loss=  0.0664137127697
Iteration 20 Loss=  0.0659695970386
Iteration 21 Loss=  0.0655315852333
Iteration 22 Loss=  0.065099209343
Iteration 23 Loss=  0.0646720779518
Iteration 24 Loss=  0.0642498605677
Iteration 25 Loss=  0.0638322756725
Iteration 26 Loss=  0.0634190814961
Iteration 27 Loss=  0.0630100688136
Iteration 28 Loss=  0.0626050552631
Iteration 29 Loss=  0.0622038808218
Iteration 30 Loss=  0.0618064041712
Iteration 31 Loss=  0.0614124997544
Iteration 32 Loss=  0.0610220553757
Iteration 33 Loss=  0.0606349702279
Iteration 34 Loss=  0.0602511532619
Iteration 35 Loss=  0.0598705218301
Iteration 36 Loss=  0.0594930005518
Iteration 37 Loss=  0.0591185203589
Iteration 38 Loss=  0.0587470176893
Iteration 39 Loss=  0.0583784338018
Iteration 40 Loss=  0.0580127141921
Iteration 41 Loss=  0.0576498080922
Iteration 42 Loss=  0.0572896680405
Iteration 43 Loss=  0.05693224951
Iteration 44 Loss=  0.0565775105871
Iteration 45 Loss=  0.0562254116919
Iteration 46 Loss=  0.0558759153346
Iteration 47 Loss=  0.0555289859026
Iteration 48 Loss=  0.0551845894739
Iteration 49 Loss=  0.0548426936528
Iteration 50 Loss=  0.0545032674254
Iteration 51 Loss=  0.0541662810319
Iteration 52 Loss=  0.0538317058534
Iteration 53 Loss=  0.053499514312
Iteration 54 Loss=  0.0531696797814
Iteration 55 Loss=  0.0528421765076
Iteration 56 Loss=  0.0525169795383
Iteration 57 Loss=  0.0521940646597
Iteration 58 Loss=  0.0518734083397
Iteration 59 Loss=  0.051554987678
Iteration 60 Loss=  0.0512387803598
Iteration 61 Loss=  0.0509247646157
Iteration 62 Loss=  0.0506129191848
Iteration 63 Loss=  0.0503032232816
Iteration 64 Loss=  0.0499956565667
Iteration 65 Loss=  0.0496901991196
Iteration 66 Loss=  0.0493868314146
Iteration 67 Loss=  0.049085534299
Iteration 68 Loss=  0.0487862889734
Iteration 69 Loss=  0.0484890769739
Iteration 70 Loss=  0.0481938801555
Iteration 71 Loss=  0.0479006806778
Iteration 72 Loss=  0.0476094609915
Iteration 73 Loss=  0.0473202038263
Iteration 74 Loss=  0.0470328921798
Iteration 75 Loss=  0.0467475093074
Iteration 76 Loss=  0.0464640387135
Iteration 77 Loss=  0.0461824641426
Iteration 78 Loss=  0.0459027695718
Iteration 79 Loss=  0.0456249392039
Iteration 80 Loss=  0.0453489574607
Iteration 81 Loss=  0.0450748089772
Iteration 82 Loss=  0.0448024785961
Iteration 83 Loss=  0.0445319513623
Iteration 84 Loss=  0.0442632125188
Iteration 85 Loss=  0.0439962475016
Iteration 86 Loss=  0.0437310419362
Iteration 87 Loss=  0.0434675816331
Iteration 88 Loss=  0.0432058525847
Iteration 89 Loss=  0.0429458409616
Iteration 90 Loss=  0.0426875331093
Iteration 91 Loss=  0.0424309155452
Iteration 92 Loss=  0.0421759749556
Iteration 93 Loss=  0.0419226981931
Iteration 94 Loss=  0.0416710722733
Iteration 95 Loss=  0.0414210843731
Iteration 96 Loss=  0.0411727218274
Iteration 97 Loss=  0.040925972127
Iteration 98 Loss=  0.0406808229162
Iteration 99 Loss=  0.0404372619908
Iteration 100 Loss=  0.0401952772954
[ -1.06026328e-03  -1.35920977e-04  -5.23483788e-04 ...,   7.12942901e-05
   4.73845904e-05   2.76552746e-04]
CROSS VALIDATION 14
Iteration 1 Loss=  7.87127765376
Iteration 2 Loss=  0.0753811098737
Iteration 3 Loss=  0.0622268111927
Iteration 4 Loss=  0.0614330114812
Iteration 5 Loss=  0.060775497055
Iteration 6 Loss=  0.060196349508
Iteration 7 Loss=  0.0596678501316
Iteration 8 Loss=  0.0591747060331
Iteration 9 Loss=  0.0587076510758
Iteration 10 Loss=  0.0582606823688
Iteration 11 Loss=  0.057829710007
Iteration 12 Loss=  0.0574118351687
Iteration 13 Loss=  0.0570049366335
Iteration 14 Loss=  0.0566074206787
Iteration 15 Loss=  0.0562180629396
Iteration 16 Loss=  0.0558359046722
Iteration 17 Loss=  0.0554601825552
Iteration 18 Loss=  0.0550902799085
Iteration 19 Loss=  0.0547256920032
Iteration 20 Loss=  0.0543660008905
Iteration 21 Loss=  0.0540108568094
Iteration 22 Loss=  0.053659964233
Iteration 23 Loss=  0.053313071248
Iteration 24 Loss=  0.0529699613655
Iteration 25 Loss=  0.0526304471329
Iteration 26 Loss=  0.0522943650984
Iteration 27 Loss=  0.0519615718022
Iteration 28 Loss=  0.051631940557
Iteration 29 Loss=  0.0513053588408
Iteration 30 Loss=  0.050981726169
Iteration 31 Loss=  0.0506609523463
Iteration 32 Loss=  0.0503429560204
Iteration 33 Loss=  0.0500276634773
Iteration 34 Loss=  0.0497150076338
Iteration 35 Loss=  0.0494049271884
Iteration 36 Loss=  0.0490973659034
Iteration 37 Loss=  0.0487922719936
Iteration 38 Loss=  0.0484895976048
Iteration 39 Loss=  0.0481892983659
Iteration 40 Loss=  0.0478913330026
Iteration 41 Loss=  0.0475956630037
Iteration 42 Loss=  0.0473022523306
Iteration 43 Loss=  0.0470110671642
Iteration 44 Loss=  0.0467220756836
Iteration 45 Loss=  0.0464352478712
Iteration 46 Loss=  0.0461505553412
Iteration 47 Loss=  0.0458679711882
Iteration 48 Loss=  0.0455874698521
Iteration 49 Loss=  0.0453090269989
Iteration 50 Loss=  0.0450326194131
Iteration 51 Loss=  0.0447582249026
Iteration 52 Loss=  0.0444858222121
Iteration 53 Loss=  0.0442153909458
Iteration 54 Loss=  0.0439469114976
Iteration 55 Loss=  0.0436803649876
Iteration 56 Loss=  0.0434157332044
Iteration 57 Loss=  0.043152998553
Iteration 58 Loss=  0.0428921440067
Iteration 59 Loss=  0.0426331530638
Iteration 60 Loss=  0.042376009707
Iteration 61 Loss=  0.0421206983671
Iteration 62 Loss=  0.0418672038889
Iteration 63 Loss=  0.0416155115
Iteration 64 Loss=  0.041365606782
Iteration 65 Loss=  0.0411174756438
Iteration 66 Loss=  0.040871104297
Iteration 67 Loss=  0.0406264792331
Iteration 68 Loss=  0.0403835872022
Iteration 69 Loss=  0.040142415193
Iteration 70 Loss=  0.0399029504151
Iteration 71 Loss=  0.0396651802816
Iteration 72 Loss=  0.0394290923934
Iteration 73 Loss=  0.0391946745245
Iteration 74 Loss=  0.0389619146083
Iteration 75 Loss=  0.0387308007253
Iteration 76 Loss=  0.0385013210911
Iteration 77 Loss=  0.0382734640456
Iteration 78 Loss=  0.0380472180431
Iteration 79 Loss=  0.037822571643
Iteration 80 Loss=  0.0375995135015
Iteration 81 Loss=  0.0373780323637
Iteration 82 Loss=  0.0371581170566
Iteration 83 Loss=  0.0369397564827
Iteration 84 Loss=  0.0367229396143
Iteration 85 Loss=  0.0365076554882
Iteration 86 Loss=  0.0362938932012
Iteration 87 Loss=  0.036081641906
Iteration 88 Loss=  0.0358708908076
Iteration 89 Loss=  0.0356616291604
Iteration 90 Loss=  0.0354538462659
Iteration 91 Loss=  0.03524753147
Iteration 92 Loss=  0.0350426741621
Iteration 93 Loss=  0.0348392637735
Iteration 94 Loss=  0.0346372897764
Iteration 95 Loss=  0.0344367416842
Iteration 96 Loss=  0.0342376090507
Iteration 97 Loss=  0.0340398814707
Iteration 98 Loss=  0.0338435485806
Iteration 99 Loss=  0.0336486000592
Iteration 100 Loss=  0.0334550256288
[-0.00068874  0.00048161 -0.0002709  ...,  0.00018159 -0.00015351
  0.00029687]
CROSS VALIDATION 15
Iteration 1 Loss=  7.91952724579
Iteration 2 Loss=  0.0772355149449
Iteration 3 Loss=  0.0636731434058
Iteration 4 Loss=  0.0626199620782
Iteration 5 Loss=  0.0617904537573
Iteration 6 Loss=  0.0610884467632
Iteration 7 Loss=  0.0604676100911
Iteration 8 Loss=  0.0599024425894
Iteration 9 Loss=  0.059377588758
Iteration 10 Loss=  0.0588831790507
Iteration 11 Loss=  0.0584125462349
Iteration 12 Loss=  0.057961005504
Iteration 13 Loss=  0.0575251579401
Iteration 14 Loss=  0.0571024710631
Iteration 15 Loss=  0.0566910149879
Iteration 16 Loss=  0.0562892903079
Iteration 17 Loss=  0.0558961122921
Iteration 18 Loss=  0.0555105308724
Iteration 19 Loss=  0.0551317740673
Iteration 20 Loss=  0.0547592071554
Iteration 21 Loss=  0.0543923026801
Iteration 22 Loss=  0.054030618056
Iteration 23 Loss=  0.0536737786072
Iteration 24 Loss=  0.0533214645512
Iteration 25 Loss=  0.0529734008933
Iteration 26 Loss=  0.0526293494936
Iteration 27 Loss=  0.0522891027799
Iteration 28 Loss=  0.0519524787173
Iteration 29 Loss=  0.0516193167513
Iteration 30 Loss=  0.0512894745092
Iteration 31 Loss=  0.0509628250991
Iteration 32 Loss=  0.0506392548835
Iteration 33 Loss=  0.0503186616322
Iteration 34 Loss=  0.0500009529806
Iteration 35 Loss=  0.0496860451363
Iteration 36 Loss=  0.049373861788
Iteration 37 Loss=  0.0490643331805
Iteration 38 Loss=  0.048757395327
Iteration 39 Loss=  0.0484529893348
Iteration 40 Loss=  0.0481510608264
Iteration 41 Loss=  0.0478515594403
Iteration 42 Loss=  0.0475544383977
Iteration 43 Loss=  0.0472596541274
Iteration 44 Loss=  0.0469671659372
Iteration 45 Loss=  0.0466769357269
Iteration 46 Loss=  0.0463889277365
Iteration 47 Loss=  0.0461031083236
Iteration 48 Loss=  0.0458194457674
Iteration 49 Loss=  0.0455379100944
Iteration 50 Loss=  0.0452584729238
Iteration 51 Loss=  0.0449811073294
Iteration 52 Loss=  0.0447057877159
Iteration 53 Loss=  0.0444324897089
Iteration 54 Loss=  0.0441611900545
Iteration 55 Loss=  0.0438918665303
Iteration 56 Loss=  0.0436244978638
Iteration 57 Loss=  0.0433590636592
Iteration 58 Loss=  0.0430955443304
Iteration 59 Loss=  0.0428339210403
Iteration 60 Loss=  0.0425741756453
Iteration 61 Loss=  0.0423162906444
Iteration 62 Loss=  0.0420602491328
Iteration 63 Loss=  0.0418060347588
Iteration 64 Loss=  0.0415536316845
Iteration 65 Loss=  0.0413030245498
Iteration 66 Loss=  0.0410541984378
Iteration 67 Loss=  0.0408071388448
Iteration 68 Loss=  0.0405618316503
Iteration 69 Loss=  0.0403182630909
Iteration 70 Loss=  0.0400764197347
Iteration 71 Loss=  0.0398362884583
Iteration 72 Loss=  0.0395978564249
Iteration 73 Loss=  0.0393611110639
Iteration 74 Loss=  0.0391260400518
Iteration 75 Loss=  0.0388926312945
Iteration 76 Loss=  0.0386608729105
Iteration 77 Loss=  0.0384307532152
Iteration 78 Loss=  0.0382022607064
Iteration 79 Loss=  0.0379753840503
Iteration 80 Loss=  0.0377501120687
Iteration 81 Loss=  0.0375264337269
Iteration 82 Loss=  0.0373043381227
Iteration 83 Loss=  0.0370838144751
Iteration 84 Loss=  0.0368648521152
Iteration 85 Loss=  0.0366474404766
Iteration 86 Loss=  0.0364315690868
Iteration 87 Loss=  0.0362172275594
Iteration 88 Loss=  0.0360044055866
Iteration 89 Loss=  0.0357930929328
Iteration 90 Loss=  0.0355832794278
Iteration 91 Loss=  0.0353749549615
Iteration 92 Loss=  0.0351681094785
Iteration 93 Loss=  0.0349627329738
Iteration 94 Loss=  0.0347588154882
Iteration 95 Loss=  0.0345563471048
Iteration 96 Loss=  0.0343553179457
Iteration 97 Loss=  0.0341557181692
Iteration 98 Loss=  0.0339575379675
Iteration 99 Loss=  0.0337607675645
Iteration 100 Loss=  0.0335653972146
[-0.00071213  0.00047094 -0.00028203 ...,  0.0001992  -0.00013947
  0.00029935]
CROSS VALIDATION 16
Iteration 1 Loss=  7.89629288223
Iteration 2 Loss=  0.0629258391266
Iteration 3 Loss=  0.0619872779553
Iteration 4 Loss=  0.0612547414719
Iteration 5 Loss=  0.0606302389484
Iteration 6 Loss=  0.0600716313668
Iteration 7 Loss=  0.0595571575615
Iteration 8 Loss=  0.0590742298414
Iteration 9 Loss=  0.0586149743976
Iteration 10 Loss=  0.0581741737564
Iteration 11 Loss=  0.0577482133659
Iteration 12 Loss=  0.0573344986115
Iteration 13 Loss=  0.0569311119868
Iteration 14 Loss=  0.0565366014103
Iteration 15 Loss=  0.0561498441627
Iteration 16 Loss=  0.0557699564351
Iteration 17 Loss=  0.0553962314475
Iteration 18 Loss=  0.0550280960528
Iteration 19 Loss=  0.0546650796396
Iteration 20 Loss=  0.0543067914199
Iteration 21 Loss=  0.0539529035592
Iteration 22 Loss=  0.0536031384547
Iteration 23 Loss=  0.0532572590112
Iteration 24 Loss=  0.0529150611151
Iteration 25 Loss=  0.0525763677457
Iteration 26 Loss=  0.0522410243187
Iteration 27 Loss=  0.0519088949708
Iteration 28 Loss=  0.0515798595677
Iteration 29 Loss=  0.0512538112775
Iteration 30 Loss=  0.0509306545855
Iteration 31 Loss=  0.0506103036611
Iteration 32 Loss=  0.0502926810046
Iteration 33 Loss=  0.0499777163183
Iteration 34 Loss=  0.0496653455615
Iteration 35 Loss=  0.0493555101529
Iteration 36 Loss=  0.0490481562959
Iteration 37 Loss=  0.0487432344036
Iteration 38 Loss=  0.0484406986075
Iteration 39 Loss=  0.0481405063357
Iteration 40 Loss=  0.047842617949
Iteration 41 Loss=  0.0475469964258
Iteration 42 Loss=  0.0472536070882
Iteration 43 Loss=  0.0469624173637
Iteration 44 Loss=  0.0466733965758
Iteration 45 Loss=  0.0463865157604
Iteration 46 Loss=  0.0461017475041
Iteration 47 Loss=  0.0458190658013
Iteration 48 Loss=  0.045538445927
Iteration 49 Loss=  0.0452598643244
Iteration 50 Loss=  0.0449832985038
Iteration 51 Loss=  0.0447087269525
Iteration 52 Loss=  0.0444361290544
Iteration 53 Loss=  0.0441654850166
Iteration 54 Loss=  0.0438967758045
Iteration 55 Loss=  0.0436299830815
Iteration 56 Loss=  0.0433650891561
Iteration 57 Loss=  0.0431020769324
Iteration 58 Loss=  0.0428409298655
Iteration 59 Loss=  0.0425816319209
Iteration 60 Loss=  0.0423241675371
Iteration 61 Loss=  0.0420685215916
Iteration 62 Loss=  0.0418146793692
Iteration 63 Loss=  0.0415626265331
Iteration 64 Loss=  0.0413123490983
Iteration 65 Loss=  0.0410638334069
Iteration 66 Loss=  0.0408170661051
Iteration 67 Loss=  0.0405720341221
Iteration 68 Loss=  0.0403287246506
Iteration 69 Loss=  0.0400871251282
Iteration 70 Loss=  0.0398472232209
Iteration 71 Loss=  0.0396090068067
Iteration 72 Loss=  0.0393724639616
Iteration 73 Loss=  0.0391375829451
Iteration 74 Loss=  0.0389043521878
Iteration 75 Loss=  0.0386727602796
Iteration 76 Loss=  0.0384427959581
Iteration 77 Loss=  0.0382144480987
Iteration 78 Loss=  0.0379877057045
Iteration 79 Loss=  0.0377625578973
Iteration 80 Loss=  0.0375389939096
Iteration 81 Loss=  0.037317003076
Iteration 82 Loss=  0.0370965748267
Iteration 83 Loss=  0.03687769868
Iteration 84 Loss=  0.0366603642364
Iteration 85 Loss=  0.0364445611729
Iteration 86 Loss=  0.036230279237
Iteration 87 Loss=  0.0360175082423
Iteration 88 Loss=  0.0358062380639
Iteration 89 Loss=  0.0355964586336
Iteration 90 Loss=  0.0353881599368
Iteration 91 Loss=  0.0351813320087
Iteration 92 Loss=  0.0349759649309
Iteration 93 Loss=  0.0347720488291
Iteration 94 Loss=  0.03456957387
Iteration 95 Loss=  0.0343685302595
Iteration 96 Loss=  0.0341689082403
Iteration 97 Loss=  0.0339706980908
Iteration 98 Loss=  0.0337738901231
Iteration 99 Loss=  0.0335784746818
Iteration 100 Loss=  0.0333844421436
[-0.00069647  0.00046996 -0.00027662 ...,  0.00019569 -0.00014058
  0.0003042 ]
CROSS VALIDATION 17
Iteration 1 Loss=  7.88731373611
Iteration 2 Loss=  0.0768516723967
Iteration 3 Loss=  0.0636809363684
Iteration 4 Loss=  0.0626076876445
Iteration 5 Loss=  0.0617684530752
Iteration 6 Loss=  0.0610610897219
Iteration 7 Loss=  0.0604370879013
Iteration 8 Loss=  0.05986998293
Iteration 9 Loss=  0.0593439357952
Iteration 10 Loss=  0.0588488113972
Iteration 11 Loss=  0.0583777863902
Iteration 12 Loss=  0.0579260791775
Iteration 13 Loss=  0.0574902282127
Iteration 14 Loss=  0.0570676590478
Iteration 15 Loss=  0.0566564128439
Iteration 16 Loss=  0.0562549697241
Iteration 17 Loss=  0.0558621301817
Iteration 18 Loss=  0.0554769332934
Iteration 19 Loss=  0.0550985989812
Iteration 20 Loss=  0.0547264864074
Iteration 21 Loss=  0.0543600634442
Iteration 22 Loss=  0.0539988839054
Iteration 23 Loss=  0.0536425703186
Iteration 24 Loss=  0.0532908007159
Iteration 25 Loss=  0.0529432983857
Iteration 26 Loss=  0.0525998238351
Iteration 27 Loss=  0.0522601684218
Iteration 28 Loss=  0.0519241492639
Iteration 29 Loss=  0.0515916051351
Iteration 30 Loss=  0.0512623931299
Iteration 31 Loss=  0.0509363859342
Iteration 32 Loss=  0.0506134695749
Iteration 33 Loss=  0.0502935415554
Iteration 34 Loss=  0.0499765092983
Iteration 35 Loss=  0.0496622888405
Iteration 36 Loss=  0.0493508037316
Iteration 37 Loss=  0.0490419841009
Iteration 38 Loss=  0.0487357658626
Iteration 39 Loss=  0.0484320900359
Iteration 40 Loss=  0.0481309021612
Iteration 41 Loss=  0.047832151796
Iteration 42 Loss=  0.0475357920792
Iteration 43 Loss=  0.0472417793518
Iteration 44 Loss=  0.0469500728261
Iteration 45 Loss=  0.0466606342964
Iteration 46 Loss=  0.0463734278848
Iteration 47 Loss=  0.0460884198172
Iteration 48 Loss=  0.0458055782252
Iteration 49 Loss=  0.0455248729711
Iteration 50 Loss=  0.0452462754915
Iteration 51 Loss=  0.0449697586582
Iteration 52 Loss=  0.0446952966542
Iteration 53 Loss=  0.044422864862
Iteration 54 Loss=  0.0441524397634
Iteration 55 Loss=  0.0438839988492
Iteration 56 Loss=  0.0436175205379
Iteration 57 Loss=  0.0433529841017
Iteration 58 Loss=  0.0430903695994
Iteration 59 Loss=  0.0428296578159
Iteration 60 Loss=  0.0425708302063
Iteration 61 Loss=  0.0423138688452
Iteration 62 Loss=  0.0420587563808
Iteration 63 Loss=  0.041805475992
Iteration 64 Loss=  0.0415540113493
Iteration 65 Loss=  0.0413043465794
Iteration 66 Loss=  0.0410564662317
Iteration 67 Loss=  0.0408103552482
Iteration 68 Loss=  0.0405659989354
Iteration 69 Loss=  0.040323382938
Iteration 70 Loss=  0.0400824932152
Iteration 71 Loss=  0.0398433160185
Iteration 72 Loss=  0.0396058378711
Iteration 73 Loss=  0.0393700455487
Iteration 74 Loss=  0.0391359260623
Iteration 75 Loss=  0.0389034666412
Iteration 76 Loss=  0.0386726547186
Iteration 77 Loss=  0.0384434779171
Iteration 78 Loss=  0.0382159240362
Iteration 79 Loss=  0.0379899810398
Iteration 80 Loss=  0.0377656370456
Iteration 81 Loss=  0.0375428803151
Iteration 82 Loss=  0.0373216992437
Iteration 83 Loss=  0.0371020823525
Iteration 84 Loss=  0.0368840182804
Iteration 85 Loss=  0.0366674957772
Iteration 86 Loss=  0.0364525036967
Iteration 87 Loss=  0.0362390309908
Iteration 88 Loss=  0.0360270667047
Iteration 89 Loss=  0.0358165999717
Iteration 90 Loss=  0.0356076200093
Iteration 91 Loss=  0.035400116115
Iteration 92 Loss=  0.0351940776635
Iteration 93 Loss=  0.0349894941039
Iteration 94 Loss=  0.0347863549568
Iteration 95 Loss=  0.0345846498128
Iteration 96 Loss=  0.0343843683304
Iteration 97 Loss=  0.0341855002353
Iteration 98 Loss=  0.0339880353186
Iteration 99 Loss=  0.0337919634368
Iteration 100 Loss=  0.0335972745109
[-0.00071182  0.00047016 -0.00028054 ...,  0.0001971  -0.0001384
  0.00030006]
CROSS VALIDATION 18
Iteration 1 Loss=  7.00193745681
Iteration 2 Loss=  0.067061277934
Iteration 3 Loss=  0.0655919698171
Iteration 4 Loss=  0.0644948669955
Iteration 5 Loss=  0.0635992947961
Iteration 6 Loss=  0.062829480048
Iteration 7 Loss=  0.0621450150719
Iteration 8 Loss=  0.061521894383
Iteration 9 Loss=  0.0609447799833
Iteration 10 Loss=  0.0604033371357
Iteration 11 Loss=  0.0598903117724
Iteration 12 Loss=  0.0594004432113
Iteration 13 Loss=  0.0589298127008
Iteration 14 Loss=  0.0584754346668
Iteration 15 Loss=  0.0580349903499
Iteration 16 Loss=  0.0576066486365
Iteration 17 Loss=  0.0571889422392
Iteration 18 Loss=  0.0567806801061
Iteration 19 Loss=  0.0563808841793
Iteration 20 Loss=  0.0559887429047
Iteration 21 Loss=  0.0556035765017
Iteration 22 Loss=  0.0552248106433
Iteration 23 Loss=  0.054851956249
Iteration 24 Loss=  0.0544845937863
Iteration 25 Loss=  0.0541223609436
Iteration 26 Loss=  0.0537649428551
Iteration 27 Loss=  0.0534120642781
Iteration 28 Loss=  0.0530634832799
Iteration 29 Loss=  0.052718986105
Iteration 30 Loss=  0.0523783829702
Iteration 31 Loss=  0.0520415045968
Iteration 32 Loss=  0.0517081993343
Iteration 33 Loss=  0.0513783307581
Iteration 34 Loss=  0.0510517756548
Iteration 35 Loss=  0.0507284223213
Iteration 36 Loss=  0.0504081691241
Iteration 37 Loss=  0.0500909232708
Iteration 38 Loss=  0.0497765997609
Iteration 39 Loss=  0.0494651204837
Iteration 40 Loss=  0.0491564134404
Iteration 41 Loss=  0.0488504120714
Iteration 42 Loss=  0.0485470546722
Iteration 43 Loss=  0.0482462838833
Iteration 44 Loss=  0.0479480462458
Iteration 45 Loss=  0.0476522918107
Iteration 46 Loss=  0.0473589737961
Iteration 47 Loss=  0.047068048284
Iteration 48 Loss=  0.0467794739534
Iteration 49 Loss=  0.0464932118429
Iteration 50 Loss=  0.0462092251404
Iteration 51 Loss=  0.0459274789955
Iteration 52 Loss=  0.0456479403521
Iteration 53 Loss=  0.0453705777991
Iteration 54 Loss=  0.0450953614364
Iteration 55 Loss=  0.0448222627544
Iteration 56 Loss=  0.0445512545262
Iteration 57 Loss=  0.0442823107101
Iteration 58 Loss=  0.0440154063614
Iteration 59 Loss=  0.0437505175535
Iteration 60 Loss=  0.0434876213057
Iteration 61 Loss=  0.0432266955178
Iteration 62 Loss=  0.0429677189112
Iteration 63 Loss=  0.042710670975
Iteration 64 Loss=  0.0424555319164
Iteration 65 Loss=  0.0422022826167
Iteration 66 Loss=  0.0419509045896
Iteration 67 Loss=  0.041701379944
Iteration 68 Loss=  0.0414536913496
Iteration 69 Loss=  0.0412078220051
Iteration 70 Loss=  0.040963755609
Iteration 71 Loss=  0.0407214763329
Iteration 72 Loss=  0.0404809687961
Iteration 73 Loss=  0.040242218043
Iteration 74 Loss=  0.0400052095212
Iteration 75 Loss=  0.0397699290614
Iteration 76 Loss=  0.0395363628588
Iteration 77 Loss=  0.0393044974554
Iteration 78 Loss=  0.0390743197231
Iteration 79 Loss=  0.0388458168485
Iteration 80 Loss=  0.0386189763174
Iteration 81 Loss=  0.0383937859011
Iteration 82 Loss=  0.0381702336425
Iteration 83 Loss=  0.0379483078433
Iteration 84 Loss=  0.0377279970516
Iteration 85 Loss=  0.0375092900496
Iteration 86 Loss=  0.0372921758421
Iteration 87 Loss=  0.0370766436451
Iteration 88 Loss=  0.0368626828751
Iteration 89 Loss=  0.0366502831378
Iteration 90 Loss=  0.0364394342179
Iteration 91 Loss=  0.0362301260689
Iteration 92 Loss=  0.0360223488029
Iteration 93 Loss=  0.0358160926803
Iteration 94 Loss=  0.0356113481008
Iteration 95 Loss=  0.0354081055931
Iteration 96 Loss=  0.0352063558057
Iteration 97 Loss=  0.0350060894977
Iteration 98 Loss=  0.0348072975294
Iteration 99 Loss=  0.0346099708533
Iteration 100 Loss=  0.0344141005054
[-0.00065124 -0.00017791 -0.0011938  ...,  0.00070459 -0.00012505
  0.00025022]
CROSS VALIDATION 19
Iteration 1 Loss=  7.72063487598
Iteration 2 Loss=  0.0758672266969
Iteration 3 Loss=  0.0618752289918
Iteration 4 Loss=  0.0608536410177
Iteration 5 Loss=  0.0600412751389
Iteration 6 Loss=  0.0593515901349
Iteration 7 Loss=  0.0587414046957
Iteration 8 Loss=  0.058186384727
Iteration 9 Loss=  0.0576716292081
Iteration 10 Loss=  0.0571874410445
Iteration 11 Loss=  0.0567272077371
Iteration 12 Loss=  0.0562862493898
Iteration 13 Loss=  0.0558611517153
Iteration 14 Loss=  0.0554493597972
Iteration 15 Loss=  0.0550489201596
Iteration 16 Loss=  0.0546583111957
Iteration 17 Loss=  0.0542763283305
Iteration 18 Loss=  0.0539020042385
Iteration 19 Loss=  0.0535345521656
Iteration 20 Loss=  0.053173324867
Iteration 21 Loss=  0.0528177843357
Iteration 22 Loss=  0.052467479136
Iteration 23 Loss=  0.0521220271926
Iteration 24 Loss=  0.0517811025546
Iteration 25 Loss=  0.0514444250979
Iteration 26 Loss=  0.0511117524308
Iteration 27 Loss=  0.0507828734667
Iteration 28 Loss=  0.0504576032773
Iteration 29 Loss=  0.0501357789355
Iteration 30 Loss=  0.0498172561327
Iteration 31 Loss=  0.0495019064056
Iteration 32 Loss=  0.0491896148486
Iteration 33 Loss=  0.0488802782143
Iteration 34 Loss=  0.0485738033272
Iteration 35 Loss=  0.048270105751
Iteration 36 Loss=  0.0479691086646
Iteration 37 Loss=  0.0476707419074
Iteration 38 Loss=  0.0473749411669
Iteration 39 Loss=  0.0470816472818
Iteration 40 Loss=  0.0467908056444
Iteration 41 Loss=  0.0465023656834
Iteration 42 Loss=  0.0462162804169
Iteration 43 Loss=  0.0459325060631
Iteration 44 Loss=  0.0456510017004
Iteration 45 Loss=  0.0453717289708
Iteration 46 Loss=  0.0450946518181
Iteration 47 Loss=  0.0448197362584
Iteration 48 Loss=  0.0445469501769
Iteration 49 Loss=  0.0442762631477
Iteration 50 Loss=  0.0440076462741
Iteration 51 Loss=  0.0437410720466
Iteration 52 Loss=  0.0434765142155
Iteration 53 Loss=  0.0432139476778
Iteration 54 Loss=  0.0429533483753
Iteration 55 Loss=  0.0426946932035
Iteration 56 Loss=  0.0424379599296
Iteration 57 Loss=  0.0421831271184
Iteration 58 Loss=  0.0419301740659
Iteration 59 Loss=  0.041679080739
Iteration 60 Loss=  0.0414298277216
Iteration 61 Loss=  0.041182396165
Iteration 62 Loss=  0.0409367677436
Iteration 63 Loss=  0.0406929246148
Iteration 64 Loss=  0.0404508493826
Iteration 65 Loss=  0.040210525064
Iteration 66 Loss=  0.03997193506
Iteration 67 Loss=  0.0397350631276
Iteration 68 Loss=  0.039499893356
Iteration 69 Loss=  0.039266410144
Iteration 70 Loss=  0.0390345981801
Iteration 71 Loss=  0.0388044424243
Iteration 72 Loss=  0.0385759280919
Iteration 73 Loss=  0.0383490406386
Iteration 74 Loss=  0.0381237657473
Iteration 75 Loss=  0.0379000893164
Iteration 76 Loss=  0.0376779974488
Iteration 77 Loss=  0.0374574764427
Iteration 78 Loss=  0.0372385127828
Iteration 79 Loss=  0.0370210931328
Iteration 80 Loss=  0.0368052043287
Iteration 81 Loss=  0.0365908333726
Iteration 82 Loss=  0.036377967428
Iteration 83 Loss=  0.0361665938142
Iteration 84 Loss=  0.035956700003
Iteration 85 Loss=  0.0357482736147
Iteration 86 Loss=  0.0355413024149
Iteration 87 Loss=  0.035335774312
Iteration 88 Loss=  0.0351316773545
Iteration 89 Loss=  0.0349289997289
Iteration 90 Loss=  0.034727729758
Iteration 91 Loss=  0.0345278558991
Iteration 92 Loss=  0.0343293667427
Iteration 93 Loss=  0.0341322510112
Iteration 94 Loss=  0.0339364975576
Iteration 95 Loss=  0.0337420953647
Iteration 96 Loss=  0.0335490335439
Iteration 97 Loss=  0.0333573013346
Iteration 98 Loss=  0.0331668881032
Iteration 99 Loss=  0.0329777833425
Iteration 100 Loss=  0.0327899766707
[-0.00084464  0.00047144 -0.0003545  ...,  0.00017396 -0.00015344
  0.0003167 ]
Accuracy (Logistic Loss):	0.95 for lmda= 0.3 learning rate= 0.0001
---------------------------------------------------------------------------------
lmda= 0.3 learning rate= 0.001
CROSS VALIDATION 0
Iteration 1 Loss=  141.327629424
Iteration 2 Loss=  50.7550364899
Iteration 3 Loss=  7.35312290345
Iteration 4 Loss=  6.89989380691
Iteration 5 Loss=  6.47460068489
Iteration 6 Loss=  6.07552163328
Iteration 7 Loss=  5.70104088396
Iteration 8 Loss=  5.34964226379
Iteration 9 Loss=  5.01990305718
Iteration 10 Loss=  4.71048824744
Iteration 11 Loss=  4.42014511389
Iteration 12 Loss=  4.14769816273
Iteration 13 Loss=  3.89204437146
Iteration 14 Loss=  3.65214872759
Iteration 15 Loss=  3.42704004336
Iteration 16 Loss=  3.21580702939
Iteration 17 Loss=  3.01759461013
Iteration 18 Loss=  2.83160046478
Iteration 19 Loss=  2.65707177655
Iteration 20 Loss=  2.49330217287
Iteration 21 Loss=  2.33962883884
Iteration 22 Loss=  2.19542978754
Iteration 23 Loss=  2.06012127597
Iteration 24 Loss=  1.93315536609
Iteration 25 Loss=  1.81401764529
Iteration 26 Loss=  1.70222513225
Iteration 27 Loss=  1.59732438793
Iteration 28 Loss=  1.49888982101
Iteration 29 Loss=  1.40652213392
Iteration 30 Loss=  1.31984683566
Iteration 31 Loss=  1.23851276932
Iteration 32 Loss=  1.16219065093
Iteration 33 Loss=  1.09057165192
Iteration 34 Loss=  1.02336606195
Iteration 35 Loss=  0.960302051364
Iteration 36 Loss=  0.901124533868
Iteration 37 Loss=  0.845594118996
Iteration 38 Loss=  0.793486141941
Iteration 39 Loss=  0.744589759931
Iteration 40 Loss=  0.698707107281
Iteration 41 Loss=  0.655652503552
Iteration 42 Loss=  0.615251710828
Iteration 43 Loss=  0.577341237054
Iteration 44 Loss=  0.5417676829
Iteration 45 Loss=  0.508387129898
Iteration 46 Loss=  0.477064567725
Iteration 47 Loss=  0.447673358484
Iteration 48 Loss=  0.420094735706
Iteration 49 Loss=  0.394217335372
Iteration 50 Loss=  0.36993675564
Iteration 51 Loss=  0.347155140922
Iteration 52 Loss=  0.32578078464
Iteration 53 Loss=  0.305727743718
Iteration 54 Loss=  0.28691545723
Iteration 55 Loss=  0.269268363099
Iteration 56 Loss=  0.252715511776
Iteration 57 Loss=  0.237190185303
Iteration 58 Loss=  0.222629541955
Iteration 59 Loss=  0.20897431413
Iteration 60 Loss=  0.196168580505
Iteration 61 Loss=  0.184159609023
Iteration 62 Loss=  0.172897736893
Iteration 63 Loss=  0.162336244331
Iteration 64 Loss=  0.152431206489
Iteration 65 Loss=  0.143141351796
Iteration 66 Loss=  0.13442796678
Iteration 67 Loss=  0.12625484782
Iteration 68 Loss=  0.118588250809
Iteration 69 Loss=  0.111396787468
Iteration 70 Loss=  0.104651260667
Iteration 71 Loss=  0.0983244669287
Iteration 72 Loss=  0.0923909904394
Iteration 73 Loss=  0.0868269923808
Iteration 74 Loss=  0.0816099981319
Iteration 75 Loss=  0.0767187069856
Iteration 76 Loss=  0.0721328688166
Iteration 77 Loss=  0.0678332608083
Iteration 78 Loss=  0.0638017518079
Iteration 79 Loss=  0.0600213964829
Iteration 80 Loss=  0.0564764959556
Iteration 81 Loss=  0.0531525941391
Iteration 82 Loss=  0.0500364127621
Iteration 83 Loss=  0.0471157401441
Iteration 84 Loss=  0.0443792879471
Iteration 85 Loss=  0.0418165316276
Iteration 86 Loss=  0.039417555627
Iteration 87 Loss=  0.0371729268255
Iteration 88 Loss=  0.0350736158835
Iteration 89 Loss=  0.0331109751642
Iteration 90 Loss=  0.031276762506
Iteration 91 Loss=  0.0295631753578
Iteration 92 Loss=  0.0279628457896
Iteration 93 Loss=  0.0264687646648
Iteration 94 Loss=  0.025074153448
Iteration 95 Loss=  0.0237723512793
Iteration 96 Loss=  0.0225567898152
Iteration 97 Loss=  0.0214210793958
Iteration 98 Loss=  0.0203591656449
Iteration 99 Loss=  0.019365485243
Iteration 100 Loss=  0.0184350655985
[ -6.32928115e-04   2.01992053e-04   1.13705757e-04 ...,   2.76204191e-04
   1.13276809e-04   7.59265711e-05]
CROSS VALIDATION 1
Iteration 1 Loss=  66.6561668447
Iteration 2 Loss=  7.31926428017
Iteration 3 Loss=  6.86812214213
Iteration 4 Loss=  6.4447873384
Iteration 5 Loss=  6.04754589066
Iteration 6 Loss=  5.67478946617
Iteration 7 Loss=  5.325008866
Iteration 8 Loss=  4.9967879147
Iteration 9 Loss=  4.68879772649
Iteration 10 Loss=  4.39979132501
Iteration 11 Loss=  4.12859859452
Iteration 12 Loss=  3.87412154249
Iteration 13 Loss=  3.63532985404
Iteration 14 Loss=  3.41125672045
Iteration 15 Loss=  3.20099492482
Iteration 16 Loss=  3.00369316894
Iteration 17 Loss=  2.81855262661
Iteration 18 Loss=  2.64482370941
Iteration 19 Loss=  2.48180303174
Iteration 20 Loss=  2.32883056305
Iteration 21 Loss=  2.18528695551
Iteration 22 Loss=  2.05059103642
Iteration 23 Loss=  1.92419745519
Iteration 24 Loss=  1.80559447536
Iteration 25 Loss=  1.69430190271
Iteration 26 Loss=  1.58986914106
Iteration 27 Loss=  1.49187336793
Iteration 28 Loss=  1.39991782269
Iteration 29 Loss=  1.31363020017
Iteration 30 Loss=  1.23266114337
Iteration 31 Loss=  1.15668282911
Iteration 32 Loss=  1.08538764089
Iteration 33 Loss=  1.01848692375
Iteration 34 Loss=  0.955709815919
Iteration 35 Loss=  0.896802152889
Iteration 36 Loss=  0.841525439267
Iteration 37 Loss=  0.789655884605
Iteration 38 Loss=  0.740983499372
Iteration 39 Loss=  0.695311247646
Iteration 40 Loss=  0.652454253356
Iteration 41 Loss=  0.612239057173
Iteration 42 Loss=  0.574502921302
Iteration 43 Loss=  0.539093179619
Iteration 44 Loss=  0.505866630509
Iteration 45 Loss=  0.474688969516
Iteration 46 Loss=  0.445434258227
Iteration 47 Loss=  0.417984424557
Iteration 48 Loss=  0.392228787721
Iteration 49 Loss=  0.368063598811
Iteration 50 Loss=  0.345391585997
Iteration 51 Loss=  0.324121493823
Iteration 52 Loss=  0.304167611716
Iteration 53 Loss=  0.285449299745
Iteration 54 Loss=  0.2678905378
Iteration 55 Loss=  0.251419539279
Iteration 56 Loss=  0.235968470547
Iteration 57 Loss=  0.221473297962
Iteration 58 Loss=  0.207873751976
Iteration 59 Loss=  0.19511336383
Iteration 60 Loss=  0.183139505021
Iteration 61 Loss=  0.171903356749
Iteration 62 Loss=  0.161359766952
Iteration 63 Loss=  0.151467003497
Iteration 64 Loss=  0.142186449589
Iteration 65 Loss=  0.133482288877
Iteration 66 Loss=  0.125321201132
Iteration 67 Loss=  0.117672059758
Iteration 68 Loss=  0.110505609028
Iteration 69 Loss=  0.10379410809
Iteration 70 Loss=  0.0975109549779
Iteration 71 Loss=  0.0916303342764
Iteration 72 Loss=  0.0861269519477
Iteration 73 Loss=  0.0809759230049
Iteration 74 Loss=  0.0761528646607
Iteration 75 Loss=  0.0716342149256
Iteration 76 Loss=  0.0673977288694
Iteration 77 Loss=  0.0634230108073
Iteration 78 Loss=  0.0596918835528
Iteration 79 Loss=  0.0561884428235
Iteration 80 Loss=  0.052898782836
Iteration 81 Loss=  0.0498105161278
Iteration 82 Loss=  0.0469122670233
Iteration 83 Loss=  0.0441932884705
Iteration 84 Loss=  0.0416432767931
Iteration 85 Loss=  0.0392523730331
Iteration 86 Loss=  0.0370112666655
Iteration 87 Loss=  0.0349112877749
Iteration 88 Loss=  0.0329444077223
Iteration 89 Loss=  0.0311031424783
Iteration 90 Loss=  0.0293804126974
Iteration 91 Loss=  0.0277694271597
Iteration 92 Loss=  0.0262636303422
Iteration 93 Loss=  0.0248567162487
Iteration 94 Loss=  0.0235426781172
Iteration 95 Loss=  0.022315849052
Iteration 96 Loss=  0.0211708983621
Iteration 97 Loss=  0.0201027764071
Iteration 98 Loss=  0.0191066292386
Iteration 99 Loss=  0.0181777182792
Iteration 100 Loss=  0.0173113778597
[ -3.84987135e-04   2.57403158e-04  -1.70809442e-04 ...,   1.53757410e-04
   8.49699087e-06   2.08334574e-04]
CROSS VALIDATION 2
Iteration 1 Loss=  306.013361422
Iteration 2 Loss=  68.5642606553
Iteration 3 Loss=  17.414751628
Iteration 4 Loss=  7.8833706081
Iteration 5 Loss=  7.35296590794
Iteration 6 Loss=  6.89974648128
Iteration 7 Loss=  6.47446242809
Iteration 8 Loss=  6.07539187801
Iteration 9 Loss=  5.70091909273
Iteration 10 Loss=  5.3495279242
Iteration 11 Loss=  5.01979567617
Iteration 12 Loss=  4.71038734403
Iteration 13 Loss=  4.42005020971
Iteration 14 Loss=  4.14760876973
Iteration 15 Loss=  3.89195997592
Iteration 16 Loss=  3.65206876949
Iteration 17 Loss=  3.42696389035
Iteration 18 Loss=  3.21573394481
Iteration 19 Loss=  3.01752371573
Iteration 20 Loss=  2.83153070017
Iteration 21 Loss=  2.65700186051
Iteration 22 Loss=  2.49323057614
Iteration 23 Loss=  2.33955378316
Iteration 24 Loss=  2.1953492908
Iteration 25 Loss=  2.06003326372
Iteration 26 Loss=  1.93305786008
Iteration 27 Loss=  1.81390901606
Iteration 28 Loss=  1.70210436798
Iteration 29 Loss=  1.59719130369
Iteration 30 Loss=  1.49874513571
Iteration 31 Loss=  1.4063673886
Iteration 32 Loss=  1.31968419375
Iteration 33 Loss=  1.23834478467
Iteration 34 Loss=  1.16202008606
Iteration 35 Loss=  1.09040138934
Iteration 36 Loss=  1.02319910674
Iteration 37 Loss=  0.960141594833
Iteration 38 Loss=  0.900974037176
Iteration 39 Loss=  0.845457374817
Iteration 40 Loss=  0.793367274431
Iteration 41 Loss=  0.744493128622
Iteration 42 Loss=  0.698637093155
Iteration 43 Loss=  0.65561318136
Iteration 44 Loss=  0.615246450862
Iteration 45 Loss=  0.577372320671
Iteration 46 Loss=  0.541836035651
Iteration 47 Loss=  0.508492251467
Iteration 48 Loss=  0.477204668877
Iteration 49 Loss=  0.447845634303
Iteration 50 Loss=  0.420295658036
Iteration 51 Loss=  0.394442860983
Iteration 52 Loss=  0.37018240655
Iteration 53 Loss=  0.347415981066
Iteration 54 Loss=  0.326051357677
Iteration 55 Loss=  0.306002037814
Iteration 56 Loss=  0.287186936719
Iteration 57 Loss=  0.269530077949
Iteration 58 Loss=  0.252960280333
Iteration 59 Loss=  0.237410841808
Iteration 60 Loss=  0.222819234368
Iteration 61 Loss=  0.209126821825
Iteration 62 Loss=  0.196278604043
Iteration 63 Loss=  0.184222984418
Iteration 64 Loss=  0.172911554035
Iteration 65 Loss=  0.162298886105
Iteration 66 Loss=  0.152342337094
Iteration 67 Loss=  0.143001855754
Iteration 68 Loss=  0.134239806858
Iteration 69 Loss=  0.126020819849
Iteration 70 Loss=  0.118311669761
Iteration 71 Loss=  0.111081186879
Iteration 72 Loss=  0.104300177906
Iteration 73 Loss=  0.097941336457
Iteration 74 Loss=  0.0919791319206
Iteration 75 Loss=  0.0863896851492
Iteration 76 Loss=  0.0811506479959
Iteration 77 Loss=  0.0762410917021
Iteration 78 Loss=  0.071641390952
Iteration 79 Loss=  0.0673330905836
Iteration 80 Loss=  0.0632987631413
Iteration 81 Loss=  0.059521881831
Iteration 82 Loss=  0.0559867257331
Iteration 83 Loss=  0.0526783176175
Iteration 84 Loss=  0.0495823940932
Iteration 85 Loss=  0.0466854178591
Iteration 86 Loss=  0.043974638775
Iteration 87 Loss=  0.0414381907943
Iteration 88 Loss=  0.039065191976
Iteration 89 Loss=  0.0368458033893
Iteration 90 Loss=  0.03477119724
Iteration 91 Loss=  0.0328333879547
Iteration 92 Loss=  0.0310249054919
Iteration 93 Loss=  0.0293383554846
Iteration 94 Loss=  0.0277660165019
Iteration 95 Loss=  0.0262996993254
Iteration 96 Loss=  0.0249309967112
Iteration 97 Loss=  0.0236517743559
Iteration 98 Loss=  0.0224545713736
Iteration 99 Loss=  0.0213327263682
Iteration 100 Loss=  0.020280320104
[ -1.02643710e-03  -2.73314744e-04  -3.79123328e-04 ...,   9.98046124e-04
   2.39958188e-04   8.78955321e-05]
CROSS VALIDATION 3
Iteration 1 Loss=  66.7004090752
Iteration 2 Loss=  7.32066476293
Iteration 3 Loss=  6.86943630245
Iteration 4 Loss=  6.44602049698
Iteration 5 Loss=  6.04870304027
Iteration 6 Loss=  5.67587529181
Iteration 7 Loss=  5.32602776392
Iteration 8 Loss=  4.99774401016
Iteration 9 Loss=  4.68969489049
Iteration 10 Loss=  4.40063318994
Iteration 11 Loss=  4.12938856889
Iteration 12 Loss=  3.87486282471
Iteration 13 Loss=  3.63602544537
Iteration 14 Loss=  3.41190943718
Iteration 15 Loss=  3.20160740963
Iteration 16 Loss=  3.00426790164
Iteration 17 Loss=  2.81909193415
Iteration 18 Loss=  2.6453297753
Iteration 19 Loss=  2.48227790493
Iteration 20 Loss=  2.32927616618
Iteration 21 Loss=  2.18570509271
Iteration 22 Loss=  2.05098340063
Iteration 23 Loss=  1.924565635
Iteration 24 Loss=  1.80593996144
Iteration 25 Loss=  1.69462609384
Iteration 26 Loss=  1.59017334981
Iteration 27 Loss=  1.49215882596
Iteration 28 Loss=  1.40018568574
Iteration 29 Loss=  1.31388155273
Iteration 30 Loss=  1.23289700308
Iteration 31 Loss=  1.15690415084
Iteration 32 Loss=  1.08559532063
Iteration 33 Loss=  1.01868180218
Iteration 34 Loss=  0.955892681819
Iteration 35 Loss=  0.896973746229
Iteration 36 Loss=  0.841686454164
Iteration 37 Loss=  0.789806972019
Iteration 38 Loss=  0.741125269597
Iteration 39 Loss=  0.695444272589
Iteration 40 Loss=  0.652579068609
Iteration 41 Loss=  0.612356163878
Iteration 42 Loss=  0.574612787846
Iteration 43 Loss=  0.539196243188
Iteration 44 Loss=  0.505963298607
Iteration 45 Loss=  0.474779621614
Iteration 46 Loss=  0.445519247843
Iteration 47 Loss=  0.418064082238
Iteration 48 Loss=  0.392303425638
Iteration 49 Loss=  0.368133517881
Iteration 50 Loss=  0.345457086539
Iteration 51 Loss=  0.324182890461
Iteration 52 Loss=  0.304225252408
Iteration 53 Loss=  0.28550358754
Iteration 54 Loss=  0.267941953023
Iteration 55 Loss=  0.251468660572
Iteration 56 Loss=  0.236015995997
Iteration 57 Loss=  0.22152007075
Iteration 58 Loss=  0.207920795042
Iteration 59 Loss=  0.195161922877
Iteration 60 Loss=  0.183191089782
Iteration 61 Loss=  0.171959759587
Iteration 62 Loss=  0.161423028595
Iteration 63 Loss=  0.151539292504
Iteration 64 Loss=  0.142269832743
Iteration 65 Loss=  0.133578402196
Iteration 66 Loss=  0.125430883997
Iteration 67 Loss=  0.117795063581
Iteration 68 Loss=  0.110640495507
Iteration 69 Loss=  0.103938387407
Iteration 70 Loss=  0.097661415053
Iteration 71 Loss=  0.0917834488343
Iteration 72 Loss=  0.0862792650584
Iteration 73 Loss=  0.0811243615269
Iteration 74 Loss=  0.0762949720143
Iteration 75 Loss=  0.0717683051832
Iteration 76 Loss=  0.0675229480751
Iteration 77 Loss=  0.0635392944614
Iteration 78 Loss=  0.0597998228208
Iteration 79 Loss=  0.0562890960889
Iteration 80 Loss=  0.052993473184
Iteration 81 Loss=  0.0499006423714
Iteration 82 Loss=  0.0469991434989
Iteration 83 Loss=  0.0442780261894
Iteration 84 Loss=  0.0417267188344
Iteration 85 Loss=  0.0393350886057
Iteration 86 Loss=  0.0370935898386
Iteration 87 Loss=  0.0349933719192
Iteration 88 Loss=  0.0330262695885
Iteration 89 Loss=  0.0311846885187
Iteration 90 Loss=  0.0294614579903
Iteration 91 Loss=  0.0278497207907
Iteration 92 Loss=  0.0263428915414
Iteration 93 Loss=  0.0249346739355
Iteration 94 Loss=  0.0236191023298
Iteration 95 Loss=  0.0223905672147
Iteration 96 Loss=  0.0212437971992
Iteration 97 Loss=  0.0201737968736
Iteration 98 Loss=  0.0191757654265
Iteration 99 Loss=  0.0182450296302
Iteration 100 Loss=  0.0173770145742
[ -4.06344444e-04   2.59466445e-04  -1.85631524e-04 ...,   1.86310040e-04
   7.09430228e-06   2.05456146e-04]
CROSS VALIDATION 4
Iteration 1 Loss=  66.7004090752
Iteration 2 Loss=  7.32066476293
Iteration 3 Loss=  6.86943630245
Iteration 4 Loss=  6.44602049698
Iteration 5 Loss=  6.04870304027
Iteration 6 Loss=  5.67587529181
Iteration 7 Loss=  5.32602776392
Iteration 8 Loss=  4.99774401016
Iteration 9 Loss=  4.68969489049
Iteration 10 Loss=  4.40063318994
Iteration 11 Loss=  4.12938856889
Iteration 12 Loss=  3.87486282471
Iteration 13 Loss=  3.63602544537
Iteration 14 Loss=  3.41190943718
Iteration 15 Loss=  3.20160740963
Iteration 16 Loss=  3.00426790164
Iteration 17 Loss=  2.81909193415
Iteration 18 Loss=  2.6453297753
Iteration 19 Loss=  2.48227790493
Iteration 20 Loss=  2.32927616618
Iteration 21 Loss=  2.18570509271
Iteration 22 Loss=  2.05098340063
Iteration 23 Loss=  1.924565635
Iteration 24 Loss=  1.80593996144
Iteration 25 Loss=  1.69462609384
Iteration 26 Loss=  1.59017334981
Iteration 27 Loss=  1.49215882596
Iteration 28 Loss=  1.40018568574
Iteration 29 Loss=  1.31388155273
Iteration 30 Loss=  1.23289700308
Iteration 31 Loss=  1.15690415084
Iteration 32 Loss=  1.08559532063
Iteration 33 Loss=  1.01868180218
Iteration 34 Loss=  0.955892681819
Iteration 35 Loss=  0.896973746229
Iteration 36 Loss=  0.841686454164
Iteration 37 Loss=  0.789806972019
Iteration 38 Loss=  0.741125269598
Iteration 39 Loss=  0.695444272589
Iteration 40 Loss=  0.65257906861
Iteration 41 Loss=  0.61235616388
Iteration 42 Loss=  0.574612787851
Iteration 43 Loss=  0.539196243198
Iteration 44 Loss=  0.505963298629
Iteration 45 Loss=  0.474779621662
Iteration 46 Loss=  0.445519247944
Iteration 47 Loss=  0.418064082445
Iteration 48 Loss=  0.392303426053
Iteration 49 Loss=  0.368133518694
Iteration 50 Loss=  0.345457088099
Iteration 51 Loss=  0.324182893389
Iteration 52 Loss=  0.304225257787
Iteration 53 Loss=  0.285503597213
Iteration 54 Loss=  0.267941970062
Iteration 55 Loss=  0.251468689981
Iteration 56 Loss=  0.236016045758
Iteration 57 Loss=  0.22152015334
Iteration 58 Loss=  0.207920929595
Iteration 59 Loss=  0.195162138204
Iteration 60 Loss=  0.183191428513
Iteration 61 Loss=  0.171960283746
Iteration 62 Loss=  0.161423826929
Iteration 63 Loss=  0.151540489875
Iteration 64 Loss=  0.142271601724
Iteration 65 Loss=  0.133580976761
Iteration 66 Loss=  0.125434574609
Iteration 67 Loss=  0.117800272206
Iteration 68 Loss=  0.110647728002
Iteration 69 Loss=  0.103948259627
Iteration 70 Loss=  0.0976746480302
Iteration 71 Loss=  0.091800847998
Iteration 72 Loss=  0.0863016790192
Iteration 73 Loss=  0.0811526178781
Iteration 74 Loss=  0.0763297912861
Iteration 75 Loss=  0.0718101997711
Iteration 76 Loss=  0.0675721201288
Iteration 77 Loss=  0.0635955529807
Iteration 78 Loss=  0.0598625414375
Iteration 79 Loss=  0.0563572259081
Iteration 80 Loss=  0.0530656106936
Iteration 81 Loss=  0.0499751369539
Iteration 82 Loss=  0.0470742198925
Iteration 83 Loss=  0.0443518981629
Iteration 84 Loss=  0.0417976800813
Iteration 85 Loss=  0.0394015803482
Iteration 86 Loss=  0.0371542552619
Iteration 87 Loss=  0.0350471098068
Iteration 88 Loss=  0.0330722920822
Iteration 89 Loss=  0.0312225753001
Iteration 90 Loss=  0.0294911893986
Iteration 91 Loss=  0.0278716717894
Iteration 92 Loss=  0.0263577775475
Iteration 93 Loss=  0.0249434532655
Iteration 94 Loss=  0.0236228517296
Iteration 95 Loss=  0.022390352744
Iteration 96 Loss=  0.021240562578
Iteration 97 Loss=  0.0201682868354
Iteration 98 Loss=  0.0191684938968
Iteration 99 Loss=  0.0182362928627
Iteration 100 Loss=  0.0173669400224
[ -4.01064256e-04   2.61061569e-04  -1.81423983e-04 ...,   1.83669768e-04
   9.98821835e-06   2.05048880e-04]
CROSS VALIDATION 5
Iteration 1 Loss=  66.6045164033
Iteration 2 Loss=  7.31892567362
Iteration 3 Loss=  6.86780440649
Iteration 4 Loss=  6.44448918723
Iteration 5 Loss=  6.04726611682
Iteration 6 Loss=  5.67452693693
Iteration 7 Loss=  5.32476251844
Iteration 8 Loss=  4.99655675142
Iteration 9 Loss=  4.68858081157
Iteration 10 Loss=  4.39958778021
Iteration 11 Loss=  4.12840759574
Iteration 12 Loss=  3.87394231643
Iteration 13 Loss=  3.63516167505
Iteration 14 Loss=  3.41109890761
Iteration 15 Loss=  3.20084683919
Iteration 16 Loss=  3.00355421096
Iteration 17 Loss=  2.81842223367
Iteration 18 Loss=  2.64470135358
Iteration 19 Loss=  2.48168821763
Iteration 20 Loss=  2.32872282582
Iteration 21 Loss=  2.18518585894
Iteration 22 Loss=  2.0504961712
Iteration 23 Loss=  1.92410843724
Iteration 24 Loss=  1.80551094428
Iteration 25 Loss=  1.69422352028
Iteration 26 Loss=  1.58979558994
Iteration 27 Loss=  1.49180435034
Iteration 28 Loss=  1.39985305919
Iteration 29 Loss=  1.31356942856
Iteration 30 Loss=  1.23260411762
Iteration 31 Loss=  1.15662931835
Iteration 32 Loss=  1.08533742853
Iteration 33 Loss=  1.01843980654
Iteration 34 Loss=  0.955665603229
Iteration 35 Loss=  0.896760665891
Iteration 36 Loss=  0.841486510277
Iteration 37 Loss=  0.789619356452
Iteration 38 Loss=  0.740949224834
Iteration 39 Loss=  0.695279088957
Iteration 40 Loss=  0.6524240818
Iteration 41 Loss=  0.61221075276
Iteration 42 Loss=  0.574476372562
Iteration 43 Loss=  0.539068283525
Iteration 44 Loss=  0.505843292542
Iteration 45 Loss=  0.474667103911
Iteration 46 Loss=  0.44541378839
Iteration 47 Loss=  0.417965283669
Iteration 48 Loss=  0.392210919535
Iteration 49 Loss=  0.368046958691
Iteration 50 Loss=  0.345376142461
Iteration 51 Loss=  0.324107231253
Iteration 52 Loss=  0.30415453565
Iteration 53 Loss=  0.285437447045
Iteration 54 Loss=  0.267879994546
Iteration 55 Loss=  0.25141046858
Iteration 56 Loss=  0.235961150254
Iteration 57 Loss=  0.22146816518
Iteration 58 Loss=  0.207871448781
Iteration 59 Loss=  0.195114777297
Iteration 60 Loss=  0.183145793101
Iteration 61 Loss=  0.171915947196
Iteration 62 Loss=  0.161380308505
Iteration 63 Loss=  0.151497240661
Iteration 64 Loss=  0.142227994192
Iteration 65 Loss=  0.133536284839
Iteration 66 Loss=  0.125387927887
Iteration 67 Loss=  0.117750577934
Iteration 68 Loss=  0.110593580035
Iteration 69 Loss=  0.103887881758
Iteration 70 Loss=  0.0976059281322
Iteration 71 Loss=  0.0917214984736
Iteration 72 Loss=  0.0862095184876
Iteration 73 Loss=  0.081045923568
Iteration 74 Loss=  0.0762076316327
Iteration 75 Loss=  0.0716726397417
Iteration 76 Loss=  0.0674202218008
Iteration 77 Loss=  0.0634311706439
Iteration 78 Loss=  0.0596879915561
Iteration 79 Loss=  0.0561749465898
Iteration 80 Loss=  0.0528779017684
Iteration 81 Loss=  0.0497840204447
Iteration 82 Loss=  0.0468814148223
Iteration 83 Loss=  0.0441588753181
Iteration 84 Loss=  0.0416057488931
Iteration 85 Loss=  0.0392119599984
Iteration 86 Loss=  0.0369680979651
Iteration 87 Loss=  0.0348654717674
Iteration 88 Loss=  0.0328960717495
Iteration 89 Loss=  0.0310524465147
Iteration 90 Loss=  0.0293275508972
Iteration 91 Loss=  0.0277146249464
Iteration 92 Loss=  0.0262071375107
Iteration 93 Loss=  0.0247987938493
Iteration 94 Loss=  0.0234835787204
Iteration 95 Loss=  0.0222557933773
Iteration 96 Loss=  0.0211100535584
Iteration 97 Loss=  0.0200412425308
Iteration 98 Loss=  0.0190444413338
Iteration 99 Loss=  0.0181148692923
Iteration 100 Loss=  0.0172478591334
[ -3.87751826e-04   2.62766800e-04  -1.76535296e-04 ...,   1.67649361e-04
  -9.80757908e-06   2.08313677e-04]
CROSS VALIDATION 6
Iteration 1 Loss=  66.7007906535
Iteration 2 Loss=  7.3206675327
Iteration 3 Loss=  6.86943890149
Iteration 4 Loss=  6.44602293583
Iteration 5 Loss=  6.04870532879
Iteration 6 Loss=  5.67587743927
Iteration 7 Loss=  5.32602977902
Iteration 8 Loss=  4.99774590105
Iteration 9 Loss=  4.68969666483
Iteration 10 Loss=  4.40063485491
Iteration 11 Loss=  4.12939013124
Iteration 12 Loss=  3.87486429076
Iteration 13 Loss=  3.63602682106
Iteration 14 Loss=  3.41191072807
Iteration 15 Loss=  3.20160862096
Iteration 16 Loss=  3.0042690383
Iteration 17 Loss=  2.81909300075
Iteration 18 Loss=  2.64533077616
Iteration 19 Loss=  2.48227884409
Iteration 20 Loss=  2.32927704746
Iteration 21 Loss=  2.18570591967
Iteration 22 Loss=  2.05098417662
Iteration 23 Loss=  1.92456636316
Iteration 24 Loss=  1.80594064472
Iteration 25 Loss=  1.694626735
Iteration 26 Loss=  1.59017395145
Iteration 27 Loss=  1.49215939052
Iteration 28 Loss=  1.4001862155
Iteration 29 Loss=  1.31388204984
Iteration 30 Loss=  1.23289746954
Iteration 31 Loss=  1.15690458855
Iteration 32 Loss=  1.08559573137
Iteration 33 Loss=  1.0186821876
Iteration 34 Loss=  0.955893043473
Iteration 35 Loss=  0.896974085588
Iteration 36 Loss=  0.841686772598
Iteration 37 Loss=  0.789807270813
Iteration 38 Loss=  0.741125549956
Iteration 39 Loss=  0.695444535639
Iteration 40 Loss=  0.652579315402
Iteration 41 Loss=  0.612356395397
Iteration 42 Loss=  0.574613005005
Iteration 43 Loss=  0.539196446836
Iteration 44 Loss=  0.50596348953
Iteration 45 Loss=  0.474779800543
Iteration 46 Loss=  0.445519415458
Iteration 47 Loss=  0.41806423919
Iteration 48 Loss=  0.392303572579
Iteration 49 Loss=  0.368133655517
Iteration 50 Loss=  0.345457215726
Iteration 51 Loss=  0.324183012354
Iteration 52 Loss=  0.304225368691
Iteration 53 Loss=  0.285503700763
Iteration 54 Loss=  0.26794206709
Iteration 55 Loss=  0.251468781432
Iteration 56 Loss=  0.236016132642
Iteration 57 Loss=  0.221520236664
Iteration 58 Loss=  0.207921010302
Iteration 59 Loss=  0.195162217164
Iteration 60 Loss=  0.183191506559
Iteration 61 Loss=  0.171960361748
Iteration 62 Loss=  0.161423905866
Iteration 63 Loss=  0.151540570885
Iteration 64 Loss=  0.14227168619
Iteration 65 Loss=  0.133581066497
Iteration 66 Loss=  0.125434672282
Iteration 67 Loss=  0.117800382057
Iteration 68 Loss=  0.110647856873
Iteration 69 Loss=  0.103948418206
Iteration 70 Loss=  0.0976748523585
Iteration 71 Loss=  0.091801121527
Iteration 72 Loss=  0.0863020558572
Iteration 73 Loss=  0.0811531480059
Iteration 74 Loss=  0.0763305482163
Iteration 75 Loss=  0.0718112902795
Iteration 76 Loss=  0.0675736947218
Iteration 77 Loss=  0.0635978154522
Iteration 78 Loss=  0.0598657565412
Iteration 79 Loss=  0.0563617250877
Iteration 80 Loss=  0.0530717959766
Iteration 81 Loss=  0.0499834822823
Iteration 82 Loss=  0.0470852679009
Iteration 83 Loss=  0.044366249427
Iteration 84 Loss=  0.0418159715874
Iteration 85 Loss=  0.039424450671
Iteration 86 Loss=  0.0371822958724
Iteration 87 Loss=  0.0350808050438
Iteration 88 Loss=  0.0331119542046
Iteration 89 Loss=  0.031268284671
Iteration 90 Loss=  0.0295427516227
Iteration 91 Loss=  0.0279286020526
Iteration 92 Loss=  0.0264193171992
Iteration 93 Loss=  0.0250086163024
Iteration 94 Loss=  0.0236904919258
Iteration 95 Loss=  0.0224592383285
Iteration 96 Loss=  0.0213094460637
Iteration 97 Loss=  0.0202359626681
Iteration 98 Loss=  0.0192338438927
Iteration 99 Loss=  0.0182983253336
Iteration 100 Loss=  0.017424829576
[ -4.04078110e-04   2.60148903e-04  -1.79540746e-04 ...,   1.81862020e-04
   7.78285199e-06   2.04226597e-04]
CROSS VALIDATION 7
Iteration 1 Loss=  66.7007906535
Iteration 2 Loss=  7.3206675327
Iteration 3 Loss=  6.86943890149
Iteration 4 Loss=  6.44602293583
Iteration 5 Loss=  6.04870532879
Iteration 6 Loss=  5.67587743927
Iteration 7 Loss=  5.32602977902
Iteration 8 Loss=  4.99774590105
Iteration 9 Loss=  4.68969666483
Iteration 10 Loss=  4.40063485491
Iteration 11 Loss=  4.12939013124
Iteration 12 Loss=  3.87486429076
Iteration 13 Loss=  3.63602682106
Iteration 14 Loss=  3.41191072807
Iteration 15 Loss=  3.20160862096
Iteration 16 Loss=  3.0042690383
Iteration 17 Loss=  2.81909300075
Iteration 18 Loss=  2.64533077616
Iteration 19 Loss=  2.48227884409
Iteration 20 Loss=  2.32927704746
Iteration 21 Loss=  2.18570591967
Iteration 22 Loss=  2.05098417662
Iteration 23 Loss=  1.92456636316
Iteration 24 Loss=  1.80594064472
Iteration 25 Loss=  1.694626735
Iteration 26 Loss=  1.59017395145
Iteration 27 Loss=  1.49215939052
Iteration 28 Loss=  1.4001862155
Iteration 29 Loss=  1.31388204984
Iteration 30 Loss=  1.23289746954
Iteration 31 Loss=  1.15690458855
Iteration 32 Loss=  1.08559573137
Iteration 33 Loss=  1.0186821876
Iteration 34 Loss=  0.955893043473
Iteration 35 Loss=  0.896974085587
Iteration 36 Loss=  0.841686772597
Iteration 37 Loss=  0.789807270811
Iteration 38 Loss=  0.741125549951
Iteration 39 Loss=  0.695444535628
Iteration 40 Loss=  0.652579315378
Iteration 41 Loss=  0.612356395346
Iteration 42 Loss=  0.574613004897
Iteration 43 Loss=  0.539196446614
Iteration 44 Loss=  0.505963489085
Iteration 45 Loss=  0.474779799669
Iteration 46 Loss=  0.445519413779
Iteration 47 Loss=  0.418064236031
Iteration 48 Loss=  0.392303566752
Iteration 49 Loss=  0.368133644979
Iteration 50 Loss=  0.345457197028
Iteration 51 Loss=  0.324182979793
Iteration 52 Loss=  0.304225313018
Iteration 53 Loss=  0.285503607264
Iteration 54 Loss=  0.267941912792
Iteration 55 Loss=  0.251468531123
Iteration 56 Loss=  0.236015733311
Iteration 57 Loss=  0.22151960989
Iteration 58 Loss=  0.207920042065
Iteration 59 Loss=  0.195160744523
Iteration 60 Loss=  0.183189300744
Iteration 61 Loss=  0.171957107464
Iteration 62 Loss=  0.161419177183
Iteration 63 Loss=  0.151533805119
Iteration 64 Loss=  0.142262158774
Iteration 65 Loss=  0.133567872174
Iteration 66 Loss=  0.12541672077
Iteration 67 Loss=  0.117776419078
Iteration 68 Loss=  0.110616522366
Iteration 69 Loss=  0.103908350006
Iteration 70 Loss=  0.0976248327457
Iteration 71 Loss=  0.0917402460958
Iteration 72 Loss=  0.0862298856756
Iteration 73 Loss=  0.0810697993963
Iteration 74 Loss=  0.0762366892237
Iteration 75 Loss=  0.071708044633
Iteration 76 Loss=  0.0674624845672
Iteration 77 Loss=  0.0634801869325
Iteration 78 Loss=  0.0597432266376
Iteration 79 Loss=  0.0562356739814
Iteration 80 Loss=  0.0529434143746
Iteration 81 Loss=  0.0498537700923
Iteration 82 Loss=  0.0469550701489
Iteration 83 Loss=  0.0442363081302
Iteration 84 Loss=  0.0416869697286
Iteration 85 Loss=  0.0392970292028
Iteration 86 Loss=  0.0370570378408
Iteration 87 Loss=  0.034958197024
Iteration 88 Loss=  0.0329923451393
Iteration 89 Loss=  0.0311518617464
Iteration 90 Loss=  0.0294295449659
Iteration 91 Loss=  0.0278185193641
Iteration 92 Loss=  0.0263121996217
Iteration 93 Loss=  0.0249043016875
Iteration 94 Loss=  0.0235888735283
Iteration 95 Loss=  0.0223603130739
Iteration 96 Loss=  0.0212133504093
Iteration 97 Loss=  0.0201429919305
Iteration 98 Loss=  0.0191444459889
Iteration 99 Loss=  0.0182130594295
Iteration 100 Loss=  0.0173442883783
[ -4.14964258e-04   2.55972412e-04  -1.88891505e-04 ...,   1.77177547e-04
   5.51441818e-06   2.06197872e-04]
CROSS VALIDATION 8
Iteration 1 Loss=  66.7007906535
Iteration 2 Loss=  7.3206675327
Iteration 3 Loss=  6.86943890149
Iteration 4 Loss=  6.44602293583
Iteration 5 Loss=  6.04870532879
Iteration 6 Loss=  5.67587743927
Iteration 7 Loss=  5.32602977902
Iteration 8 Loss=  4.99774590105
Iteration 9 Loss=  4.68969666483
Iteration 10 Loss=  4.40063485491
Iteration 11 Loss=  4.12939013124
Iteration 12 Loss=  3.87486429076
Iteration 13 Loss=  3.63602682106
Iteration 14 Loss=  3.41191072807
Iteration 15 Loss=  3.20160862096
Iteration 16 Loss=  3.0042690383
Iteration 17 Loss=  2.81909300075
Iteration 18 Loss=  2.64533077616
Iteration 19 Loss=  2.48227884409
Iteration 20 Loss=  2.32927704746
Iteration 21 Loss=  2.18570591967
Iteration 22 Loss=  2.05098417662
Iteration 23 Loss=  1.92456636316
Iteration 24 Loss=  1.80594064472
Iteration 25 Loss=  1.694626735
Iteration 26 Loss=  1.59017395145
Iteration 27 Loss=  1.49215939052
Iteration 28 Loss=  1.4001862155
Iteration 29 Loss=  1.31388204984
Iteration 30 Loss=  1.23289746954
Iteration 31 Loss=  1.15690458855
Iteration 32 Loss=  1.08559573137
Iteration 33 Loss=  1.0186821876
Iteration 34 Loss=  0.955893043473
Iteration 35 Loss=  0.896974085588
Iteration 36 Loss=  0.841686772598
Iteration 37 Loss=  0.789807270813
Iteration 38 Loss=  0.741125549956
Iteration 39 Loss=  0.695444535639
Iteration 40 Loss=  0.652579315402
Iteration 41 Loss=  0.612356395398
Iteration 42 Loss=  0.574613005005
Iteration 43 Loss=  0.539196446836
Iteration 44 Loss=  0.50596348953
Iteration 45 Loss=  0.474779800543
Iteration 46 Loss=  0.445519415458
Iteration 47 Loss=  0.418064239191
Iteration 48 Loss=  0.39230357258
Iteration 49 Loss=  0.368133655518
Iteration 50 Loss=  0.345457215728
Iteration 51 Loss=  0.324183012358
Iteration 52 Loss=  0.304225368697
Iteration 53 Loss=  0.285503700771
Iteration 54 Loss=  0.267942067102
Iteration 55 Loss=  0.251468781448
Iteration 56 Loss=  0.236016132659
Iteration 57 Loss=  0.221520236678
Iteration 58 Loss=  0.207921010303
Iteration 59 Loss=  0.19516221713
Iteration 60 Loss=  0.183191506441
Iteration 61 Loss=  0.171960361449
Iteration 62 Loss=  0.161423905189
Iteration 63 Loss=  0.151540569456
Iteration 64 Loss=  0.142271683308
Iteration 65 Loss=  0.133581060915
Iteration 66 Loss=  0.125434661872
Iteration 67 Loss=  0.117800363371
Iteration 68 Loss=  0.110647824633
Iteration 69 Loss=  0.103948364874
Iteration 70 Loss=  0.0976747680109
Iteration 71 Loss=  0.0918009943271
Iteration 72 Loss=  0.0863018732848
Iteration 73 Loss=  0.0811528986534
Iteration 74 Loss=  0.0763302235525
Iteration 75 Loss=  0.0718108856038
Iteration 76 Loss=  0.0675732087909
Iteration 77 Loss=  0.0635972487716
Iteration 78 Loss=  0.0598651086865
Iteration 79 Loss=  0.0563609914414
Iteration 80 Loss=  0.0530709640272
Iteration 81 Loss=  0.0499825273511
Iteration 82 Loss=  0.0470841479609
Iteration 83 Loss=  0.044364898567
Iteration 84 Loss=  0.0418142916384
Iteration 85 Loss=  0.0394223005377
Iteration 86 Loss=  0.0371794782341
Iteration 87 Loss=  0.035077050387
Iteration 88 Loss=  0.0331069027475
Iteration 89 Loss=  0.0312614677698
Iteration 90 Loss=  0.0295335758641
Iteration 91 Loss=  0.0279163415218
Iteration 92 Loss=  0.0264031222138
Iteration 93 Loss=  0.0249875494382
Iteration 94 Loss=  0.0236636026175
Iteration 95 Loss=  0.0224256827539
Iteration 96 Loss=  0.0212686464719
Iteration 97 Loss=  0.0201877797514
Iteration 98 Loss=  0.0191787138233
Iteration 99 Loss=  0.0182373035987
Iteration 100 Loss=  0.0173595007589
[ -4.02807244e-04   2.60677621e-04  -1.77542709e-04 ...,   1.81975426e-04
   6.67925334e-06   2.03983982e-04]
CROSS VALIDATION 9
Iteration 1 Loss=  162.427331344
Iteration 2 Loss=  78.1709607466
Iteration 3 Loss=  8.19314149274
Iteration 4 Loss=  7.68813594327
Iteration 5 Loss=  7.21425790338
Iteration 6 Loss=  6.76958881996
Iteration 7 Loss=  6.352328422
Iteration 8 Loss=  5.96078743672
Iteration 9 Loss=  5.59338075422
Iteration 10 Loss=  5.24862101112
Iteration 11 Loss=  4.92511256413
Iteration 12 Loss=  4.62154582491
Iteration 13 Loss=  4.33669192847
Iteration 14 Loss=  4.06939771065
Iteration 15 Loss=  3.81858097716
Iteration 16 Loss=  3.58322605901
Iteration 17 Loss=  3.36237966296
Iteration 18 Loss=  3.15514703036
Iteration 19 Loss=  2.96068840386
Iteration 20 Loss=  2.77821576665
Iteration 21 Loss=  2.60698978829
Iteration 22 Loss=  2.44631691089
Iteration 23 Loss=  2.29554654386
Iteration 24 Loss=  2.15406837612
Iteration 25 Loss=  2.02130983266
Iteration 26 Loss=  1.89673369542
Iteration 27 Loss=  1.77983589107
Iteration 28 Loss=  1.67014343537
Iteration 29 Loss=  1.56721251865
Iteration 30 Loss=  1.47062671662
Iteration 31 Loss=  1.37999531245
Iteration 32 Loss=  1.29495171728
Iteration 33 Loss=  1.21515197723
Iteration 34 Loss=  1.14027335606
Iteration 35 Loss=  1.07001298565
Iteration 36 Loss=  1.00408658312
Iteration 37 Loss=  0.942227242729
Iteration 38 Loss=  0.884184319557
Iteration 39 Loss=  0.829722420489
Iteration 40 Loss=  0.778620502778
Iteration 41 Loss=  0.730671057085
Iteration 42 Loss=  0.68567934242
Iteration 43 Loss=  0.643462656339
Iteration 44 Loss=  0.603849648561
Iteration 45 Loss=  0.566679688022
Iteration 46 Loss=  0.531802266107
Iteration 47 Loss=  0.499076393685
Iteration 48 Loss=  0.468369957742
Iteration 49 Loss=  0.43955903966
Iteration 50 Loss=  0.412527232634
Iteration 51 Loss=  0.38716501219
Iteration 52 Loss=  0.363369211947
Iteration 53 Loss=  0.341042639194
Iteration 54 Loss=  0.320093830362
Iteration 55 Loss=  0.300436902342
Iteration 56 Loss=  0.281991424482
Iteration 57 Loss=  0.264682240018
Iteration 58 Loss=  0.248439202278
Iteration 59 Loss=  0.233196834721
Iteration 60 Loss=  0.218893949441
Iteration 61 Loss=  0.205473260933
Iteration 62 Loss=  0.192881021469
Iteration 63 Loss=  0.181066694477
Iteration 64 Loss=  0.169982678197
Iteration 65 Loss=  0.159584090263
Iteration 66 Loss=  0.149828617127
Iteration 67 Loss=  0.14067641753
Iteration 68 Loss=  0.132090053717
Iteration 69 Loss=  0.124034420719
Iteration 70 Loss=  0.116476657077
Iteration 71 Loss=  0.109386039564
Iteration 72 Loss=  0.102733875013
Iteration 73 Loss=  0.0964933996047
Iteration 74 Loss=  0.0906396861386
Iteration 75 Loss=  0.0851495507748
Iteration 76 Loss=  0.0800014456317
Iteration 77 Loss=  0.0751753225319
Iteration 78 Loss=  0.0706524569722
Iteration 79 Loss=  0.0664152328928
Iteration 80 Loss=  0.0624469088727
Iteration 81 Loss=  0.058731406847
Iteration 82 Loss=  0.0552531662921
Iteration 83 Loss=  0.0519970772323
Iteration 84 Loss=  0.0489484667607
Iteration 85 Loss=  0.0460931156513
Iteration 86 Loss=  0.0434173317933
Iteration 87 Loss=  0.0409081337394
Iteration 88 Loss=  0.0385535357716
Iteration 89 Loss=  0.0363428221451
Iteration 90 Loss=  0.0342666657667
Iteration 91 Loss=  0.0323170260542
Iteration 92 Loss=  0.0304868775149
Iteration 93 Loss=  0.0287698803401
Iteration 94 Loss=  0.0271600879121
Iteration 95 Loss=  0.0256517395153
Iteration 96 Loss=  0.0242391536121
Iteration 97 Loss=  0.0229167245121
Iteration 98 Loss=  0.0216790153873
Iteration 99 Loss=  0.0205209190186
Iteration 100 Loss=  0.0194378303928
[-0.00078222  0.00023042 -0.00014788 ...,  0.00091274  0.00036272
  0.00015132]
CROSS VALIDATION 10
Iteration 1 Loss=  66.7027231138
Iteration 2 Loss=  7.32089359303
Iteration 3 Loss=  6.869651028
Iteration 4 Loss=  6.44622198736
Iteration 5 Loss=  6.04889211125
Iteration 6 Loss=  5.6760527089
Iteration 7 Loss=  5.32619424545
Iteration 8 Loss=  4.99790023016
Iteration 9 Loss=  4.68984148146
Iteration 10 Loss=  4.40077074538
Iteration 11 Loss=  4.12951764574
Iteration 12 Loss=  3.87498394557
Iteration 13 Loss=  3.63613910063
Iteration 14 Loss=  3.412016087
Iteration 15 Loss=  3.20170748581
Iteration 16 Loss=  3.00436180935
Iteration 17 Loss=  2.81918005361
Iteration 18 Loss=  2.64541246329
Iteration 19 Loss=  2.48235549623
Iteration 20 Loss=  2.32934897493
Iteration 21 Loss=  2.18577341371
Iteration 22 Loss=  2.05104751048
Iteration 23 Loss=  1.92462579327
Iteration 24 Loss=  1.8059964117
Iteration 25 Loss=  1.69467906464
Iteration 26 Loss=  1.59022305561
Iteration 27 Loss=  1.49220546801
Iteration 28 Loss=  1.40022945288
Iteration 29 Loss=  1.31392262217
Iteration 30 Loss=  1.23293554108
Iteration 31 Loss=  1.15694031344
Iteration 32 Loss=  1.08562925423
Iteration 33 Loss=  1.01871364414
Iteration 34 Loss=  0.955922561033
Iteration 35 Loss=  0.897001783628
Iteration 36 Loss=  0.841712763192
Iteration 37 Loss=  0.789831659085
Iteration 38 Loss=  0.741148434487
Iteration 39 Loss=  0.695466008847
Iteration 40 Loss=  0.652599463888
Iteration 41 Loss=  0.612375300254
Iteration 42 Loss=  0.574630742105
Iteration 43 Loss=  0.539213087085
Iteration 44 Loss=  0.505979099101
Iteration 45 Loss=  0.474794441101
Iteration 46 Loss=  0.445533144398
Iteration 47 Loss=  0.418077109922
Iteration 48 Loss=  0.392315634909
Iteration 49 Loss=  0.368144956212
Iteration 50 Loss=  0.345467799319
Iteration 51 Loss=  0.324192922243
Iteration 52 Loss=  0.304234648474
Iteration 53 Loss=  0.285512395584
Iteration 54 Loss=  0.267950224595
Iteration 55 Loss=  0.251476451857
Iteration 56 Loss=  0.236023367777
Iteration 57 Loss=  0.22152708791
Iteration 58 Loss=  0.207927526591
Iteration 59 Loss=  0.195168443637
Iteration 60 Loss=  0.183197484299
Iteration 61 Loss=  0.171966127774
Iteration 62 Loss=  0.161429491844
Iteration 63 Loss=  0.15154599939
Iteration 64 Loss=  0.142276964853
Iteration 65 Loss=  0.133586182115
Iteration 66 Loss=  0.125439587613
Iteration 67 Loss=  0.117805036445
Iteration 68 Loss=  0.110652168142
Iteration 69 Loss=  0.103952280043
Iteration 70 Loss=  0.0976781218165
Iteration 71 Loss=  0.0918035953719
Iteration 72 Loss=  0.0863034386023
Iteration 73 Loss=  0.0811530156016
Iteration 74 Loss=  0.0763283095763
Iteration 75 Loss=  0.0718061466066
Iteration 76 Loss=  0.0675645968061
Iteration 77 Loss=  0.0635834239958
Iteration 78 Loss=  0.0598444201275
Iteration 79 Loss=  0.0563315011449
Iteration 80 Loss=  0.0530305454502
Iteration 81 Loss=  0.0499290607872
Iteration 82 Loss=  0.0470158079171
Iteration 83 Loss=  0.0442804810615
Iteration 84 Loss=  0.0417134840398
Iteration 85 Loss=  0.0393057902081
Iteration 86 Loss=  0.0370488526514
Iteration 87 Loss=  0.0349345346596
Iteration 88 Loss=  0.0329550459985
Iteration 89 Loss=  0.0311028859002
Iteration 90 Loss=  0.0293708026955
Iteration 91 Loss=  0.0277517811024
Iteration 92 Loss=  0.0262390618502
Iteration 93 Loss=  0.0248261855824
Iteration 94 Loss=  0.0235070378958
Iteration 95 Loss=  0.0222758649981
Iteration 96 Loss=  0.0211272405216
Iteration 97 Loss=  0.0200559916576
Iteration 98 Loss=  0.0190571183523
Iteration 99 Loss=  0.0181257433994
Iteration 100 Loss=  0.0172571131506
[ -3.96503433e-04   2.62303991e-04  -1.81622151e-04 ...,   1.80023707e-04
   3.51591582e-06   2.06642727e-04]
CROSS VALIDATION 11
Iteration 1 Loss=  66.7026824699
Iteration 2 Loss=  7.32089365999
Iteration 3 Loss=  6.86965109084
Iteration 4 Loss=  6.44622204632
Iteration 5 Loss=  6.04889216658
Iteration 6 Loss=  5.67605276083
Iteration 7 Loss=  5.32619429417
Iteration 8 Loss=  4.99790027587
Iteration 9 Loss=  4.68984152436
Iteration 10 Loss=  4.40077078564
Iteration 11 Loss=  4.12951768352
Iteration 12 Loss=  3.87498398102
Iteration 13 Loss=  3.63613913389
Iteration 14 Loss=  3.41201611821
Iteration 15 Loss=  3.20170751509
Iteration 16 Loss=  3.00436183683
Iteration 17 Loss=  2.8191800794
Iteration 18 Loss=  2.64541248749
Iteration 19 Loss=  2.48235551893
Iteration 20 Loss=  2.32934899624
Iteration 21 Loss=  2.1857734337
Iteration 22 Loss=  2.05104752925
Iteration 23 Loss=  1.92462581088
Iteration 24 Loss=  1.80599642822
Iteration 25 Loss=  1.69467908014
Iteration 26 Loss=  1.59022307016
Iteration 27 Loss=  1.49220548166
Iteration 28 Loss=  1.40022946569
Iteration 29 Loss=  1.31392263419
Iteration 30 Loss=  1.23293555236
Iteration 31 Loss=  1.15694032402
Iteration 32 Loss=  1.08562926416
Iteration 33 Loss=  1.01871365346
Iteration 34 Loss=  0.955922569778
Iteration 35 Loss=  0.897001791834
Iteration 36 Loss=  0.841712770893
Iteration 37 Loss=  0.789831666312
Iteration 38 Loss=  0.74114844127
Iteration 39 Loss=  0.695466015215
Iteration 40 Loss=  0.652599469868
Iteration 41 Loss=  0.612375305872
Iteration 42 Loss=  0.574630747386
Iteration 43 Loss=  0.539213092053
Iteration 44 Loss=  0.505979103781
Iteration 45 Loss=  0.474794445517
Iteration 46 Loss=  0.445533148576
Iteration 47 Loss=  0.418077113887
Iteration 48 Loss=  0.392315638686
Iteration 49 Loss=  0.368144959826
Iteration 50 Loss=  0.345467802792
Iteration 51 Loss=  0.324192925593
Iteration 52 Loss=  0.304234651711
Iteration 53 Loss=  0.285512398713
Iteration 54 Loss=  0.267950227616
Iteration 55 Loss=  0.251476454783
Iteration 56 Loss=  0.236023370656
Iteration 57 Loss=  0.221527090874
Iteration 58 Loss=  0.207927529938
Iteration 59 Loss=  0.195168447949
Iteration 60 Loss=  0.183197490654
Iteration 61 Loss=  0.171966138073
Iteration 62 Loss=  0.161429509347
Iteration 63 Loss=  0.151546029577
Iteration 64 Loss=  0.142277016756
Iteration 65 Loss=  0.133586270353
Iteration 66 Loss=  0.125439735444
Iteration 67 Loss=  0.117805280274
Iteration 68 Loss=  0.110652564086
Iteration 69 Loss=  0.103952913347
Iteration 70 Loss=  0.097679120118
Iteration 71 Loss=  0.0918051469584
Iteration 72 Loss=  0.0863058168838
Iteration 73 Loss=  0.0811566108017
Iteration 74 Loss=  0.0763336679632
Iteration 75 Loss=  0.0718140160209
Iteration 76 Loss=  0.0675759743002
Iteration 77 Loss=  0.0635995965074
Iteration 78 Loss=  0.0598669821413
Iteration 79 Loss=  0.0563623255675
Iteration 80 Loss=  0.0530716796213
Iteration 81 Loss=  0.0499825263289
Iteration 82 Loss=  0.0470833093573
Iteration 83 Loss=  0.0443630739916
Iteration 84 Loss=  0.0418112994021
Iteration 85 Loss=  0.0394179198334
Iteration 86 Loss=  0.0371734474525
Iteration 87 Loss=  0.0350690750231
Iteration 88 Loss=  0.0330966775409
Iteration 89 Loss=  0.0312487155437
Iteration 90 Loss=  0.0295181029452
Iteration 91 Loss=  0.0278981061545
Iteration 92 Loss=  0.0263823067594
Iteration 93 Loss=  0.024964619286
Iteration 94 Loss=  0.0236393274244
Iteration 95 Loss=  0.0224010947071
Iteration 96 Loss=  0.0212449220372
Iteration 97 Loss=  0.0201660573316
Iteration 98 Loss=  0.019159891585
Iteration 99 Loss=  0.0182218817897
Iteration 100 Loss=  0.0173475240342
[ -4.04299081e-04   2.61270936e-04  -1.77499162e-04 ...,   1.82183102e-04
   7.81066261e-06   2.04089773e-04]
CROSS VALIDATION 12
Iteration 1 Loss=  133.036994294
Iteration 2 Loss=  7.29726346728
Iteration 3 Loss=  6.52895473058
Iteration 4 Loss=  6.12356779749
Iteration 5 Loss=  5.74613398761
Iteration 6 Loss=  5.39196652405
Iteration 7 Loss=  5.05963146805
Iteration 8 Loss=  4.74778306065
Iteration 9 Loss=  4.45515823553
Iteration 10 Loss=  4.18057153034
Iteration 11 Loss=  3.92291039025
Iteration 12 Loss=  3.6811308194
Iteration 13 Loss=  3.45425330289
Iteration 14 Loss=  3.24135892391
Iteration 15 Loss=  3.04158563987
Iteration 16 Loss=  2.85412472663
Iteration 17 Loss=  2.67821741845
Iteration 18 Loss=  2.51315176307
Iteration 19 Loss=  2.35825969203
Iteration 20 Loss=  2.2129142928
Iteration 21 Loss=  2.07652726394
Iteration 22 Loss=  1.94854653561
Iteration 23 Loss=  1.82845404051
Iteration 24 Loss=  1.71576362316
Iteration 25 Loss=  1.61001907787
Iteration 26 Loss=  1.51079230668
Iteration 27 Loss=  1.41768159014
Iteration 28 Loss=  1.3303099637
Iteration 29 Loss=  1.2483236937
Iteration 30 Loss=  1.17139084672
Iteration 31 Loss=  1.09919994676
Iteration 32 Loss=  1.03145871496
Iteration 33 Loss=  0.967892886772
Iteration 34 Loss=  0.908245101944
Iteration 35 Loss=  0.852273862791
Iteration 36 Loss=  0.799752556648
Iteration 37 Loss=  0.750468538527
Iteration 38 Loss=  0.704222270307
Iteration 39 Loss=  0.660826512993
Iteration 40 Loss=  0.620105568788
Iteration 41 Loss=  0.581894569958
Iteration 42 Loss=  0.546038811632
Iteration 43 Loss=  0.512393125902
Iteration 44 Loss=  0.480821294742
Iteration 45 Loss=  0.451195499482
Iteration 46 Loss=  0.42339580471
Iteration 47 Loss=  0.397309674669
Iteration 48 Loss=  0.372831520368
Iteration 49 Loss=  0.349862275769
Iteration 50 Loss=  0.328309001511
Iteration 51 Loss=  0.308084514663
Iteration 52 Loss=  0.289107042895
Iteration 53 Loss=  0.271299901134
Iteration 54 Loss=  0.254591188086
Iteration 55 Loss=  0.238913498927
Iteration 56 Loss=  0.224203649008
Iteration 57 Loss=  0.210402402194
Iteration 58 Loss=  0.197454197796
Iteration 59 Loss=  0.18530687445
Iteration 60 Loss=  0.173911399905
Iteration 61 Loss=  0.163221631211
Iteration 62 Loss=  0.153194140808
Iteration 63 Loss=  0.143788134145
Iteration 64 Loss=  0.134965445391
Iteration 65 Loss=  0.126690548412
Iteration 66 Loss=  0.118930500047
Iteration 67 Loss=  0.111654761816
Iteration 68 Loss=  0.104834900853
Iteration 69 Loss=  0.0984442141328
Iteration 70 Loss=  0.0924573425014
Iteration 71 Loss=  0.0868499532934
Iteration 72 Loss=  0.0815985705647
Iteration 73 Loss=  0.0766805983896
Iteration 74 Loss=  0.0720745070874
Iteration 75 Loss=  0.067760071782
Iteration 76 Loss=  0.0637185299024
Iteration 77 Loss=  0.0599325821132
Iteration 78 Loss=  0.0563862512941
Iteration 79 Loss=  0.0530646660824
Iteration 80 Loss=  0.0499538290001
Iteration 81 Loss=  0.0470404025781
Iteration 82 Loss=  0.0443115418873
Iteration 83 Loss=  0.0417548186354
Iteration 84 Loss=  0.0393582844173
Iteration 85 Loss=  0.0371106753196
Iteration 86 Loss=  0.0350016789037
Iteration 87 Loss=  0.0330221318444
Iteration 88 Loss=  0.0311640486506
Iteration 89 Loss=  0.0294204781194
Iteration 90 Loss=  0.0277852649767
Iteration 91 Loss=  0.0262528079681
Iteration 92 Loss=  0.0248178683451
Iteration 93 Loss=  0.0234754385813
Iteration 94 Loss=  0.022220656496
Iteration 95 Loss=  0.0210487459588
Iteration 96 Loss=  0.0199549740098
Iteration 97 Loss=  0.0189346288093
Iteration 98 Loss=  0.0179830365358
Iteration 99 Loss=  0.0170956372422
Iteration 100 Loss=  0.0162681187215
[ -1.30521456e-03  -3.47435987e-04  -4.42805234e-04 ...,   1.25882827e-04
   2.47979270e-04   4.90167193e-05]
CROSS VALIDATION 13
Iteration 1 Loss=  224.595872785
Iteration 2 Loss=  66.8373600761
Iteration 3 Loss=  7.81530354529
Iteration 4 Loss=  7.33358672023
Iteration 5 Loss=  6.88156178086
Iteration 6 Loss=  6.45739858959
Iteration 7 Loss=  6.05937981415
Iteration 8 Loss=  5.68589397461
Iteration 9 Loss=  5.33542891881
Iteration 10 Loss=  5.0065657001
Iteration 11 Loss=  4.69797283233
Iteration 12 Loss=  4.40840089902
Iteration 13 Loss=  4.13667749475
Iteration 14 Loss=  3.88170247843
Iteration 15 Loss=  3.64244351902
Iteration 16 Loss=  3.41793191595
Iteration 17 Loss=  3.20725867707
Iteration 18 Loss=  3.00957083836
Iteration 19 Loss=  2.82406801046
Iteration 20 Loss=  2.64999913819
Iteration 21 Loss=  2.48665945961
Iteration 22 Loss=  2.33338765274
Iteration 23 Loss=  2.18956315798
Iteration 24 Loss=  2.05460366575
Iteration 25 Loss=  1.9279627589
Iteration 26 Loss=  1.8091277006
Iteration 27 Loss=  1.69761735859
Iteration 28 Loss=  1.59298025759
Iteration 29 Loss=  1.49479275189
Iteration 30 Loss=  1.4026573109
Iteration 31 Loss=  1.31620091071
Iteration 32 Loss=  1.23507352537
Iteration 33 Loss=  1.15894671175
Iteration 34 Loss=  1.08751228252
Iteration 35 Loss=  1.02048106186
Iteration 36 Loss=  0.957581718927
Iteration 37 Loss=  0.898559674179
Iteration 38 Loss=  0.843176073558
Iteration 39 Loss=  0.791206825247
Iteration 40 Loss=  0.742441693026
Iteration 41 Loss=  0.696683439325
Iteration 42 Loss=  0.653747010373
Iteration 43 Loss=  0.61345875633
Iteration 44 Loss=  0.575655682854
Iteration 45 Loss=  0.540184738621
Iteration 46 Loss=  0.506902154926
Iteration 47 Loss=  0.475672861802
Iteration 48 Loss=  0.446369998484
Iteration 49 Loss=  0.418874508754
Iteration 50 Loss=  0.393074776952
Iteration 51 Loss=  0.368866246459
Iteration 52 Loss=  0.346150984272
Iteration 53 Loss=  0.324837195849
Iteration 54 Loss=  0.304838724874
Iteration 55 Loss=  0.286074582155
Iteration 56 Loss=  0.268468544329
Iteration 57 Loss=  0.251948851785
Iteration 58 Loss=  0.236448011939
Iteration 59 Loss=  0.221902678908
Iteration 60 Loss=  0.208253551875
Iteration 61 Loss=  0.195445235788
Iteration 62 Loss=  0.183426041674
Iteration 63 Loss=  0.172147743481
Iteration 64 Loss=  0.161565326513
Iteration 65 Loss=  0.151636754862
Iteration 66 Loss=  0.142322765876
Iteration 67 Loss=  0.133586682968
Iteration 68 Loss=  0.12539422963
Iteration 69 Loss=  0.117713327939
Iteration 70 Loss=  0.110513873744
Iteration 71 Loss=  0.103767497322
Iteration 72 Loss=  0.0974473370766
Iteration 73 Loss=  0.0915278619369
Iteration 74 Loss=  0.0859847637522
Iteration 75 Loss=  0.0807949102797
Iteration 76 Loss=  0.0759363309598
Iteration 77 Loss=  0.0713882228014
Iteration 78 Loss=  0.0671309912291
Iteration 79 Loss=  0.0631463339269
Iteration 80 Loss=  0.0594173243945
Iteration 81 Loss=  0.0559284083152
Iteration 82 Loss=  0.0526652495257
Iteration 83 Loss=  0.0496144490701
Iteration 84 Loss=  0.0467632429384
Iteration 85 Loss=  0.0440992977602
Iteration 86 Loss=  0.0416106610699
Iteration 87 Loss=  0.0392858280533
Iteration 88 Loss=  0.037113822647
Iteration 89 Loss=  0.0350842028235
Iteration 90 Loss=  0.033186982912
Iteration 91 Loss=  0.0314125529078
Iteration 92 Loss=  0.0297516848675
Iteration 93 Loss=  0.0281956414127
Iteration 94 Loss=  0.0267363232616
Iteration 95 Loss=  0.0253663864254
Iteration 96 Loss=  0.0240793048819
Iteration 97 Loss=  0.0228693814522
Iteration 98 Loss=  0.0217317013621
Iteration 99 Loss=  0.020662020195
Iteration 100 Loss=  0.0196566025519
[ -1.14880263e-03  -4.52604310e-04  -5.89561226e-04 ...,   5.17512751e-04
  -5.15599550e-05   1.33104391e-04]
CROSS VALIDATION 14
Iteration 1 Loss=  66.6775115349
Iteration 2 Loss=  7.32177756945
Iteration 3 Loss=  6.8704805182
Iteration 4 Loss=  6.44700034975
Iteration 5 Loss=  6.04962249722
Iteration 6 Loss=  5.67673807562
Iteration 7 Loss=  5.32683736777
Iteration 8 Loss=  4.99850371195
Iteration 9 Loss=  4.69040776606
Iteration 10 Loss=  4.40130212554
Iteration 11 Loss=  4.13001627288
Iteration 12 Loss=  3.87545183851
Iteration 13 Loss=  3.63657815376
Iteration 14 Loss=  3.41242807793
Iteration 15 Loss=  3.20209408259
Iteration 16 Loss=  3.00472457723
Iteration 17 Loss=  2.81952046133
Iteration 18 Loss=  2.64573188909
Iteration 19 Loss=  2.48265523337
Iteration 20 Loss=  2.32963023699
Iteration 21 Loss=  2.18603733944
Iteration 22 Loss=  2.05129516845
Iteration 23 Loss=  1.92485818619
Iteration 24 Loss=  1.80621448046
Iteration 25 Loss=  1.69488369215
Iteration 26 Loss=  1.59041507034
Iteration 27 Loss=  1.49238564737
Iteration 28 Loss=  1.40039852632
Iteration 29 Loss=  1.31408127415
Iteration 30 Loss=  1.23308441379
Iteration 31 Loss=  1.15708000933
Iteration 32 Loss=  1.08576033839
Iteration 33 Loss=  1.01883664637
Iteration 34 Loss=  0.95603797772
Iteration 35 Loss=  0.897110079306
Iteration 36 Loss=  0.841814371692
Iteration 37 Loss=  0.78992698417
Iteration 38 Loss=  0.741237849773
Iteration 39 Loss=  0.695549856755
Iteration 40 Loss=  0.652678053273
Iteration 41 Loss=  0.612448902245
Iteration 42 Loss=  0.574699583546
Iteration 43 Loss=  0.539277340851
Iteration 44 Loss=  0.506038870403
Iteration 45 Loss=  0.474849748846
Iteration 46 Loss=  0.445583896747
Iteration 47 Loss=  0.418123073538
Iteration 48 Loss=  0.392356398334
Iteration 49 Loss=  0.368179889574
Iteration 50 Loss=  0.345496015698
Iteration 51 Loss=  0.32421325069
Iteration 52 Loss=  0.304245634473
Iteration 53 Loss=  0.285512349716
Iteration 54 Loss=  0.267937339801
Iteration 55 Loss=  0.251448997885
Iteration 56 Loss=  0.235979944253
Iteration 57 Loss=  0.221466881242
Iteration 58 Loss=  0.207850490775
Iteration 59 Loss=  0.195075335715
Iteration 60 Loss=  0.183089737362
Iteration 61 Loss=  0.171845610433
Iteration 62 Loss=  0.161298241001
Iteration 63 Loss=  0.151406003216
Iteration 64 Loss=  0.142130031413
Iteration 65 Loss=  0.13343388747
Iteration 66 Loss=  0.12528327557
Iteration 67 Loss=  0.117645842418
Iteration 68 Loss=  0.110491052019
Iteration 69 Loss=  0.10379006459
Iteration 70 Loss=  0.0975155357316
Iteration 71 Loss=  0.0916413153865
Iteration 72 Loss=  0.0861421213336
Iteration 73 Loss=  0.0809933138263
Iteration 74 Loss=  0.076170880029
Iteration 75 Loss=  0.0716516710385
Iteration 76 Loss=  0.0674138413643
Iteration 77 Loss=  0.0634373420742
Iteration 78 Loss=  0.0597042667027
Iteration 79 Loss=  0.0561988978152
Iteration 80 Loss=  0.0529074369417
Iteration 81 Loss=  0.0498175348288
Iteration 82 Loss=  0.0469177970348
Iteration 83 Loss=  0.0441974152338
Iteration 84 Loss=  0.0416460022051
Iteration 85 Loss=  0.039253618795
Iteration 86 Loss=  0.0370109011919
Iteration 87 Loss=  0.0349091657919
Iteration 88 Loss=  0.0329404099864
Iteration 89 Loss=  0.0310972088268
Iteration 90 Loss=  0.0293725671312
Iteration 91 Loss=  0.0277597931422
Iteration 92 Loss=  0.0262524300795
Iteration 93 Loss=  0.0248442458633
Iteration 94 Loss=  0.0235292556827
Iteration 95 Loss=  0.0223017430653
Iteration 96 Loss=  0.0211562552442
Iteration 97 Loss=  0.020087572406
Iteration 98 Loss=  0.0190906707382
Iteration 99 Loss=  0.0181607003613
Iteration 100 Loss=  0.0172929849133
[ -3.77466439e-04   2.73264991e-04  -1.68064364e-04 ...,   1.64821399e-04
  -8.50862229e-06   2.00885349e-04]
CROSS VALIDATION 15
Iteration 1 Loss=  66.6775115349
Iteration 2 Loss=  7.32177756945
Iteration 3 Loss=  6.8704805182
Iteration 4 Loss=  6.44700034975
Iteration 5 Loss=  6.04962249722
Iteration 6 Loss=  5.67673807562
Iteration 7 Loss=  5.32683736777
Iteration 8 Loss=  4.99850371195
Iteration 9 Loss=  4.69040776606
Iteration 10 Loss=  4.40130212554
Iteration 11 Loss=  4.13001627288
Iteration 12 Loss=  3.87545183851
Iteration 13 Loss=  3.63657815376
Iteration 14 Loss=  3.41242807793
Iteration 15 Loss=  3.20209408259
Iteration 16 Loss=  3.00472457723
Iteration 17 Loss=  2.81952046133
Iteration 18 Loss=  2.64573188909
Iteration 19 Loss=  2.48265523337
Iteration 20 Loss=  2.32963023699
Iteration 21 Loss=  2.18603733944
Iteration 22 Loss=  2.05129516845
Iteration 23 Loss=  1.92485818619
Iteration 24 Loss=  1.80621448047
Iteration 25 Loss=  1.69488369217
Iteration 26 Loss=  1.59041507038
Iteration 27 Loss=  1.49238564745
Iteration 28 Loss=  1.4003985265
Iteration 29 Loss=  1.3140812745
Iteration 30 Loss=  1.23308441449
Iteration 31 Loss=  1.15708001068
Iteration 32 Loss=  1.08576034095
Iteration 33 Loss=  1.01883665113
Iteration 34 Loss=  0.956037986396
Iteration 35 Loss=  0.897110094828
Iteration 36 Loss=  0.84181439896
Iteration 37 Loss=  0.789927031232
Iteration 38 Loss=  0.741237929619
Iteration 39 Loss=  0.69554998999
Iteration 40 Loss=  0.652678272039
Iteration 41 Loss=  0.612449255864
Iteration 42 Loss=  0.574700146487
Iteration 43 Loss=  0.539278223759
Iteration 44 Loss=  0.50604023505
Iteration 45 Loss=  0.474851827888
Iteration 46 Loss=  0.445587019079
Iteration 47 Loss=  0.418127695601
Iteration 48 Loss=  0.39236314076
Iteration 49 Loss=  0.368189576679
Iteration 50 Loss=  0.34550971228
Iteration 51 Loss=  0.324232286047
Iteration 52 Loss=  0.304271598188
Iteration 53 Loss=  0.285547039371
Iteration 54 Loss=  0.267982641597
Iteration 55 Loss=  0.251506692684
Iteration 56 Loss=  0.236051457319
Iteration 57 Loss=  0.22155302821
Iteration 58 Loss=  0.207951296209
Iteration 59 Loss=  0.195189990589
Iteration 60 Loss=  0.183216712191
Iteration 61 Loss=  0.171982877675
Iteration 62 Loss=  0.16144352395
Iteration 63 Loss=  0.151556977666
Iteration 64 Loss=  0.14228444526
Iteration 65 Loss=  0.133589602791
Iteration 66 Loss=  0.125438259963
Iteration 67 Loss=  0.117798141539
Iteration 68 Loss=  0.110638772051
Iteration 69 Loss=  0.103931387888
Iteration 70 Loss=  0.0976487848963
Iteration 71 Loss=  0.0917650673823
Iteration 72 Loss=  0.0862553549364
Iteration 73 Loss=  0.0810955561467
Iteration 74 Loss=  0.0762623076152
Iteration 75 Loss=  0.0717331231153
Iteration 76 Loss=  0.0674867215764
Iteration 77 Loss=  0.0635034204763
Iteration 78 Loss=  0.0597654325694
Iteration 79 Loss=  0.0562569322622
Iteration 80 Loss=  0.0529638584218
Iteration 81 Loss=  0.0498735329891
Iteration 82 Loss=  0.0469742381207
Iteration 83 Loss=  0.0442548898356
Iteration 84 Loss=  0.0417048883722
Iteration 85 Loss=  0.0393141391895
Iteration 86 Loss=  0.0370731584794
Iteration 87 Loss=  0.0349731494875
Iteration 88 Loss=  0.033005981895
Iteration 89 Loss=  0.0311640868847
Iteration 90 Loss=  0.0294403300207
Iteration 91 Loss=  0.0278279175039
Iteration 92 Loss=  0.026320354738
Iteration 93 Loss=  0.0249114447115
Iteration 94 Loss=  0.0235953007842
Iteration 95 Loss=  0.0223663494076
Iteration 96 Loss=  0.0212193071959
Iteration 97 Loss=  0.0201491316995
Iteration 98 Loss=  0.0191509616
Iteration 99 Loss=  0.0182200699421
Iteration 100 Loss=  0.0173518481083
[ -4.05360838e-04   2.73346220e-04  -1.81326878e-04 ...,   1.82371710e-04
   6.47902967e-06   2.03435893e-04]
CROSS VALIDATION 16
Iteration 1 Loss=  105.726856975
Iteration 2 Loss=  6.82204522632
Iteration 3 Loss=  6.40155209427
Iteration 4 Loss=  6.00697784366
Iteration 5 Loss=  5.63672512912
Iteration 6 Loss=  5.28929511084
Iteration 7 Loss=  4.96328137371
Iteration 8 Loss=  4.65736420582
Iteration 9 Loss=  4.37030520875
Iteration 10 Loss=  4.10094221833
Iteration 11 Loss=  3.84818452623
Iteration 12 Loss=  3.61100840791
Iteration 13 Loss=  3.38845297336
Iteration 14 Loss=  3.17961634942
Iteration 15 Loss=  2.98365217056
Iteration 16 Loss=  2.79976631478
Iteration 17 Loss=  2.62721380581
Iteration 18 Loss=  2.46529582926
Iteration 19 Loss=  2.31335685793
Iteration 20 Loss=  2.17078191413
Iteration 21 Loss=  2.03699399745
Iteration 22 Loss=  1.91145168933
Iteration 23 Loss=  1.7936469282
Iteration 24 Loss=  1.68310293985
Iteration 25 Loss=  1.57937230674
Iteration 26 Loss=  1.48203516205
Iteration 27 Loss=  1.39069749717
Iteration 28 Loss=  1.30498957399
Iteration 29 Loss=  1.22456443476
Iteration 30 Loss=  1.14909650339
Iteration 31 Loss=  1.0782802728
Iteration 32 Loss=  1.01182907334
Iteration 33 Loss=  0.949473917433
Iteration 34 Loss=  0.890962416122
Iteration 35 Loss=  0.836057762957
Iteration 36 Loss=  0.784537780739
Iteration 37 Loss=  0.736194026175
Iteration 38 Loss=  0.690830946827
Iteration 39 Loss=  0.648265083709
Iteration 40 Loss=  0.608324311929
Iteration 41 Loss=  0.570847111699
Iteration 42 Loss=  0.53568186464
Iteration 43 Loss=  0.502686177421
Iteration 44 Loss=  0.471726246772
Iteration 45 Loss=  0.442676291825
Iteration 46 Loss=  0.415418080527
Iteration 47 Loss=  0.389840555967
Iteration 48 Loss=  0.365839531433
Iteration 49 Loss=  0.343317396232
Iteration 50 Loss=  0.322182783186
Iteration 51 Loss=  0.302350187634
Iteration 52 Loss=  0.2837395641
Iteration 53 Loss=  0.266275936852
Iteration 54 Loss=  0.249889047869
Iteration 55 Loss=  0.234513047861
Iteration 56 Loss=  0.220086224257
Iteration 57 Loss=  0.206550756212
Iteration 58 Loss=  0.193852487406
Iteration 59 Loss=  0.181940710023
Iteration 60 Loss=  0.170767956101
Iteration 61 Loss=  0.160289794153
Iteration 62 Loss=  0.150464627603
Iteration 63 Loss=  0.14125348507
Iteration 64 Loss=  0.13261978294
Iteration 65 Loss=  0.124529037624
Iteration 66 Loss=  0.116948524225
Iteration 67 Loss=  0.109846926138
Iteration 68 Loss=  0.103194072571
Iteration 69 Loss=  0.0969608672581
Iteration 70 Loss=  0.0911194396933
Iteration 71 Loss=  0.0856434380042
Iteration 72 Loss=  0.0805083169662
Iteration 73 Loss=  0.0756915047988
Iteration 74 Loss=  0.071172421079
Iteration 75 Loss=  0.0669323853761
Iteration 76 Loss=  0.0629544584488
Iteration 77 Loss=  0.0592232265041
Iteration 78 Loss=  0.055724532966
Iteration 79 Loss=  0.0524451886919
Iteration 80 Loss=  0.0493727089248
Iteration 81 Loss=  0.0464951120538
Iteration 82 Loss=  0.0438007936338
Iteration 83 Loss=  0.0412784850199
Iteration 84 Loss=  0.0389173128234
Iteration 85 Loss=  0.0367069604568
Iteration 86 Loss=  0.0346378790886
Iteration 87 Loss=  0.0327014370143
Iteration 88 Loss=  0.0308898988015
Iteration 89 Loss=  0.0291962120812
Iteration 90 Loss=  0.0276136965358
Iteration 91 Loss=  0.0261357908178
Iteration 92 Loss=  0.0247559714117
Iteration 93 Loss=  0.0234678394853
Iteration 94 Loss=  0.0222652665176
Iteration 95 Loss=  0.0211424786148
Iteration 96 Loss=  0.0200940375464
Iteration 97 Loss=  0.0191147626313
Iteration 98 Loss=  0.0181996675936
Iteration 99 Loss=  0.0173439609479
Iteration 100 Loss=  0.0165431109197
[-0.00056131  0.00022846 -0.00042014 ...,  0.00045656 -0.00011222
  0.00017509]
CROSS VALIDATION 17
Iteration 1 Loss=  66.6822839646
Iteration 2 Loss=  7.32181694216
Iteration 3 Loss=  6.87051746407
Iteration 4 Loss=  6.44703501836
Iteration 5 Loss=  6.04965502895
Iteration 6 Loss=  5.67676860216
Iteration 7 Loss=  5.32686601273
Iteration 8 Loss=  4.9985305913
Iteration 9 Loss=  4.69043298863
Iteration 10 Loss=  4.40132579345
Iteration 11 Loss=  4.13003848196
Iteration 12 Loss=  3.87547267868
Iteration 13 Loss=  3.63659770938
Iteration 14 Loss=  3.41244642819
Iteration 15 Loss=  3.20211130179
Iteration 16 Loss=  3.00474073507
Iteration 17 Loss=  2.81953562325
Iteration 18 Loss=  2.64574611645
Iteration 19 Loss=  2.4826685838
Iteration 20 Loss=  2.32964276453
Iteration 21 Loss=  2.18604909481
Iteration 22 Loss=  2.05130619925
Iteration 23 Loss=  1.92486853708
Iteration 24 Loss=  1.80622419335
Iteration 25 Loss=  1.69489280637
Iteration 26 Loss=  1.59042362281
Iteration 27 Loss=  1.49239367273
Iteration 28 Loss=  1.40040605711
Iteration 29 Loss=  1.31408834094
Iteration 30 Loss=  1.23309104536
Iteration 31 Loss=  1.15708623284
Iteration 32 Loss=  1.08576617957
Iteration 33 Loss=  1.01884212984
Iteration 34 Loss=  0.956043127369
Iteration 35 Loss=  0.897114918848
Iteration 36 Loss=  0.841818925517
Iteration 37 Loss=  0.78993127859
Iteration 38 Loss=  0.741241914879
Iteration 39 Loss=  0.695553729147
Iteration 40 Loss=  0.652681780031
Iteration 41 Loss=  0.612452546608
Iteration 42 Loss=  0.574703232916
Iteration 43 Loss=  0.539281117845
Iteration 44 Loss=  0.506042947835
Iteration 45 Loss=  0.474854369527
Iteration 46 Loss=  0.445589398917
Iteration 47 Loss=  0.418129922328
Iteration 48 Loss=  0.392365222676
Iteration 49 Loss=  0.368191522181
Iteration 50 Loss=  0.345511530622
Iteration 51 Loss=  0.324233988478
Iteration 52 Loss=  0.304273199501
Iteration 53 Loss=  0.285548559842
Iteration 54 Loss=  0.267984109241
Iteration 55 Loss=  0.251508145854
Iteration 56 Loss=  0.23605294791
Iteration 57 Loss=  0.221554626078
Iteration 58 Loss=  0.207953095635
Iteration 59 Loss=  0.195192119557
Iteration 60 Loss=  0.183219344891
Iteration 61 Loss=  0.171986250185
Iteration 62 Loss=  0.161447952634
Iteration 63 Loss=  0.151562879408
Iteration 64 Loss=  0.142292358144
Iteration 65 Loss=  0.133600204793
Iteration 66 Loss=  0.125452381344
Iteration 67 Loss=  0.117816763966
Iteration 68 Loss=  0.11066300478
Iteration 69 Loss=  0.103962411044
Iteration 70 Loss=  0.0976877547371
Iteration 71 Loss=  0.0918129895047
Iteration 72 Loss=  0.0863129456891
Iteration 73 Loss=  0.0811631234646
Iteration 74 Loss=  0.0763396831263
Iteration 75 Loss=  0.0718196655101
Iteration 76 Loss=  0.0675813916414
Iteration 77 Loss=  0.0636049091205
Iteration 78 Loss=  0.0598723109037
Iteration 79 Loss=  0.056367790289
Iteration 80 Loss=  0.0530774066612
Iteration 81 Loss=  0.0499886562958
Iteration 82 Loss=  0.0470900063452
Iteration 83 Loss=  0.0443705400566
Iteration 84 Loss=  0.0418197967892
Iteration 85 Loss=  0.0394277986909
Iteration 86 Loss=  0.0371851714251
Iteration 87 Loss=  0.0350832355092
Iteration 88 Loss=  0.0331139905383
Iteration 89 Loss=  0.0312699993072
Iteration 90 Loss=  0.0295442366364
Iteration 91 Loss=  0.027929969758
Iteration 92 Loss=  0.0264207037024
Iteration 93 Loss=  0.0250101872627
Iteration 94 Loss=  0.0236924489858
Iteration 95 Loss=  0.0224618241059
Iteration 96 Loss=  0.0213129451583
Iteration 97 Loss=  0.0202406958556
Iteration 98 Loss=  0.0192401526907
Iteration 99 Loss=  0.0183065448747
Iteration 100 Loss=  0.0174352499874
[ -4.03483719e-04   2.60723246e-04  -1.79141818e-04 ...,   1.82141881e-04
   7.72581506e-06   2.04357705e-04]
CROSS VALIDATION 18
Iteration 1 Loss=  137.939696507
Iteration 2 Loss=  135.205236773
Iteration 3 Loss=  6.87823398543
Iteration 4 Loss=  6.45424866969
Iteration 5 Loss=  6.05641673621
Iteration 6 Loss=  5.68311387814
Iteration 7 Loss=  5.33282438696
Iteration 8 Loss=  5.00412823389
Iteration 9 Loss=  4.69569376899
Iteration 10 Loss=  4.40627182379
Iteration 11 Loss=  4.13469045049
Iteration 12 Loss=  3.87985007868
Iteration 13 Loss=  3.64071900198
Iteration 14 Loss=  3.41632914664
Iteration 15 Loss=  3.20577209156
Iteration 16 Loss=  3.00819532089
Iteration 17 Loss=  2.82279870496
Iteration 18 Loss=  2.64883121973
Iteration 19 Loss=  2.4855879208
Iteration 20 Loss=  2.33240717379
Iteration 21 Loss=  2.1886681091
Iteration 22 Loss=  2.0537882379
Iteration 23 Loss=  1.92722116671
Iteration 24 Loss=  1.8084543825
Iteration 25 Loss=  1.69700712047
Iteration 26 Loss=  1.59242834333
Iteration 27 Loss=  1.49429485278
Iteration 28 Loss=  1.40220953653
Iteration 29 Loss=  1.31579974208
Iteration 30 Loss=  1.23471576383
Iteration 31 Loss=  1.15862943104
Iteration 32 Loss=  1.08723278643
Iteration 33 Loss=  1.0202368479
Iteration 34 Loss=  0.957370447158
Iteration 35 Loss=  0.898379140435
Iteration 36 Loss=  0.843024186876
Iteration 37 Loss=  0.791081590419
Iteration 38 Loss=  0.742341200946
Iteration 39 Loss=  0.696605870064
Iteration 40 Loss=  0.6536906561
Iteration 41 Loss=  0.613422071851
Iteration 42 Loss=  0.575637367517
Iteration 43 Loss=  0.540183841132
Iteration 44 Loss=  0.506918171134
Iteration 45 Loss=  0.475705772617
Iteration 46 Loss=  0.446420190477
Iteration 47 Loss=  0.418942554865
Iteration 48 Loss=  0.393161126257
Iteration 49 Loss=  0.368970938231
Iteration 50 Loss=  0.346273509336
Iteration 51 Loss=  0.324976566341
Iteration 52 Loss=  0.304993727432
Iteration 53 Loss=  0.286244133824
Iteration 54 Loss=  0.268652058658
Iteration 55 Loss=  0.252146532491
Iteration 56 Loss=  0.236661005175
Iteration 57 Loss=  0.222133037039
Iteration 58 Loss=  0.208504000096
Iteration 59 Loss=  0.195718779173
Iteration 60 Loss=  0.183725484772
Iteration 61 Loss=  0.172475208395
Iteration 62 Loss=  0.161921853634
Iteration 63 Loss=  0.152022057503
Iteration 64 Loss=  0.142735182337
Iteration 65 Loss=  0.134023326115
Iteration 66 Loss=  0.125851287923
Iteration 67 Loss=  0.118186443019
Iteration 68 Loss=  0.110998516846
Iteration 69 Loss=  0.104259279941
Iteration 70 Loss=  0.0979422074495
Iteration 71 Loss=  0.0920221616534
Iteration 72 Loss=  0.0864751620827
Iteration 73 Loss=  0.081278287574
Iteration 74 Loss=  0.0764096959563
Iteration 75 Loss=  0.0718486807548
Iteration 76 Loss=  0.0675756730205
Iteration 77 Loss=  0.0635721616826
Iteration 78 Loss=  0.0598205918113
Iteration 79 Loss=  0.0563043325832
Iteration 80 Loss=  0.0530077622913
Iteration 81 Loss=  0.0499164319247
Iteration 82 Loss=  0.0470172066753
Iteration 83 Loss=  0.0442982941111
Iteration 84 Loss=  0.0417491351993
Iteration 85 Loss=  0.0393601988422
Iteration 86 Loss=  0.0371227398425
Iteration 87 Loss=  0.0350285639164
Iteration 88 Loss=  0.0330698229574
Iteration 89 Loss=  0.0312388543793
Iteration 90 Loss=  0.0295280751151
Iteration 91 Loss=  0.0279299360871
Iteration 92 Loss=  0.0264369373586
Iteration 93 Loss=  0.0250417011865
Iteration 94 Loss=  0.0237370955006
Iteration 95 Loss=  0.0225163848069
Iteration 96 Loss=  0.021373362434
Iteration 97 Loss=  0.0203024095846
Iteration 98 Loss=  0.0192984533701
Iteration 99 Loss=  0.0183568513333
Iteration 100 Loss=  0.0174732792865
[ -5.24113399e-04  -2.41364522e-04  -4.20278747e-04 ...,   4.76112141e-04
   4.09398972e-05   1.71129853e-04]
CROSS VALIDATION 19
Iteration 1 Loss=  121.781367777
Iteration 2 Loss=  19.1489279408
Iteration 3 Loss=  7.93121044199
Iteration 4 Loss=  7.44234938997
Iteration 5 Loss=  6.9836205769
Iteration 6 Loss=  6.55316672284
Iteration 7 Loss=  6.14924502619
Iteration 8 Loss=  5.77022010753
Iteration 9 Loss=  5.41455738835
Iteration 10 Loss=  5.08081687794
Iteration 11 Loss=  4.7676473432
Iteration 12 Loss=  4.47378083784
Iteration 13 Loss=  4.19802756879
Iteration 14 Loss=  3.939271079
Iteration 15 Loss=  3.69646372722
Iteration 16 Loss=  3.46862244629
Iteration 17 Loss=  3.254824763
Iteration 18 Loss=  3.05420506322
Iteration 19 Loss=  2.86595108722
Iteration 20 Loss=  2.68930064103
Iteration 21 Loss=  2.52353851052
Iteration 22 Loss=  2.36799356571
Iteration 23 Loss=  2.22203604345
Iteration 24 Loss=  2.08507499776
Iteration 25 Loss=  1.95655590722
Iteration 26 Loss=  1.83595842989
Iteration 27 Loss=  1.72279429663
Iteration 28 Loss=  1.61660533431
Iteration 29 Loss=  1.51696161095
Iteration 30 Loss=  1.42345969524
Iteration 31 Loss=  1.33572102349
Iteration 32 Loss=  1.2533903675
Iteration 33 Loss=  1.17613439702
Iteration 34 Loss=  1.10364033134
Iteration 35 Loss=  1.03561467442
Iteration 36 Loss=  0.971782028744
Iteration 37 Loss=  0.911883983169
Iteration 38 Loss=  0.855678070389
Iteration 39 Loss=  0.802936789979
Iteration 40 Loss=  0.753446693008
Iteration 41 Loss=  0.707007524257
Iteration 42 Loss=  0.663431417895
Iteration 43 Loss=  0.622542141879
Iteration 44 Loss=  0.584174385492
Iteration 45 Loss=  0.548173083255
Iteration 46 Loss=  0.514392767635
Iteration 47 Loss=  0.48269694356
Iteration 48 Loss=  0.45295748178
Iteration 49 Loss=  0.42505403705
Iteration 50 Loss=  0.398873509567
Iteration 51 Loss=  0.374309576513
Iteration 52 Loss=  0.351262312606
Iteration 53 Loss=  0.329637888409
Iteration 54 Loss=  0.309348297977
Iteration 55 Loss=  0.290311055632
Iteration 56 Loss=  0.27244883402
Iteration 57 Loss=  0.255689072098
Iteration 58 Loss=  0.239963619092
Iteration 59 Loss=  0.225208470503
Iteration 60 Loss=  0.211363601606
Iteration 61 Loss=  0.198372847962
Iteration 62 Loss=  0.186183760553
Iteration 63 Loss=  0.17474738795
Iteration 64 Loss=  0.164017984161
Iteration 65 Loss=  0.15395267417
Iteration 66 Loss=  0.144511118047
Iteration 67 Loss=  0.135655210216
Iteration 68 Loss=  0.127348843965
Iteration 69 Loss=  0.119557762393
Iteration 70 Loss=  0.112249503046
Iteration 71 Loss=  0.105393427388
Iteration 72 Loss=  0.0989608103487
Iteration 73 Loss=  0.092924945744
Iteration 74 Loss=  0.087261206088
Iteration 75 Loss=  0.0819470032984
Iteration 76 Loss=  0.0769616394732
Iteration 77 Loss=  0.0722860846883
Iteration 78 Loss=  0.0679027354998
Iteration 79 Loss=  0.0637951918181
Iteration 80 Loss=  0.0599480647945
Iteration 81 Loss=  0.0563468110982
Iteration 82 Loss=  0.0529775805089
Iteration 83 Loss=  0.0498270631724
Iteration 84 Loss=  0.0468823355479
Iteration 85 Loss=  0.0441307298409
Iteration 86 Loss=  0.0415597706852
Iteration 87 Loss=  0.0391572104269
Iteration 88 Loss=  0.0369111555924
Iteration 89 Loss=  0.034810246279
Iteration 90 Loss=  0.0328438467985
Iteration 91 Loss=  0.0310022134221
Iteration 92 Loss=  0.0292766053504
Iteration 93 Loss=  0.027659308483
Iteration 94 Loss=  0.0261435652336
Iteration 95 Loss=  0.0247234370094
Iteration 96 Loss=  0.0233936404734
Iteration 97 Loss=  0.0221493849932
Iteration 98 Loss=  0.0209862171689
Iteration 99 Loss=  0.0198998727071
Iteration 100 Loss=  0.018886148655
[ -5.36148909e-04  -7.87668444e-05  -3.49968941e-04 ...,   6.08472837e-04
   1.22357854e-05   9.14094665e-05]
Accuracy (Logistic Loss):	0.9 for lmda= 0.3 learning rate= 0.001
---------------------------------------------------------------------------------
lmda= 0.3 learning rate= 0.01
CROSS VALIDATION 0
Iteration 1 Loss=  1422.63046967
Iteration 2 Loss=  402.311438487
Iteration 3 Loss=  212.578396444
Iteration 4 Loss=  112.324856595
Iteration 5 Loss=  59.3516256601
Iteration 6 Loss=  31.3609611912
Iteration 7 Loss=  16.5709005591
Iteration 8 Loss=  8.75594162011
Iteration 9 Loss=  4.62657496381
Iteration 10 Loss=  2.44464808293
Iteration 11 Loss=  1.2917340158
Iteration 12 Loss=  0.682543188661
Iteration 13 Loss=  0.360679310407
Iteration 14 Loss=  0.190990577778
Iteration 15 Loss=  0.101834269789
Iteration 16 Loss=  0.0541792539083
Iteration 17 Loss=  0.0302370922184
Iteration 18 Loss=  0.0165922386834
Iteration 19 Loss=  0.0105739148422
Iteration 20 Loss=  0.00666963651709
Iteration 21 Loss=  0.00541795947451
Iteration 22 Loss=  0.00778004964807
Iteration 23 Loss=  9580.6193707
Iteration 24 Loss=  5052.54102942
Iteration 25 Loss=  424.856150127
Iteration 26 Loss=  224.490855773
Iteration 27 Loss=  118.619312233
Iteration 28 Loss=  62.6775695878
Iteration 29 Loss=  33.1183654287
Iteration 30 Loss=  17.4994999947
Iteration 31 Loss=  9.24660671208
Iteration 32 Loss=  4.8858387871
Iteration 33 Loss=  2.58164248487
Iteration 34 Loss=  1.36416266692
Iteration 35 Loss=  0.720817062068
Iteration 36 Loss=  0.380965829709
Iteration 37 Loss=  0.201373772432
Iteration 38 Loss=  0.106524999657
Iteration 39 Loss=  0.0567770765526
Iteration 40 Loss=  0.0308898503519
Iteration 41 Loss=  0.0172110384069
Iteration 42 Loss=  0.0104987810016
Iteration 43 Loss=  0.00657088342869
Iteration 44 Loss=  0.00540408695346
Iteration 45 Loss=  0.0620125435949
Iteration 46 Loss=  6462.77342633
Iteration 47 Loss=  518.956722568
Iteration 48 Loss=  1239.35108523
Iteration 49 Loss=  231.326510747
Iteration 50 Loss=  122.231221897
Iteration 51 Loss=  64.5860760114
Iteration 52 Loss=  34.1268061449
Iteration 53 Loss=  18.0323526304
Iteration 54 Loss=  9.52816215231
Iteration 55 Loss=  5.03461462946
Iteration 56 Loss=  2.66036799569
Iteration 57 Loss=  1.40631329411
Iteration 58 Loss=  0.743011928453
Iteration 59 Loss=  0.39322231086
Iteration 60 Loss=  0.207959123797
Iteration 61 Loss=  0.110687818986
Iteration 62 Loss=  0.0591995491598
Iteration 63 Loss=  0.0325576251097
Iteration 64 Loss=  0.0183828131536
Iteration 65 Loss=  0.0115702909598
Iteration 66 Loss=  0.00725890155903
Iteration 67 Loss=  0.0209036255071
Iteration 68 Loss=  8606.40271553
Iteration 69 Loss=  1941.41383533
Iteration 70 Loss=  2838.11447091
Iteration 71 Loss=  311.470450201
Iteration 72 Loss=  164.578688342
Iteration 73 Loss=  86.9621673603
Iteration 74 Loss=  45.9502196289
Iteration 75 Loss=  24.2797531758
Iteration 76 Loss=  12.8292988165
Iteration 77 Loss=  6.77890136306
Iteration 78 Loss=  3.58197260111
Iteration 79 Loss=  1.89268426887
Iteration 80 Loss=  1.00013749648
Iteration 81 Loss=  0.528463853209
Iteration 82 Loss=  0.279423067016
Iteration 83 Loss=  0.147816568144
Iteration 84 Loss=  0.0782115123584
Iteration 85 Loss=  0.0420114495957
Iteration 86 Loss=  0.0231679320476
Iteration 87 Loss=  0.0130045574653
Iteration 88 Loss=  0.00849360422863
Iteration 89 Loss=  0.0064353899912
Iteration 90 Loss=  0.17223138242
Iteration 91 Loss=  6372.33304741
Iteration 92 Loss=  523.339451997
Iteration 93 Loss=  1228.21391896
Iteration 94 Loss=  231.410302903
Iteration 95 Loss=  122.275497054
Iteration 96 Loss=  64.6094706777
Iteration 97 Loss=  34.139167714
Iteration 98 Loss=  18.0388843923
Iteration 99 Loss=  9.53161346521
Iteration 100 Loss=  5.03643641431
[-0.02266378 -0.00307065 -0.0043004  ...,  0.01475457  0.00088541
 -0.00131341]
CROSS VALIDATION 1
Iteration 1 Loss=  1647.93804487
Iteration 2 Loss=  423.215542203
Iteration 3 Loss=  368.29814324
Iteration 4 Loss=  164.53071914
Iteration 5 Loss=  86.936818332
Iteration 6 Loss=  45.9367735167
Iteration 7 Loss=  24.2726522734
Iteration 8 Loss=  12.8254904139
Iteration 9 Loss=  6.7768945349
Iteration 10 Loss=  3.58086231981
Iteration 11 Loss=  1.89214939843
Iteration 12 Loss=  0.999972809606
Iteration 13 Loss=  0.528306530763
Iteration 14 Loss=  0.279365889146
Iteration 15 Loss=  0.147755955728
Iteration 16 Loss=  0.078280936367
Iteration 17 Loss=  0.0418823268738
Iteration 18 Loss=  0.022343819354
Iteration 19 Loss=  0.0126204207865
Iteration 20 Loss=  0.00837690708838
Iteration 21 Loss=  0.00619928290796
Iteration 22 Loss=  0.0611615418091
Iteration 23 Loss=  6447.49364848
Iteration 24 Loss=  788.806656508
Iteration 25 Loss=  281.861528309
Iteration 26 Loss=  148.933552405
Iteration 27 Loss=  78.6953904818
Iteration 28 Loss=  41.5820638336
Iteration 29 Loss=  21.9716557994
Iteration 30 Loss=  11.6096608504
Iteration 31 Loss=  6.1344591546
Iteration 32 Loss=  3.24140296642
Iteration 33 Loss=  1.71273341736
Iteration 34 Loss=  0.904995770345
Iteration 35 Loss=  0.47819940239
Iteration 36 Loss=  0.252846915297
Iteration 37 Loss=  0.134289720789
Iteration 38 Loss=  0.0711700231327
Iteration 39 Loss=  0.038860217058
Iteration 40 Loss=  0.0215605965
Iteration 41 Loss=  0.0132867012194
Iteration 42 Loss=  0.00798886315394
Iteration 43 Loss=  0.00658699708243
Iteration 44 Loss=  0.0276537008088
Iteration 45 Loss=  7317.83825002
Iteration 46 Loss=  1516.62177545
Iteration 47 Loss=  385.945049464
Iteration 48 Loss=  548.420251331
Iteration 49 Loss=  180.910356011
Iteration 50 Loss=  95.5916976301
Iteration 51 Loss=  50.5099478951
Iteration 52 Loss=  26.6890838809
Iteration 53 Loss=  14.1023150505
Iteration 54 Loss=  7.45155924687
Iteration 55 Loss=  3.93734893958
Iteration 56 Loss=  2.08046613602
Iteration 57 Loss=  1.09930305674
Iteration 58 Loss=  0.580871049574
Iteration 59 Loss=  0.30695595593
Iteration 60 Loss=  0.162248593424
Iteration 61 Loss=  0.0859406479824
Iteration 62 Loss=  0.0458091420314
Iteration 63 Loss=  0.0249390463278
Iteration 64 Loss=  0.0139913219575
Iteration 65 Loss=  0.00941925117832
Iteration 66 Loss=  0.00643819397135
Iteration 67 Loss=  0.0120314467446
Iteration 68 Loss=  0.00673226500837
Iteration 69 Loss=  0.0045781449211
Iteration 70 Loss=  0.00582098413374
Iteration 71 Loss=  0.00611339900372
Iteration 72 Loss=  0.00648696044331
Iteration 73 Loss=  0.00421235077594
Iteration 74 Loss=  0.00556873035081
Iteration 75 Loss=  0.0202811146829
Iteration 76 Loss=  5804.35323095
Iteration 77 Loss=  341.636550132
Iteration 78 Loss=  180.518233006
Iteration 79 Loss=  95.3845027265
Iteration 80 Loss=  50.4004676369
Iteration 81 Loss=  26.6312354919
Iteration 82 Loss=  14.07176058
Iteration 83 Loss=  7.43565513196
Iteration 84 Loss=  3.92921264732
Iteration 85 Loss=  2.07640170827
Iteration 86 Loss=  1.09740365908
Iteration 87 Loss=  0.580745364357
Iteration 88 Loss=  0.30678302839
Iteration 89 Loss=  0.163707263443
Iteration 90 Loss=  0.0869813871104
Iteration 91 Loss=  0.0470847373744
Iteration 92 Loss=  0.0363365900715
Iteration 93 Loss=  10268.4064249
Iteration 94 Loss=  1129.08449562
Iteration 95 Loss=  1041.85768472
Iteration 96 Loss=  238.725030858
Iteration 97 Loss=  126.140545349
Iteration 98 Loss=  66.6517336858
Iteration 99 Loss=  35.2182844227
Iteration 100 Loss=  18.6090817011
[-0.02080837 -0.02048832 -0.00551164 ...,  0.01476307  0.00041809
  0.00240845]
CROSS VALIDATION 2
Iteration 1 Loss=  5553.85744342
Iteration 2 Loss=  386.691363241
Iteration 3 Loss=  204.324863907
Iteration 4 Loss=  107.963751277
Iteration 5 Loss=  57.0472710343
Iteration 6 Loss=  30.1434959649
Iteration 7 Loss=  15.9276228209
Iteration 8 Loss=  8.41617384763
Iteration 9 Loss=  4.44707643556
Iteration 10 Loss=  2.34999724566
Iteration 11 Loss=  1.2418350852
Iteration 12 Loss=  0.656419364552
Iteration 13 Loss=  0.350752498051
Iteration 14 Loss=  6556.01972427
Iteration 15 Loss=  576.517219735
Iteration 16 Loss=  391.552637373
Iteration 17 Loss=  1255.57294524
Iteration 18 Loss=  145.011451269
Iteration 19 Loss=  76.6229811727
Iteration 20 Loss=  40.4870180418
Iteration 21 Loss=  21.3930416898
Iteration 22 Loss=  11.3039268612
Iteration 23 Loss=  5.97296634913
Iteration 24 Loss=  3.15639588244
Iteration 25 Loss=  1.6676665782
Iteration 26 Loss=  0.881456484714
Iteration 27 Loss=  0.465665485845
Iteration 28 Loss=  0.24649548353
Iteration 29 Loss=  0.130698532765
Iteration 30 Loss=  0.0696497467057
Iteration 31 Loss=  0.0376726161678
Iteration 32 Loss=  0.021364710141
Iteration 33 Loss=  0.012572286778
Iteration 34 Loss=  0.00884789108499
Iteration 35 Loss=  0.00944786833939
Iteration 36 Loss=  38.1485661385
Iteration 37 Loss=  2314.19480789
Iteration 38 Loss=  1344.07574496
Iteration 39 Loss=  298.805564782
Iteration 40 Loss=  157.88665629
Iteration 41 Loss=  83.4261445319
Iteration 42 Loss=  44.0817593772
Iteration 43 Loss=  23.2924764856
Iteration 44 Loss=  12.3075727579
Iteration 45 Loss=  6.5032306584
Iteration 46 Loss=  3.43625910879
Iteration 47 Loss=  1.81569396679
Iteration 48 Loss=  0.959399648862
Iteration 49 Loss=  0.506960717106
Iteration 50 Loss=  0.268246657793
Iteration 51 Loss=  0.142166539043
Iteration 52 Loss=  0.0754146538622
Iteration 53 Loss=  0.0405117802651
Iteration 54 Loss=  0.0223171741642
Iteration 55 Loss=  0.0129399691893
Iteration 56 Loss=  0.00839095767355
Iteration 57 Loss=  0.00538350381925
Iteration 58 Loss=  0.0227788426528
Iteration 59 Loss=  5277.51380466
Iteration 60 Loss=  1716.84188512
Iteration 61 Loss=  509.088564746
Iteration 62 Loss=  255.373607722
Iteration 63 Loss=  134.937530556
Iteration 64 Loss=  71.2999957782
Iteration 65 Loss=  37.6743918244
Iteration 66 Loss=  19.9068707446
Iteration 67 Loss=  10.5186451813
Iteration 68 Loss=  5.55802566113
Iteration 69 Loss=  2.936845091
Iteration 70 Loss=  1.55190139667
Iteration 71 Loss=  0.820875536946
Iteration 72 Loss=  0.434018113048
Iteration 73 Loss=  0.230071966044
Iteration 74 Loss=  0.122351350044
Iteration 75 Loss=  0.065184090723
Iteration 76 Loss=  0.0355690011926
Iteration 77 Loss=  0.0194866930084
Iteration 78 Loss=  0.0125878940678
Iteration 79 Loss=  0.00744758872173
Iteration 80 Loss=  0.00594063545857
Iteration 81 Loss=  0.0170090117981
Iteration 82 Loss=  651.849997992
Iteration 83 Loss=  2621.93463471
Iteration 84 Loss=  1754.09159542
Iteration 85 Loss=  307.280223472
Iteration 86 Loss=  162.364603428
Iteration 87 Loss=  85.7922587681
Iteration 88 Loss=  45.331996686
Iteration 89 Loss=  23.9530926572
Iteration 90 Loss=  12.6566374701
Iteration 91 Loss=  6.68767395163
Iteration 92 Loss=  3.5337243083
Iteration 93 Loss=  1.86736783887
Iteration 94 Loss=  0.987497792165
Iteration 95 Loss=  0.52160525657
Iteration 96 Loss=  0.276643592898
Iteration 97 Loss=  0.145987108382
Iteration 98 Loss=  0.0781189515804
Iteration 99 Loss=  0.041328644146
Iteration 100 Loss=  0.0232651142506
[ -1.47166118e-03  -1.84276469e-04  -4.91885202e-04 ...,   1.52923114e-03
   5.70419886e-04   8.41538508e-05]
CROSS VALIDATION 3
Iteration 1 Loss=  2348.80424702
Iteration 2 Loss=  359.083467725
Iteration 3 Loss=  189.737055565
Iteration 4 Loss=  100.255660564
Iteration 5 Loss=  52.974351506
Iteration 6 Loss=  27.9912567271
Iteration 7 Loss=  14.790384591
Iteration 8 Loss=  7.81522437371
Iteration 9 Loss=  4.12948060298
Iteration 10 Loss=  2.18206159608
Iteration 11 Loss=  1.15297112755
Iteration 12 Loss=  0.609318702937
Iteration 13 Loss=  0.32200368855
Iteration 14 Loss=  0.170635080779
Iteration 15 Loss=  0.0901591520527
Iteration 16 Loss=  0.0487579344386
Iteration 17 Loss=  0.0261927891846
Iteration 18 Loss=  0.0155620857367
Iteration 19 Loss=  0.00885213499512
Iteration 20 Loss=  0.00658886524509
Iteration 21 Loss=  0.00475659474826
Iteration 22 Loss=  0.0058274756998
Iteration 23 Loss=  0.0337892760667
Iteration 24 Loss=  0.00677326798181
Iteration 25 Loss=  0.00566271456222
Iteration 26 Loss=  0.00507999280955
Iteration 27 Loss=  0.0044593769216
Iteration 28 Loss=  0.00858240806556
Iteration 29 Loss=  0.00667723009626
Iteration 30 Loss=  0.0055661933285
Iteration 31 Loss=  0.00502510986555
Iteration 32 Loss=  0.00513539759974
Iteration 33 Loss=  0.00614819473872
Iteration 34 Loss=  0.0250964125727
Iteration 35 Loss=  0.0119816499039
Iteration 36 Loss=  0.00772414454639
Iteration 37 Loss=  0.0215122916478
Iteration 38 Loss=  4279.70907093
Iteration 39 Loss=  3303.67601856
Iteration 40 Loss=  1576.73737968
Iteration 41 Loss=  653.937599188
Iteration 42 Loss=  234.319554165
Iteration 43 Loss=  123.812723961
Iteration 44 Loss=  65.4217300358
Iteration 45 Loss=  34.5683595672
Iteration 46 Loss=  18.265666204
Iteration 47 Loss=  9.65144383237
Iteration 48 Loss=  5.09977338514
Iteration 49 Loss=  2.69469202101
Iteration 50 Loss=  1.42389007425
Iteration 51 Loss=  0.752380362117
Iteration 52 Loss=  0.397601362582
Iteration 53 Loss=  0.210119627762
Iteration 54 Loss=  0.111326464596
Iteration 55 Loss=  0.0594199980934
Iteration 56 Loss=  0.0319767694813
Iteration 57 Loss=  0.0181687528856
Iteration 58 Loss=  0.0105396005484
Iteration 59 Loss=  0.00714003953721
Iteration 60 Loss=  0.00821706530467
Iteration 61 Loss=  10162.8241035
Iteration 62 Loss=  1060.92200249
Iteration 63 Loss=  374.686917174
Iteration 64 Loss=  197.981803155
Iteration 65 Loss=  104.612124373
Iteration 66 Loss=  55.2762748469
Iteration 67 Loss=  29.2075758834
Iteration 68 Loss=  15.4330676806
Iteration 69 Loss=  8.15472280681
Iteration 70 Loss=  4.30899087655
Iteration 71 Loss=  2.27693559049
Iteration 72 Loss=  1.20328578412
Iteration 73 Loss=  0.635899815739
Iteration 74 Loss=  0.336482935418
Iteration 75 Loss=  0.182359163079
Iteration 76 Loss=  10071.0355573
Iteration 77 Loss=  4253.29447414
Iteration 78 Loss=  926.918200136
Iteration 79 Loss=  277.797030066
Iteration 80 Loss=  146.785901516
Iteration 81 Loss=  77.560587594
Iteration 82 Loss=  40.9824423586
Iteration 83 Loss=  21.6548202749
Iteration 84 Loss=  11.4422514511
Iteration 85 Loss=  6.04609896555
Iteration 86 Loss=  3.19470437148
Iteration 87 Loss=  1.68819063527
Iteration 88 Loss=  0.892032985702
Iteration 89 Loss=  0.471665035386
Iteration 90 Loss=  0.249252166102
Iteration 91 Loss=  0.132118699429
Iteration 92 Loss=  0.0701396850184
Iteration 93 Loss=  0.0376218170741
Iteration 94 Loss=  0.0207421036774
Iteration 95 Loss=  0.0136118092896
Iteration 96 Loss=  0.00751472251688
Iteration 97 Loss=  0.0221290760098
Iteration 98 Loss=  7447.30939575
Iteration 99 Loss=  290.048592032
Iteration 100 Loss=  153.259536489
[ 0.03919133 -0.02615447  0.00115849 ...,  0.05555832 -0.02034081
  0.00253649]
CROSS VALIDATION 4
Iteration 1 Loss=  2348.80424702
Iteration 2 Loss=  359.083467725
Iteration 3 Loss=  189.737055565
Iteration 4 Loss=  100.255660564
Iteration 5 Loss=  52.974351506
Iteration 6 Loss=  27.9912567271
Iteration 7 Loss=  14.790384591
Iteration 8 Loss=  7.81522437371
Iteration 9 Loss=  4.12948060298
Iteration 10 Loss=  2.18206159608
Iteration 11 Loss=  1.15297112758
Iteration 12 Loss=  0.609318724176
Iteration 13 Loss=  0.322005510288
Iteration 14 Loss=  0.170680617584
Iteration 15 Loss=  0.0903226349348
Iteration 16 Loss=  0.0488752407399
Iteration 17 Loss=  0.0262984396834
Iteration 18 Loss=  0.0157150734829
Iteration 19 Loss=  0.00894159455886
Iteration 20 Loss=  0.0064422701498
Iteration 21 Loss=  0.00477628753984
Iteration 22 Loss=  0.0056965547978
Iteration 23 Loss=  0.02383512682
Iteration 24 Loss=  4020.46268938
Iteration 25 Loss=  761.783481385
Iteration 26 Loss=  1508.37607913
Iteration 27 Loss=  368.177666025
Iteration 28 Loss=  163.427625947
Iteration 29 Loss=  86.3539520255
Iteration 30 Loss=  45.62879126
Iteration 31 Loss=  24.1099167594
Iteration 32 Loss=  12.7395062373
Iteration 33 Loss=  6.73156553422
Iteration 34 Loss=  3.55696372899
Iteration 35 Loss=  1.87975412755
Iteration 36 Loss=  0.993221225025
Iteration 37 Loss=  0.525128957436
Iteration 38 Loss=  0.277433923764
Iteration 39 Loss=  0.146962735674
Iteration 40 Loss=  0.0780077518597
Iteration 41 Loss=  0.0426853033828
Iteration 42 Loss=  0.0229298427985
Iteration 43 Loss=  0.0141674441198
Iteration 44 Loss=  0.00920464047834
Iteration 45 Loss=  6.16528875202
Iteration 46 Loss=  7943.33764498
Iteration 47 Loss=  1083.27452211
Iteration 48 Loss=  379.437891584
Iteration 49 Loss=  200.492182987
Iteration 50 Loss=  105.938590559
Iteration 51 Loss=  55.9771697946
Iteration 52 Loss=  29.5779236036
Iteration 53 Loss=  15.6287566704
Iteration 54 Loss=  8.258122262
Iteration 55 Loss=  4.36360973887
Iteration 56 Loss=  2.30585606553
Iteration 57 Loss=  1.21850843099
Iteration 58 Loss=  0.644793341742
Iteration 59 Loss=  0.340900345289
Iteration 60 Loss=  0.180678121554
Iteration 61 Loss=  0.0960979653779
Iteration 62 Loss=  0.051666073321
Iteration 63 Loss=  0.0284226111129
Iteration 64 Loss=  0.016542552157
Iteration 65 Loss=  0.0102999036199
Iteration 66 Loss=  0.0123324610818
Iteration 67 Loss=  9974.00303906
Iteration 68 Loss=  1297.98481348
Iteration 69 Loss=  1898.49546717
Iteration 70 Loss=  213.361873044
Iteration 71 Loss=  112.738839851
Iteration 72 Loss=  59.5703713588
Iteration 73 Loss=  31.4765448048
Iteration 74 Loss=  16.631974088
Iteration 75 Loss=  8.78821242224
Iteration 76 Loss=  4.64362661762
Iteration 77 Loss=  2.45365805243
Iteration 78 Loss=  1.29649518503
Iteration 79 Loss=  0.685078734516
Iteration 80 Loss=  0.362096430286
Iteration 81 Loss=  0.191406120866
Iteration 82 Loss=  0.101356995525
Iteration 83 Loss=  0.0542481511332
Iteration 84 Loss=  0.029254717467
Iteration 85 Loss=  0.0167739749811
Iteration 86 Loss=  0.0105621395718
Iteration 87 Loss=  0.00669976656809
Iteration 88 Loss=  0.00511488726691
Iteration 89 Loss=  0.00503975152822
[ -4.14919592e-04  -2.52480790e-04  -3.47070315e-05 ...,   2.01187241e-04
   1.71549860e-04   1.64862840e-05]
CROSS VALIDATION 5
Iteration 1 Loss=  1985.57739074
Iteration 2 Loss=  359.083467725
Iteration 3 Loss=  189.737055565
Iteration 4 Loss=  100.255660564
Iteration 5 Loss=  52.974351506
Iteration 6 Loss=  27.9912567271
Iteration 7 Loss=  14.790384591
Iteration 8 Loss=  7.81522437371
Iteration 9 Loss=  4.12948060298
Iteration 10 Loss=  2.18206159607
Iteration 11 Loss=  1.15297112542
Iteration 12 Loss=  0.609318216082
Iteration 13 Loss=  0.321976789345
Iteration 14 Loss=  0.170306056333
Iteration 15 Loss=  0.0903056877312
Iteration 16 Loss=  0.0485011164304
Iteration 17 Loss=  0.0262803390041
Iteration 18 Loss=  0.0153353664067
Iteration 19 Loss=  0.00888235810701
Iteration 20 Loss=  0.00643836600467
Iteration 21 Loss=  0.00487151211607
Iteration 22 Loss=  0.00534866439469
Iteration 23 Loss=  0.0209037785007
Iteration 24 Loss=  0.00570442892971
Iteration 25 Loss=  0.00372471133915
Iteration 26 Loss=  0.00579080290768
Iteration 27 Loss=  0.00493986605466
Iteration 28 Loss=  0.00537313411809
Iteration 29 Loss=  0.00884795516684
Iteration 30 Loss=  9810.30397088
Iteration 31 Loss=  4855.48730137
Iteration 32 Loss=  876.948147733
Iteration 33 Loss=  1813.41257783
Iteration 34 Loss=  248.313058722
Iteration 35 Loss=  131.206788546
Iteration 36 Loss=  69.3286992203
Iteration 37 Loss=  36.6327732645
Iteration 38 Loss=  19.3564871711
Iteration 39 Loss=  10.227825038
Iteration 40 Loss=  5.40430730446
Iteration 41 Loss=  2.85559611787
Iteration 42 Loss=  1.5088765771
Iteration 43 Loss=  0.797308022636
Iteration 44 Loss=  0.421331000839
Iteration 45 Loss=  0.222645023876
Iteration 46 Loss=  0.117937557801
Iteration 47 Loss=  0.0626693801016
Iteration 48 Loss=  0.0334643499684
Iteration 49 Loss=  0.019313145172
Iteration 50 Loss=  0.0108965934034
Iteration 51 Loss=  0.0078851131241
Iteration 52 Loss=  0.0115742255881
Iteration 53 Loss=  9025.92524209
Iteration 54 Loss=  6321.74425395
Iteration 55 Loss=  531.90031019
Iteration 56 Loss=  1515.82182966
Iteration 57 Loss=  212.789090939
Iteration 58 Loss=  154.040335348
Iteration 59 Loss=  81.3937769187
Iteration 60 Loss=  43.0078713222
Iteration 61 Loss=  22.7250419589
Iteration 62 Loss=  12.0077445397
Iteration 63 Loss=  6.34480363957
Iteration 64 Loss=  3.35254744067
Iteration 65 Loss=  1.77146133757
Iteration 66 Loss=  0.936027108244
Iteration 67 Loss=  0.494590777992
Iteration 68 Loss=  0.261381142052
Iteration 69 Loss=  0.138295391497
Iteration 70 Loss=  0.0732456085286
Iteration 71 Loss=  0.0389668259813
Iteration 72 Loss=  0.0214820023864
Iteration 73 Loss=  0.0121531445175
Iteration 74 Loss=  0.00795317557802
Iteration 75 Loss=  0.00641370505668
Iteration 76 Loss=  0.00478910582544
Iteration 77 Loss=  0.013342616278
Iteration 78 Loss=  0.00845458088159
Iteration 79 Loss=  0.004006717302
Iteration 80 Loss=  0.005131537882
Iteration 81 Loss=  0.0100409056652
Iteration 82 Loss=  9425.82792794
Iteration 83 Loss=  6304.34072215
Iteration 84 Loss=  513.8593907
Iteration 85 Loss=  1523.08889496
Iteration 86 Loss=  214.152606071
Iteration 87 Loss=  153.944078987
Iteration 88 Loss=  81.3429157672
Iteration 89 Loss=  42.9809966649
Iteration 90 Loss=  22.7108415882
Iteration 91 Loss=  12.0002411686
Iteration 92 Loss=  6.34083891362
Iteration 93 Loss=  3.35045250872
Iteration 94 Loss=  1.77035439098
Iteration 95 Loss=  0.935442205389
Iteration 96 Loss=  0.494281657366
Iteration 97 Loss=  0.261216190773
Iteration 98 Loss=  0.138210149297
Iteration 99 Loss=  0.0731925015479
Iteration 100 Loss=  0.0389505303633
[-0.00281467 -0.00057447 -0.00160573 ...,  0.00081377  0.00087515
  0.00021286]
CROSS VALIDATION 6
Iteration 1 Loss=  2348.80424702
Iteration 2 Loss=  359.083467725
Iteration 3 Loss=  189.737055565
Iteration 4 Loss=  100.255660564
Iteration 5 Loss=  52.974351506
Iteration 6 Loss=  27.9912567271
Iteration 7 Loss=  14.790384591
Iteration 8 Loss=  7.81522437371
Iteration 9 Loss=  4.12948060298
Iteration 10 Loss=  2.18206159608
Iteration 11 Loss=  1.15297112758
Iteration 12 Loss=  0.609318724204
Iteration 13 Loss=  0.322005491323
Iteration 14 Loss=  0.170669414601
Iteration 15 Loss=  0.0903200630583
Iteration 16 Loss=  0.0488381130764
Iteration 17 Loss=  0.026213062762
Iteration 18 Loss=  0.0155785616854
Iteration 19 Loss=  0.00886732682292
Iteration 20 Loss=  0.00650983650961
Iteration 21 Loss=  0.00484017950624
Iteration 22 Loss=  0.00591015472572
Iteration 23 Loss=  0.0308196657298
Iteration 24 Loss=  0.00697296278518
Iteration 25 Loss=  0.00614713536825
Iteration 26 Loss=  0.0125084238756
Iteration 27 Loss=  9046.01921623
Iteration 28 Loss=  3535.45171762
Iteration 29 Loss=  1154.36816855
Iteration 30 Loss=  247.802184256
Iteration 31 Loss=  130.936846247
Iteration 32 Loss=  69.1860637005
Iteration 33 Loss=  36.5574057083
Iteration 34 Loss=  19.3166636309
Iteration 35 Loss=  10.2067918347
Iteration 36 Loss=  5.39335519015
Iteration 37 Loss=  2.84977244786
Iteration 38 Loss=  1.50619101891
Iteration 39 Loss=  0.796322159956
Iteration 40 Loss=  0.421141510759
Iteration 41 Loss=  0.222945098071
Iteration 42 Loss=  0.118248328678
Iteration 43 Loss=  0.0630838313207
Iteration 44 Loss=  0.0342205398494
Iteration 45 Loss=  0.0190881659626
Iteration 46 Loss=  0.0111305119355
Iteration 47 Loss=  0.0077737673431
Iteration 48 Loss=  0.00499843067883
Iteration 49 Loss=  0.013198444481
Iteration 50 Loss=  9582.63168682
Iteration 51 Loss=  2113.91865914
Iteration 52 Loss=  4598.08325578
Iteration 53 Loss=  312.31037633
Iteration 54 Loss=  165.022499094
Iteration 55 Loss=  87.1966712318
Iteration 56 Loss=  46.0740778722
Iteration 57 Loss=  24.345202882
Iteration 58 Loss=  12.8638256203
Iteration 59 Loss=  6.7971505677
Iteration 60 Loss=  3.59156422075
Iteration 61 Loss=  1.89775604108
Iteration 62 Loss=  1.00276031114
Iteration 63 Loss=  0.529853476118
Iteration 64 Loss=  0.28004425054
Iteration 65 Loss=  0.148099054188
Iteration 66 Loss=  0.0785174128671
Iteration 67 Loss=  0.0420635125039
Iteration 68 Loss=  0.0226437718341
Iteration 69 Loss=  0.0132551024578
Iteration 70 Loss=  0.00801877334041
Iteration 71 Loss=  0.00584453067827
Iteration 72 Loss=  0.00520336750543
Iteration 73 Loss=  0.00810948449865
Iteration 74 Loss=  0.00718306993922
Iteration 75 Loss=  0.00505999728511
Iteration 76 Loss=  0.00395322816037
Iteration 77 Loss=  0.00994906986743
Iteration 78 Loss=  12.7308298667
Iteration 79 Loss=  1219.22329962
Iteration 80 Loss=  1303.14158584
Iteration 81 Loss=  398.318286064
Iteration 82 Loss=  184.057032109
Iteration 83 Loss=  97.2543780686
Iteration 84 Loss=  51.388495974
Iteration 85 Loss=  27.1533022062
Iteration 86 Loss=  14.3476048961
Iteration 87 Loss=  7.58118671623
Iteration 88 Loss=  4.00604900528
Iteration 89 Loss=  2.1167604296
Iteration 90 Loss=  1.11891621385
Iteration 91 Loss=  0.591618968196
Iteration 92 Loss=  0.312741179709
Iteration 93 Loss=  0.165745444935
Iteration 94 Loss=  0.0877211466469
Iteration 95 Loss=  0.047139595834
Iteration 96 Loss=  0.0261791177992
Iteration 97 Loss=  0.0146335193481
Iteration 98 Loss=  0.00965726331296
Iteration 99 Loss=  0.00709183973359
Iteration 100 Loss=  0.0112261996467
[ -5.04497191e-04  -2.24743234e-04  -1.50109084e-05 ...,   2.14192611e-04
   1.95548616e-04   3.88725772e-05]
CROSS VALIDATION 7
Iteration 1 Loss=  2348.80424702
Iteration 2 Loss=  359.083467725
Iteration 3 Loss=  189.737055565
Iteration 4 Loss=  100.255660564
Iteration 5 Loss=  52.974351506
Iteration 6 Loss=  27.9912567271
Iteration 7 Loss=  14.790384591
Iteration 8 Loss=  7.81522437371
Iteration 9 Loss=  4.12948060298
Iteration 10 Loss=  2.18206159608
Iteration 11 Loss=  1.15297112758
Iteration 12 Loss=  0.609318724204
Iteration 13 Loss=  0.322005491323
Iteration 14 Loss=  0.170669415602
Iteration 15 Loss=  0.0903203295357
Iteration 16 Loss=  0.0488500086987
Iteration 17 Loss=  0.0262937915472
Iteration 18 Loss=  0.0155849745141
Iteration 19 Loss=  0.00882868787128
Iteration 20 Loss=  0.00652075029652
Iteration 21 Loss=  0.00475757231716
Iteration 22 Loss=  0.00561614352511
Iteration 23 Loss=  0.0161251192789
Iteration 24 Loss=  0.0058289310792
Iteration 25 Loss=  0.00371688455464
Iteration 26 Loss=  0.00560079659191
Iteration 27 Loss=  0.0485173195121
Iteration 28 Loss=  5854.45893768
Iteration 29 Loss=  467.6805245
Iteration 30 Loss=  247.118939298
Iteration 31 Loss=  130.575824651
Iteration 32 Loss=  68.9953025522
Iteration 33 Loss=  36.4566089244
Iteration 34 Loss=  19.2634032333
Iteration 35 Loss=  10.1786401719
Iteration 36 Loss=  5.37831838881
Iteration 37 Loss=  2.84186470582
Iteration 38 Loss=  1.50166602229
Iteration 39 Loss=  0.794015771078
Iteration 40 Loss=  0.419458563826
Iteration 41 Loss=  0.222249036397
Iteration 42 Loss=  0.118001231955
Iteration 43 Loss=  0.0634994654602
Iteration 44 Loss=  0.034368327184
Iteration 45 Loss=  0.0201642794858
Iteration 46 Loss=  0.0119396632912
Iteration 47 Loss=  0.00825506081741
Iteration 48 Loss=  0.00602457039463
Iteration 49 Loss=  0.0281087648438
Iteration 50 Loss=  7612.83885257
Iteration 51 Loss=  3291.44154296
Iteration 52 Loss=  1082.59480899
Iteration 53 Loss=  250.155322647
Iteration 54 Loss=  132.180227214
Iteration 55 Loss=  69.843057032
Iteration 56 Loss=  36.904556138
Iteration 57 Loss=  19.5000952573
Iteration 58 Loss=  10.3037090451
Iteration 59 Loss=  5.44444421762
Iteration 60 Loss=  2.87680713033
Iteration 61 Loss=  1.52011817034
Iteration 62 Loss=  0.803280537384
Iteration 63 Loss=  0.424576516046
Iteration 64 Loss=  0.224457910166
Iteration 65 Loss=  0.118819218359
Iteration 66 Loss=  0.0628730398581
Iteration 67 Loss=  0.0337479889073
Iteration 68 Loss=  0.0189648120963
Iteration 69 Loss=  0.0113212035918
Iteration 70 Loss=  0.00686834007228
Iteration 71 Loss=  0.00609475274399
Iteration 72 Loss=  0.0112708334467
Iteration 73 Loss=  0.0691838497118
Iteration 74 Loss=  3925.20510799
Iteration 75 Loss=  3685.87852331
Iteration 76 Loss=  593.61276937
Iteration 77 Loss=  694.48974349
Iteration 78 Loss=  371.852115551
Iteration 79 Loss=  139.506735111
Iteration 80 Loss=  73.7143297605
Iteration 81 Loss=  38.9501080918
Iteration 82 Loss=  20.5809499658
Iteration 83 Loss=  10.8748338375
Iteration 84 Loss=  5.74640430143
Iteration 85 Loss=  3.0364116815
Iteration 86 Loss=  1.60470072675
Iteration 87 Loss=  0.847900108743
Iteration 88 Loss=  0.448484149676
Iteration 89 Loss=  0.237303299238
Iteration 90 Loss=  0.12603833869
Iteration 91 Loss=  0.0672251872591
Iteration 92 Loss=  0.0358515464015
Iteration 93 Loss=  0.0202886468416
Iteration 94 Loss=  0.0120855194273
Iteration 95 Loss=  0.0113662980781
Iteration 96 Loss=  0.0308743008942
Iteration 97 Loss=  6283.53017739
Iteration 98 Loss=  916.637949048
Iteration 99 Loss=  538.775016851
Iteration 100 Loss=  261.358543722
[-0.20399767 -0.03241858 -0.06448179 ...,  0.12487096  0.03142076
 -0.00300727]
CROSS VALIDATION 8
Iteration 1 Loss=  2348.80424702
Iteration 2 Loss=  359.083467725
Iteration 3 Loss=  189.737055565
Iteration 4 Loss=  100.255660564
Iteration 5 Loss=  52.974351506
Iteration 6 Loss=  27.9912567271
Iteration 7 Loss=  14.790384591
Iteration 8 Loss=  7.81522437371
Iteration 9 Loss=  4.12948060298
Iteration 10 Loss=  2.18206159608
Iteration 11 Loss=  1.15297112758
Iteration 12 Loss=  0.609318724204
Iteration 13 Loss=  0.322005491323
Iteration 14 Loss=  0.170669415225
Iteration 15 Loss=  0.0903201307844
Iteration 16 Loss=  0.0488348521062
Iteration 17 Loss=  0.0261045951966
Iteration 18 Loss=  0.0156627802174
Iteration 19 Loss=  0.008735165563
Iteration 20 Loss=  0.00664755186849
Iteration 21 Loss=  0.00470250787502
Iteration 22 Loss=  0.00591613207237
Iteration 23 Loss=  0.0263727303552
Iteration 24 Loss=  0.00554512133916
Iteration 25 Loss=  0.00481854271948
Iteration 26 Loss=  0.807572318218
Iteration 27 Loss=  4339.91059098
Iteration 28 Loss=  1923.11545883
Iteration 29 Loss=  1666.40607435
Iteration 30 Loss=  814.499603608
Iteration 31 Loss=  191.704725889
Iteration 32 Loss=  101.295363049
Iteration 33 Loss=  53.5237226292
Iteration 34 Loss=  28.2815402197
Iteration 35 Loss=  14.9437573932
Iteration 36 Loss=  7.89618171719
Iteration 37 Loss=  4.17230950234
Iteration 38 Loss=  2.20462686077
Iteration 39 Loss=  1.16502423923
Iteration 40 Loss=  0.616306532101
Iteration 41 Loss=  0.325781406818
Iteration 42 Loss=  0.172804986816
Iteration 43 Loss=  0.0918289456491
Iteration 44 Loss=  0.049188569943
Iteration 45 Loss=  0.0268308916371
Iteration 46 Loss=  0.0152803986307
Iteration 47 Loss=  0.00961926749554
Iteration 48 Loss=  0.00804501865592
Iteration 49 Loss=  0.179406365552
Iteration 50 Loss=  6141.73902445
Iteration 51 Loss=  808.907596982
Iteration 52 Loss=  543.606615907
Iteration 53 Loss=  262.370705347
Iteration 54 Loss=  138.634745326
Iteration 55 Loss=  73.2535767905
Iteration 56 Loss=  38.7066496207
Iteration 57 Loss=  20.4523081398
Iteration 58 Loss=  10.8068487596
Iteration 59 Loss=  5.71026010072
Iteration 60 Loss=  3.01730001438
Iteration 61 Loss=  1.59478803303
Iteration 62 Loss=  0.842635690049
Iteration 63 Loss=  0.445723195953
Iteration 64 Loss=  0.235411165883
Iteration 65 Loss=  0.125400730968
Iteration 66 Loss=  0.0662127617969
Iteration 67 Loss=  0.036484982019
Iteration 68 Loss=  0.0201334903946
Iteration 69 Loss=  0.0123218459589
Iteration 70 Loss=  0.0076716028947
Iteration 71 Loss=  0.0112854472355
Iteration 72 Loss=  7953.7137296
Iteration 73 Loss=  3828.89876695
Iteration 74 Loss=  1854.47551987
Iteration 75 Loss=  323.068149989
Iteration 76 Loss=  170.70682734
Iteration 77 Loss=  90.2002283468
Iteration 78 Loss=  47.661135296
Iteration 79 Loss=  25.1837923178
Iteration 80 Loss=  13.3069300923
Iteration 81 Loss=  7.03128370215
Iteration 82 Loss=  3.71527844216
Iteration 83 Loss=  1.96312583509
Iteration 84 Loss=  1.03731151811
Iteration 85 Loss=  0.548335705296
Iteration 86 Loss=  0.290271999261
Iteration 87 Loss=  0.153469522413
Iteration 88 Loss=  0.0815279055687
Iteration 89 Loss=  0.0435952089009
Iteration 90 Loss=  0.023967664701
Iteration 91 Loss=  0.0137886833861
Iteration 92 Loss=  0.00822233865518
Iteration 93 Loss=  0.0058035388062
Iteration 94 Loss=  0.00533238075703
Iteration 95 Loss=  0.0065063801914
Iteration 96 Loss=  0.00429408018759
Iteration 97 Loss=  0.00458146073681
Iteration 98 Loss=  0.0067433918652
Iteration 99 Loss=  0.00654928243019
Iteration 100 Loss=  0.00513663538988
[ -3.60142415e-04  -2.29855641e-04  -3.88227726e-05 ...,   2.02647702e-04
   9.52694854e-05   1.52814592e-05]
CROSS VALIDATION 9
Iteration 1 Loss=  2724.17469863
Iteration 2 Loss=  1836.0240545
Iteration 3 Loss=  748.952769368
Iteration 4 Loss=  205.954811732
Iteration 5 Loss=  108.825003292
Iteration 6 Loss=  57.5023289914
Iteration 7 Loss=  30.3838064728
Iteration 8 Loss=  16.0545792139
Iteration 9 Loss=  8.48312122995
Iteration 10 Loss=  4.48241868805
Iteration 11 Loss=  2.36847801494
Iteration 12 Loss=  1.2515291961
Iteration 13 Loss=  0.661486337539
Iteration 14 Loss=  0.349451282489
Iteration 15 Loss=  0.184973948384
Iteration 16 Loss=  0.0977047560523
Iteration 17 Loss=  0.0520111292205
Iteration 18 Loss=  0.0278816558639
Iteration 19 Loss=  0.0158342132395
Iteration 20 Loss=  0.00912377973284
Iteration 21 Loss=  0.00665737966786
Iteration 22 Loss=  0.00468072809125
Iteration 23 Loss=  0.0448249868712
Iteration 24 Loss=  0.00873690021137
Iteration 25 Loss=  8378.47698833
Iteration 26 Loss=  2820.21592706
Iteration 27 Loss=  375.878631133
Iteration 28 Loss=  198.61149602
Iteration 29 Loss=  104.944849438
Iteration 30 Loss=  55.4520843169
Iteration 31 Loss=  29.3004723104
Iteration 32 Loss=  15.4821534373
Iteration 33 Loss=  8.1806563985
Iteration 34 Loss=  4.32263184736
Iteration 35 Loss=  2.28425629949
Iteration 36 Loss=  1.20702645183
Iteration 37 Loss=  0.63831972245
Iteration 38 Loss=  0.337344803944
Iteration 39 Loss=  0.17954616565
Iteration 40 Loss=  0.0949957345967
Iteration 41 Loss=  0.0511250084351
Iteration 42 Loss=  0.0279707710248
Iteration 43 Loss=  0.0158131941867
Iteration 44 Loss=  0.0100981778482
Iteration 45 Loss=  0.00648662041143
Iteration 46 Loss=  0.00528197125943
Iteration 47 Loss=  0.92267770124
Iteration 48 Loss=  6667.73651133
Iteration 49 Loss=  669.460437265
Iteration 50 Loss=  1129.2462494
Iteration 51 Loss=  347.867257466
Iteration 52 Loss=  183.8104928
Iteration 53 Loss=  97.1241085165
Iteration 54 Loss=  51.3196625036
Iteration 55 Loss=  27.1169311071
Iteration 56 Loss=  14.3283863688
Iteration 57 Loss=  7.57101366387
Iteration 58 Loss=  4.00046777343
Iteration 59 Loss=  2.11381796282
Iteration 60 Loss=  1.11694363493
Iteration 61 Loss=  0.590382480937
Iteration 62 Loss=  0.311993026234
Iteration 63 Loss=  0.165210981968
Iteration 64 Loss=  0.0877411942514
Iteration 65 Loss=  0.0472453959997
Iteration 66 Loss=  0.0250257548927
Iteration 67 Loss=  0.0156918589195
Iteration 68 Loss=  6.45198621097
Iteration 69 Loss=  7823.61047964
Iteration 70 Loss=  606.895425537
Iteration 71 Loss=  329.087697845
Iteration 72 Loss=  173.887512351
Iteration 73 Loss=  91.8808977468
Iteration 74 Loss=  48.5493791467
Iteration 75 Loss=  25.6530565616
Iteration 76 Loss=  13.5550464907
Iteration 77 Loss=  7.16233411704
Iteration 78 Loss=  3.78471630003
Iteration 79 Loss=  1.99973777461
Iteration 80 Loss=  1.05680495797
Iteration 81 Loss=  0.558357858402
Iteration 82 Loss=  0.295242141169
Iteration 83 Loss=  0.156162505039
Iteration 84 Loss=  0.0837189917995
Iteration 85 Loss=  0.044199372113
Iteration 86 Loss=  0.0244661087034
Iteration 87 Loss=  0.0144407879082
Iteration 88 Loss=  0.00908623328772
Iteration 89 Loss=  0.142987213208
Iteration 90 Loss=  6006.12182616
Iteration 91 Loss=  814.995289893
Iteration 92 Loss=  537.575358162
Iteration 93 Loss=  262.527794672
Iteration 94 Loss=  138.717750167
Iteration 95 Loss=  73.297435936
Iteration 96 Loss=  38.7298244697
Iteration 97 Loss=  20.464553559
Iteration 98 Loss=  10.8133191437
Iteration 99 Loss=  5.71367807102
Iteration 100 Loss=  3.01906534575
[-0.02217615 -0.00359407 -0.00709001 ...,  0.01343098  0.00329971
 -0.00034494]
CROSS VALIDATION 10
Iteration 1 Loss=  2352.67735773
Iteration 2 Loss=  359.483425906
Iteration 3 Loss=  189.948390517
Iteration 4 Loss=  100.367328394
Iteration 5 Loss=  53.0333559634
Iteration 6 Loss=  28.0224341364
Iteration 7 Loss=  14.8068521056
Iteration 8 Loss=  7.82391441153
Iteration 9 Loss=  4.13407899335
Iteration 10 Loss=  2.18450677777
Iteration 11 Loss=  1.15425369516
Iteration 12 Loss=  0.609983515516
Iteration 13 Loss=  0.322370936663
Iteration 14 Loss=  0.170892223738
Iteration 15 Loss=  0.0903706385263
Iteration 16 Loss=  0.0485951903792
Iteration 17 Loss=  0.0263191362183
Iteration 18 Loss=  0.0155239206905
Iteration 19 Loss=  0.00896154072142
Iteration 20 Loss=  0.00632656249952
Iteration 21 Loss=  0.0049612268119
Iteration 22 Loss=  0.00558313336444
Iteration 23 Loss=  0.154661587897
Iteration 24 Loss=  1957.36730213
Iteration 25 Loss=  1334.02278084
Iteration 26 Loss=  1022.23427784
Iteration 27 Loss=  145.328928221
Iteration 28 Loss=  76.7907336524
Iteration 29 Loss=  40.5756572147
Iteration 30 Loss=  21.4398779657
Iteration 31 Loss=  11.3286733657
Iteration 32 Loss=  5.98598744041
Iteration 33 Loss=  3.16295160784
Iteration 34 Loss=  1.67128029813
Iteration 35 Loss=  0.883092233313
Iteration 36 Loss=  0.466625507441
Iteration 37 Loss=  0.246702250453
Iteration 38 Loss=  0.13110464835
Iteration 39 Loss=  0.0696826882872
Iteration 40 Loss=  0.0378836823947
Iteration 41 Loss=  0.0217370161714
Iteration 42 Loss=  0.0124813179722
Iteration 43 Loss=  0.0084078540382
Iteration 44 Loss=  0.0065387198557
Iteration 45 Loss=  0.00501131825468
Iteration 46 Loss=  0.00829012677144
Iteration 47 Loss=  0.0590879230239
Iteration 48 Loss=  6090.21299886
Iteration 49 Loss=  638.076486984
Iteration 50 Loss=  388.413052705
Iteration 51 Loss=  205.234591918
Iteration 52 Loss=  108.444444456
Iteration 53 Loss=  57.3012445093
Iteration 54 Loss=  30.2775549158
Iteration 55 Loss=  15.9984366749
Iteration 56 Loss=  8.45345592649
Iteration 57 Loss=  4.46674375461
Iteration 58 Loss=  2.36019446728
Iteration 59 Loss=  1.24711152333
Iteration 60 Loss=  0.659038982306
Iteration 61 Loss=  0.348793611734
Iteration 62 Loss=  0.184277145471
Iteration 63 Loss=  0.0981244569351
Iteration 64 Loss=  0.0518455828641
Iteration 65 Loss=  0.0292540555847
Iteration 66 Loss=  0.0160140101686
Iteration 67 Loss=  0.0110144013915
Iteration 68 Loss=  0.00666098553247
Iteration 69 Loss=  0.0231580978333
Iteration 70 Loss=  8568.15317045
Iteration 71 Loss=  2428.19257789
Iteration 72 Loss=  2052.41771217
Iteration 73 Loss=  256.443077516
Iteration 74 Loss=  177.357721108
Iteration 75 Loss=  312.76387193
Iteration 76 Loss=  134.297665276
Iteration 77 Loss=  70.9618956846
Iteration 78 Loss=  37.4957422289
Iteration 79 Loss=  19.8124736062
Iteration 80 Loss=  10.4687649067
Iteration 81 Loss=  5.53161815387
Iteration 82 Loss=  2.92286627051
Iteration 83 Loss=  1.54442525417
Iteration 84 Loss=  0.816108784245
Iteration 85 Loss=  0.431290595282
Iteration 86 Loss=  0.227920677855
Iteration 87 Loss=  0.120610295447
Iteration 88 Loss=  0.0638681120823
Iteration 89 Loss=  0.0340540760965
Iteration 90 Loss=  0.0184012152681
Iteration 91 Loss=  0.0121730084456
Iteration 92 Loss=  0.0212954965528
Iteration 93 Loss=  4313.0457798
Iteration 94 Loss=  2164.95497857
Iteration 95 Loss=  543.25260389
Iteration 96 Loss=  280.275775453
Iteration 97 Loss=  148.095652293
Iteration 98 Loss=  78.2526502434
Iteration 99 Loss=  41.3481231575
Iteration 100 Loss=  21.8480432718
[-0.03183199 -0.02717522 -0.01396514 ...,  0.02053557  0.0180777
  0.00162784]
CROSS VALIDATION 11
Iteration 1 Loss=  2352.67735773
Iteration 2 Loss=  359.483425906
Iteration 3 Loss=  189.948390517
Iteration 4 Loss=  100.367328394
Iteration 5 Loss=  53.0333559634
Iteration 6 Loss=  28.0224341364
Iteration 7 Loss=  14.8068521056
Iteration 8 Loss=  7.82391441153
Iteration 9 Loss=  4.13407899335
Iteration 10 Loss=  2.18450677777
Iteration 11 Loss=  1.15425369516
Iteration 12 Loss=  0.609983515517
Iteration 13 Loss=  0.322370937658
Iteration 14 Loss=  0.170892515425
Iteration 15 Loss=  0.090391641583
Iteration 16 Loss=  0.0488449884781
Iteration 17 Loss=  0.0263146347108
Iteration 18 Loss=  0.0154977203061
Iteration 19 Loss=  0.00885775011175
Iteration 20 Loss=  0.00644634421844
Iteration 21 Loss=  0.00478089230322
Iteration 22 Loss=  0.00568387556896
Iteration 23 Loss=  0.0155503913225
Iteration 24 Loss=  0.00553649215961
Iteration 25 Loss=  0.00611372652228
Iteration 26 Loss=  0.0158215274441
Iteration 27 Loss=  13322.7793314
Iteration 28 Loss=  5695.62421863
Iteration 29 Loss=  412.847657497
Iteration 30 Loss=  218.145656848
Iteration 31 Loss=  115.266555966
Iteration 32 Loss=  60.9060020878
Iteration 33 Loss=  32.1823960244
Iteration 34 Loss=  17.0051523802
Iteration 35 Loss=  8.9857473599
Iteration 36 Loss=  4.74806701546
Iteration 37 Loss=  2.50910286047
Iteration 38 Loss=  1.32638524795
Iteration 39 Loss=  0.701103839914
Iteration 40 Loss=  0.370995343075
Iteration 41 Loss=  0.196562604687
Iteration 42 Loss=  0.104832284688
Iteration 43 Loss=  0.0561677614403
Iteration 44 Loss=  0.0309975636273
Iteration 45 Loss=  0.0168973140748
Iteration 46 Loss=  0.0110721577983
Iteration 47 Loss=  0.00653354257346
Iteration 48 Loss=  0.00549407797863
Iteration 49 Loss=  0.0294530083888
Iteration 50 Loss=  6058.95473786
Iteration 51 Loss=  470.339736243
Iteration 52 Loss=  248.524047167
Iteration 53 Loss=  131.318273284
Iteration 54 Loss=  69.3876069334
Iteration 55 Loss=  36.6638996656
Iteration 56 Loss=  19.3729341318
Iteration 57 Loss=  10.2365154943
Iteration 58 Loss=  5.40890000053
Iteration 59 Loss=  2.8580567315
Iteration 60 Loss=  1.51053147913
Iteration 61 Loss=  0.798192082596
Iteration 62 Loss=  0.422255836749
Iteration 63 Loss=  0.223336845879
Iteration 64 Loss=  0.118786013705
Iteration 65 Loss=  0.0638244580278
Iteration 66 Loss=  0.0344410401598
Iteration 67 Loss=  0.0202152379197
Iteration 68 Loss=  0.0115841658508
Iteration 69 Loss=  0.00869165642192
Iteration 70 Loss=  0.00674724093749
Iteration 71 Loss=  0.0830404574034
Iteration 72 Loss=  6313.67696138
Iteration 73 Loss=  860.314882185
Iteration 74 Loss=  548.092998964
Iteration 75 Loss=  261.847063488
Iteration 76 Loss=  138.358056831
Iteration 77 Loss=  73.1073766304
Iteration 78 Loss=  38.6293985345
Iteration 79 Loss=  20.4114892357
Iteration 80 Loss=  10.7852803664
Iteration 81 Loss=  5.69886508878
Iteration 82 Loss=  3.01132026347
Iteration 83 Loss=  1.59172083766
Iteration 84 Loss=  0.840865629854
Iteration 85 Loss=  0.444875563178
Iteration 86 Loss=  0.234937912563
Iteration 87 Loss=  0.125129990003
Iteration 88 Loss=  0.0660706997405
Iteration 89 Loss=  0.0361629087493
Iteration 90 Loss=  0.0200115853303
Iteration 91 Loss=  0.0121846596673
Iteration 92 Loss=  0.00758185404267
Iteration 93 Loss=  0.0168730178286
Iteration 94 Loss=  9058.3072598
Iteration 95 Loss=  6241.51151673
Iteration 96 Loss=  1553.90357285
Iteration 97 Loss=  356.934222883
Iteration 98 Loss=  681.200909805
Iteration 99 Loss=  228.429969161
Iteration 100 Loss=  120.70071069
[-0.14516116 -0.02378941 -0.0185756  ...,  0.03512116  0.02909741
  0.00878345]
CROSS VALIDATION 12
Iteration 1 Loss=  2168.23911175
Iteration 2 Loss=  814.064387296
Iteration 3 Loss=  197.688253097
Iteration 4 Loss=  104.457014688
Iteration 5 Loss=  55.1943160334
Iteration 6 Loss=  29.1642694509
Iteration 7 Loss=  15.4101848475
Iteration 8 Loss=  8.14262800009
Iteration 9 Loss=  4.30250457111
Iteration 10 Loss=  2.27341167795
Iteration 11 Loss=  1.20125398161
Iteration 12 Loss=  0.634736385467
Iteration 13 Loss=  0.335454884787
Iteration 14 Loss=  0.177344245116
Iteration 15 Loss=  0.0940487578817
Iteration 16 Loss=  0.0504842933591
Iteration 17 Loss=  0.0273412588644
Iteration 18 Loss=  0.0159937679042
Iteration 19 Loss=  0.00919390467181
Iteration 20 Loss=  0.0066436422088
Iteration 21 Loss=  0.00488739575755
Iteration 22 Loss=  0.00514022296394
Iteration 23 Loss=  0.0286393873508
Iteration 24 Loss=  2012.25061657
Iteration 25 Loss=  645.529049499
Iteration 26 Loss=  234.951859168
Iteration 27 Loss=  124.146829261
Iteration 28 Loss=  65.5982688116
Iteration 29 Loss=  34.661641354
Iteration 30 Loss=  18.3149556097
Iteration 31 Loss=  9.67748744379
Iteration 32 Loss=  5.11351297926
Iteration 33 Loss=  2.70194253839
Iteration 34 Loss=  1.42768650639
Iteration 35 Loss=  0.754379019332
Iteration 36 Loss=  0.398608571058
Iteration 37 Loss=  0.210641663286
Iteration 38 Loss=  0.111564586676
Iteration 39 Loss=  0.0591086837206
Iteration 40 Loss=  0.0327975047883
Iteration 41 Loss=  0.0177356224816
Iteration 42 Loss=  0.0109046126734
Iteration 43 Loss=  0.00703323126614
Iteration 44 Loss=  0.00608785913987
Iteration 45 Loss=  0.00445727439948
Iteration 46 Loss=  0.00672755587644
Iteration 47 Loss=  3.59073429945
Iteration 48 Loss=  5885.09646348
Iteration 49 Loss=  919.88564894
Iteration 50 Loss=  308.019420663
Iteration 51 Loss=  162.755189782
Iteration 52 Loss=  85.9986435688
Iteration 53 Loss=  45.4411281698
Iteration 54 Loss=  24.0114228544
Iteration 55 Loss=  12.6871802492
Iteration 56 Loss=  6.70447314346
Iteration 57 Loss=  3.54286384983
Iteration 58 Loss=  1.87255670784
Iteration 59 Loss=  0.989719617225
Iteration 60 Loss=  0.523365404698
Iteration 61 Loss=  0.277026455335
Iteration 62 Loss=  0.14701169876
Iteration 63 Loss=  0.0782032658653
Iteration 64 Loss=  0.0425401070177
Iteration 65 Loss=  0.0234930695363
Iteration 66 Loss=  0.0139547857547
Iteration 67 Loss=  0.00902905801722
Iteration 68 Loss=  0.00710651649749
Iteration 69 Loss=  0.00532345383523
Iteration 70 Loss=  0.00554250353153
Iteration 71 Loss=  1.30409443185
Iteration 72 Loss=  6004.14662292
Iteration 73 Loss=  946.454893779
Iteration 74 Loss=  307.751308696
Iteration 75 Loss=  162.613521387
Iteration 76 Loss=  85.9237856715
Iteration 77 Loss=  45.4015251316
Iteration 78 Loss=  23.990300068
Iteration 79 Loss=  12.6763346557
Iteration 80 Loss=  6.69913312505
Iteration 81 Loss=  3.53942358451
Iteration 82 Loss=  1.87140091246
Iteration 83 Loss=  0.988376990523
Iteration 84 Loss=  0.52342857763
Iteration 85 Loss=  0.27629829078
Iteration 86 Loss=  0.147351805885
Iteration 87 Loss=  0.0779633592663
Iteration 88 Loss=  0.0424855540306
Iteration 89 Loss=  0.0236446670622
Iteration 90 Loss=  0.0137492389063
Iteration 91 Loss=  0.00930334259532
Iteration 92 Loss=  0.047811154806
Iteration 93 Loss=  8500.87280643
Iteration 94 Loss=  758.293436807
Iteration 95 Loss=  293.188835898
Iteration 96 Loss=  154.918818179
Iteration 97 Loss=  81.8579607665
Iteration 98 Loss=  43.2531426758
Iteration 99 Loss=  22.8546451039
Iteration 100 Loss=  12.0762901383
[-0.03974319 -0.02708206 -0.00993909 ...,  0.02755069  0.00588144
 -0.00110115]
CROSS VALIDATION 13
Iteration 1 Loss=  3225.97472367
Iteration 2 Loss=  455.211409245
Iteration 3 Loss=  240.530350776
Iteration 4 Loss=  127.094463077
Iteration 5 Loss=  67.1557767766
Iteration 6 Loss=  35.4846170773
Iteration 7 Loss=  18.7498106218
Iteration 8 Loss=  9.9072944334
Iteration 9 Loss=  5.23514715975
Iteration 10 Loss=  2.76612466981
Iteration 11 Loss=  1.46177211856
Iteration 12 Loss=  0.772334305183
Iteration 13 Loss=  0.408312658049
Iteration 14 Loss=  0.215804695828
Iteration 15 Loss=  0.114328029351
Iteration 16 Loss=  0.0606672302904
Iteration 17 Loss=  0.0326838144442
Iteration 18 Loss=  0.0186347404896
Iteration 19 Loss=  0.0104886923399
Iteration 20 Loss=  0.00673838797869
Iteration 21 Loss=  0.00526025839614
Iteration 22 Loss=  0.0137976936564
Iteration 23 Loss=  7660.01050583
Iteration 24 Loss=  2210.84327603
Iteration 25 Loss=  826.080134132
Iteration 26 Loss=  1702.21685744
Iteration 27 Loss=  2357.92023916
Iteration 28 Loss=  247.073469647
Iteration 29 Loss=  175.679501899
Iteration 30 Loss=  92.8277529028
Iteration 31 Loss=  49.0494998894
Iteration 32 Loss=  25.9173939277
Iteration 33 Loss=  13.6945597716
Iteration 34 Loss=  7.23610436531
Iteration 35 Loss=  3.82350416947
Iteration 36 Loss=  2.02031139912
Iteration 37 Loss=  1.06751768794
Iteration 38 Loss=  0.564073802326
Iteration 39 Loss=  0.298174979726
Iteration 40 Loss=  0.157622489493
Iteration 41 Loss=  0.0838108275663
Iteration 42 Loss=  0.0448136227591
Iteration 43 Loss=  0.0247332054829
Iteration 44 Loss=  0.0148199595029
Iteration 45 Loss=  0.0852200537786
Iteration 46 Loss=  6391.14326627
Iteration 47 Loss=  788.781679585
Iteration 48 Loss=  281.884849566
Iteration 49 Loss=  148.945827494
Iteration 50 Loss=  78.7020693594
Iteration 51 Loss=  41.585513196
Iteration 52 Loss=  21.9736339128
Iteration 53 Loss=  11.6106583864
Iteration 54 Loss=  6.13517905664
Iteration 55 Loss=  3.24170364898
Iteration 56 Loss=  1.71304778898
Iteration 57 Loss=  0.90511415135
Iteration 58 Loss=  0.478451145079
Iteration 59 Loss=  0.252835632972
Iteration 60 Loss=  0.13444994987
Iteration 61 Loss=  0.0712219239728
Iteration 62 Loss=  0.0394898550805
Iteration 63 Loss=  0.0219021599005
Iteration 64 Loss=  0.0130675875625
Iteration 65 Loss=  0.00834070820774
Iteration 66 Loss=  0.00645196732871
Iteration 67 Loss=  0.0224855691824
Iteration 68 Loss=  7575.34101183
Iteration 69 Loss=  417.171202055
Iteration 70 Loss=  2404.89426562
Iteration 71 Loss=  294.823847561
Iteration 72 Loss=  155.782746281
Iteration 73 Loss=  82.3144540028
Iteration 74 Loss=  43.4943503021
Iteration 75 Loss=  22.9820938633
Iteration 76 Loss=  12.1435688698
Iteration 77 Loss=  6.41657221372
Iteration 78 Loss=  3.39046942585
Iteration 79 Loss=  1.79149903481
Iteration 80 Loss=  0.946614878379
Iteration 81 Loss=  0.5001851343
Iteration 82 Loss=  0.26434014197
Iteration 83 Loss=  0.140326620237
Iteration 84 Loss=  0.0745880193578
Iteration 85 Loss=  0.0398775246247
Iteration 86 Loss=  0.0218526609573
Iteration 87 Loss=  0.0129186076758
Iteration 88 Loss=  0.00788912676635
Iteration 89 Loss=  0.00588720732193
Iteration 90 Loss=  0.01636106043
Iteration 91 Loss=  4859.02656297
Iteration 92 Loss=  1649.91400173
Iteration 93 Loss=  300.349525867
Iteration 94 Loss=  158.702473938
Iteration 95 Loss=  83.8572165594
Iteration 96 Loss=  44.3095346568
Iteration 97 Loss=  23.4128312631
Iteration 98 Loss=  12.3711673346
Iteration 99 Loss=  6.5368335636
Iteration 100 Loss=  3.45401463602
[-0.01933718 -0.00932689 -0.0103989  ...,  0.01411867 -0.00366328
  0.0009088 ]
CROSS VALIDATION 14
Iteration 1 Loss=  1174.46304686
Iteration 2 Loss=  327.419709025
Iteration 3 Loss=  173.006159036
Iteration 4 Loss=  91.4151782535
Iteration 5 Loss=  48.3031058646
Iteration 6 Loss=  25.5230048307
Iteration 7 Loss=  13.486167482
Iteration 8 Loss=  7.12599141669
Iteration 9 Loss=  3.7653212999
Iteration 10 Loss=  1.98956810119
Iteration 11 Loss=  1.05128087762
Iteration 12 Loss=  0.555524027942
Iteration 13 Loss=  0.293575837783
Iteration 14 Loss=  0.155242542121
Iteration 15 Loss=  0.0828241708366
Iteration 16 Loss=  0.0451139095282
Iteration 17 Loss=  0.0242739733407
Iteration 18 Loss=  0.0141982654898
Iteration 19 Loss=  0.00858039561851
Iteration 20 Loss=  0.00653233088731
Iteration 21 Loss=  0.00440750921497
Iteration 22 Loss=  0.0132829614771
Iteration 23 Loss=  9319.69894397
Iteration 24 Loss=  6949.66350149
Iteration 25 Loss=  1590.98043241
Iteration 26 Loss=  354.512296266
Iteration 27 Loss=  591.892222008
Iteration 28 Loss=  228.152914877
Iteration 29 Loss=  120.55431725
Iteration 30 Loss=  63.7000119653
Iteration 31 Loss=  33.658616439
Iteration 32 Loss=  17.7849646434
Iteration 33 Loss=  9.39744412668
Iteration 34 Loss=  4.96554015624
Iteration 35 Loss=  2.62375479022
Iteration 36 Loss=  1.38637267701
Iteration 37 Loss=  0.732549095948
Iteration 38 Loss=  0.387073539065
Iteration 39 Loss=  0.204526971422
Iteration 40 Loss=  0.108083915279
Iteration 41 Loss=  0.0573243778258
Iteration 42 Loss=  0.0310331454103
Iteration 43 Loss=  0.016987985923
Iteration 44 Loss=  0.0106620156457
Iteration 45 Loss=  0.00744598315247
Iteration 46 Loss=  0.0406936662322
Iteration 47 Loss=  7609.77331532
Iteration 48 Loss=  765.053036597
Iteration 49 Loss=  879.01236195
Iteration 50 Loss=  272.406381656
Iteration 51 Loss=  143.93752266
Iteration 52 Loss=  76.0555252175
Iteration 53 Loss=  40.1871785009
Iteration 54 Loss=  21.2346086789
Iteration 55 Loss=  11.2202105888
Iteration 56 Loss=  5.92867650915
Iteration 57 Loss=  3.13266893636
Iteration 58 Loss=  1.65527960569
Iteration 59 Loss=  0.874661864605
Iteration 60 Loss=  0.462506840027
Iteration 61 Loss=  0.244378667989
Iteration 62 Loss=  0.129678152278
Iteration 63 Loss=  0.0694421470421
Iteration 64 Loss=  0.0371493264614
Iteration 65 Loss=  0.0209171439999
Iteration 66 Loss=  0.012505003174
Iteration 67 Loss=  0.00852560653212
Iteration 68 Loss=  0.00708365399885
Iteration 69 Loss=  35.603472912
Iteration 70 Loss=  1178.42437313
Iteration 71 Loss=  331.09414621
Iteration 72 Loss=  174.94770454
Iteration 73 Loss=  92.4410765761
Iteration 74 Loss=  48.8451829707
Iteration 75 Loss=  25.809434375
Iteration 76 Loss=  13.6375147403
Iteration 77 Loss=  7.20596219157
Iteration 78 Loss=  3.80757726722
Iteration 79 Loss=  2.01189575601
Iteration 80 Loss=  1.06307309245
Iteration 81 Loss=  0.561770196308
Iteration 82 Loss=  0.296865511576
Iteration 83 Loss=  0.157045329439
Iteration 84 Loss=  0.084223588921
Iteration 85 Loss=  0.0452038729951
Iteration 86 Loss=  0.0247659432358
Iteration 87 Loss=  0.0141457829592
Iteration 88 Loss=  0.00892732252402
Iteration 89 Loss=  0.00610816368587
Iteration 90 Loss=  0.00494822535992
Iteration 91 Loss=  0.0120980882622
Iteration 92 Loss=  9620.74048217
Iteration 93 Loss=  6902.85347838
Iteration 94 Loss=  1589.83527111
Iteration 95 Loss=  357.482037486
Iteration 96 Loss=  582.505397869
Iteration 97 Loss=  228.074620744
Iteration 98 Loss=  120.512947208
Iteration 99 Loss=  63.67815234
Iteration 100 Loss=  33.6470659742
[-0.07623477 -0.01243295 -0.01002579 ...,  0.01867944  0.01577554
  0.00476253]
CROSS VALIDATION 15
Iteration 1 Loss=  1174.46304686
Iteration 2 Loss=  327.419709025
Iteration 3 Loss=  173.006159036
Iteration 4 Loss=  91.4151782535
Iteration 5 Loss=  48.3031058646
Iteration 6 Loss=  25.5230048307
Iteration 7 Loss=  13.486167482
Iteration 8 Loss=  7.12599141669
Iteration 9 Loss=  3.7653212999
Iteration 10 Loss=  1.98956810359
Iteration 11 Loss=  1.05128142134
Iteration 12 Loss=  0.555551877017
Iteration 13 Loss=  0.293810943066
Iteration 14 Loss=  0.155262821176
Iteration 15 Loss=  0.0828877984628
Iteration 16 Loss=  0.0450402363885
Iteration 17 Loss=  0.0244303452028
Iteration 18 Loss=  0.0140492870422
Iteration 19 Loss=  0.00872720445385
Iteration 20 Loss=  0.00643473988311
Iteration 21 Loss=  0.00453982026111
Iteration 22 Loss=  0.0109415157596
Iteration 23 Loss=  9653.60321341
Iteration 24 Loss=  6111.80230959
Iteration 25 Loss=  1592.63943013
Iteration 26 Loss=  356.490248155
Iteration 27 Loss=  700.774730081
Iteration 28 Loss=  227.867939957
Iteration 29 Loss=  120.403738604
Iteration 30 Loss=  63.6204473196
Iteration 31 Loss=  33.6165750671
Iteration 32 Loss=  17.7627502926
Iteration 33 Loss=  9.3857062276
Iteration 34 Loss=  4.95933793695
Iteration 35 Loss=  2.6204775833
Iteration 36 Loss=  1.38464102505
Iteration 37 Loss=  0.731634103897
Iteration 38 Loss=  0.386590106576
Iteration 39 Loss=  0.204275889619
Iteration 40 Loss=  0.10805872697
Iteration 41 Loss=  0.0573516294901
Iteration 42 Loss=  0.0311475087417
Iteration 43 Loss=  0.0168961045897
Iteration 44 Loss=  0.0107096417614
Iteration 45 Loss=  0.00780895295106
Iteration 46 Loss=  0.117808935853
Iteration 47 Loss=  10316.1419987
Iteration 48 Loss=  2597.4222534
Iteration 49 Loss=  555.804220336
Iteration 50 Loss=  294.985199296
Iteration 51 Loss=  155.868003348
Iteration 52 Loss=  82.359503208
Iteration 53 Loss=  43.5181539698
Iteration 54 Loss=  22.9946715457
Iteration 55 Loss=  12.1502148244
Iteration 56 Loss=  6.42008388711
Iteration 57 Loss=  3.39232496819
Iteration 58 Loss=  1.79247950838
Iteration 59 Loss=  0.947135382861
Iteration 60 Loss=  0.500527434157
Iteration 61 Loss=  0.264540704628
Iteration 62 Loss=  0.139852525332
Iteration 63 Loss=  0.07408912804
Iteration 64 Loss=  0.0393673455082
Iteration 65 Loss=  0.0219762091065
Iteration 66 Loss=  0.0125847732691
Iteration 67 Loss=  0.00849142267996
Iteration 68 Loss=  0.00646445661573
Iteration 69 Loss=  11251.5849126
Iteration 70 Loss=  4061.66176116
Iteration 71 Loss=  3521.58718771
Iteration 72 Loss=  390.33437198
Iteration 73 Loss=  206.249802851
Iteration 74 Loss=  108.980874424
Iteration 75 Loss=  57.5846901474
Iteration 76 Loss=  30.4273255001
Iteration 77 Loss=  16.0775743469
Iteration 78 Loss=  8.49527168865
Iteration 79 Loss=  4.48883892246
Iteration 80 Loss=  2.37187256446
Iteration 81 Loss=  1.25337719377
Iteration 82 Loss=  0.66284201171
Iteration 83 Loss=  0.350041247286
Iteration 84 Loss=  0.18555005244
Iteration 85 Loss=  0.0980987993188
Iteration 86 Loss=  0.0525549559928
Iteration 87 Loss=  0.0283200339428
Iteration 88 Loss=  0.0162449429391
Iteration 89 Loss=  0.00989806912372
Iteration 90 Loss=  0.00722699389828
Iteration 91 Loss=  0.0179720431983
Iteration 92 Loss=  5020.79256534
Iteration 93 Loss=  2262.68991317
Iteration 94 Loss=  438.08348626
Iteration 95 Loss=  231.480082615
Iteration 96 Loss=  122.31236814
Iteration 97 Loss=  64.6289530871
Iteration 98 Loss=  34.1494620754
Iteration 99 Loss=  18.044323857
Iteration 100 Loss=  9.53448762197
[-0.01252497 -0.00223873 -0.00778058 ...,  0.01374412  0.01065941
  0.00239757]
CROSS VALIDATION 16
Iteration 1 Loss=  2822.86218467
Iteration 2 Loss=  332.021734113
Iteration 3 Loss=  175.437835145
Iteration 4 Loss=  92.7000579725
Iteration 5 Loss=  48.9820268302
Iteration 6 Loss=  25.881741663
Iteration 7 Loss=  13.6757218733
Iteration 8 Loss=  7.22617611284
Iteration 9 Loss=  3.81850058517
Iteration 10 Loss=  2.01756389314
Iteration 11 Loss=  1.06627256789
Iteration 12 Loss=  0.563347077676
Iteration 13 Loss=  0.297946701068
Iteration 14 Loss=  0.157625443079
Iteration 15 Loss=  0.0839221880582
Iteration 16 Loss=  0.0450532356655
Iteration 17 Loss=  0.0250191403057
Iteration 18 Loss=  0.0139851621187
Iteration 19 Loss=  0.00910962827578
Iteration 20 Loss=  0.00593142690452
Iteration 21 Loss=  0.00545195270355
Iteration 22 Loss=  0.00763204603341
Iteration 23 Loss=  9430.15141979
Iteration 24 Loss=  6184.51525142
Iteration 25 Loss=  1775.48101697
Iteration 26 Loss=  198.583215289
Iteration 27 Loss=  104.929906114
Iteration 28 Loss=  55.4441894255
Iteration 29 Loss=  29.2963412919
Iteration 30 Loss=  15.4800175805
Iteration 31 Loss=  8.17953494605
Iteration 32 Loss=  4.32207957503
Iteration 33 Loss=  2.28373736332
Iteration 34 Loss=  1.2068231804
Iteration 35 Loss=  0.637657615601
Iteration 36 Loss=  0.33724857096
Iteration 37 Loss=  0.178166678374
Iteration 38 Loss=  0.0946745537807
Iteration 39 Loss=  0.0504014778981
Iteration 40 Loss=  0.0275776289392
Iteration 41 Loss=  0.0156967728614
Iteration 42 Loss=  0.0102360819809
Iteration 43 Loss=  0.00658982620682
Iteration 44 Loss=  0.00567449433158
Iteration 45 Loss=  0.0049964652466
Iteration 46 Loss=  0.0194420080827
Iteration 47 Loss=  4228.40593747
Iteration 48 Loss=  652.72408956
Iteration 49 Loss=  632.92742567
Iteration 50 Loss=  250.346130824
Iteration 51 Loss=  132.281048848
Iteration 52 Loss=  69.8963304393
Iteration 53 Loss=  36.9327054135
Iteration 54 Loss=  19.5149691062
Iteration 55 Loss=  10.3115657234
Iteration 56 Loss=  5.44855526543
Iteration 57 Loss=  2.87897658216
Iteration 58 Loss=  1.52124196823
Iteration 59 Loss=  0.804049312101
Iteration 60 Loss=  0.425212735326
Iteration 61 Loss=  0.224787350234
Iteration 62 Loss=  0.119216996734
Iteration 63 Loss=  0.0631884415081
Iteration 64 Loss=  0.0343327076005
Iteration 65 Loss=  0.0186603439589
Iteration 66 Loss=  0.0115050108392
Iteration 67 Loss=  0.00722871608936
Iteration 68 Loss=  0.0073657473426
Iteration 69 Loss=  0.00487955092547
Iteration 70 Loss=  0.00718302621278
Iteration 71 Loss=  0.00754616790752
Iteration 72 Loss=  0.0050200836233
Iteration 73 Loss=  0.006081403996
Iteration 74 Loss=  0.00455665709669
Iteration 75 Loss=  0.00563197852957
Iteration 76 Loss=  0.00796726115287
Iteration 77 Loss=  0.0151445104711
Iteration 78 Loss=  10129.8617142
Iteration 79 Loss=  764.87772837
Iteration 80 Loss=  522.119894403
Iteration 81 Loss=  211.976237931
Iteration 82 Loss=  112.006680479
Iteration 83 Loss=  59.1835037471
Iteration 84 Loss=  31.2721268125
Iteration 85 Loss=  16.5239611287
Iteration 86 Loss=  8.73113917133
Iteration 87 Loss=  4.61346953284
Iteration 88 Loss=  2.4377232718
Iteration 89 Loss=  1.28807550581
Iteration 90 Loss=  0.680634833054
Iteration 91 Loss=  0.359766566207
Iteration 92 Loss=  0.190209626267
Iteration 93 Loss=  0.100921682329
Iteration 94 Loss=  0.0536489325732
Iteration 95 Loss=  0.029330807806
Iteration 96 Loss=  0.0165458708588
Iteration 97 Loss=  0.010321548624
Iteration 98 Loss=  0.00721776112918
Iteration 99 Loss=  0.00471094763682
Iteration 100 Loss=  0.00570535252015
[ -3.60137597e-04  -2.50956262e-04   2.56253591e-05 ...,   1.99969970e-04
   1.60411151e-04   2.49479293e-05]
CROSS VALIDATION 17
Iteration 1 Loss=  1175.20205303
Iteration 2 Loss=  327.515279909
Iteration 3 Loss=  173.056657985
Iteration 4 Loss=  91.4418615262
Iteration 5 Loss=  48.317205109
Iteration 6 Loss=  25.5304547675
Iteration 7 Loss=  13.4901039736
Iteration 8 Loss=  7.12807142983
Iteration 9 Loss=  3.76642036346
Iteration 10 Loss=  1.99014882653
Iteration 11 Loss=  1.05158754372
Iteration 12 Loss=  0.555715955512
Iteration 13 Loss=  0.293897259103
Iteration 14 Loss=  0.155314416841
Iteration 15 Loss=  0.0830159140602
Iteration 16 Loss=  0.0451460040251
Iteration 17 Loss=  0.0244746010056
Iteration 18 Loss=  0.0141736613554
Iteration 19 Loss=  0.00872193783915
Iteration 20 Loss=  0.00650822368591
Iteration 21 Loss=  0.00458821548741
Iteration 22 Loss=  0.0116168138491
Iteration 23 Loss=  9621.85881319
Iteration 24 Loss=  6917.69074936
Iteration 25 Loss=  1594.19491633
Iteration 26 Loss=  354.900251094
Iteration 27 Loss=  692.446289657
Iteration 28 Loss=  228.147086346
Iteration 29 Loss=  120.551237497
Iteration 30 Loss=  63.6983846464
Iteration 31 Loss=  33.6577565757
Iteration 32 Loss=  17.784510298
Iteration 33 Loss=  9.39720405392
Iteration 34 Loss=  4.96541330356
Iteration 35 Loss=  2.62368776221
Iteration 36 Loss=  1.3863372599
Iteration 37 Loss=  0.73253038189
Iteration 38 Loss=  0.387063697295
Iteration 39 Loss=  0.20452643137
Iteration 40 Loss=  0.108195516673
Iteration 41 Loss=  0.0574176630783
Iteration 42 Loss=  0.0312129520107
Iteration 43 Loss=  0.0170190915492
Iteration 44 Loss=  0.0108085943807
Iteration 45 Loss=  0.00774964338689
Iteration 46 Loss=  0.245059734388
Iteration 47 Loss=  5508.60756878
Iteration 48 Loss=  788.012313483
Iteration 49 Loss=  346.262131535
Iteration 50 Loss=  601.459010848
Iteration 51 Loss=  193.589476798
Iteration 52 Loss=  102.291251526
Iteration 53 Loss=  54.0499427545
Iteration 54 Loss=  28.5595910518
Iteration 55 Loss=  15.0906772418
Iteration 56 Loss=  7.9738025381
Iteration 57 Loss=  4.21329844233
Iteration 58 Loss=  2.22627581751
Iteration 59 Loss=  1.17634771984
Iteration 60 Loss=  0.621573466748
Iteration 61 Loss=  0.328436397663
Iteration 62 Loss=  0.173607602415
Iteration 63 Loss=  0.0920032842212
Iteration 64 Loss=  0.048728031407
Iteration 65 Loss=  0.0263284923914
Iteration 66 Loss=  0.0152606106707
Iteration 67 Loss=  0.00982386198518
Iteration 68 Loss=  0.00778041478989
Iteration 69 Loss=  0.33169176451
Iteration 70 Loss=  2184.97413287
Iteration 71 Loss=  449.790609182
Iteration 72 Loss=  390.736781778
Iteration 73 Loss=  656.851865036
Iteration 74 Loss=  149.871244477
Iteration 75 Loss=  79.1908600558
Iteration 76 Loss=  41.8438663017
Iteration 77 Loss=  22.1099902924
Iteration 78 Loss=  11.6827558361
Iteration 79 Loss=  6.17308760357
Iteration 80 Loss=  3.26193749171
Iteration 81 Loss=  1.72357887823
Iteration 82 Loss=  0.910878736177
Iteration 83 Loss=  0.481244023094
Iteration 84 Loss=  0.25451774886
Iteration 85 Loss=  0.134866578044
Iteration 86 Loss=  0.0716787966695
Iteration 87 Loss=  0.0383112107922
Iteration 88 Loss=  0.021062842016
Iteration 89 Loss=  0.0127842216968
Iteration 90 Loss=  0.00800625069214
Iteration 91 Loss=  0.00636963219888
Iteration 92 Loss=  0.00491852508304
Iteration 93 Loss=  0.00988517599281
Iteration 94 Loss=  10.5962372718
Iteration 95 Loss=  3685.18250269
Iteration 96 Loss=  1770.78574726
Iteration 97 Loss=  1353.75733137
Iteration 98 Loss=  485.758614782
Iteration 99 Loss=  366.620996704
Iteration 100 Loss=  373.378841418
[-0.11291162 -0.02567967  0.03206852 ...,  0.06470009  0.00052789
 -0.00339968]
CROSS VALIDATION 18
Iteration 1 Loss=  3624.85791083
Iteration 2 Loss=  1780.76163774
Iteration 3 Loss=  189.874779428
Iteration 4 Loss=  100.328432838
Iteration 5 Loss=  53.0128038381
Iteration 6 Loss=  28.0115744988
Iteration 7 Loss=  14.8011093377
Iteration 8 Loss=  7.82079699355
Iteration 9 Loss=  4.13245144125
Iteration 10 Loss=  2.18355686613
Iteration 11 Loss=  1.1537767286
Iteration 12 Loss=  0.609691238845
Iteration 13 Loss=  0.322217033981
Iteration 14 Loss=  0.170315292586
Iteration 15 Loss=  0.0903603497834
Iteration 16 Loss=  0.0485222933041
Iteration 17 Loss=  0.0263921612936
Iteration 18 Loss=  0.0149749253838
Iteration 19 Loss=  0.00901335717449
Iteration 20 Loss=  0.00638059620505
Iteration 21 Loss=  0.00478557304002
Iteration 22 Loss=  0.00503777776321
Iteration 23 Loss=  0.0207895104856
Iteration 24 Loss=  5421.25476699
Iteration 25 Loss=  1966.93870168
Iteration 26 Loss=  477.824306283
Iteration 27 Loss=  722.925573828
Iteration 28 Loss=  142.7985389
Iteration 29 Loss=  75.4536946005
Iteration 30 Loss=  39.8691756495
Iteration 31 Loss=  21.0665795179
Iteration 32 Loss=  11.131462151
Iteration 33 Loss=  5.88178533997
Iteration 34 Loss=  3.1079462935
Iteration 35 Loss=  1.6422126144
Iteration 36 Loss=  0.867798714989
Iteration 37 Loss=  0.458544930384
Iteration 38 Loss=  0.24236022036
Iteration 39 Loss=  0.12812702475
Iteration 40 Loss=  0.0681864443624
Iteration 41 Loss=  0.0361004623713
Iteration 42 Loss=  0.0202429714411
Iteration 43 Loss=  0.0117671541695
Iteration 44 Loss=  0.00777850780138
Iteration 45 Loss=  0.00535256625722
Iteration 46 Loss=  0.00959634557442
Iteration 47 Loss=  0.00636276923157
Iteration 48 Loss=  0.00368481151321
Iteration 49 Loss=  0.00566598090065
Iteration 50 Loss=  0.0058629885725
Iteration 51 Loss=  0.00468529449481
Iteration 52 Loss=  0.00523227773648
Iteration 53 Loss=  0.21677572334
Iteration 54 Loss=  694.722238727
Iteration 55 Loss=  1791.66478628
Iteration 56 Loss=  251.197710046
Iteration 57 Loss=  132.731017792
Iteration 58 Loss=  70.1341173432
Iteration 59 Loss=  37.0583561736
Iteration 60 Loss=  19.5814028211
Iteration 61 Loss=  10.3466805739
Iteration 62 Loss=  5.46733381339
Iteration 63 Loss=  2.88899426003
Iteration 64 Loss=  1.52692224561
Iteration 65 Loss=  0.806743118376
Iteration 66 Loss=  0.426750824969
Iteration 67 Loss=  0.225401524641
Iteration 68 Loss=  0.119829505177
Iteration 69 Loss=  0.0632196163739
Iteration 70 Loss=  0.034631069689
Iteration 71 Loss=  0.0183844545514
Iteration 72 Loss=  0.012225225425
Iteration 73 Loss=  0.0074998242091
Iteration 74 Loss=  0.00590747999987
Iteration 75 Loss=  0.00450217751457
Iteration 76 Loss=  0.0488468689613
Iteration 77 Loss=  5437.94338198
Iteration 78 Loss=  1973.95424639
Iteration 79 Loss=  489.015983383
Iteration 80 Loss=  727.927449137
Iteration 81 Loss=  144.293807246
Iteration 82 Loss=  76.243783365
Iteration 83 Loss=  40.2866527174
Iteration 84 Loss=  21.2871701215
Iteration 85 Loss=  11.2479838143
Iteration 86 Loss=  5.9433619094
Iteration 87 Loss=  3.14047434816
Iteration 88 Loss=  1.65940185784
Iteration 89 Loss=  0.876873245807
Iteration 90 Loss=  0.463359043428
Iteration 91 Loss=  0.244871515259
Iteration 92 Loss=  0.129464224022
Iteration 93 Loss=  0.0688293541123
Iteration 94 Loss=  0.0365125812632
Iteration 95 Loss=  0.0203959001471
Iteration 96 Loss=  0.0119180652901
Iteration 97 Loss=  0.00779266864989
Iteration 98 Loss=  0.00537770730642
Iteration 99 Loss=  0.00979589412456
Iteration 100 Loss=  0.00651693750731
[ -4.29213736e-04  -3.48301802e-04  -3.64524620e-05 ...,   2.78892280e-04
   1.51108556e-04   5.20268929e-05]
CROSS VALIDATION 19
Iteration 1 Loss=  3399.80879477
Iteration 2 Loss=  363.60297359
Iteration 3 Loss=  192.125129126
Iteration 4 Loss=  101.517501018
Iteration 5 Loss=  53.6410986936
Iteration 6 Loss=  28.3435608658
Iteration 7 Loss=  14.9765284907
Iteration 8 Loss=  7.91348817984
Iteration 9 Loss=  4.18147131543
Iteration 10 Loss=  2.20982161371
Iteration 11 Loss=  1.16758376971
Iteration 12 Loss=  0.617483081337
Iteration 13 Loss=  0.326126862591
Iteration 14 Loss=  0.173149365682
Iteration 15 Loss=  0.0916419146681
Iteration 16 Loss=  0.0494190678954
Iteration 17 Loss=  0.0266659525132
Iteration 18 Loss=  0.0153945636205
Iteration 19 Loss=  0.0091194121085
Iteration 20 Loss=  0.00626527712933
Iteration 21 Loss=  0.00567999284513
Iteration 22 Loss=  0.00659961446815
Iteration 23 Loss=  0.0212178546968
Iteration 24 Loss=  1.4591858743
Iteration 25 Loss=  2588.72623316
Iteration 26 Loss=  1744.74781185
Iteration 27 Loss=  319.022608736
Iteration 28 Loss=  168.569193184
Iteration 29 Loss=  89.0707182269
Iteration 30 Loss=  47.0643104804
Iteration 31 Loss=  24.8684344877
Iteration 32 Loss=  13.1402973412
Iteration 33 Loss=  6.9432361856
Iteration 34 Loss=  3.66875478365
Iteration 35 Loss=  1.93854296552
Iteration 36 Loss=  1.02431196417
Iteration 37 Loss=  0.541251559631
Iteration 38 Loss=  0.286291846614
Iteration 39 Loss=  0.152296025834
Iteration 40 Loss=  0.080410471384
Iteration 41 Loss=  0.0438173470801
Iteration 42 Loss=  0.0238255393853
Iteration 43 Loss=  0.0140165999907
Iteration 44 Loss=  0.0091453291726
Iteration 45 Loss=  0.00655158450318
Iteration 46 Loss=  0.00936801409813
Iteration 47 Loss=  6728.73648766
Iteration 48 Loss=  1165.86800241
Iteration 49 Loss=  2281.92906771
Iteration 50 Loss=  240.164465064
Iteration 51 Loss=  126.901131765
Iteration 52 Loss=  67.0536219378
Iteration 53 Loss=  35.4306392106
Iteration 54 Loss=  18.7212884046
Iteration 55 Loss=  9.89219069528
Iteration 56 Loss=  5.22696059359
Iteration 57 Loss=  2.76188742243
Iteration 58 Loss=  1.45936132276
Iteration 59 Loss=  0.771136890606
Iteration 60 Loss=  0.407662776885
Iteration 61 Loss=  0.215324112139
Iteration 62 Loss=  0.113991245212
Iteration 63 Loss=  0.060590946389
Iteration 64 Loss=  0.0327156283826
Iteration 65 Loss=  0.018257643822
Iteration 66 Loss=  0.0111202567223
Iteration 67 Loss=  0.00653494771582
Iteration 68 Loss=  0.00532917314561
Iteration 69 Loss=  0.00424937799447
Iteration 70 Loss=  0.00613146288727
Iteration 71 Loss=  0.00981158000633
Iteration 72 Loss=  0.00446994422766
Iteration 73 Loss=  0.00591509964472
Iteration 74 Loss=  0.102885463762
Iteration 75 Loss=  6419.32779545
Iteration 76 Loss=  792.669337442
Iteration 77 Loss=  282.779233281
Iteration 78 Loss=  149.418460943
Iteration 79 Loss=  78.9516125762
Iteration 80 Loss=  41.7174496983
Iteration 81 Loss=  22.0431926916
Iteration 82 Loss=  11.6474604165
Iteration 83 Loss=  6.15443216652
Iteration 84 Loss=  3.25195655859
Iteration 85 Loss=  1.71830985753
Iteration 86 Loss=  0.907942286147
Iteration 87 Loss=  0.47975411115
Iteration 88 Loss=  0.253627057691
Iteration 89 Loss=  0.13471498469
Iteration 90 Loss=  0.071427170839
Iteration 91 Loss=  0.0393920032588
Iteration 92 Loss=  0.0217057085896
Iteration 93 Loss=  0.0132980297964
Iteration 94 Loss=  0.00822976435516
Iteration 95 Loss=  0.00721679402466
Iteration 96 Loss=  0.0257620112298
Iteration 97 Loss=  8150.73742884
Iteration 98 Loss=  623.406282453
Iteration 99 Loss=  634.105367614
Iteration 100 Loss=  241.585542528
[-0.2014116  -0.08972946 -0.11985976 ...,  0.05023792  0.03406926
 -0.00580678]
Accuracy (Logistic Loss):	0.75 for lmda= 0.3 learning rate= 0.01
---------------------------------------------------------------------------------
lmda= 0.3 learning rate= 0.1
CROSS VALIDATION 0
Iteration 1 Loss=  43056.7971149
Iteration 2 Loss=  31344.9434271
Iteration 3 Loss=  36930.2880628
Iteration 4 Loss=  87217.9530487
Iteration 5 Loss=  43040.9175845
Iteration 6 Loss=  33949.3007208
Iteration 7 Loss=  50950.871925
Iteration 8 Loss=  17133.9968481
Iteration 9 Loss=  48052.2124451
Iteration 10 Loss=  54517.7242319
Iteration 11 Loss=  43739.3675392
Iteration 12 Loss=  26697.3300633
Iteration 13 Loss=  62577.8772594
Iteration 14 Loss=  32785.5685223
Iteration 15 Loss=  46168.031546
Iteration 16 Loss=  40976.0857717
Iteration 17 Loss=  31981.2083087
Iteration 18 Loss=  45279.3802869
Iteration 19 Loss=  28090.4663413
Iteration 20 Loss=  33298.0771694
Iteration 21 Loss=  62891.848983
Iteration 22 Loss=  30320.6958931
Iteration 23 Loss=  58433.5717967
Iteration 24 Loss=  43976.068659
Iteration 25 Loss=  61386.6423798
Iteration 26 Loss=  58271.5998171
Iteration 27 Loss=  64875.7200716
Iteration 28 Loss=  40463.0171058
Iteration 29 Loss=  65239.3017806
Iteration 30 Loss=  59753.1109175
Iteration 31 Loss=  31852.2607608
Iteration 32 Loss=  28812.0833585
Iteration 33 Loss=  35656.6552388
Iteration 34 Loss=  52223.7227711
Iteration 35 Loss=  51310.7649085
Iteration 36 Loss=  34203.2426227
Iteration 37 Loss=  78456.3969905
Iteration 38 Loss=  43654.5547849
Iteration 39 Loss=  31105.6744292
Iteration 40 Loss=  59809.7931494
Iteration 41 Loss=  32931.5747978
Iteration 42 Loss=  55186.999915
Iteration 43 Loss=  31829.9551435
Iteration 44 Loss=  40844.3500269
Iteration 45 Loss=  22388.9384467
Iteration 46 Loss=  71546.8812621
Iteration 47 Loss=  49011.7886527
Iteration 48 Loss=  40605.3240189
Iteration 49 Loss=  72592.7094586
Iteration 50 Loss=  47186.3888591
Iteration 51 Loss=  29834.6803886
Iteration 52 Loss=  42537.7413312
Iteration 53 Loss=  50620.7712219
Iteration 54 Loss=  23183.7695103
Iteration 55 Loss=  54067.6368953
Iteration 56 Loss=  23469.6811815
Iteration 57 Loss=  46848.6392419
Iteration 58 Loss=  28913.6458162
Iteration 59 Loss=  37828.9589828
Iteration 60 Loss=  64293.5616579
Iteration 61 Loss=  33854.982659
Iteration 62 Loss=  35338.0606157
Iteration 63 Loss=  29117.9002473
Iteration 64 Loss=  57341.8136517
Iteration 65 Loss=  48824.3062977
Iteration 66 Loss=  71650.5043123
Iteration 67 Loss=  55029.0185939
Iteration 68 Loss=  34405.7978173
Iteration 69 Loss=  50031.0000559
Iteration 70 Loss=  62773.4261725
Iteration 71 Loss=  61473.5241144
Iteration 72 Loss=  20528.434599
Iteration 73 Loss=  46314.9136989
Iteration 74 Loss=  53090.3322787
Iteration 75 Loss=  35869.3329438
Iteration 76 Loss=  54611.358977
Iteration 77 Loss=  35446.5053534
Iteration 78 Loss=  54613.9740969
Iteration 79 Loss=  35445.9066969
Iteration 80 Loss=  54613.9777958
Iteration 81 Loss=  35445.9058484
Iteration 82 Loss=  54613.977801
Iteration 83 Loss=  35445.9058472
Iteration 84 Loss=  54613.977801
Iteration 85 Loss=  35445.9058472
Iteration 86 Loss=  54613.977801
Iteration 87 Loss=  35445.9058472
Iteration 88 Loss=  54613.977801
Iteration 89 Loss=  35445.9058472
Iteration 90 Loss=  54613.977801
Iteration 91 Loss=  35445.9058472
Iteration 92 Loss=  54613.977801
Iteration 93 Loss=  35445.9058472
Iteration 94 Loss=  54613.977801
Iteration 95 Loss=  35445.9058472
Iteration 96 Loss=  54613.977801
Iteration 97 Loss=  35445.9058472
Iteration 98 Loss=  54613.977801
Iteration 99 Loss=  35445.9058472
Iteration 100 Loss=  54613.977801
[-0.30502843 -0.77501482 -0.25613441 ...,  0.43836455 -0.46571712
 -0.04239405]
CROSS VALIDATION 1
Iteration 1 Loss=  36871.4767571
Iteration 2 Loss=  88943.6171817
Iteration 3 Loss=  38699.8862825
Iteration 4 Loss=  86056.1584276
Iteration 5 Loss=  38593.904048
Iteration 6 Loss=  86057.7948592
Iteration 7 Loss=  38593.7548132
Iteration 8 Loss=  86057.7971804
Iteration 9 Loss=  38593.7546017
Iteration 10 Loss=  86057.7971837
Iteration 11 Loss=  38593.7546014
Iteration 12 Loss=  86057.7971837
Iteration 13 Loss=  38593.7546014
Iteration 14 Loss=  86057.7971837
Iteration 15 Loss=  38593.7546014
Iteration 16 Loss=  86057.7971837
Iteration 17 Loss=  38593.7546014
Iteration 18 Loss=  86057.7971837
Iteration 19 Loss=  38593.7546014
Iteration 20 Loss=  86057.7971837
Iteration 21 Loss=  38593.7546014
Iteration 22 Loss=  86057.7971837
Iteration 23 Loss=  38593.7546014
Iteration 24 Loss=  86057.7971837
Iteration 25 Loss=  38593.7546014
Iteration 26 Loss=  86057.7971837
Iteration 27 Loss=  38593.7546014
Iteration 28 Loss=  86057.7971837
Iteration 29 Loss=  38593.7546014
Iteration 30 Loss=  86057.7971837
Iteration 31 Loss=  38593.7546014
Iteration 32 Loss=  86057.7971837
Iteration 33 Loss=  38593.7546014
Iteration 34 Loss=  86057.7971837
Iteration 35 Loss=  38593.7546014
Iteration 36 Loss=  86057.7971837
Iteration 37 Loss=  38593.7546014
Iteration 38 Loss=  86057.7971837
Iteration 39 Loss=  38593.7546014
Iteration 40 Loss=  86057.7971837
Iteration 41 Loss=  38593.7546014
Iteration 42 Loss=  86057.7971837
Iteration 43 Loss=  38593.7546014
Iteration 44 Loss=  86057.7971837
Iteration 45 Loss=  38593.7546014
Iteration 46 Loss=  86057.7971837
Iteration 47 Loss=  38593.7546014
Iteration 48 Loss=  86057.7971837
Iteration 49 Loss=  38593.7546014
Iteration 50 Loss=  86057.7971837
Iteration 51 Loss=  38593.7546014
Iteration 52 Loss=  86057.7971837
Iteration 53 Loss=  38593.7546014
Iteration 54 Loss=  86057.7971837
Iteration 55 Loss=  38593.7546014
Iteration 56 Loss=  86057.7971837
Iteration 57 Loss=  38593.7546014
Iteration 58 Loss=  86057.7971837
Iteration 59 Loss=  38593.7546014
Iteration 60 Loss=  86057.7971837
Iteration 61 Loss=  38593.7546014
Iteration 62 Loss=  86057.7971837
Iteration 63 Loss=  38593.7546014
Iteration 64 Loss=  86057.7971837
Iteration 65 Loss=  38593.7546014
Iteration 66 Loss=  86057.7971837
Iteration 67 Loss=  38593.7546014
Iteration 68 Loss=  86057.7971837
Iteration 69 Loss=  38593.7546014
Iteration 70 Loss=  86057.7971837
Iteration 71 Loss=  38593.7546014
Iteration 72 Loss=  86057.7971837
Iteration 73 Loss=  38593.7546014
Iteration 74 Loss=  86057.7971837
Iteration 75 Loss=  38593.7546014
Iteration 76 Loss=  86057.7971837
Iteration 77 Loss=  38593.7546014
Iteration 78 Loss=  86057.7971837
Iteration 79 Loss=  38593.7546014
Iteration 80 Loss=  86057.7971837
Iteration 81 Loss=  38593.7546014
Iteration 82 Loss=  86057.7971837
Iteration 83 Loss=  38593.7546014
Iteration 84 Loss=  86057.7971837
Iteration 85 Loss=  38593.7546014
Iteration 86 Loss=  86057.7971837
Iteration 87 Loss=  38593.7546014
Iteration 88 Loss=  86057.7971837
Iteration 89 Loss=  38593.7546014
Iteration 90 Loss=  86057.7971837
Iteration 91 Loss=  38593.7546014
Iteration 92 Loss=  86057.7971837
Iteration 93 Loss=  38593.7546014
Iteration 94 Loss=  86057.7971837
Iteration 95 Loss=  38593.7546014
Iteration 96 Loss=  86057.7971837
Iteration 97 Loss=  38593.7546014
Iteration 98 Loss=  86057.7971837
Iteration 99 Loss=  38593.7546014
Iteration 100 Loss=  86057.7971837
[-0.52259015  0.03582248  0.21315283 ...,  0.34155618  0.49757702
  0.25795078]
CROSS VALIDATION 2
Iteration 1 Loss=  33565.9102094
Iteration 2 Loss=  36214.6297239
Iteration 3 Loss=  37298.8178232
Iteration 4 Loss=  29975.5949252
Iteration 5 Loss=  44159.4517017
Iteration 6 Loss=  26637.8591116
Iteration 7 Loss=  35681.0926817
Iteration 8 Loss=  31084.3881952
Iteration 9 Loss=  27512.2991611
Iteration 10 Loss=  44481.9464037
Iteration 11 Loss=  56323.9222228
Iteration 12 Loss=  52083.2622105
Iteration 13 Loss=  38185.4597925
Iteration 14 Loss=  59717.580221
Iteration 15 Loss=  57541.4878531
Iteration 16 Loss=  63051.6677947
Iteration 17 Loss=  37486.774729
Iteration 18 Loss=  34041.7001667
Iteration 19 Loss=  56388.7030101
Iteration 20 Loss=  9250.1427064
Iteration 21 Loss=  51546.5777888
Iteration 22 Loss=  20056.2009117
Iteration 23 Loss=  41212.5287114
Iteration 24 Loss=  31023.8154108
Iteration 25 Loss=  27514.768545
Iteration 26 Loss=  44482.0792912
Iteration 27 Loss=  56323.9270672
Iteration 28 Loss=  52083.262396
Iteration 29 Loss=  38185.4597996
Iteration 30 Loss=  59717.5802214
Iteration 31 Loss=  57541.4878531
Iteration 32 Loss=  63051.6677947
Iteration 33 Loss=  37486.774729
Iteration 34 Loss=  34041.7001667
Iteration 35 Loss=  56388.7030101
Iteration 36 Loss=  9250.1427064
Iteration 37 Loss=  51546.5777888
Iteration 38 Loss=  20056.2009117
Iteration 39 Loss=  41212.5287114
Iteration 40 Loss=  31023.8154108
Iteration 41 Loss=  27514.768545
Iteration 42 Loss=  44482.0792912
Iteration 43 Loss=  56323.9270672
Iteration 44 Loss=  52083.262396
Iteration 45 Loss=  38185.4597996
Iteration 46 Loss=  59717.5802214
Iteration 47 Loss=  57541.4878531
Iteration 48 Loss=  63051.6677947
Iteration 49 Loss=  37486.774729
Iteration 50 Loss=  34041.7001667
Iteration 51 Loss=  56388.7030101
Iteration 52 Loss=  9250.1427064
Iteration 53 Loss=  51546.5777888
Iteration 54 Loss=  20056.2009117
Iteration 55 Loss=  41212.5287114
Iteration 56 Loss=  31023.8154108
Iteration 57 Loss=  27514.768545
Iteration 58 Loss=  44482.0792912
Iteration 59 Loss=  56323.9270672
Iteration 60 Loss=  52083.262396
Iteration 61 Loss=  38185.4597996
Iteration 62 Loss=  59717.5802214
Iteration 63 Loss=  57541.4878531
Iteration 64 Loss=  63051.6677947
Iteration 65 Loss=  37486.774729
Iteration 66 Loss=  34041.7001667
Iteration 67 Loss=  56388.7030101
Iteration 68 Loss=  9250.1427064
Iteration 69 Loss=  51546.5777888
Iteration 70 Loss=  20056.2009117
Iteration 71 Loss=  41212.5287114
Iteration 72 Loss=  31023.8154108
Iteration 73 Loss=  27514.768545
Iteration 74 Loss=  44482.0792912
Iteration 75 Loss=  56323.9270672
Iteration 76 Loss=  52083.262396
Iteration 77 Loss=  38185.4597996
Iteration 78 Loss=  59717.5802214
Iteration 79 Loss=  57541.4878531
Iteration 80 Loss=  63051.6677947
Iteration 81 Loss=  37486.774729
Iteration 82 Loss=  34041.7001667
Iteration 83 Loss=  56388.7030101
Iteration 84 Loss=  9250.1427064
Iteration 85 Loss=  51546.5777888
Iteration 86 Loss=  20056.2009117
Iteration 87 Loss=  41212.5287114
Iteration 88 Loss=  31023.8154108
Iteration 89 Loss=  27514.768545
Iteration 90 Loss=  44482.0792912
Iteration 91 Loss=  56323.9270672
Iteration 92 Loss=  52083.262396
Iteration 93 Loss=  38185.4597996
Iteration 94 Loss=  59717.5802214
Iteration 95 Loss=  57541.4878531
Iteration 96 Loss=  63051.6677947
Iteration 97 Loss=  37486.774729
Iteration 98 Loss=  34041.7001667
Iteration 99 Loss=  56388.7030101
Iteration 100 Loss=  9250.1427064
[-0.29486499 -0.35537172  0.23698444 ..., -0.12692135  0.33044157
  0.01538898]
CROSS VALIDATION 3
Iteration 1 Loss=  49515.7059459
Iteration 2 Loss=  23114.3570246
Iteration 3 Loss=  42401.8990203
Iteration 4 Loss=  30584.0668556
Iteration 5 Loss=  46961.3834086
Iteration 6 Loss=  25865.903964
Iteration 7 Loss=  35392.2048526
Iteration 8 Loss=  36268.0250569
Iteration 9 Loss=  23032.0248276
Iteration 10 Loss=  39236.7755688
Iteration 11 Loss=  40579.8785519
Iteration 12 Loss=  33205.1495021
Iteration 13 Loss=  30580.4630793
Iteration 14 Loss=  44854.3274422
Iteration 15 Loss=  41363.6710723
Iteration 16 Loss=  59929.1519931
Iteration 17 Loss=  32452.7684634
Iteration 18 Loss=  49462.9903102
Iteration 19 Loss=  43678.8684387
Iteration 20 Loss=  38848.0881137
Iteration 21 Loss=  32979.6154607
Iteration 22 Loss=  36320.1731545
Iteration 23 Loss=  31402.0095707
Iteration 24 Loss=  47445.7996672
Iteration 25 Loss=  35776.9546747
Iteration 26 Loss=  13961.7303154
Iteration 27 Loss=  62700.4865118
Iteration 28 Loss=  66003.9536392
Iteration 29 Loss=  42184.0408159
Iteration 30 Loss=  23187.4135716
Iteration 31 Loss=  62513.9889601
Iteration 32 Loss=  44606.8707944
Iteration 33 Loss=  50246.7552618
Iteration 34 Loss=  36406.3297603
Iteration 35 Loss=  28915.5888798
Iteration 36 Loss=  48652.7195941
Iteration 37 Loss=  45804.6998792
Iteration 38 Loss=  29757.9853035
Iteration 39 Loss=  62010.2905375
Iteration 40 Loss=  11497.616557
Iteration 41 Loss=  51926.3885439
Iteration 42 Loss=  36900.7922408
Iteration 43 Loss=  39551.6510339
Iteration 44 Loss=  41471.6118184
Iteration 45 Loss=  36704.1534858
Iteration 46 Loss=  60511.3713228
Iteration 47 Loss=  40824.4288152
Iteration 48 Loss=  40464.7080185
Iteration 49 Loss=  45097.099851
Iteration 50 Loss=  35756.2008582
Iteration 51 Loss=  54510.6643001
Iteration 52 Loss=  35430.2921301
Iteration 53 Loss=  54552.2373816
Iteration 54 Loss=  35429.8320992
Iteration 55 Loss=  54552.2962995
Iteration 56 Loss=  35429.8314473
Iteration 57 Loss=  54552.296383
Iteration 58 Loss=  35429.8314464
Iteration 59 Loss=  54552.2963831
Iteration 60 Loss=  35429.8314464
Iteration 61 Loss=  54552.2963831
Iteration 62 Loss=  35429.8314464
Iteration 63 Loss=  54552.2963831
Iteration 64 Loss=  35429.8314464
Iteration 65 Loss=  54552.2963831
Iteration 66 Loss=  35429.8314464
Iteration 67 Loss=  54552.2963831
Iteration 68 Loss=  35429.8314464
Iteration 69 Loss=  54552.2963831
Iteration 70 Loss=  35429.8314464
Iteration 71 Loss=  54552.2963831
Iteration 72 Loss=  35429.8314464
Iteration 73 Loss=  54552.2963831
Iteration 74 Loss=  35429.8314464
Iteration 75 Loss=  54552.2963831
Iteration 76 Loss=  35429.8314464
Iteration 77 Loss=  54552.2963831
Iteration 78 Loss=  35429.8314464
Iteration 79 Loss=  54552.2963831
Iteration 80 Loss=  35429.8314464
Iteration 81 Loss=  54552.2963831
Iteration 82 Loss=  35429.8314464
Iteration 83 Loss=  54552.2963831
Iteration 84 Loss=  35429.8314464
Iteration 85 Loss=  54552.2963831
Iteration 86 Loss=  35429.8314464
Iteration 87 Loss=  54552.2963831
Iteration 88 Loss=  35429.8314464
Iteration 89 Loss=  54552.2963831
Iteration 90 Loss=  35429.8314464
Iteration 91 Loss=  54552.2963831
Iteration 92 Loss=  35429.8314464
Iteration 93 Loss=  54552.2963831
Iteration 94 Loss=  35429.8314464
Iteration 95 Loss=  54552.2963831
Iteration 96 Loss=  35429.8314464
Iteration 97 Loss=  54552.2963831
Iteration 98 Loss=  35429.8314464
Iteration 99 Loss=  54552.2963831
Iteration 100 Loss=  35429.8314464
[-0.51115432 -0.00128011 -0.21637761 ...,  0.29714714 -0.17351384
  0.05701844]
CROSS VALIDATION 4
Iteration 1 Loss=  49515.7059459
Iteration 2 Loss=  24544.7790345
Iteration 3 Loss=  42401.8990203
Iteration 4 Loss=  29124.005799
Iteration 5 Loss=  46961.3834086
Iteration 6 Loss=  25865.903964
Iteration 7 Loss=  35392.2048526
Iteration 8 Loss=  36268.0250569
Iteration 9 Loss=  20119.0381945
Iteration 10 Loss=  38125.9563723
Iteration 11 Loss=  31076.9044595
Iteration 12 Loss=  59827.6264212
Iteration 13 Loss=  32957.1049442
Iteration 14 Loss=  52317.9203888
Iteration 15 Loss=  31840.7930963
Iteration 16 Loss=  38348.9672406
Iteration 17 Loss=  22475.8091408
Iteration 18 Loss=  69276.5319482
Iteration 19 Loss=  51947.7548438
Iteration 20 Loss=  68104.2331214
Iteration 21 Loss=  31954.9873653
Iteration 22 Loss=  40761.3104277
Iteration 23 Loss=  22032.4722018
Iteration 24 Loss=  40813.2578782
Iteration 25 Loss=  31021.7736106
Iteration 26 Loss=  25947.4103525
Iteration 27 Loss=  49858.0866827
Iteration 28 Loss=  16193.2950776
Iteration 29 Loss=  45132.5911875
Iteration 30 Loss=  87693.3688339
Iteration 31 Loss=  43291.3268912
Iteration 32 Loss=  72643.1343397
Iteration 33 Loss=  45991.250732
Iteration 34 Loss=  41054.6994596
Iteration 35 Loss=  22388.5174182
Iteration 36 Loss=  69280.4369922
Iteration 37 Loss=  51948.5477767
Iteration 38 Loss=  68104.223347
Iteration 39 Loss=  31954.9870343
Iteration 40 Loss=  40761.3104316
Iteration 41 Loss=  22032.4722014
Iteration 42 Loss=  40813.2578782
Iteration 43 Loss=  31021.7736106
Iteration 44 Loss=  25947.4103525
Iteration 45 Loss=  49858.0866827
Iteration 46 Loss=  16193.2950776
Iteration 47 Loss=  45132.5911875
Iteration 48 Loss=  87693.3688339
Iteration 49 Loss=  43291.3268912
Iteration 50 Loss=  72643.1343397
Iteration 51 Loss=  45991.250732
Iteration 52 Loss=  41054.6994596
Iteration 53 Loss=  22388.5174182
Iteration 54 Loss=  69280.4369922
Iteration 55 Loss=  51948.5477767
Iteration 56 Loss=  68104.223347
Iteration 57 Loss=  31954.9870343
Iteration 58 Loss=  40761.3104316
Iteration 59 Loss=  22032.4722014
Iteration 60 Loss=  40813.2578782
Iteration 61 Loss=  31021.7736106
Iteration 62 Loss=  25947.4103525
Iteration 63 Loss=  49858.0866827
Iteration 64 Loss=  16193.2950776
Iteration 65 Loss=  45132.5911875
Iteration 66 Loss=  87693.3688339
Iteration 67 Loss=  43291.3268912
Iteration 68 Loss=  72643.1343397
Iteration 69 Loss=  45991.250732
Iteration 70 Loss=  41054.6994596
Iteration 71 Loss=  22388.5174182
Iteration 72 Loss=  69280.4369922
Iteration 73 Loss=  51948.5477767
Iteration 74 Loss=  68104.223347
Iteration 75 Loss=  31954.9870343
Iteration 76 Loss=  40761.3104316
Iteration 77 Loss=  22032.4722014
Iteration 78 Loss=  40813.2578782
Iteration 79 Loss=  31021.7736106
Iteration 80 Loss=  25947.4103525
Iteration 81 Loss=  49858.0866827
Iteration 82 Loss=  16193.2950776
Iteration 83 Loss=  45132.5911875
Iteration 84 Loss=  87693.3688339
Iteration 85 Loss=  43291.3268912
Iteration 86 Loss=  72643.1343397
Iteration 87 Loss=  45991.250732
Iteration 88 Loss=  41054.6994596
Iteration 89 Loss=  22388.5174182
Iteration 90 Loss=  69280.4369922
Iteration 91 Loss=  51948.5477767
Iteration 92 Loss=  68104.223347
Iteration 93 Loss=  31954.9870343
Iteration 94 Loss=  40761.3104316
Iteration 95 Loss=  22032.4722014
Iteration 96 Loss=  40813.2578782
Iteration 97 Loss=  31021.7736106
Iteration 98 Loss=  25947.4103525
Iteration 99 Loss=  49858.0866827
Iteration 100 Loss=  16193.2950776
[-0.32232799 -0.24189131  0.24676588 ...,  0.07259134  0.44700356
  0.04374171]
CROSS VALIDATION 5
Iteration 1 Loss=  46848.6431967
Iteration 2 Loss=  18454.6523766
Iteration 3 Loss=  36614.3851344
Iteration 4 Loss=  48408.5921087
Iteration 5 Loss=  60489.2332567
Iteration 6 Loss=  10102.5042268
Iteration 7 Loss=  46248.7984893
Iteration 8 Loss=  21000.1112231
Iteration 9 Loss=  50992.4709495
Iteration 10 Loss=  35030.8355939
Iteration 11 Loss=  42497.8296179
Iteration 12 Loss=  5848.44734299
Iteration 13 Loss=  29819.9524365
Iteration 14 Loss=  45749.858567
Iteration 15 Loss=  44074.8604785
Iteration 16 Loss=  39573.295533
Iteration 17 Loss=  50465.9042463
Iteration 18 Loss=  32421.2790634
Iteration 19 Loss=  33387.5029958
Iteration 20 Loss=  62720.7098078
Iteration 21 Loss=  32459.3309711
Iteration 22 Loss=  17499.7353003
Iteration 23 Loss=  83068.4832465
Iteration 24 Loss=  40506.8089725
Iteration 25 Loss=  68458.3001231
Iteration 26 Loss=  46027.6943192
Iteration 27 Loss=  32392.1215781
Iteration 28 Loss=  38321.3333672
Iteration 29 Loss=  36275.4199657
Iteration 30 Loss=  27538.5082925
Iteration 31 Loss=  49726.2783587
Iteration 32 Loss=  24730.791322
Iteration 33 Loss=  47929.5317958
Iteration 34 Loss=  25387.7652967
Iteration 35 Loss=  61317.8945066
Iteration 36 Loss=  31573.9680289
Iteration 37 Loss=  41164.0305238
Iteration 38 Loss=  28634.5252699
Iteration 39 Loss=  45181.6688771
Iteration 40 Loss=  110769.549392
Iteration 41 Loss=  39596.9809074
Iteration 42 Loss=  109865.396062
Iteration 43 Loss=  33751.6709037
Iteration 44 Loss=  47721.3525249
Iteration 45 Loss=  60458.6425978
Iteration 46 Loss=  10102.6561386
Iteration 47 Loss=  46248.7749838
Iteration 48 Loss=  21000.1110388
Iteration 49 Loss=  50992.4709383
Iteration 50 Loss=  35030.8355977
Iteration 51 Loss=  42497.8296178
Iteration 52 Loss=  5848.44734299
Iteration 53 Loss=  29819.9524365
Iteration 54 Loss=  45749.858567
Iteration 55 Loss=  44074.8604785
Iteration 56 Loss=  39573.295533
Iteration 57 Loss=  50465.9042463
Iteration 58 Loss=  32421.2790634
Iteration 59 Loss=  33387.5029958
Iteration 60 Loss=  62720.7098078
Iteration 61 Loss=  32459.3309711
Iteration 62 Loss=  17499.7353003
Iteration 63 Loss=  83068.4832465
Iteration 64 Loss=  40506.8089725
Iteration 65 Loss=  68458.3001231
Iteration 66 Loss=  46027.6943192
Iteration 67 Loss=  32392.1215781
Iteration 68 Loss=  38321.3333672
Iteration 69 Loss=  36275.4199657
Iteration 70 Loss=  27538.5082925
Iteration 71 Loss=  49726.2783587
Iteration 72 Loss=  24730.791322
Iteration 73 Loss=  47929.5317958
Iteration 74 Loss=  25387.7652967
Iteration 75 Loss=  61317.8945066
Iteration 76 Loss=  31573.9680289
Iteration 77 Loss=  41164.0305238
Iteration 78 Loss=  28634.5252699
Iteration 79 Loss=  45181.6688771
Iteration 80 Loss=  110769.549392
Iteration 81 Loss=  39596.9809074
Iteration 82 Loss=  109865.396062
Iteration 83 Loss=  33751.6709037
Iteration 84 Loss=  47721.3525249
Iteration 85 Loss=  60458.6425978
Iteration 86 Loss=  10102.6561386
Iteration 87 Loss=  46248.7749838
Iteration 88 Loss=  21000.1110388
Iteration 89 Loss=  50992.4709383
Iteration 90 Loss=  35030.8355977
Iteration 91 Loss=  42497.8296178
Iteration 92 Loss=  5848.44734299
Iteration 93 Loss=  29819.9524365
Iteration 94 Loss=  45749.858567
Iteration 95 Loss=  44074.8604785
Iteration 96 Loss=  39573.295533
Iteration 97 Loss=  50465.9042463
Iteration 98 Loss=  32421.2790634
Iteration 99 Loss=  33387.5029958
Iteration 100 Loss=  62720.7098078
[-0.20945908  0.03883868 -0.43900842 ...,  0.50638222  0.07601425
  0.07038481]
CROSS VALIDATION 6
Iteration 1 Loss=  49515.7059459
Iteration 2 Loss=  24544.7790345
Iteration 3 Loss=  50923.1342347
Iteration 4 Loss=  43272.7483656
Iteration 5 Loss=  56268.7476671
Iteration 6 Loss=  56534.7503272
Iteration 7 Loss=  50812.3389459
Iteration 8 Loss=  23368.2269966
Iteration 9 Loss=  34509.7089633
Iteration 10 Loss=  62745.2094121
Iteration 11 Loss=  36521.307186
Iteration 12 Loss=  43010.9351054
Iteration 13 Loss=  16986.4146654
Iteration 14 Loss=  47884.1486779
Iteration 15 Loss=  16461.7132047
Iteration 16 Loss=  47965.8740783
Iteration 17 Loss=  16497.2415207
Iteration 18 Loss=  47965.9901461
Iteration 19 Loss=  16497.2918859
Iteration 20 Loss=  47965.9903106
Iteration 21 Loss=  16497.2919572
Iteration 22 Loss=  47965.9903109
Iteration 23 Loss=  16497.2919573
Iteration 24 Loss=  47965.9903109
Iteration 25 Loss=  16497.2919573
Iteration 26 Loss=  47965.9903109
Iteration 27 Loss=  16497.2919573
Iteration 28 Loss=  47965.9903109
Iteration 29 Loss=  16497.2919573
Iteration 30 Loss=  47965.9903109
Iteration 31 Loss=  16497.2919573
Iteration 32 Loss=  47965.9903109
Iteration 33 Loss=  16497.2919573
Iteration 34 Loss=  47965.9903109
Iteration 35 Loss=  16497.2919573
Iteration 36 Loss=  47965.9903109
Iteration 37 Loss=  16497.2919573
Iteration 38 Loss=  47965.9903109
Iteration 39 Loss=  16497.2919573
Iteration 40 Loss=  47965.9903109
Iteration 41 Loss=  16497.2919573
Iteration 42 Loss=  47965.9903109
Iteration 43 Loss=  16497.2919573
Iteration 44 Loss=  47965.9903109
Iteration 45 Loss=  16497.2919573
Iteration 46 Loss=  47965.9903109
Iteration 47 Loss=  16497.2919573
Iteration 48 Loss=  47965.9903109
Iteration 49 Loss=  16497.2919573
Iteration 50 Loss=  47965.9903109
Iteration 51 Loss=  16497.2919573
Iteration 52 Loss=  47965.9903109
Iteration 53 Loss=  16497.2919573
Iteration 54 Loss=  47965.9903109
Iteration 55 Loss=  16497.2919573
Iteration 56 Loss=  47965.9903109
Iteration 57 Loss=  16497.2919573
Iteration 58 Loss=  47965.9903109
Iteration 59 Loss=  16497.2919573
Iteration 60 Loss=  47965.9903109
Iteration 61 Loss=  16497.2919573
Iteration 62 Loss=  47965.9903109
Iteration 63 Loss=  16497.2919573
Iteration 64 Loss=  47965.9903109
Iteration 65 Loss=  16497.2919573
Iteration 66 Loss=  47965.9903109
Iteration 67 Loss=  16497.2919573
Iteration 68 Loss=  47965.9903109
Iteration 69 Loss=  16497.2919573
Iteration 70 Loss=  47965.9903109
Iteration 71 Loss=  16497.2919573
Iteration 72 Loss=  47965.9903109
Iteration 73 Loss=  16497.2919573
Iteration 74 Loss=  47965.9903109
Iteration 75 Loss=  16497.2919573
Iteration 76 Loss=  47965.9903109
Iteration 77 Loss=  16497.2919573
Iteration 78 Loss=  47965.9903109
Iteration 79 Loss=  16497.2919573
Iteration 80 Loss=  47965.9903109
Iteration 81 Loss=  16497.2919573
Iteration 82 Loss=  47965.9903109
Iteration 83 Loss=  16497.2919573
Iteration 84 Loss=  47965.9903109
Iteration 85 Loss=  16497.2919573
Iteration 86 Loss=  47965.9903109
Iteration 87 Loss=  16497.2919573
Iteration 88 Loss=  47965.9903109
Iteration 89 Loss=  16497.2919573
Iteration 90 Loss=  47965.9903109
Iteration 91 Loss=  16497.2919573
Iteration 92 Loss=  47965.9903109
Iteration 93 Loss=  16497.2919573
Iteration 94 Loss=  47965.9903109
Iteration 95 Loss=  16497.2919573
Iteration 96 Loss=  47965.9903109
Iteration 97 Loss=  16497.2919573
Iteration 98 Loss=  47965.9903109
Iteration 99 Loss=  16497.2919573
Iteration 100 Loss=  47965.9903109
[-0.02368004 -0.85275892 -0.1262475  ...,  0.41272034 -0.46188979
 -0.07627624]
CROSS VALIDATION 7
Iteration 1 Loss=  49515.7059459
Iteration 2 Loss=  24544.7790345
Iteration 3 Loss=  50923.1342347
Iteration 4 Loss=  43272.7483656
Iteration 5 Loss=  56268.7476671
Iteration 6 Loss=  56534.7503272
Iteration 7 Loss=  50812.3389459
Iteration 8 Loss=  23368.2269966
Iteration 9 Loss=  34509.7089633
Iteration 10 Loss=  62745.2094121
Iteration 11 Loss=  36369.6645517
Iteration 12 Loss=  43010.9351054
Iteration 13 Loss=  16986.4146654
Iteration 14 Loss=  47884.1486779
Iteration 15 Loss=  16461.7132047
Iteration 16 Loss=  47965.8740783
Iteration 17 Loss=  16497.2415207
Iteration 18 Loss=  47965.9901461
Iteration 19 Loss=  16497.2918859
Iteration 20 Loss=  47965.9903106
Iteration 21 Loss=  16497.2919572
Iteration 22 Loss=  47965.9903109
Iteration 23 Loss=  16497.2919573
Iteration 24 Loss=  47965.9903109
Iteration 25 Loss=  16497.2919573
Iteration 26 Loss=  47965.9903109
Iteration 27 Loss=  16497.2919573
Iteration 28 Loss=  47965.9903109
Iteration 29 Loss=  16497.2919573
Iteration 30 Loss=  47965.9903109
Iteration 31 Loss=  16497.2919573
Iteration 32 Loss=  47965.9903109
Iteration 33 Loss=  16497.2919573
Iteration 34 Loss=  47965.9903109
Iteration 35 Loss=  16497.2919573
Iteration 36 Loss=  47965.9903109
Iteration 37 Loss=  16497.2919573
Iteration 38 Loss=  47965.9903109
Iteration 39 Loss=  16497.2919573
Iteration 40 Loss=  47965.9903109
Iteration 41 Loss=  16497.2919573
Iteration 42 Loss=  47965.9903109
Iteration 43 Loss=  16497.2919573
Iteration 44 Loss=  47965.9903109
Iteration 45 Loss=  16497.2919573
Iteration 46 Loss=  47965.9903109
Iteration 47 Loss=  16497.2919573
Iteration 48 Loss=  47965.9903109
Iteration 49 Loss=  16497.2919573
Iteration 50 Loss=  47965.9903109
Iteration 51 Loss=  16497.2919573
Iteration 52 Loss=  47965.9903109
Iteration 53 Loss=  16497.2919573
Iteration 54 Loss=  47965.9903109
Iteration 55 Loss=  16497.2919573
Iteration 56 Loss=  47965.9903109
Iteration 57 Loss=  16497.2919573
Iteration 58 Loss=  47965.9903109
Iteration 59 Loss=  16497.2919573
Iteration 60 Loss=  47965.9903109
Iteration 61 Loss=  16497.2919573
Iteration 62 Loss=  47965.9903109
Iteration 63 Loss=  16497.2919573
Iteration 64 Loss=  47965.9903109
Iteration 65 Loss=  16497.2919573
Iteration 66 Loss=  47965.9903109
Iteration 67 Loss=  16497.2919573
Iteration 68 Loss=  47965.9903109
Iteration 69 Loss=  16497.2919573
Iteration 70 Loss=  47965.9903109
Iteration 71 Loss=  16497.2919573
Iteration 72 Loss=  47965.9903109
Iteration 73 Loss=  16497.2919573
Iteration 74 Loss=  47965.9903109
Iteration 75 Loss=  16497.2919573
Iteration 76 Loss=  47965.9903109
Iteration 77 Loss=  16497.2919573
Iteration 78 Loss=  47965.9903109
Iteration 79 Loss=  16497.2919573
Iteration 80 Loss=  47965.9903109
Iteration 81 Loss=  16497.2919573
Iteration 82 Loss=  47965.9903109
Iteration 83 Loss=  16497.2919573
Iteration 84 Loss=  47965.9903109
Iteration 85 Loss=  16497.2919573
Iteration 86 Loss=  47965.9903109
Iteration 87 Loss=  16497.2919573
Iteration 88 Loss=  47965.9903109
Iteration 89 Loss=  16497.2919573
Iteration 90 Loss=  47965.9903109
Iteration 91 Loss=  16497.2919573
Iteration 92 Loss=  47965.9903109
Iteration 93 Loss=  16497.2919573
Iteration 94 Loss=  47965.9903109
Iteration 95 Loss=  16497.2919573
Iteration 96 Loss=  47965.9903109
Iteration 97 Loss=  16497.2919573
Iteration 98 Loss=  47965.9903109
Iteration 99 Loss=  16497.2919573
Iteration 100 Loss=  47965.9903109
[-0.02368004 -0.85275892 -0.1262475  ...,  0.41272034 -0.46188979
 -0.07627624]
CROSS VALIDATION 8
Iteration 1 Loss=  48458.9781391
Iteration 2 Loss=  31605.3641797
Iteration 3 Loss=  38864.6350585
Iteration 4 Loss=  36610.5448418
Iteration 5 Loss=  35321.4960637
Iteration 6 Loss=  26840.4268041
Iteration 7 Loss=  38721.6705189
Iteration 8 Loss=  56937.3546063
Iteration 9 Loss=  48843.9192529
Iteration 10 Loss=  32650.9860797
Iteration 11 Loss=  28909.0269881
Iteration 12 Loss=  48584.9947476
Iteration 13 Loss=  32336.0521804
Iteration 14 Loss=  47239.5384507
Iteration 15 Loss=  63864.1139457
Iteration 16 Loss=  36313.308585
Iteration 17 Loss=  53351.6427518
Iteration 18 Loss=  43849.3824531
Iteration 19 Loss=  71888.6909747
Iteration 20 Loss=  63682.4986352
Iteration 21 Loss=  66149.4476568
Iteration 22 Loss=  46681.7852819
Iteration 23 Loss=  38062.0470349
Iteration 24 Loss=  60497.6401482
Iteration 25 Loss=  30088.9813449
Iteration 26 Loss=  54984.4783238
Iteration 27 Loss=  32573.5281084
Iteration 28 Loss=  50636.2786581
Iteration 29 Loss=  16592.4385281
Iteration 30 Loss=  47956.3932148
Iteration 31 Loss=  16497.3849189
Iteration 32 Loss=  47965.976704
Iteration 33 Loss=  16497.2920891
Iteration 34 Loss=  47965.9902916
Iteration 35 Loss=  16497.2919575
Iteration 36 Loss=  47965.9903108
Iteration 37 Loss=  16497.2919573
Iteration 38 Loss=  47965.9903109
Iteration 39 Loss=  16497.2919573
Iteration 40 Loss=  47965.9903109
Iteration 41 Loss=  16497.2919573
Iteration 42 Loss=  47965.9903109
Iteration 43 Loss=  16497.2919573
Iteration 44 Loss=  47965.9903109
Iteration 45 Loss=  16497.2919573
Iteration 46 Loss=  47965.9903109
Iteration 47 Loss=  16497.2919573
Iteration 48 Loss=  47965.9903109
Iteration 49 Loss=  16497.2919573
Iteration 50 Loss=  47965.9903109
Iteration 51 Loss=  16497.2919573
Iteration 52 Loss=  47965.9903109
Iteration 53 Loss=  16497.2919573
Iteration 54 Loss=  47965.9903109
Iteration 55 Loss=  16497.2919573
Iteration 56 Loss=  47965.9903109
Iteration 57 Loss=  16497.2919573
Iteration 58 Loss=  47965.9903109
Iteration 59 Loss=  16497.2919573
Iteration 60 Loss=  47965.9903109
Iteration 61 Loss=  16497.2919573
Iteration 62 Loss=  47965.9903109
Iteration 63 Loss=  16497.2919573
Iteration 64 Loss=  47965.9903109
Iteration 65 Loss=  16497.2919573
Iteration 66 Loss=  47965.9903109
Iteration 67 Loss=  16497.2919573
Iteration 68 Loss=  47965.9903109
Iteration 69 Loss=  16497.2919573
Iteration 70 Loss=  47965.9903109
Iteration 71 Loss=  16497.2919573
Iteration 72 Loss=  47965.9903109
Iteration 73 Loss=  16497.2919573
Iteration 74 Loss=  47965.9903109
Iteration 75 Loss=  16497.2919573
Iteration 76 Loss=  47965.9903109
Iteration 77 Loss=  16497.2919573
Iteration 78 Loss=  47965.9903109
Iteration 79 Loss=  16497.2919573
Iteration 80 Loss=  47965.9903109
Iteration 81 Loss=  16497.2919573
Iteration 82 Loss=  47965.9903109
Iteration 83 Loss=  16497.2919573
Iteration 84 Loss=  47965.9903109
Iteration 85 Loss=  16497.2919573
Iteration 86 Loss=  47965.9903109
Iteration 87 Loss=  16497.2919573
Iteration 88 Loss=  47965.9903109
Iteration 89 Loss=  16497.2919573
Iteration 90 Loss=  47965.9903109
Iteration 91 Loss=  16497.2919573
Iteration 92 Loss=  47965.9903109
Iteration 93 Loss=  16497.2919573
Iteration 94 Loss=  47965.9903109
Iteration 95 Loss=  16497.2919573
Iteration 96 Loss=  47965.9903109
Iteration 97 Loss=  16497.2919573
Iteration 98 Loss=  47965.9903109
Iteration 99 Loss=  16497.2919573
Iteration 100 Loss=  47965.9903109
[-0.02368004 -0.85275892 -0.1262475  ...,  0.41272034 -0.46188979
 -0.07627624]
CROSS VALIDATION 9
Iteration 1 Loss=  24419.8090578
Iteration 2 Loss=  89727.636114
Iteration 3 Loss=  36224.8905718
Iteration 4 Loss=  86019.6009369
Iteration 5 Loss=  36211.3965573
Iteration 6 Loss=  86020.7016015
Iteration 7 Loss=  36211.4503602
Iteration 8 Loss=  86020.7031633
Iteration 9 Loss=  36211.4504369
Iteration 10 Loss=  86020.7031655
Iteration 11 Loss=  36211.450437
Iteration 12 Loss=  86020.7031655
Iteration 13 Loss=  36211.450437
Iteration 14 Loss=  86020.7031655
Iteration 15 Loss=  36211.450437
Iteration 16 Loss=  86020.7031655
Iteration 17 Loss=  36211.450437
Iteration 18 Loss=  86020.7031655
Iteration 19 Loss=  36211.450437
Iteration 20 Loss=  86020.7031655
Iteration 21 Loss=  36211.450437
Iteration 22 Loss=  86020.7031655
Iteration 23 Loss=  36211.450437
Iteration 24 Loss=  86020.7031655
Iteration 25 Loss=  36211.450437
Iteration 26 Loss=  86020.7031655
Iteration 27 Loss=  36211.450437
Iteration 28 Loss=  86020.7031655
Iteration 29 Loss=  36211.450437
Iteration 30 Loss=  86020.7031655
Iteration 31 Loss=  36211.450437
Iteration 32 Loss=  86020.7031655
Iteration 33 Loss=  36211.450437
Iteration 34 Loss=  86020.7031655
Iteration 35 Loss=  36211.450437
Iteration 36 Loss=  86020.7031655
Iteration 37 Loss=  36211.450437
Iteration 38 Loss=  86020.7031655
Iteration 39 Loss=  36211.450437
Iteration 40 Loss=  86020.7031655
Iteration 41 Loss=  36211.450437
Iteration 42 Loss=  86020.7031655
Iteration 43 Loss=  36211.450437
Iteration 44 Loss=  86020.7031655
Iteration 45 Loss=  36211.450437
Iteration 46 Loss=  86020.7031655
Iteration 47 Loss=  36211.450437
Iteration 48 Loss=  86020.7031655
Iteration 49 Loss=  36211.450437
Iteration 50 Loss=  86020.7031655
Iteration 51 Loss=  36211.450437
Iteration 52 Loss=  86020.7031655
Iteration 53 Loss=  36211.450437
Iteration 54 Loss=  86020.7031655
Iteration 55 Loss=  36211.450437
Iteration 56 Loss=  86020.7031655
Iteration 57 Loss=  36211.450437
Iteration 58 Loss=  86020.7031655
Iteration 59 Loss=  36211.450437
Iteration 60 Loss=  86020.7031655
Iteration 61 Loss=  36211.450437
Iteration 62 Loss=  86020.7031655
Iteration 63 Loss=  36211.450437
Iteration 64 Loss=  86020.7031655
Iteration 65 Loss=  36211.450437
Iteration 66 Loss=  86020.7031655
Iteration 67 Loss=  36211.450437
Iteration 68 Loss=  86020.7031655
Iteration 69 Loss=  36211.450437
Iteration 70 Loss=  86020.7031655
Iteration 71 Loss=  36211.450437
Iteration 72 Loss=  86020.7031655
Iteration 73 Loss=  36211.450437
Iteration 74 Loss=  86020.7031655
Iteration 75 Loss=  36211.450437
Iteration 76 Loss=  86020.7031655
Iteration 77 Loss=  36211.450437
Iteration 78 Loss=  86020.7031655
Iteration 79 Loss=  36211.450437
Iteration 80 Loss=  86020.7031655
Iteration 81 Loss=  36211.450437
Iteration 82 Loss=  86020.7031655
Iteration 83 Loss=  36211.450437
Iteration 84 Loss=  86020.7031655
Iteration 85 Loss=  36211.450437
Iteration 86 Loss=  86020.7031655
Iteration 87 Loss=  36211.450437
Iteration 88 Loss=  86020.7031655
Iteration 89 Loss=  36211.450437
Iteration 90 Loss=  86020.7031655
Iteration 91 Loss=  36211.450437
Iteration 92 Loss=  86020.7031655
Iteration 93 Loss=  36211.450437
Iteration 94 Loss=  86020.7031655
Iteration 95 Loss=  36211.450437
Iteration 96 Loss=  86020.7031655
Iteration 97 Loss=  36211.450437
Iteration 98 Loss=  86020.7031655
Iteration 99 Loss=  36211.450437
Iteration 100 Loss=  86020.7031655
[-0.52404041  0.03577654  0.21303792 ...,  0.34292698  0.49928093
  0.25761125]
CROSS VALIDATION 10
Iteration 1 Loss=  49241.0731926
Iteration 2 Loss=  26820.4183456
Iteration 3 Loss=  50611.7720566
Iteration 4 Loss=  17966.5712623
Iteration 5 Loss=  47292.1306516
Iteration 6 Loss=  30277.5531919
Iteration 7 Loss=  49429.8427723
Iteration 8 Loss=  30210.3425854
Iteration 9 Loss=  43767.7775133
Iteration 10 Loss=  39905.0863424
Iteration 11 Loss=  51163.0235848
Iteration 12 Loss=  43520.0367832
Iteration 13 Loss=  53714.1376356
Iteration 14 Loss=  49503.9494327
Iteration 15 Loss=  29199.0780536
Iteration 16 Loss=  64212.3116335
Iteration 17 Loss=  45312.8023362
Iteration 18 Loss=  85917.9393104
Iteration 19 Loss=  29810.5219772
Iteration 20 Loss=  24422.2892796
Iteration 21 Loss=  50271.9070052
Iteration 22 Loss=  20288.8373465
Iteration 23 Loss=  49668.3768474
Iteration 24 Loss=  78125.230084
Iteration 25 Loss=  36017.8806841
Iteration 26 Loss=  32243.7285667
Iteration 27 Loss=  36210.0969447
Iteration 28 Loss=  45095.0973666
Iteration 29 Loss=  24365.7253344
Iteration 30 Loss=  16558.9560783
Iteration 31 Loss=  70013.168403
Iteration 32 Loss=  26884.1808495
Iteration 33 Loss=  59322.2073286
Iteration 34 Loss=  20497.161531
Iteration 35 Loss=  58761.0548454
Iteration 36 Loss=  57282.4307968
Iteration 37 Loss=  59339.0372848
Iteration 38 Loss=  41728.1829876
Iteration 39 Loss=  63863.9163897
Iteration 40 Loss=  29142.0915831
Iteration 41 Loss=  37680.8540084
Iteration 42 Loss=  48697.8532117
Iteration 43 Loss=  46005.9551028
Iteration 44 Loss=  74686.1897013
Iteration 45 Loss=  45170.6582102
Iteration 46 Loss=  28278.869892
Iteration 47 Loss=  50677.1994176
Iteration 48 Loss=  17969.9021849
Iteration 49 Loss=  47292.1029654
Iteration 50 Loss=  30277.5538567
Iteration 51 Loss=  49429.8427203
Iteration 52 Loss=  30210.3425873
Iteration 53 Loss=  43767.7775132
Iteration 54 Loss=  39905.0863424
Iteration 55 Loss=  51163.0235848
Iteration 56 Loss=  43520.0367832
Iteration 57 Loss=  53714.1376356
Iteration 58 Loss=  49503.9494327
Iteration 59 Loss=  29199.0780536
Iteration 60 Loss=  64212.3116335
Iteration 61 Loss=  45312.8023362
Iteration 62 Loss=  85917.9393104
Iteration 63 Loss=  29810.5219772
Iteration 64 Loss=  24422.2892796
Iteration 65 Loss=  50271.9070052
Iteration 66 Loss=  20288.8373465
Iteration 67 Loss=  49668.3768474
Iteration 68 Loss=  78125.230084
Iteration 69 Loss=  36017.8806841
Iteration 70 Loss=  32243.7285667
Iteration 71 Loss=  36210.0969447
Iteration 72 Loss=  45095.0973666
Iteration 73 Loss=  24365.7253344
Iteration 74 Loss=  16558.9560783
Iteration 75 Loss=  70013.168403
Iteration 76 Loss=  26884.1808495
Iteration 77 Loss=  59322.2073286
Iteration 78 Loss=  20497.161531
Iteration 79 Loss=  58761.0548454
Iteration 80 Loss=  57282.4307968
Iteration 81 Loss=  59339.0372848
Iteration 82 Loss=  41728.1829876
Iteration 83 Loss=  63863.9163897
Iteration 84 Loss=  29142.0915831
Iteration 85 Loss=  37680.8540084
Iteration 86 Loss=  48697.8532117
Iteration 87 Loss=  46005.9551028
Iteration 88 Loss=  74686.1897013
Iteration 89 Loss=  45170.6582102
Iteration 90 Loss=  28278.869892
Iteration 91 Loss=  50677.1994176
Iteration 92 Loss=  17969.9021849
Iteration 93 Loss=  47292.1029654
Iteration 94 Loss=  30277.5538567
Iteration 95 Loss=  49429.8427203
Iteration 96 Loss=  30210.3425873
Iteration 97 Loss=  43767.7775132
Iteration 98 Loss=  39905.0863424
Iteration 99 Loss=  51163.0235848
Iteration 100 Loss=  43520.0367832
[-0.69262007  0.01062566 -0.57190567 ...,  0.42879119 -0.19944575
  0.1389136 ]
CROSS VALIDATION 11
Iteration 1 Loss=  49241.0731926
Iteration 2 Loss=  27087.577247
Iteration 3 Loss=  50611.1638338
Iteration 4 Loss=  35772.2439641
Iteration 5 Loss=  27234.7665607
Iteration 6 Loss=  45400.6297058
Iteration 7 Loss=  38608.7003173
Iteration 8 Loss=  51494.0686337
Iteration 9 Loss=  34165.4818774
Iteration 10 Loss=  74061.3062081
Iteration 11 Loss=  65821.3578937
Iteration 12 Loss=  31611.0899
Iteration 13 Loss=  6938.72066595
Iteration 14 Loss=  32079.7888139
Iteration 15 Loss=  27514.9700814
Iteration 16 Loss=  59038.8439019
Iteration 17 Loss=  26710.5423821
Iteration 18 Loss=  41094.3347817
Iteration 19 Loss=  65371.5976741
Iteration 20 Loss=  50512.0482105
Iteration 21 Loss=  16723.5389916
Iteration 22 Loss=  48474.6237342
Iteration 23 Loss=  13752.3390127
Iteration 24 Loss=  47969.2609573
Iteration 25 Loss=  13783.7287414
Iteration 26 Loss=  47968.54531
Iteration 27 Loss=  13783.7732404
Iteration 28 Loss=  47968.5442955
Iteration 29 Loss=  13783.7733035
Iteration 30 Loss=  47968.5442941
Iteration 31 Loss=  13783.7733036
Iteration 32 Loss=  47968.5442941
Iteration 33 Loss=  13783.7733036
Iteration 34 Loss=  47968.5442941
Iteration 35 Loss=  13783.7733036
Iteration 36 Loss=  47968.5442941
Iteration 37 Loss=  13783.7733036
Iteration 38 Loss=  47968.5442941
Iteration 39 Loss=  13783.7733036
Iteration 40 Loss=  47968.5442941
Iteration 41 Loss=  13783.7733036
Iteration 42 Loss=  47968.5442941
Iteration 43 Loss=  13783.7733036
Iteration 44 Loss=  47968.5442941
Iteration 45 Loss=  13783.7733036
Iteration 46 Loss=  47968.5442941
Iteration 47 Loss=  13783.7733036
Iteration 48 Loss=  47968.5442941
Iteration 49 Loss=  13783.7733036
Iteration 50 Loss=  47968.5442941
Iteration 51 Loss=  13783.7733036
Iteration 52 Loss=  47968.5442941
Iteration 53 Loss=  13783.7733036
Iteration 54 Loss=  47968.5442941
Iteration 55 Loss=  13783.7733036
Iteration 56 Loss=  47968.5442941
Iteration 57 Loss=  13783.7733036
Iteration 58 Loss=  47968.5442941
Iteration 59 Loss=  13783.7733036
Iteration 60 Loss=  47968.5442941
Iteration 61 Loss=  13783.7733036
Iteration 62 Loss=  47968.5442941
Iteration 63 Loss=  13783.7733036
Iteration 64 Loss=  47968.5442941
Iteration 65 Loss=  13783.7733036
Iteration 66 Loss=  47968.5442941
Iteration 67 Loss=  13783.7733036
Iteration 68 Loss=  47968.5442941
Iteration 69 Loss=  13783.7733036
Iteration 70 Loss=  47968.5442941
Iteration 71 Loss=  13783.7733036
Iteration 72 Loss=  47968.5442941
Iteration 73 Loss=  13783.7733036
Iteration 74 Loss=  47968.5442941
Iteration 75 Loss=  13783.7733036
Iteration 76 Loss=  47968.5442941
Iteration 77 Loss=  13783.7733036
Iteration 78 Loss=  47968.5442941
Iteration 79 Loss=  13783.7733036
Iteration 80 Loss=  47968.5442941
Iteration 81 Loss=  13783.7733036
Iteration 82 Loss=  47968.5442941
Iteration 83 Loss=  13783.7733036
Iteration 84 Loss=  47968.5442941
Iteration 85 Loss=  13783.7733036
Iteration 86 Loss=  47968.5442941
Iteration 87 Loss=  13783.7733036
Iteration 88 Loss=  47968.5442941
Iteration 89 Loss=  13783.7733036
Iteration 90 Loss=  47968.5442941
Iteration 91 Loss=  13783.7733036
Iteration 92 Loss=  47968.5442941
Iteration 93 Loss=  13783.7733036
Iteration 94 Loss=  47968.5442941
Iteration 95 Loss=  13783.7733036
Iteration 96 Loss=  47968.5442941
Iteration 97 Loss=  13783.7733036
Iteration 98 Loss=  47968.5442941
Iteration 99 Loss=  13783.7733036
Iteration 100 Loss=  47968.5442941
[-0.02373151 -0.85277435 -0.12623236 ...,  0.41273162 -0.46185973
 -0.07629306]
CROSS VALIDATION 12
Iteration 1 Loss=  28154.7165108
Iteration 2 Loss=  37662.6293155
Iteration 3 Loss=  36133.3984724
Iteration 4 Loss=  56713.367681
Iteration 5 Loss=  50747.8551499
Iteration 6 Loss=  34639.888767
Iteration 7 Loss=  66006.2237454
Iteration 8 Loss=  37018.6278368
Iteration 9 Loss=  41235.867821
Iteration 10 Loss=  35190.5637761
Iteration 11 Loss=  56877.3887725
Iteration 12 Loss=  62228.7448165
Iteration 13 Loss=  52339.7509395
Iteration 14 Loss=  39282.1652597
Iteration 15 Loss=  39240.9113465
Iteration 16 Loss=  43836.2786767
Iteration 17 Loss=  41898.5893589
Iteration 18 Loss=  33281.5613089
Iteration 19 Loss=  20685.1181561
Iteration 20 Loss=  52580.0399299
Iteration 21 Loss=  32229.80308
Iteration 22 Loss=  49283.7827205
Iteration 23 Loss=  19922.3714463
Iteration 24 Loss=  56070.0928509
Iteration 25 Loss=  20422.8946023
Iteration 26 Loss=  33429.6837726
Iteration 27 Loss=  54944.8526523
Iteration 28 Loss=  30852.3929009
Iteration 29 Loss=  47779.9421702
Iteration 30 Loss=  48355.1965771
Iteration 31 Loss=  65149.2748333
Iteration 32 Loss=  39350.3417443
Iteration 33 Loss=  30887.0046295
Iteration 34 Loss=  72011.0377482
Iteration 35 Loss=  56665.9230886
Iteration 36 Loss=  51889.3000415
Iteration 37 Loss=  18910.4638489
Iteration 38 Loss=  43189.2753803
Iteration 39 Loss=  34482.2828136
Iteration 40 Loss=  42283.1287403
Iteration 41 Loss=  34620.4958978
Iteration 42 Loss=  25098.9721739
Iteration 43 Loss=  33304.2664402
Iteration 44 Loss=  24112.7744737
Iteration 45 Loss=  39852.026632
Iteration 46 Loss=  27745.8289132
Iteration 47 Loss=  61180.2329772
Iteration 48 Loss=  33668.5966596
Iteration 49 Loss=  43941.3086492
Iteration 50 Loss=  42027.0017384
Iteration 51 Loss=  46457.3055077
Iteration 52 Loss=  65415.8875427
Iteration 53 Loss=  39326.9469745
Iteration 54 Loss=  30886.2443089
Iteration 55 Loss=  72011.0221526
Iteration 56 Loss=  56665.9231128
Iteration 57 Loss=  51889.3000359
Iteration 58 Loss=  18910.4638476
Iteration 59 Loss=  43189.2753803
Iteration 60 Loss=  34482.2828136
Iteration 61 Loss=  42283.1287403
Iteration 62 Loss=  34620.4958978
Iteration 63 Loss=  25098.9721739
Iteration 64 Loss=  33304.2664402
Iteration 65 Loss=  24112.7744737
Iteration 66 Loss=  39852.026632
Iteration 67 Loss=  27745.8289132
Iteration 68 Loss=  61180.2329772
Iteration 69 Loss=  33668.5966596
Iteration 70 Loss=  43941.3086492
Iteration 71 Loss=  42027.0017384
Iteration 72 Loss=  46457.3055077
Iteration 73 Loss=  65415.8875427
Iteration 74 Loss=  39326.9469745
Iteration 75 Loss=  30886.2443089
Iteration 76 Loss=  72011.0221526
Iteration 77 Loss=  56665.9231128
Iteration 78 Loss=  51889.3000359
Iteration 79 Loss=  18910.4638476
Iteration 80 Loss=  43189.2753803
Iteration 81 Loss=  34482.2828136
Iteration 82 Loss=  42283.1287403
Iteration 83 Loss=  34620.4958978
Iteration 84 Loss=  25098.9721739
Iteration 85 Loss=  33304.2664402
Iteration 86 Loss=  24112.7744737
Iteration 87 Loss=  39852.026632
Iteration 88 Loss=  27745.8289132
Iteration 89 Loss=  61180.2329772
Iteration 90 Loss=  33668.5966596
Iteration 91 Loss=  43941.3086492
Iteration 92 Loss=  42027.0017384
Iteration 93 Loss=  46457.3055077
Iteration 94 Loss=  65415.8875427
Iteration 95 Loss=  39326.9469745
Iteration 96 Loss=  30886.2443089
Iteration 97 Loss=  72011.0221526
Iteration 98 Loss=  56665.9231128
Iteration 99 Loss=  51889.3000359
Iteration 100 Loss=  18910.4638476
[-0.10330891 -0.69613066  0.13384142 ...,  0.11260752 -0.24922931
 -0.0208611 ]
CROSS VALIDATION 13
Iteration 1 Loss=  36768.580702
Iteration 2 Loss=  26988.7430383
Iteration 3 Loss=  49004.5336262
Iteration 4 Loss=  22356.8136937
Iteration 5 Loss=  50581.6818371
Iteration 6 Loss=  32135.1319344
Iteration 7 Loss=  49514.2833384
Iteration 8 Loss=  30422.5443378
Iteration 9 Loss=  52081.9267702
Iteration 10 Loss=  31035.802826
Iteration 11 Loss=  49563.9862527
Iteration 12 Loss=  34903.6228816
Iteration 13 Loss=  9225.88766095
Iteration 14 Loss=  41763.7503644
Iteration 15 Loss=  30416.9131271
Iteration 16 Loss=  50795.5541596
Iteration 17 Loss=  32103.1304553
Iteration 18 Loss=  49512.9414161
Iteration 19 Loss=  30422.5728412
Iteration 20 Loss=  52081.9248399
Iteration 21 Loss=  31035.8027476
Iteration 22 Loss=  49563.9862517
Iteration 23 Loss=  34903.6228817
Iteration 24 Loss=  9225.88766096
Iteration 25 Loss=  41763.7503644
Iteration 26 Loss=  30416.9131271
Iteration 27 Loss=  50795.5541596
Iteration 28 Loss=  32103.1304553
Iteration 29 Loss=  49512.9414161
Iteration 30 Loss=  30422.5728412
Iteration 31 Loss=  52081.9248399
Iteration 32 Loss=  31035.8027476
Iteration 33 Loss=  49563.9862517
Iteration 34 Loss=  34903.6228817
Iteration 35 Loss=  9225.88766096
Iteration 36 Loss=  41763.7503644
Iteration 37 Loss=  30416.9131271
Iteration 38 Loss=  50795.5541596
Iteration 39 Loss=  32103.1304553
Iteration 40 Loss=  49512.9414161
Iteration 41 Loss=  30422.5728412
Iteration 42 Loss=  52081.9248399
Iteration 43 Loss=  31035.8027476
Iteration 44 Loss=  49563.9862517
Iteration 45 Loss=  34903.6228817
Iteration 46 Loss=  9225.88766096
Iteration 47 Loss=  41763.7503644
Iteration 48 Loss=  30416.9131271
Iteration 49 Loss=  50795.5541596
Iteration 50 Loss=  32103.1304553
Iteration 51 Loss=  49512.9414161
Iteration 52 Loss=  30422.5728412
Iteration 53 Loss=  52081.9248399
Iteration 54 Loss=  31035.8027476
Iteration 55 Loss=  49563.9862517
Iteration 56 Loss=  34903.6228817
Iteration 57 Loss=  9225.88766096
Iteration 58 Loss=  41763.7503644
Iteration 59 Loss=  30416.9131271
Iteration 60 Loss=  50795.5541596
Iteration 61 Loss=  32103.1304553
Iteration 62 Loss=  49512.9414161
Iteration 63 Loss=  30422.5728412
Iteration 64 Loss=  52081.9248399
Iteration 65 Loss=  31035.8027476
Iteration 66 Loss=  49563.9862517
Iteration 67 Loss=  34903.6228817
Iteration 68 Loss=  9225.88766096
Iteration 69 Loss=  41763.7503644
Iteration 70 Loss=  30416.9131271
Iteration 71 Loss=  50795.5541596
Iteration 72 Loss=  32103.1304553
Iteration 73 Loss=  49512.9414161
Iteration 74 Loss=  30422.5728412
Iteration 75 Loss=  52081.9248399
Iteration 76 Loss=  31035.8027476
Iteration 77 Loss=  49563.9862517
Iteration 78 Loss=  34903.6228817
Iteration 79 Loss=  9225.88766096
Iteration 80 Loss=  41763.7503644
Iteration 81 Loss=  30416.9131271
Iteration 82 Loss=  50795.5541596
Iteration 83 Loss=  32103.1304553
Iteration 84 Loss=  49512.9414161
Iteration 85 Loss=  30422.5728412
Iteration 86 Loss=  52081.9248399
Iteration 87 Loss=  31035.8027476
Iteration 88 Loss=  49563.9862517
Iteration 89 Loss=  34903.6228817
Iteration 90 Loss=  9225.88766096
Iteration 91 Loss=  41763.7503644
Iteration 92 Loss=  30416.9131271
Iteration 93 Loss=  50795.5541596
Iteration 94 Loss=  32103.1304553
Iteration 95 Loss=  49512.9414161
Iteration 96 Loss=  30422.5728412
Iteration 97 Loss=  52081.9248399
Iteration 98 Loss=  31035.8027476
Iteration 99 Loss=  49563.9862517
Iteration 100 Loss=  34903.6228817
[ 0.14411458 -0.58966082  0.19966678 ...,  0.150839   -0.30827135
 -0.00861527]
CROSS VALIDATION 14
Iteration 1 Loss=  46942.2349021
Iteration 2 Loss=  23869.8126976
Iteration 3 Loss=  41407.5191433
Iteration 4 Loss=  29731.8831393
Iteration 5 Loss=  46900.1812501
Iteration 6 Loss=  38711.4083675
Iteration 7 Loss=  26013.1278509
Iteration 8 Loss=  24097.1049702
Iteration 9 Loss=  30963.7323274
Iteration 10 Loss=  43054.4086096
Iteration 11 Loss=  42772.7947671
Iteration 12 Loss=  62723.3742226
Iteration 13 Loss=  33644.8285117
Iteration 14 Loss=  38357.8643121
Iteration 15 Loss=  33195.4716851
Iteration 16 Loss=  31590.1637622
Iteration 17 Loss=  40874.652365
Iteration 18 Loss=  46289.677268
Iteration 19 Loss=  31987.7792023
Iteration 20 Loss=  35461.6927002
Iteration 21 Loss=  40624.7323857
Iteration 22 Loss=  24535.0408938
Iteration 23 Loss=  43300.6239686
Iteration 24 Loss=  52104.5599919
Iteration 25 Loss=  46207.7779496
Iteration 26 Loss=  43945.1036887
Iteration 27 Loss=  26349.0484734
Iteration 28 Loss=  41600.7044986
Iteration 29 Loss=  40217.3649646
Iteration 30 Loss=  46899.1440136
Iteration 31 Loss=  11129.4107968
Iteration 32 Loss=  55455.2914094
Iteration 33 Loss=  42475.801391
Iteration 34 Loss=  62119.4091277
Iteration 35 Loss=  27532.4511477
Iteration 36 Loss=  40489.6368645
Iteration 37 Loss=  62451.0290279
Iteration 38 Loss=  40491.5861421
Iteration 39 Loss=  45192.0707322
Iteration 40 Loss=  43941.0051591
Iteration 41 Loss=  26347.5650742
Iteration 42 Loss=  41600.6601613
Iteration 43 Loss=  40217.36441
Iteration 44 Loss=  46899.1439508
Iteration 45 Loss=  11129.410796
Iteration 46 Loss=  55455.2914093
Iteration 47 Loss=  42475.801391
Iteration 48 Loss=  62119.4091277
Iteration 49 Loss=  27532.4511477
Iteration 50 Loss=  40489.6368645
Iteration 51 Loss=  62451.0290279
Iteration 52 Loss=  40491.5861421
Iteration 53 Loss=  45192.0707322
Iteration 54 Loss=  43941.0051591
Iteration 55 Loss=  26347.5650742
Iteration 56 Loss=  41600.6601613
Iteration 57 Loss=  40217.36441
Iteration 58 Loss=  46899.1439508
Iteration 59 Loss=  11129.410796
Iteration 60 Loss=  55455.2914093
Iteration 61 Loss=  42475.801391
Iteration 62 Loss=  62119.4091277
Iteration 63 Loss=  27532.4511477
Iteration 64 Loss=  40489.6368645
Iteration 65 Loss=  62451.0290279
Iteration 66 Loss=  40491.5861421
Iteration 67 Loss=  45192.0707322
Iteration 68 Loss=  43941.0051591
Iteration 69 Loss=  26347.5650742
Iteration 70 Loss=  41600.6601613
Iteration 71 Loss=  40217.36441
Iteration 72 Loss=  46899.1439508
Iteration 73 Loss=  11129.410796
Iteration 74 Loss=  55455.2914093
Iteration 75 Loss=  42475.801391
Iteration 76 Loss=  62119.4091277
Iteration 77 Loss=  27532.4511477
Iteration 78 Loss=  40489.6368645
Iteration 79 Loss=  62451.0290279
Iteration 80 Loss=  40491.5861421
Iteration 81 Loss=  45192.0707322
Iteration 82 Loss=  43941.0051591
Iteration 83 Loss=  26347.5650742
Iteration 84 Loss=  41600.6601613
Iteration 85 Loss=  40217.36441
Iteration 86 Loss=  46899.1439508
Iteration 87 Loss=  11129.410796
Iteration 88 Loss=  55455.2914093
Iteration 89 Loss=  42475.801391
Iteration 90 Loss=  62119.4091277
Iteration 91 Loss=  27532.4511477
Iteration 92 Loss=  40489.6368645
Iteration 93 Loss=  62451.0290279
Iteration 94 Loss=  40491.5861421
Iteration 95 Loss=  45192.0707322
Iteration 96 Loss=  43941.0051591
Iteration 97 Loss=  26347.5650742
Iteration 98 Loss=  41600.6601613
Iteration 99 Loss=  40217.36441
Iteration 100 Loss=  46899.1439508
[-0.27279756 -0.56284912 -0.07647129 ...,  0.43101121 -0.34147964
 -0.01963616]
CROSS VALIDATION 15
Iteration 1 Loss=  49238.8725453
Iteration 2 Loss=  23613.8805803
Iteration 3 Loss=  42277.1973738
Iteration 4 Loss=  30392.7875196
Iteration 5 Loss=  46900.1812501
Iteration 6 Loss=  25753.9204606
Iteration 7 Loss=  34219.3471714
Iteration 8 Loss=  36398.4137967
Iteration 9 Loss=  22161.7701807
Iteration 10 Loss=  38078.250573
Iteration 11 Loss=  29148.1890675
Iteration 12 Loss=  59551.1913833
Iteration 13 Loss=  43760.8690195
Iteration 14 Loss=  53017.032194
Iteration 15 Loss=  59692.2047331
Iteration 16 Loss=  22543.9324706
Iteration 17 Loss=  38906.3612253
Iteration 18 Loss=  64296.9549339
Iteration 19 Loss=  33478.0815597
Iteration 20 Loss=  35316.8781443
Iteration 21 Loss=  28917.160084
Iteration 22 Loss=  57085.4802608
Iteration 23 Loss=  48649.5436068
Iteration 24 Loss=  65339.0311601
Iteration 25 Loss=  21039.1661755
Iteration 26 Loss=  41563.1817864
Iteration 27 Loss=  31421.6702067
Iteration 28 Loss=  52114.3411216
Iteration 29 Loss=  15517.018158
Iteration 30 Loss=  53340.0753854
Iteration 31 Loss=  50761.1204448
Iteration 32 Loss=  44396.1705083
Iteration 33 Loss=  40822.3387649
Iteration 34 Loss=  58220.0249292
Iteration 35 Loss=  58121.8918172
Iteration 36 Loss=  41010.4174402
Iteration 37 Loss=  29326.5088279
Iteration 38 Loss=  59581.0340681
Iteration 39 Loss=  29131.0612311
Iteration 40 Loss=  38713.8660068
Iteration 41 Loss=  51170.5320208
Iteration 42 Loss=  7427.33433201
Iteration 43 Loss=  34103.2204045
Iteration 44 Loss=  22419.5697346
Iteration 45 Loss=  66170.5045636
Iteration 46 Loss=  48522.9291064
Iteration 47 Loss=  32610.3702516
Iteration 48 Loss=  43744.6553346
Iteration 49 Loss=  61516.7387114
Iteration 50 Loss=  42149.8292621
Iteration 51 Loss=  51604.9397354
Iteration 52 Loss=  48788.8033139
Iteration 53 Loss=  56711.7050134
Iteration 54 Loss=  21407.3729131
Iteration 55 Loss=  34878.3219426
Iteration 56 Loss=  46847.2001598
Iteration 57 Loss=  49425.4795589
Iteration 58 Loss=  46115.8667933
Iteration 59 Loss=  29665.2819716
Iteration 60 Loss=  61287.3323737
Iteration 61 Loss=  11414.8778981
Iteration 62 Loss=  72470.7993706
Iteration 63 Loss=  9781.41246552
Iteration 64 Loss=  55787.4897139
Iteration 65 Loss=  29835.0171696
Iteration 66 Loss=  38839.4612073
Iteration 67 Loss=  43720.5779101
Iteration 68 Loss=  43885.4302685
Iteration 69 Loss=  48937.5726267
Iteration 70 Loss=  72032.4591959
Iteration 71 Loss=  31350.9925369
Iteration 72 Loss=  70752.5504304
Iteration 73 Loss=  32074.6860669
Iteration 74 Loss=  76687.5427285
Iteration 75 Loss=  24422.3154826
Iteration 76 Loss=  103763.655156
Iteration 77 Loss=  40999.4565838
Iteration 78 Loss=  38777.5818448
Iteration 79 Loss=  46882.6833553
Iteration 80 Loss=  25391.5879824
Iteration 81 Loss=  72704.622964
Iteration 82 Loss=  52895.2136076
Iteration 83 Loss=  49295.7537736
Iteration 84 Loss=  42390.8829985
Iteration 85 Loss=  67053.2478179
Iteration 86 Loss=  49937.2736397
Iteration 87 Loss=  49061.5623421
Iteration 88 Loss=  29140.3135666
Iteration 89 Loss=  54306.3591372
Iteration 90 Loss=  60207.0145
Iteration 91 Loss=  47483.6622666
Iteration 92 Loss=  57271.450387
Iteration 93 Loss=  42351.723082
Iteration 94 Loss=  54983.6078367
Iteration 95 Loss=  40382.7540952
Iteration 96 Loss=  49463.9506817
Iteration 97 Loss=  36119.3322853
Iteration 98 Loss=  52389.3973697
Iteration 99 Loss=  30750.4595313
Iteration 100 Loss=  27993.9844858
[-0.11823132 -0.09941029 -0.25592094 ...,  0.56202942 -0.01889262
  0.08557381]
CROSS VALIDATION 16
Iteration 1 Loss=  49238.8725453
Iteration 2 Loss=  24429.9156516
Iteration 3 Loss=  26015.1254039
Iteration 4 Loss=  41910.6748916
Iteration 5 Loss=  14841.8867619
Iteration 6 Loss=  51194.9878481
Iteration 7 Loss=  25704.5785416
Iteration 8 Loss=  79783.3983579
Iteration 9 Loss=  33880.0972983
Iteration 10 Loss=  34883.7323436
Iteration 11 Loss=  48397.6446721
Iteration 12 Loss=  40489.4215852
Iteration 13 Loss=  67706.239053
Iteration 14 Loss=  36554.4831374
Iteration 15 Loss=  52323.5551624
Iteration 16 Loss=  38003.7166975
Iteration 17 Loss=  68173.6652542
Iteration 18 Loss=  48212.5914194
Iteration 19 Loss=  40407.5969537
Iteration 20 Loss=  67937.7938132
Iteration 21 Loss=  36611.3358793
Iteration 22 Loss=  52393.9136272
Iteration 23 Loss=  38005.3792541
Iteration 24 Loss=  68172.8514165
Iteration 25 Loss=  48212.592961
Iteration 26 Loss=  40407.5969709
Iteration 27 Loss=  67937.7938137
Iteration 28 Loss=  36611.3350477
Iteration 29 Loss=  52393.9133561
Iteration 30 Loss=  38005.3792476
Iteration 31 Loss=  68172.8514197
Iteration 32 Loss=  48212.592961
Iteration 33 Loss=  40407.5969709
Iteration 34 Loss=  67937.7938137
Iteration 35 Loss=  36611.3350477
Iteration 36 Loss=  52393.9133561
Iteration 37 Loss=  38005.3792476
Iteration 38 Loss=  68172.8514197
Iteration 39 Loss=  48212.592961
Iteration 40 Loss=  40407.5969709
Iteration 41 Loss=  67937.7938137
Iteration 42 Loss=  36611.3350477
Iteration 43 Loss=  52393.9133561
Iteration 44 Loss=  38005.3792476
Iteration 45 Loss=  68172.8514197
Iteration 46 Loss=  48212.592961
Iteration 47 Loss=  40407.5969709
Iteration 48 Loss=  67937.7938137
Iteration 49 Loss=  36611.3350477
Iteration 50 Loss=  52393.9133561
Iteration 51 Loss=  38005.3792476
Iteration 52 Loss=  68172.8514197
Iteration 53 Loss=  48212.592961
Iteration 54 Loss=  40407.5969709
Iteration 55 Loss=  67937.7938137
Iteration 56 Loss=  36611.3350477
Iteration 57 Loss=  52393.9133561
Iteration 58 Loss=  38005.3792476
Iteration 59 Loss=  68172.8514197
Iteration 60 Loss=  48212.592961
Iteration 61 Loss=  40407.5969709
Iteration 62 Loss=  67937.7938137
Iteration 63 Loss=  36611.3350477
Iteration 64 Loss=  52393.9133561
Iteration 65 Loss=  38005.3792476
Iteration 66 Loss=  68172.8514197
Iteration 67 Loss=  48212.592961
Iteration 68 Loss=  40407.5969709
Iteration 69 Loss=  67937.7938137
Iteration 70 Loss=  36611.3350477
Iteration 71 Loss=  52393.9133561
Iteration 72 Loss=  38005.3792476
Iteration 73 Loss=  68172.8514197
Iteration 74 Loss=  48212.592961
Iteration 75 Loss=  40407.5969709
Iteration 76 Loss=  67937.7938137
Iteration 77 Loss=  36611.3350477
Iteration 78 Loss=  52393.9133561
Iteration 79 Loss=  38005.3792476
Iteration 80 Loss=  68172.8514197
Iteration 81 Loss=  48212.592961
Iteration 82 Loss=  40407.5969709
Iteration 83 Loss=  67937.7938137
Iteration 84 Loss=  36611.3350477
Iteration 85 Loss=  52393.9133561
Iteration 86 Loss=  38005.3792476
Iteration 87 Loss=  68172.8514197
Iteration 88 Loss=  48212.592961
Iteration 89 Loss=  40407.5969709
Iteration 90 Loss=  67937.7938137
Iteration 91 Loss=  36611.3350477
Iteration 92 Loss=  52393.9133561
Iteration 93 Loss=  38005.3792476
Iteration 94 Loss=  68172.8514197
Iteration 95 Loss=  48212.592961
Iteration 96 Loss=  40407.5969709
Iteration 97 Loss=  67937.7938137
Iteration 98 Loss=  36611.3350477
Iteration 99 Loss=  52393.9133561
Iteration 100 Loss=  38005.3792476
[-0.17495669 -0.81845981 -0.2226258  ...,  0.31371283 -0.38833625
 -0.0542279 ]
CROSS VALIDATION 17
Iteration 1 Loss=  48282.5884314
Iteration 2 Loss=  29903.0645901
Iteration 3 Loss=  40456.684567
Iteration 4 Loss=  43755.4802685
Iteration 5 Loss=  43885.2035636
Iteration 6 Loss=  48937.6458358
Iteration 7 Loss=  72032.4642315
Iteration 8 Loss=  48285.300915
Iteration 9 Loss=  42884.1789417
Iteration 10 Loss=  52071.1643507
Iteration 11 Loss=  2802.23606073
Iteration 12 Loss=  44907.1566909
Iteration 13 Loss=  28444.9029259
Iteration 14 Loss=  39832.5612769
Iteration 15 Loss=  69157.0286682
Iteration 16 Loss=  25279.7594092
Iteration 17 Loss=  57715.4810296
Iteration 18 Loss=  46202.2484559
Iteration 19 Loss=  49551.2302455
Iteration 20 Loss=  43385.7377135
Iteration 21 Loss=  62232.3436697
Iteration 22 Loss=  41021.4447883
Iteration 23 Loss=  62403.6234311
Iteration 24 Loss=  41019.9869621
Iteration 25 Loss=  62403.866965
Iteration 26 Loss=  41019.9848965
Iteration 27 Loss=  62403.8673102
Iteration 28 Loss=  41019.9848936
Iteration 29 Loss=  62403.8673107
Iteration 30 Loss=  41019.9848936
Iteration 31 Loss=  62403.8673107
Iteration 32 Loss=  41019.9848936
Iteration 33 Loss=  62403.8673107
Iteration 34 Loss=  41019.9848936
Iteration 35 Loss=  62403.8673107
Iteration 36 Loss=  41019.9848936
Iteration 37 Loss=  62403.8673107
Iteration 38 Loss=  41019.9848936
Iteration 39 Loss=  62403.8673107
Iteration 40 Loss=  41019.9848936
Iteration 41 Loss=  62403.8673107
Iteration 42 Loss=  41019.9848936
Iteration 43 Loss=  62403.8673107
Iteration 44 Loss=  41019.9848936
Iteration 45 Loss=  62403.8673107
Iteration 46 Loss=  41019.9848936
Iteration 47 Loss=  62403.8673107
Iteration 48 Loss=  41019.9848936
Iteration 49 Loss=  62403.8673107
Iteration 50 Loss=  41019.9848936
Iteration 51 Loss=  62403.8673107
Iteration 52 Loss=  41019.9848936
Iteration 53 Loss=  62403.8673107
Iteration 54 Loss=  41019.9848936
Iteration 55 Loss=  62403.8673107
Iteration 56 Loss=  41019.9848936
Iteration 57 Loss=  62403.8673107
Iteration 58 Loss=  41019.9848936
Iteration 59 Loss=  62403.8673107
Iteration 60 Loss=  41019.9848936
Iteration 61 Loss=  62403.8673107
Iteration 62 Loss=  41019.9848936
Iteration 63 Loss=  62403.8673107
Iteration 64 Loss=  41019.9848936
Iteration 65 Loss=  62403.8673107
Iteration 66 Loss=  41019.9848936
Iteration 67 Loss=  62403.8673107
Iteration 68 Loss=  41019.9848936
Iteration 69 Loss=  62403.8673107
Iteration 70 Loss=  41019.9848936
Iteration 71 Loss=  62403.8673107
Iteration 72 Loss=  41019.9848936
Iteration 73 Loss=  62403.8673107
Iteration 74 Loss=  41019.9848936
Iteration 75 Loss=  62403.8673107
Iteration 76 Loss=  41019.9848936
Iteration 77 Loss=  62403.8673107
Iteration 78 Loss=  41019.9848936
Iteration 79 Loss=  62403.8673107
Iteration 80 Loss=  41019.9848936
Iteration 81 Loss=  62403.8673107
Iteration 82 Loss=  41019.9848936
Iteration 83 Loss=  62403.8673107
Iteration 84 Loss=  41019.9848936
Iteration 85 Loss=  62403.8673107
Iteration 86 Loss=  41019.9848936
Iteration 87 Loss=  62403.8673107
Iteration 88 Loss=  41019.9848936
Iteration 89 Loss=  62403.8673107
Iteration 90 Loss=  41019.9848936
Iteration 91 Loss=  62403.8673107
Iteration 92 Loss=  41019.9848936
Iteration 93 Loss=  62403.8673107
Iteration 94 Loss=  41019.9848936
Iteration 95 Loss=  62403.8673107
Iteration 96 Loss=  41019.9848936
Iteration 97 Loss=  62403.8673107
Iteration 98 Loss=  41019.9848936
Iteration 99 Loss=  62403.8673107
Iteration 100 Loss=  41019.9848936
[-0.17813607 -0.8293133  -0.23425012 ...,  0.37142883 -0.50630114
 -0.02782964]
CROSS VALIDATION 18
Iteration 1 Loss=  48637.5683463
Iteration 2 Loss=  26982.2857046
Iteration 3 Loss=  41538.7943667
Iteration 4 Loss=  42882.5393068
Iteration 5 Loss=  39197.7638089
Iteration 6 Loss=  57945.1600727
Iteration 7 Loss=  41906.0519166
Iteration 8 Loss=  29246.205773
Iteration 9 Loss=  42027.2861177
Iteration 10 Loss=  26288.7560361
Iteration 11 Loss=  41796.9306068
Iteration 12 Loss=  26969.3121463
Iteration 13 Loss=  43937.0033494
Iteration 14 Loss=  44260.6637461
Iteration 15 Loss=  23699.4665114
Iteration 16 Loss=  33529.8411611
Iteration 17 Loss=  73692.079121
Iteration 18 Loss=  36797.7265979
Iteration 19 Loss=  49598.0202199
Iteration 20 Loss=  63364.2447413
Iteration 21 Loss=  46855.3416739
Iteration 22 Loss=  42988.4953702
Iteration 23 Loss=  23719.381872
Iteration 24 Loss=  33528.2696128
Iteration 25 Loss=  73692.0728488
Iteration 26 Loss=  36797.7261373
Iteration 27 Loss=  49598.0202436
Iteration 28 Loss=  63364.2447393
Iteration 29 Loss=  46855.341674
Iteration 30 Loss=  42988.4953702
Iteration 31 Loss=  23719.381872
Iteration 32 Loss=  33528.2696128
Iteration 33 Loss=  73692.0728488
Iteration 34 Loss=  36797.7261373
Iteration 35 Loss=  49598.0202436
Iteration 36 Loss=  63364.2447393
Iteration 37 Loss=  46855.341674
Iteration 38 Loss=  42988.4953702
Iteration 39 Loss=  23719.381872
Iteration 40 Loss=  33528.2696128
Iteration 41 Loss=  73692.0728488
Iteration 42 Loss=  36797.7261373
Iteration 43 Loss=  49598.0202436
Iteration 44 Loss=  63364.2447393
Iteration 45 Loss=  46855.341674
Iteration 46 Loss=  42988.4953702
Iteration 47 Loss=  23719.381872
Iteration 48 Loss=  33528.2696128
Iteration 49 Loss=  73692.0728488
Iteration 50 Loss=  36797.7261373
Iteration 51 Loss=  49598.0202436
Iteration 52 Loss=  63364.2447393
Iteration 53 Loss=  46855.341674
Iteration 54 Loss=  42988.4953702
Iteration 55 Loss=  23719.381872
Iteration 56 Loss=  33528.2696128
Iteration 57 Loss=  73692.0728488
Iteration 58 Loss=  36797.7261373
Iteration 59 Loss=  49598.0202436
Iteration 60 Loss=  63364.2447393
Iteration 61 Loss=  46855.341674
Iteration 62 Loss=  42988.4953702
Iteration 63 Loss=  23719.381872
Iteration 64 Loss=  33528.2696128
Iteration 65 Loss=  73692.0728488
Iteration 66 Loss=  36797.7261373
Iteration 67 Loss=  49598.0202436
Iteration 68 Loss=  63364.2447393
Iteration 69 Loss=  46855.341674
Iteration 70 Loss=  42988.4953702
Iteration 71 Loss=  23719.381872
Iteration 72 Loss=  33528.2696128
Iteration 73 Loss=  73692.0728488
Iteration 74 Loss=  36797.7261373
Iteration 75 Loss=  49598.0202436
Iteration 76 Loss=  63364.2447393
Iteration 77 Loss=  46855.341674
Iteration 78 Loss=  42988.4953702
Iteration 79 Loss=  23719.381872
Iteration 80 Loss=  33528.2696128
Iteration 81 Loss=  73692.0728488
Iteration 82 Loss=  36797.7261373
Iteration 83 Loss=  49598.0202436
Iteration 84 Loss=  63364.2447393
Iteration 85 Loss=  46855.341674
Iteration 86 Loss=  42988.4953702
Iteration 87 Loss=  23719.381872
Iteration 88 Loss=  33528.2696128
Iteration 89 Loss=  73692.0728488
Iteration 90 Loss=  36797.7261373
Iteration 91 Loss=  49598.0202436
Iteration 92 Loss=  63364.2447393
Iteration 93 Loss=  46855.341674
Iteration 94 Loss=  42988.4953702
Iteration 95 Loss=  23719.381872
Iteration 96 Loss=  33528.2696128
Iteration 97 Loss=  73692.0728488
Iteration 98 Loss=  36797.7261373
Iteration 99 Loss=  49598.0202436
Iteration 100 Loss=  63364.2447393
[-0.34512707 -0.47977547  0.0970114  ...,  0.48787968  0.14780533
  0.00176231]
CROSS VALIDATION 19
Iteration 1 Loss=  49116.003729
Iteration 2 Loss=  26984.3445668
Iteration 3 Loss=  51409.8331876
Iteration 4 Loss=  14624.3249467
Iteration 5 Loss=  29729.1351339
Iteration 6 Loss=  43977.2256082
Iteration 7 Loss=  43113.0458797
Iteration 8 Loss=  28539.5562756
Iteration 9 Loss=  46386.9303341
Iteration 10 Loss=  18582.5714765
Iteration 11 Loss=  56907.3792316
Iteration 12 Loss=  42525.3851886
Iteration 13 Loss=  60434.6814874
Iteration 14 Loss=  17176.5729297
Iteration 15 Loss=  47426.4242414
Iteration 16 Loss=  36261.4351598
Iteration 17 Loss=  55360.6844619
Iteration 18 Loss=  15055.5185427
Iteration 19 Loss=  29729.7403506
Iteration 20 Loss=  43978.1200594
Iteration 21 Loss=  43113.0572929
Iteration 22 Loss=  28539.5565076
Iteration 23 Loss=  46386.9303524
Iteration 24 Loss=  18582.5714781
Iteration 25 Loss=  56907.3792316
Iteration 26 Loss=  42525.3851886
Iteration 27 Loss=  60434.6814874
Iteration 28 Loss=  17176.5729297
Iteration 29 Loss=  47426.4242414
Iteration 30 Loss=  36261.4351598
Iteration 31 Loss=  55360.6844619
Iteration 32 Loss=  15055.5185427
Iteration 33 Loss=  29729.7403506
Iteration 34 Loss=  43978.1200594
Iteration 35 Loss=  43113.0572929
Iteration 36 Loss=  28539.5565076
Iteration 37 Loss=  46386.9303524
Iteration 38 Loss=  18582.5714781
Iteration 39 Loss=  56907.3792316
Iteration 40 Loss=  42525.3851886
Iteration 41 Loss=  60434.6814874
Iteration 42 Loss=  17176.5729297
Iteration 43 Loss=  47426.4242414
Iteration 44 Loss=  36261.4351598
Iteration 45 Loss=  55360.6844619
Iteration 46 Loss=  15055.5185427
Iteration 47 Loss=  29729.7403506
Iteration 48 Loss=  43978.1200594
Iteration 49 Loss=  43113.0572929
Iteration 50 Loss=  28539.5565076
Iteration 51 Loss=  46386.9303524
Iteration 52 Loss=  18582.5714781
Iteration 53 Loss=  56907.3792316
Iteration 54 Loss=  42525.3851886
Iteration 55 Loss=  60434.6814874
Iteration 56 Loss=  17176.5729297
Iteration 57 Loss=  47426.4242414
Iteration 58 Loss=  36261.4351598
Iteration 59 Loss=  55360.6844619
Iteration 60 Loss=  15055.5185427
Iteration 61 Loss=  29729.7403506
Iteration 62 Loss=  43978.1200594
Iteration 63 Loss=  43113.0572929
Iteration 64 Loss=  28539.5565076
Iteration 65 Loss=  46386.9303524
Iteration 66 Loss=  18582.5714781
Iteration 67 Loss=  56907.3792316
Iteration 68 Loss=  42525.3851886
Iteration 69 Loss=  60434.6814874
Iteration 70 Loss=  17176.5729297
Iteration 71 Loss=  47426.4242414
Iteration 72 Loss=  36261.4351598
Iteration 73 Loss=  55360.6844619
Iteration 74 Loss=  15055.5185427
Iteration 75 Loss=  29729.7403506
Iteration 76 Loss=  43978.1200594
Iteration 77 Loss=  43113.0572929
Iteration 78 Loss=  28539.5565076
Iteration 79 Loss=  46386.9303524
Iteration 80 Loss=  18582.5714781
Iteration 81 Loss=  56907.3792316
Iteration 82 Loss=  42525.3851886
Iteration 83 Loss=  60434.6814874
Iteration 84 Loss=  17176.5729297
Iteration 85 Loss=  47426.4242414
Iteration 86 Loss=  36261.4351598
Iteration 87 Loss=  55360.6844619
Iteration 88 Loss=  15055.5185427
Iteration 89 Loss=  29729.7403506
Iteration 90 Loss=  43978.1200594
Iteration 91 Loss=  43113.0572929
Iteration 92 Loss=  28539.5565076
Iteration 93 Loss=  46386.9303524
Iteration 94 Loss=  18582.5714781
Iteration 95 Loss=  56907.3792316
Iteration 96 Loss=  42525.3851886
Iteration 97 Loss=  60434.6814874
Iteration 98 Loss=  17176.5729297
Iteration 99 Loss=  47426.4242414
Iteration 100 Loss=  36261.4351598
[-0.2613111   0.12088805  0.22271977 ...,  0.17099992  0.23666002
  0.09819163]
Accuracy (Logistic Loss):	0.75 for lmda= 0.3 learning rate= 0.1
---------------------------------------------------------------------------------
lmda= 1 learning rate= 0.0001
CROSS VALIDATION 0
Iteration 1 Loss=  6.11018664174
Iteration 2 Loss=  0.207425270189
Iteration 3 Loss=  0.201215635358
Iteration 4 Loss=  0.196519396011
Iteration 5 Loss=  0.192202256647
Iteration 6 Loss=  0.188093819894
Iteration 7 Loss=  0.184135440437
Iteration 8 Loss=  0.180300001798
Iteration 9 Loss=  0.176572519273
Iteration 10 Loss=  0.172943592021
Iteration 11 Loss=  0.169406719155
Iteration 12 Loss=  0.165957045627
Iteration 13 Loss=  0.162590717417
Iteration 14 Loss=  0.159304524771
Iteration 15 Loss=  0.156095693004
Iteration 16 Loss=  0.15296175391
Iteration 17 Loss=  0.14990046357
Iteration 18 Loss=  0.146909748044
Iteration 19 Loss=  0.143987666458
Iteration 20 Loss=  0.141132385243
Iteration 21 Loss=  0.13834215974
Iteration 22 Loss=  0.135615320736
Iteration 23 Loss=  0.132950264382
Iteration 24 Loss=  0.130345444462
Iteration 25 Loss=  0.127799366303
Iteration 26 Loss=  0.125310581886
Iteration 27 Loss=  0.122877685804
Iteration 28 Loss=  0.120499311882
Iteration 29 Loss=  0.118174130299
Iteration 30 Loss=  0.115900845105
Iteration 31 Loss=  0.113678192095
Iteration 32 Loss=  0.111504936964
Iteration 33 Loss=  0.109379873743
Iteration 34 Loss=  0.107301823468
Iteration 35 Loss=  0.105269633101
Iteration 36 Loss=  0.103282174665
Iteration 37 Loss=  0.101338344607
Iteration 38 Loss=  0.0994370633761
Iteration 39 Loss=  0.0975772752197
Iteration 40 Loss=  0.0957579481856
Iteration 41 Loss=  0.0939780743317
Iteration 42 Loss=  0.0922366701227
Iteration 43 Loss=  0.0905327769953
Iteration 44 Loss=  0.0888654620617
Iteration 45 Loss=  0.0872338189099
Iteration 46 Loss=  0.0856369684542
Iteration 47 Loss=  0.0840740597769
Iteration 48 Loss=  0.0825442709062
Iteration 49 Loss=  0.0810468094673
Iteration 50 Loss=  0.0795809131568
Iteration 51 Loss=  0.0781458499939
Iteration 52 Loss=  0.0767409183176
Iteration 53 Loss=  0.0753654465145
Iteration 54 Loss=  0.074018792475
Iteration 55 Loss=  0.0727003427957
Iteration 56 Loss=  0.0714095117561
Iteration 57 Loss=  0.0701457401094
Iteration 58 Loss=  0.0689084937349
Iteration 59 Loss=  0.0676972622021
Iteration 60 Loss=  0.0665115572956
Iteration 61 Loss=  0.0653509115451
Iteration 62 Loss=  0.0642148767985
Iteration 63 Loss=  0.0631030228657
Iteration 64 Loss=  0.0620149362504
Iteration 65 Loss=  0.0609502189775
Iteration 66 Loss=  0.0599084875101
Iteration 67 Loss=  0.0588893717469
Iteration 68 Loss=  0.0578925140756
Iteration 69 Loss=  0.0569175684599
Iteration 70 Loss=  0.0559641995302
Iteration 71 Loss=  0.055032081648
Iteration 72 Loss=  0.0541208979166
Iteration 73 Loss=  0.053230339114
Iteration 74 Loss=  0.0523601025276
Iteration 75 Loss=  0.0515098906812
Iteration 76 Loss=  0.0506794099483
Iteration 77 Loss=  0.0498683690612
Iteration 78 Loss=  0.0490764775289
Iteration 79 Loss=  0.048303443993
Iteration 80 Loss=  0.0475489745575
Iteration 81 Loss=  0.0468127711371
Iteration 82 Loss=  0.0460945298777
Iteration 83 Loss=  0.0453939397068
Iteration 84 Loss=  0.0447106810722
Iteration 85 Loss=  0.0440444249292
Iteration 86 Loss=  0.0433948320279
Iteration 87 Loss=  0.0427615525447
Iteration 88 Loss=  0.0421442260911
Iteration 89 Loss=  0.0415424821147
Iteration 90 Loss=  0.0409559406931
Iteration 91 Loss=  0.0403842137027
Iteration 92 Loss=  0.0398269063273
Iteration 93 Loss=  0.0392836188586
Iteration 94 Loss=  0.0387539487281
Iteration 95 Loss=  0.0382374927039
Iteration 96 Loss=  0.0377338491827
Iteration 97 Loss=  0.0372426205091
Iteration 98 Loss=  0.0367634152611
Iteration 99 Loss=  0.0362958504471
Iteration 100 Loss=  0.0358395535709
[ -1.75691859e-04   2.42480868e-04   8.49903325e-05 ...,   2.24590483e-04
   1.86298667e-05   1.09732468e-04]
CROSS VALIDATION 1
Iteration 1 Loss=  9.18373492998
Iteration 2 Loss=  0.21300775046
Iteration 3 Loss=  0.201131675652
Iteration 4 Loss=  0.195456261364
Iteration 5 Loss=  0.190614169893
Iteration 6 Loss=  0.186175889736
Iteration 7 Loss=  0.181993292565
Iteration 8 Loss=  0.177997880197
Iteration 9 Loss=  0.174152368914
Iteration 10 Loss=  0.170434130072
Iteration 11 Loss=  0.16682828127
Iteration 12 Loss=  0.163324398611
Iteration 13 Loss=  0.159914796394
Iteration 14 Loss=  0.156593559489
Iteration 15 Loss=  0.153355967024
Iteration 16 Loss=  0.150198132753
Iteration 17 Loss=  0.147116771749
Iteration 18 Loss=  0.14410904395
Iteration 19 Loss=  0.141172446221
Iteration 20 Loss=  0.138304735985
Iteration 21 Loss=  0.135503875999
Iteration 22 Loss=  0.13276799361
Iteration 23 Loss=  0.130095350154
Iteration 24 Loss=  0.127484317617
Iteration 25 Loss=  0.124933360546
Iteration 26 Loss=  0.122441021866
Iteration 27 Loss=  0.120005911606
Iteration 28 Loss=  0.117626697852
Iteration 29 Loss=  0.115302099385
Iteration 30 Loss=  0.113030879655
Iteration 31 Loss=  0.110811841764
Iteration 32 Loss=  0.108643824248
Iteration 33 Loss=  0.106525697467
Iteration 34 Loss=  0.10445636045
Iteration 35 Loss=  0.10243473809
Iteration 36 Loss=  0.100459778577
Iteration 37 Loss=  0.0985304510117
Iteration 38 Loss=  0.0966457431688
Iteration 39 Loss=  0.0948046593783
Iteration 40 Loss=  0.0930062185576
Iteration 41 Loss=  0.0912494524261
Iteration 42 Loss=  0.0895334039604
Iteration 43 Loss=  0.0878571261591
Iteration 44 Loss=  0.0862196811832
Iteration 45 Loss=  0.084620139929
Iteration 46 Loss=  0.0830575820676
Iteration 47 Loss=  0.0815310965585
Iteration 48 Loss=  0.080039782609
Iteration 49 Loss=  0.0785827510221
Iteration 50 Loss=  0.0771591258406
Iteration 51 Loss=  0.0757680461797
Iteration 52 Loss=  0.0744086681244
Iteration 53 Loss=  0.0730801665705
Iteration 54 Loss=  0.0717817368962
Iteration 55 Loss=  0.0705125963723
Iteration 56 Loss=  0.0692719852423
Iteration 57 Loss=  0.068059167434
Iteration 58 Loss=  0.0668734308896
Iteration 59 Loss=  0.0657140875285
Iteration 60 Loss=  0.0645804728778
Iteration 61 Loss=  0.063471945417
Iteration 62 Loss=  0.0623878856984
Iteration 63 Loss=  0.0613276953023
Iteration 64 Loss=  0.0602907956889
Iteration 65 Loss=  0.0592766270025
Iteration 66 Loss=  0.0582846468776
Iteration 67 Loss=  0.0573143292862
Iteration 68 Loss=  0.0563651634596
Iteration 69 Loss=  0.0554366529052
Iteration 70 Loss=  0.0545283145354
Iteration 71 Loss=  0.0536396779145
Iteration 72 Loss=  0.0527702846272
Iteration 73 Loss=  0.051919687764
Iteration 74 Loss=  0.05108745152
Iteration 75 Loss=  0.0502731508958
Iteration 76 Loss=  0.0494763714923
Iteration 77 Loss=  0.0486967093877
Iteration 78 Loss=  0.0479337710835
Iteration 79 Loss=  0.0471871735103
Iteration 80 Loss=  0.0464565440783
Iteration 81 Loss=  0.0457415207629
Iteration 82 Loss=  0.0450417522119
Iteration 83 Loss=  0.0443568978645
Iteration 84 Loss=  0.0436866280692
Iteration 85 Loss=  0.0430306241916
Iteration 86 Loss=  0.0423885787016
Iteration 87 Loss=  0.0417601952307
Iteration 88 Loss=  0.041145188593
Iteration 89 Loss=  0.0405432847626
Iteration 90 Loss=  0.0399542208037
Iteration 91 Loss=  0.0393777447493
Iteration 92 Loss=  0.0388136154286
Iteration 93 Loss=  0.0382616022436
Iteration 94 Loss=  0.0377214848966
Iteration 95 Loss=  0.0371930530748
Iteration 96 Loss=  0.0366761060952
Iteration 97 Loss=  0.0361704525199
Iteration 98 Loss=  0.0356759097482
Iteration 99 Loss=  0.0351923035953
Iteration 100 Loss=  0.0347194678683
[ -4.18643517e-04   1.47717833e-04  -1.68762327e-04 ...,   1.22388490e-04
  -4.88964670e-05   1.45264756e-04]
CROSS VALIDATION 2
Iteration 1 Loss=  2.77431133292
Iteration 2 Loss=  0.20799684412
Iteration 3 Loss=  0.202685413698
Iteration 4 Loss=  0.197997770506
Iteration 5 Loss=  0.193604362664
Iteration 6 Loss=  0.189401553811
Iteration 7 Loss=  0.18534436465
Iteration 8 Loss=  0.181409353118
Iteration 9 Loss=  0.177582657547
Iteration 10 Loss=  0.173855253473
Iteration 11 Loss=  0.17022079335
Iteration 12 Loss=  0.16667451926
Iteration 13 Loss=  0.163212672248
Iteration 14 Loss=  0.159832151399
Iteration 15 Loss=  0.156530307026
Iteration 16 Loss=  0.153304809885
Iteration 17 Loss=  0.150153565435
Iteration 18 Loss=  0.147074655844
Iteration 19 Loss=  0.144066299615
Iteration 20 Loss=  0.141126822759
Iteration 21 Loss=  0.138254637684
Iteration 22 Loss=  0.135448227386
Iteration 23 Loss=  0.132706133338
Iteration 24 Loss=  0.130026946002
Iteration 25 Loss=  0.127409297265
Iteration 26 Loss=  0.124851854271
Iteration 27 Loss=  0.122353314331
Iteration 28 Loss=  0.119912400654
Iteration 29 Loss=  0.117527858741
Iteration 30 Loss=  0.115198453335
Iteration 31 Loss=  0.112922965848
Iteration 32 Loss=  0.110700192233
Iteration 33 Loss=  0.108528941266
Iteration 34 Loss=  0.106408033242
Iteration 35 Loss=  0.104336299083
Iteration 36 Loss=  0.102312579853
Iteration 37 Loss=  0.100335726694
Iteration 38 Loss=  0.0984046011671
Iteration 39 Loss=  0.0965180759929
Iteration 40 Loss=  0.0946750361594
Iteration 41 Loss=  0.092874380363
Iteration 42 Loss=  0.0911150227314
Iteration 43 Loss=  0.0893958947658
Iteration 44 Loss=  0.0877159474327
Iteration 45 Loss=  0.0860741533308
Iteration 46 Loss=  0.0844695088552
Iteration 47 Loss=  0.082901036284
Iteration 48 Loss=  0.0813677857202
Iteration 49 Loss=  0.079868836827
Iteration 50 Loss=  0.0784033003122
Iteration 51 Loss=  0.0769703191257
Iteration 52 Loss=  0.075569069352
Iteration 53 Loss=  0.0741987607925
Iteration 54 Loss=  0.0728586372447
Iteration 55 Loss=  0.0715479764977
Iteration 56 Loss=  0.0702660900692
Iteration 57 Loss=  0.0690123227152
Iteration 58 Loss=  0.0677860517445
Iteration 59 Loss=  0.0665866861669
Iteration 60 Loss=  0.0654136657012
Iteration 61 Loss=  0.0642664596579
Iteration 62 Loss=  0.0631445657084
Iteration 63 Loss=  0.0620475085374
Iteration 64 Loss=  0.0609748383712
Iteration 65 Loss=  0.0599261293668
Iteration 66 Loss=  0.0589009778409
Iteration 67 Loss=  0.0578990003202
Iteration 68 Loss=  0.0569198313975
Iteration 69 Loss=  0.0559631213844
Iteration 70 Loss=  0.0550285337687
Iteration 71 Loss=  0.0541157424984
Iteration 72 Loss=  0.0532244291366
Iteration 73 Loss=  0.0523542799533
Iteration 74 Loss=  0.051504983042
Iteration 75 Loss=  0.0506762255685
Iteration 76 Loss=  0.0498676912682
Iteration 77 Loss=  0.0490790583169
Iteration 78 Loss=  0.0483099976862
Iteration 79 Loss=  0.0475601720789
Iteration 80 Loss=  0.046829235504
Iteration 81 Loss=  0.0461168335093
Iteration 82 Loss=  0.0454226040433
Iteration 83 Loss=  0.0447461788671
Iteration 84 Loss=  0.0440871853995
Iteration 85 Loss=  0.0434452488434
Iteration 86 Loss=  0.0428199944348
Iteration 87 Loss=  0.0422110496557
Iteration 88 Loss=  0.0416180462775
Iteration 89 Loss=  0.0410406221364
Iteration 90 Loss=  0.040478422588
Iteration 91 Loss=  0.0399311016341
Iteration 92 Loss=  0.0393983227564
Iteration 93 Loss=  0.0388797595243
Iteration 94 Loss=  0.0383750960637
Iteration 95 Loss=  0.0378840274772
Iteration 96 Loss=  0.0374062602975
Iteration 97 Loss=  0.0369415130358
Iteration 98 Loss=  0.0364895168564
Iteration 99 Loss=  0.0360500163767
Iteration 100 Loss=  0.0356227705581
[-0.00060005 -0.00022885 -0.00028811 ...,  0.00032985  0.00020163
  0.0001104 ]
CROSS VALIDATION 3
Iteration 1 Loss=  8.16188162159
Iteration 2 Loss=  0.213384198568
Iteration 3 Loss=  0.19538342191
Iteration 4 Loss=  0.19091222494
Iteration 5 Loss=  0.186683954011
Iteration 6 Loss=  0.18263252808
Iteration 7 Loss=  0.178723401347
Iteration 8 Loss=  0.17493615985
Iteration 9 Loss=  0.171257596496
Iteration 10 Loss=  0.167678533648
Iteration 11 Loss=  0.164192208942
Iteration 12 Loss=  0.160793389628
Iteration 13 Loss=  0.157477856427
Iteration 14 Loss=  0.154242087772
Iteration 15 Loss=  0.151083058864
Iteration 16 Loss=  0.14799810955
Iteration 17 Loss=  0.144984855108
Iteration 18 Loss=  0.142041124654
Iteration 19 Loss=  0.139164917828
Iteration 20 Loss=  0.136354373853
Iteration 21 Loss=  0.133607749092
Iteration 22 Loss=  0.130923400525
Iteration 23 Loss=  0.128299773322
Iteration 24 Loss=  0.125735391271
Iteration 25 Loss=  0.123228849143
Iteration 26 Loss=  0.120778806335
Iteration 27 Loss=  0.118383981324
Iteration 28 Loss=  0.116043146599
Iteration 29 Loss=  0.11375512384
Iteration 30 Loss=  0.111518779229
Iteration 31 Loss=  0.109333018791
Iteration 32 Loss=  0.107196783793
Iteration 33 Loss=  0.105109046188
Iteration 34 Loss=  0.103068804203
Iteration 35 Loss=  0.101075078123
Iteration 36 Loss=  0.099126906376
Iteration 37 Loss=  0.0972233420149
Iteration 38 Loss=  0.0953634496763
Iteration 39 Loss=  0.0935463030986
Iteration 40 Loss=  0.0917709832527
Iteration 41 Loss=  0.0900365771201
Iteration 42 Loss=  0.088342177123
Iteration 43 Loss=  0.0866868811844
Iteration 44 Loss=  0.0850697933688
Iteration 45 Loss=  0.0834900250242
Iteration 46 Loss=  0.0819466963292
Iteration 47 Loss=  0.0804389381294
Iteration 48 Loss=  0.0789658939387
Iteration 49 Loss=  0.0775267219818
Iteration 50 Loss=  0.0761205971556
Iteration 51 Loss=  0.0747467128065
Iteration 52 Loss=  0.0734042822327
Iteration 53 Loss=  0.072092539849
Iteration 54 Loss=  0.0708107419725
Iteration 55 Loss=  0.0695581672165
Iteration 56 Loss=  0.0683341164995
Iteration 57 Loss=  0.0671379126997
Iteration 58 Loss=  0.065968900001
Iteration 59 Loss=  0.0648264429852
Iteration 60 Loss=  0.0637099255373
Iteration 61 Loss=  0.0626187496241
Iteration 62 Loss=  0.0615523340118
Iteration 63 Loss=  0.0605101129771
Iteration 64 Loss=  0.0594915350571
Iteration 65 Loss=  0.058496061878
Iteration 66 Loss=  0.057523167085
Iteration 67 Loss=  0.0565723353899
Iteration 68 Loss=  0.0556430617412
Iteration 69 Loss=  0.0547348506144
Iteration 70 Loss=  0.0538472154133
Iteration 71 Loss=  0.0529796779714
Iteration 72 Loss=  0.05213176814
Iteration 73 Loss=  0.0513030234507
Iteration 74 Loss=  0.0504929888442
Iteration 75 Loss=  0.0497012164592
Iteration 76 Loss=  0.0489272654807
Iteration 77 Loss=  0.0481707020497
Iteration 78 Loss=  0.0474310992417
Iteration 79 Loss=  0.0467080371196
Iteration 80 Loss=  0.0460011028713
Iteration 81 Loss=  0.045309891037
Iteration 82 Loss=  0.0446340038302
Iteration 83 Loss=  0.0439730515526
Iteration 84 Loss=  0.0433266530958
Iteration 85 Loss=  0.042694436522
Iteration 86 Loss=  0.0420760397041
Iteration 87 Loss=  0.0414711110091
Iteration 88 Loss=  0.040879309999
Iteration 89 Loss=  0.0403003081255
Iteration 90 Loss=  0.0397337893929
Iteration 91 Loss=  0.0391794509652
Iteration 92 Loss=  0.0386370036948
Iteration 93 Loss=  0.0381061725556
Iteration 94 Loss=  0.0375866969662
Iteration 95 Loss=  0.0370783309928
Iteration 96 Loss=  0.0365808434284
Iteration 97 Loss=  0.0360940177482
Iteration 98 Loss=  0.0356176519449
Iteration 99 Loss=  0.0351515582525
Iteration 100 Loss=  0.0346955627692
[ -4.26604455e-04   1.69986916e-04  -1.66226111e-04 ...,   1.36020105e-04
  -4.30481278e-05   1.47888934e-04]
CROSS VALIDATION 4
Iteration 1 Loss=  8.01999962228
Iteration 2 Loss=  0.21160948375
Iteration 3 Loss=  0.195026229316
Iteration 4 Loss=  0.19050811321
Iteration 5 Loss=  0.186259779496
Iteration 6 Loss=  0.182200587499
Iteration 7 Loss=  0.1782901736
Iteration 8 Loss=  0.17450536715
Iteration 9 Loss=  0.170831492121
Iteration 10 Loss=  0.167258516467
Iteration 11 Loss=  0.163779145369
Iteration 12 Loss=  0.160387795107
Iteration 13 Loss=  0.157080004072
Iteration 14 Loss=  0.153852076871
Iteration 15 Loss=  0.150700860115
Iteration 16 Loss=  0.147623596253
Iteration 17 Loss=  0.144617825538
Iteration 18 Loss=  0.141681318701
Iteration 19 Loss=  0.138812029765
Iteration 20 Loss=  0.136008062381
Iteration 21 Loss=  0.133267645382
Iteration 22 Loss=  0.130589114715
Iteration 23 Loss=  0.127970899788
Iteration 24 Loss=  0.125411512876
Iteration 25 Loss=  0.122909540643
Iteration 26 Loss=  0.120463637075
Iteration 27 Loss=  0.118072517378
Iteration 28 Loss=  0.115734952478
Iteration 29 Loss=  0.113449763937
Iteration 30 Loss=  0.111215819121
Iteration 31 Loss=  0.109032026586
Iteration 32 Loss=  0.106897331631
Iteration 33 Loss=  0.104810712065
Iteration 34 Loss=  0.102771174205
Iteration 35 Loss=  0.100777749175
Iteration 36 Loss=  0.0988294895548
Iteration 37 Loss=  0.0969254664362
Iteration 38 Loss=  0.0950647669384
Iteration 39 Loss=  0.0932464922095
Iteration 40 Loss=  0.0914697559348
Iteration 41 Loss=  0.0897336833491
Iteration 42 Loss=  0.0880374107296
Iteration 43 Loss=  0.0863800853283
Iteration 44 Loss=  0.0847608656847
Iteration 45 Loss=  0.0831789222421
Iteration 46 Loss=  0.0816334381824
Iteration 47 Loss=  0.0801236103858
Iteration 48 Loss=  0.078648650421
Iteration 49 Loss=  0.0772077854737
Iteration 50 Loss=  0.0758002591328
Iteration 51 Loss=  0.0744253319644
Iteration 52 Loss=  0.073082281822
Iteration 53 Loss=  0.0717704038599
Iteration 54 Loss=  0.0704890102363
Iteration 55 Loss=  0.069237429514
Iteration 56 Loss=  0.0680150057827
Iteration 57 Loss=  0.0668210975443
Iteration 58 Loss=  0.0656550764128
Iteration 59 Loss=  0.0645163256923
Iteration 60 Loss=  0.0634042388976
Iteration 61 Loss=  0.0623182182865
Iteration 62 Loss=  0.0612576734662
Iteration 63 Loss=  0.0602220201357
Iteration 64 Loss=  0.0592106790116
Iteration 65 Loss=  0.0582230749796
Iteration 66 Loss=  0.0572586364974
Iteration 67 Loss=  0.0563167952658
Iteration 68 Loss=  0.0553969861694
Iteration 69 Loss=  0.0544986474769
Iteration 70 Loss=  0.0536212212816
Iteration 71 Loss=  0.0527641541531
Iteration 72 Loss=  0.051926897964
Iteration 73 Loss=  0.0511089108538
Iteration 74 Loss=  0.0503096582889
Iteration 75 Loss=  0.0495286141798
Iteration 76 Loss=  0.0487652620184
Iteration 77 Loss=  0.0480190960044
Iteration 78 Loss=  0.0472896221325
Iteration 79 Loss=  0.0465763592192
Iteration 80 Loss=  0.0458788398529
Iteration 81 Loss=  0.0451966112563
Iteration 82 Loss=  0.0445292360514
Iteration 83 Loss=  0.0438762929249
Iteration 84 Loss=  0.0432373771908
Iteration 85 Loss=  0.0426121012486
Iteration 86 Loss=  0.0420000949392
Iteration 87 Loss=  0.0414010057981
Iteration 88 Loss=  0.0408144992076
Iteration 89 Loss=  0.0402402584494
Iteration 90 Loss=  0.0396779846586
Iteration 91 Loss=  0.039127396683
Iteration 92 Loss=  0.0385882308478
Iteration 93 Loss=  0.0380602406326
Iteration 94 Loss=  0.0375431962613
Iteration 95 Loss=  0.0370368842145
Iteration 96 Loss=  0.0365411066682
Iteration 97 Loss=  0.0360556808685
Iteration 98 Loss=  0.0355804384516
Iteration 99 Loss=  0.0351152247178
Iteration 100 Loss=  0.0346598978727
[ -4.15718609e-04   1.75806337e-04  -1.62317958e-04 ...,   1.33254841e-04
  -3.95627398e-05   1.48965165e-04]
CROSS VALIDATION 5
Iteration 1 Loss=  6.86613587709
Iteration 2 Loss=  0.202925907849
Iteration 3 Loss=  0.198453118239
Iteration 4 Loss=  0.19417684848
Iteration 5 Loss=  0.190050118757
Iteration 6 Loss=  0.186048813464
Iteration 7 Loss=  0.182158660522
Iteration 8 Loss=  0.178370295209
Iteration 9 Loss=  0.174677060077
Iteration 10 Loss=  0.171073907819
Iteration 11 Loss=  0.167556806699
Iteration 12 Loss=  0.164122396928
Iteration 13 Loss=  0.160767781604
Iteration 14 Loss=  0.157490394081
Iteration 15 Loss=  0.154287910845
Iteration 16 Loss=  0.151158192601
Iteration 17 Loss=  0.148099243438
Iteration 18 Loss=  0.145109181938
Iteration 19 Loss=  0.142186220383
Iteration 20 Loss=  0.139328649578
Iteration 21 Loss=  0.136534827653
Iteration 22 Loss=  0.133803171738
Iteration 23 Loss=  0.131132151746
Iteration 24 Loss=  0.128520285723
Iteration 25 Loss=  0.125966136369
Iteration 26 Loss=  0.123468308441
Iteration 27 Loss=  0.12102544682
Iteration 28 Loss=  0.118636235059
Iteration 29 Loss=  0.116299394275
Iteration 30 Loss=  0.114013682284
Iteration 31 Loss=  0.111777892881
Iteration 32 Loss=  0.109590855211
Iteration 33 Loss=  0.107451433168
Iteration 34 Loss=  0.105358524808
Iteration 35 Loss=  0.103311061753
Iteration 36 Loss=  0.101308008585
Iteration 37 Loss=  0.0993483622313
Iteration 38 Loss=  0.0974311513618
Iteration 39 Loss=  0.0955554358074
Iteration 40 Loss=  0.0937203060107
Iteration 41 Loss=  0.0919248825191
Iteration 42 Loss=  0.090168315522
Iteration 43 Loss=  0.0884497844252
Iteration 44 Loss=  0.0867684974493
Iteration 45 Loss=  0.0851236912328
Iteration 46 Loss=  0.0835146304136
Iteration 47 Loss=  0.0819406071626
Iteration 48 Loss=  0.0804009406384
Iteration 49 Loss=  0.0788949763393
Iteration 50 Loss=  0.0774220853273
Iteration 51 Loss=  0.0759816633064
Iteration 52 Loss=  0.0745731295446
Iteration 53 Loss=  0.0731959256326
Iteration 54 Loss=  0.0718495140802
Iteration 55 Loss=  0.0705333767572
Iteration 56 Loss=  0.0692470131876
Iteration 57 Loss=  0.0679899387137
Iteration 58 Loss=  0.0667616825445
Iteration 59 Loss=  0.0655617857077
Iteration 60 Loss=  0.0643897989254
Iteration 61 Loss=  0.0632452804332
Iteration 62 Loss=  0.0621277937645
Iteration 63 Loss=  0.061036905523
Iteration 64 Loss=  0.0599721831695
Iteration 65 Loss=  0.0589331928489
Iteration 66 Loss=  0.0579194972907
Iteration 67 Loss=  0.0569306538175
Iteration 68 Loss=  0.0559662125014
Iteration 69 Loss=  0.0550257145107
Iteration 70 Loss=  0.0541086906957
Iteration 71 Loss=  0.0532146604584
Iteration 72 Loss=  0.0523431309569
Iteration 73 Loss=  0.0514935966869
Iteration 74 Loss=  0.0506655394785
Iteration 75 Loss=  0.0498584289375
Iteration 76 Loss=  0.0490717233472
Iteration 77 Loss=  0.0483048710308
Iteration 78 Loss=  0.0475573121584
Iteration 79 Loss=  0.0468284809649
Iteration 80 Loss=  0.0461178083265
Iteration 81 Loss=  0.0454247246276
Iteration 82 Loss=  0.0447486628384
Iteration 83 Loss=  0.0440890617111
Iteration 84 Loss=  0.0434453689988
Iteration 85 Loss=  0.0428170446001
Iteration 86 Loss=  0.0422035635348
Iteration 87 Loss=  0.0416044186648
Iteration 88 Loss=  0.0410191230835
Iteration 89 Loss=  0.0404472121146
Iteration 90 Loss=  0.0398882448718
Iteration 91 Loss=  0.0393418053553
Iteration 92 Loss=  0.0388075030724
Iteration 93 Loss=  0.0382849731927
Iteration 94 Loss=  0.0377738762616
Iteration 95 Loss=  0.0372738975135
Iteration 96 Loss=  0.0367847458353
Iteration 97 Loss=  0.0363061524453
Iteration 98 Loss=  0.0358378693539
Iteration 99 Loss=  0.0353796676797
Iteration 100 Loss=  0.0349313358931
[ -3.21742332e-04   2.17931071e-04  -1.63539347e-04 ...,   6.68397546e-05
  -3.95099203e-05   1.78657037e-04]
CROSS VALIDATION 6
Iteration 1 Loss=  8.01505676005
Iteration 2 Loss=  0.21153734576
Iteration 3 Loss=  0.195004767372
Iteration 4 Loss=  0.190485825356
Iteration 5 Loss=  0.18623755284
Iteration 6 Loss=  0.182178820173
Iteration 7 Loss=  0.178269089851
Iteration 8 Loss=  0.174485117372
Iteration 9 Loss=  0.170812192358
Iteration 10 Loss=  0.167240266578
Iteration 11 Loss=  0.163762038445
Iteration 12 Loss=  0.160371922864
Iteration 13 Loss=  0.157065460237
Iteration 14 Loss=  0.153838959475
Iteration 15 Loss=  0.150689273167
Iteration 16 Loss=  0.147613651024
Iteration 17 Loss=  0.144609641578
Iteration 18 Loss=  0.141675024656
Iteration 19 Loss=  0.138807764021
Iteration 20 Loss=  0.13600597354
Iteration 21 Loss=  0.133267892568
Iteration 22 Loss=  0.13059186769
Iteration 23 Loss=  0.127976338853
Iteration 24 Loss=  0.125419828548
Iteration 25 Loss=  0.122920933059
Iteration 26 Loss=  0.120478315119
Iteration 27 Loss=  0.118090697488
Iteration 28 Loss=  0.115756857128
Iteration 29 Loss=  0.113475619765
Iteration 30 Loss=  0.111245854707
Iteration 31 Loss=  0.109066469862
Iteration 32 Loss=  0.106936406956
Iteration 33 Loss=  0.10485463697
Iteration 34 Loss=  0.102820155855
Iteration 35 Loss=  0.100831980595
Iteration 36 Loss=  0.098889145683
Iteration 37 Loss=  0.0969907001002
Iteration 38 Loss=  0.0951357048329
Iteration 39 Loss=  0.0933232309934
Iteration 40 Loss=  0.0915523585593
Iteration 41 Loss=  0.0898221757358
Iteration 42 Loss=  0.0881317789175
Iteration 43 Loss=  0.0864802732007
Iteration 44 Loss=  0.0848667733748
Iteration 45 Loss=  0.0832904052989
Iteration 46 Loss=  0.0817503075543
Iteration 47 Loss=  0.0802456332547
Iteration 48 Loss=  0.0787755518873
Iteration 49 Loss=  0.0773392510672
Iteration 50 Loss=  0.0759359380907
Iteration 51 Loss=  0.0745648411941
Iteration 52 Loss=  0.0732252104431
Iteration 53 Loss=  0.0719163182008
Iteration 54 Loss=  0.0706374591512
Iteration 55 Loss=  0.0693879498796
Iteration 56 Loss=  0.0681671280342
Iteration 57 Loss=  0.0669743511179
Iteration 58 Loss=  0.0658089949728
Iteration 59 Loss=  0.0646704520364
Iteration 60 Loss=  0.0635581294518
Iteration 61 Loss=  0.0624714471215
Iteration 62 Loss=  0.0614098357868
Iteration 63 Loss=  0.0603727352148
Iteration 64 Loss=  0.0593595925578
Iteration 65 Loss=  0.0583698609441
Iteration 66 Loss=  0.0574029983396
Iteration 67 Loss=  0.0564584667075
Iteration 68 Loss=  0.0555357314761
Iteration 69 Loss=  0.0546342613109
Iteration 70 Loss=  0.0537535281753
Iteration 71 Loss=  0.0528930076515
Iteration 72 Loss=  0.0520521794876
Iteration 73 Loss=  0.0512305283303
Iteration 74 Loss=  0.0504275446009
Iteration 75 Loss=  0.0496427254715
Iteration 76 Loss=  0.0488755759037
Iteration 77 Loss=  0.0481256097112
Iteration 78 Loss=  0.0473923506168
Iteration 79 Loss=  0.0466753332784
Iteration 80 Loss=  0.0459741042619
Iteration 81 Loss=  0.0452882229478
Iteration 82 Loss=  0.044617262358
Iteration 83 Loss=  0.0439608098957
Iteration 84 Loss=  0.0433184679932
Iteration 85 Loss=  0.0426898546627
Iteration 86 Loss=  0.0420746039496
Iteration 87 Loss=  0.0414723662849
Iteration 88 Loss=  0.0408828087373
Iteration 89 Loss=  0.0403056151657
Iteration 90 Loss=  0.0397404862715
Iteration 91 Loss=  0.0391871395539
Iteration 92 Loss=  0.0386453091717
Iteration 93 Loss=  0.0381147457136
Iteration 94 Loss=  0.0375952158857
Iteration 95 Loss=  0.0370865021201
Iteration 96 Loss=  0.0365884021142
Iteration 97 Loss=  0.0361007283076
Iteration 98 Loss=  0.0356233073087
Iteration 99 Loss=  0.0351559792774
Iteration 100 Loss=  0.034698597277
[ -4.24501365e-04   1.71308011e-04  -1.61583775e-04 ...,   1.28532682e-04
  -4.38321682e-05   1.47171415e-04]
CROSS VALIDATION 7
Iteration 1 Loss=  8.03428044167
Iteration 2 Loss=  0.21176609459
Iteration 3 Loss=  0.194993185236
Iteration 4 Loss=  0.190478065663
Iteration 5 Loss=  0.186226311779
Iteration 6 Loss=  0.182160633891
Iteration 7 Loss=  0.178241948405
Iteration 8 Loss=  0.174447670209
Iteration 9 Loss=  0.170763430987
Iteration 10 Loss=  0.167179382721
Iteration 11 Loss=  0.16368835639
Iteration 12 Loss=  0.160284866578
Iteration 13 Loss=  0.15696453802
Iteration 14 Loss=  0.153723757944
Iteration 15 Loss=  0.150559456283
Iteration 16 Loss=  0.147468961785
Iteration 17 Loss=  0.144449904951
Iteration 18 Loss=  0.141500150822
Iteration 19 Loss=  0.138617751335
Iteration 20 Loss=  0.135800910771
Iteration 21 Loss=  0.133047960156
Iteration 22 Loss=  0.130357337833
Iteration 23 Loss=  0.127727574341
Iteration 24 Loss=  0.125157280313
Iteration 25 Loss=  0.122645136502
Iteration 26 Loss=  0.120189885281
Iteration 27 Loss=  0.1177903232
Iteration 28 Loss=  0.115445294278
Iteration 29 Loss=  0.113153683842
Iteration 30 Loss=  0.110914412782
Iteration 31 Loss=  0.108726432166
Iteration 32 Loss=  0.106588718202
Iteration 33 Loss=  0.104500267553
Iteration 34 Loss=  0.102460093069
Iteration 35 Loss=  0.100467219979
Iteration 36 Loss=  0.0985206826136
Iteration 37 Loss=  0.0966195217364
Iteration 38 Loss=  0.0947627825173
Iteration 39 Loss=  0.0929495132079
Iteration 40 Loss=  0.0911787645282
Iteration 41 Loss=  0.0894495897573
Iteration 42 Loss=  0.087761045491
Iteration 43 Loss=  0.0861121929968
Iteration 44 Loss=  0.0845021000694
Iteration 45 Loss=  0.0829298432659
Iteration 46 Loss=  0.0813945103797
Iteration 47 Loss=  0.0798952030045
Iteration 48 Loss=  0.0784310390387
Iteration 49 Loss=  0.0770011549876
Iteration 50 Loss=  0.0756047079423
Iteration 51 Loss=  0.0742408771353
Iteration 52 Loss=  0.0729088650068
Iteration 53 Loss=  0.0716078977462
Iteration 54 Loss=  0.0703372253074
Iteration 55 Loss=  0.0690961209256
Iteration 56 Loss=  0.0678838801914
Iteration 57 Loss=  0.0666998197547
Iteration 58 Loss=  0.0655432757474
Iteration 59 Loss=  0.0644136020189
Iteration 60 Loss=  0.0633101682793
Iteration 61 Loss=  0.0622323582422
Iteration 62 Loss=  0.0611795678472
Iteration 63 Loss=  0.0601512036325
Iteration 64 Loss=  0.0591466813142
Iteration 65 Loss=  0.0581654246097
Iteration 66 Loss=  0.0572068643325
Iteration 67 Loss=  0.0562704377674
Iteration 68 Loss=  0.0553555883221
Iteration 69 Loss=  0.0544617654408
Iteration 70 Loss=  0.053588424755
Iteration 71 Loss=  0.0527350284404
Iteration 72 Loss=  0.0519010457443
Iteration 73 Loss=  0.0510859536456
Iteration 74 Loss=  0.050289237611
Iteration 75 Loss=  0.0495103924127
Iteration 76 Loss=  0.0487489229747
Iteration 77 Loss=  0.0480043452232
Iteration 78 Loss=  0.0472761869157
Iteration 79 Loss=  0.0465639884337
Iteration 80 Loss=  0.0458673035233
Iteration 81 Loss=  0.0451856999742
Iteration 82 Loss=  0.0445187602297
Iteration 83 Loss=  0.0438660819227
Iteration 84 Loss=  0.0432272783323
Iteration 85 Loss=  0.0426019787608
Iteration 86 Loss=  0.0419898288266
Iteration 87 Loss=  0.041390490673
Iteration 88 Loss=  0.040803643092
Iteration 89 Loss=  0.0402289815618
Iteration 90 Loss=  0.0396662182
Iteration 91 Loss=  0.0391150816328
Iteration 92 Loss=  0.0385753167823
Iteration 93 Loss=  0.038046684577
Iteration 94 Loss=  0.0375289615876
Iteration 95 Loss=  0.0370219395955
Iteration 96 Loss=  0.0365254251005
Iteration 97 Loss=  0.0360392387743
Iteration 98 Loss=  0.0355632148699
Iteration 99 Loss=  0.0350972005945
Iteration 100 Loss=  0.0346410554561
[ -4.30071222e-04   1.70483725e-04  -1.67495461e-04 ...,   1.25796296e-04
  -4.61596776e-05   1.49472066e-04]
CROSS VALIDATION 8
Iteration 1 Loss=  8.02062735276
Iteration 2 Loss=  0.212151093961
Iteration 3 Loss=  0.195067871411
Iteration 4 Loss=  0.19056333244
Iteration 5 Loss=  0.186320643676
Iteration 6 Loss=  0.182263695336
Iteration 7 Loss=  0.178353797132
Iteration 8 Loss=  0.174568517411
Iteration 9 Loss=  0.170893546604
Iteration 10 Loss=  0.167319049816
Iteration 11 Loss=  0.163837845115
Iteration 12 Loss=  0.160444417046
Iteration 13 Loss=  0.157134347714
Iteration 14 Loss=  0.15390397176
Iteration 15 Loss=  0.150750158346
Iteration 16 Loss=  0.147670168662
Iteration 17 Loss=  0.14466156012
Iteration 18 Loss=  0.141722120373
Iteration 19 Loss=  0.138849820915
Iteration 20 Loss=  0.136042783823
Iteration 21 Loss=  0.133299257469
Iteration 22 Loss=  0.130617598409
Iteration 23 Loss=  0.127996257575
Iteration 24 Loss=  0.125433769439
Iteration 25 Loss=  0.122928743228
Iteration 26 Loss=  0.12047985554
Iteration 27 Loss=  0.1180858439
Iteration 28 Loss=  0.115745500936
Iteration 29 Loss=  0.113457668974
Iteration 30 Loss=  0.111221234922
Iteration 31 Loss=  0.109035125375
Iteration 32 Loss=  0.106898301932
Iteration 33 Loss=  0.104809756733
Iteration 34 Loss=  0.102768508268
Iteration 35 Loss=  0.100773597501
Iteration 36 Loss=  0.0988240843683
Iteration 37 Loss=  0.096919044722
Iteration 38 Loss=  0.0950575677546
Iteration 39 Loss=  0.093238753946
Iteration 40 Loss=  0.0914617135542
Iteration 41 Loss=  0.089725565647
Iteration 42 Loss=  0.0880294376565
Iteration 43 Loss=  0.086372465414
Iteration 44 Loss=  0.084753793607
Iteration 45 Loss=  0.0831725765821
Iteration 46 Loss=  0.0816279794086
Iteration 47 Loss=  0.0801191791075
Iteration 48 Loss=  0.0786453659507
Iteration 49 Loss=  0.0772057447392
Iteration 50 Loss=  0.0757995359742
Iteration 51 Loss=  0.0744259768497
Iteration 52 Loss=  0.0730843220084
Iteration 53 Loss=  0.0717738440198
Iteration 54 Loss=  0.0704938335563
Iteration 55 Loss=  0.0692435992619
Iteration 56 Loss=  0.0680224673212
Iteration 57 Loss=  0.0668297807524
Iteration 58 Loss=  0.06566489846
Iteration 59 Loss=  0.0645271940902
Iteration 60 Loss=  0.0634160547403
Iteration 61 Loss=  0.0623308795762
Iteration 62 Loss=  0.0612710784135
Iteration 63 Loss=  0.0602360703157
Iteration 64 Loss=  0.0592252822614
Iteration 65 Loss=  0.0582381479258
Iteration 66 Loss=  0.057274106615
Iteration 67 Loss=  0.0563326023858
Iteration 68 Loss=  0.0554130833731
Iteration 69 Loss=  0.0545150013415
Iteration 70 Loss=  0.053637811466
Iteration 71 Loss=  0.0527809723441
Iteration 72 Loss=  0.0519439462296
Iteration 73 Loss=  0.0511261994781
Iteration 74 Loss=  0.0503272031858
Iteration 75 Loss=  0.0495464340014
Iteration 76 Loss=  0.0487833750895
Iteration 77 Loss=  0.0480375172185
Iteration 78 Loss=  0.0473083599483
Iteration 79 Loss=  0.0465954128887
Iteration 80 Loss=  0.045898197001
Iteration 81 Loss=  0.0452162459112
Iteration 82 Loss=  0.0445491072059
Iteration 83 Loss=  0.0438963436809
Iteration 84 Loss=  0.04325753451
Iteration 85 Loss=  0.042632276309
Iteration 86 Loss=  0.0420201840657
Iteration 87 Loss=  0.0414208919148
Iteration 88 Loss=  0.0408340537383
Iteration 89 Loss=  0.0402593435781
Iteration 90 Loss=  0.0396964558527
Iteration 91 Loss=  0.0391451053767
Iteration 92 Loss=  0.0386050271861
Iteration 93 Loss=  0.0380759761794
Iteration 94 Loss=  0.0375577265895
Iteration 95 Loss=  0.0370500713046
Iteration 96 Loss=  0.0365528210589
Iteration 97 Loss=  0.0360658035191
Iteration 98 Loss=  0.0355888622891
Iteration 99 Loss=  0.0351218558593
Iteration 100 Loss=  0.0346646565224
[ -4.16561807e-04   1.76262928e-04  -1.49587294e-04 ...,   1.30587005e-04
  -4.97631823e-05   1.46470267e-04]
CROSS VALIDATION 9
Iteration 1 Loss=  8.08297741723
Iteration 2 Loss=  0.247179929882
Iteration 3 Loss=  0.227632498206
Iteration 4 Loss=  0.222346602113
Iteration 5 Loss=  0.217384420968
Iteration 6 Loss=  0.212638227094
Iteration 7 Loss=  0.208059298933
Iteration 8 Loss=  0.203621184756
Iteration 9 Loss=  0.199307679636
Iteration 10 Loss=  0.195107926749
Iteration 11 Loss=  0.191014120801
Iteration 12 Loss=  0.187020319033
Iteration 13 Loss=  0.183121778024
Iteration 14 Loss=  0.179314561612
Iteration 15 Loss=  0.175595298039
Iteration 16 Loss=  0.171961023706
Iteration 17 Loss=  0.168409079464
Iteration 18 Loss=  0.164937039966
Iteration 19 Loss=  0.161542664498
Iteration 20 Loss=  0.158223862109
Iteration 21 Loss=  0.154978666484
Iteration 22 Loss=  0.151805217533
Iteration 23 Loss=  0.148701747674
Iteration 24 Loss=  0.145666571405
Iteration 25 Loss=  0.142698077166
Iteration 26 Loss=  0.1397947208
Iteration 27 Loss=  0.136955020106
Iteration 28 Loss=  0.134177550124
Iteration 29 Loss=  0.131460938911
Iteration 30 Loss=  0.12880386364
Iteration 31 Loss=  0.126205046916
Iteration 32 Loss=  0.123663253264
Iteration 33 Loss=  0.121177285761
Iteration 34 Loss=  0.118745982813
Iteration 35 Loss=  0.116368215114
Iteration 36 Loss=  0.114042882796
Iteration 37 Loss=  0.111768912815
Iteration 38 Loss=  0.109545256588
Iteration 39 Loss=  0.107370887904
Iteration 40 Loss=  0.10524480113
Iteration 41 Loss=  0.10316600968
Iteration 42 Loss=  0.101133544765
Iteration 43 Loss=  0.099146454373
Iteration 44 Loss=  0.0972038024674
Iteration 45 Loss=  0.095304668346
Iteration 46 Loss=  0.0934481461381
Iteration 47 Loss=  0.0916333443942
Iteration 48 Loss=  0.0898593857413
Iteration 49 Loss=  0.0881254065804
Iteration 50 Loss=  0.0864305568148
Iteration 51 Loss=  0.0847739996082
Iteration 52 Loss=  0.0831549111783
Iteration 53 Loss=  0.0815724806436
Iteration 54 Loss=  0.0800259099398
Iteration 55 Loss=  0.0785144138287
Iteration 56 Loss=  0.0770372200137
Iteration 57 Loss=  0.0755935693755
Iteration 58 Loss=  0.0741827163282
Iteration 59 Loss=  0.0728039292892
Iteration 60 Loss=  0.0714564912446
Iteration 61 Loss=  0.0701397003807
Iteration 62 Loss=  0.0688528707474
Iteration 63 Loss=  0.0675953329106
Iteration 64 Loss=  0.066366434551
Iteration 65 Loss=  0.0651655409667
Iteration 66 Loss=  0.0639920354407
Iteration 67 Loss=  0.0628453194414
Iteration 68 Loss=  0.0617248126339
Iteration 69 Loss=  0.060629952687
Iteration 70 Loss=  0.0595601948742
Iteration 71 Loss=  0.0585150114747
Iteration 72 Loss=  0.0574938909902
Iteration 73 Loss=  0.0564963372004
Iteration 74 Loss=  0.0555218680856
Iteration 75 Loss=  0.0545700146489
Iteration 76 Loss=  0.0536403196713
Iteration 77 Loss=  0.0527323364329
Iteration 78 Loss=  0.051845627432
Iteration 79 Loss=  0.0509797631307
Iteration 80 Loss=  0.0501343207522
Iteration 81 Loss=  0.0493088831509
Iteration 82 Loss=  0.0485030377739
Iteration 83 Loss=  0.0477163757293
Iteration 84 Loss=  0.0469484909739
Iteration 85 Loss=  0.0461989796318
Iteration 86 Loss=  0.0454674394564
Iteration 87 Loss=  0.0447534694432
Iteration 88 Loss=  0.0440566696068
Iteration 89 Loss=  0.0433766409268
Iteration 90 Loss=  0.0427129854725
Iteration 91 Loss=  0.0420653067078
Iteration 92 Loss=  0.0414332099775
Iteration 93 Loss=  0.0408163031683
Iteration 94 Loss=  0.0402141975335
Iteration 95 Loss=  0.0396265086637
Iteration 96 Loss=  0.0390528575792
Iteration 97 Loss=  0.038492871915
Iteration 98 Loss=  0.0379461871642
Iteration 99 Loss=  0.0374124479443
Iteration 100 Loss=  0.0368913092486
[ -3.83137533e-04   2.02460620e-04  -1.12092875e-04 ...,   2.57630342e-04
  -3.30756685e-05   1.43159658e-04]
CROSS VALIDATION 10
Iteration 1 Loss=  7.47820113366
Iteration 2 Loss=  0.254717584645
Iteration 3 Loss=  0.249071636668
Iteration 4 Loss=  0.243683518841
Iteration 5 Loss=  0.238482363032
Iteration 6 Loss=  0.233435318255
Iteration 7 Loss=  0.228524113651
Iteration 8 Loss=  0.223737220896
Iteration 9 Loss=  0.21906663949
Iteration 10 Loss=  0.214506387138
Iteration 11 Loss=  0.21005171823
Iteration 12 Loss=  0.205698688117
Iteration 13 Loss=  0.201443895585
Iteration 14 Loss=  0.197284323272
Iteration 15 Loss=  0.193217234882
Iteration 16 Loss=  0.189240106804
Iteration 17 Loss=  0.185350581396
Iteration 18 Loss=  0.181546434345
Iteration 19 Loss=  0.177825551445
Iteration 20 Loss=  0.174185911825
Iteration 21 Loss=  0.170625575684
Iteration 22 Loss=  0.167142675223
Iteration 23 Loss=  0.16373540787
Iteration 24 Loss=  0.160402031157
Iteration 25 Loss=  0.157140858776
Iteration 26 Loss=  0.153950257476
Iteration 27 Loss=  0.150828644535
Iteration 28 Loss=  0.147774485601
Iteration 29 Loss=  0.144786292766
Iteration 30 Loss=  0.141862622738
Iteration 31 Loss=  0.139002075056
Iteration 32 Loss=  0.136203290266
Iteration 33 Loss=  0.133464948055
Iteration 34 Loss=  0.130785765311
Iteration 35 Loss=  0.128164494136
Iteration 36 Loss=  0.125599919815
Iteration 37 Loss=  0.123090858781
Iteration 38 Loss=  0.120636156601
Iteration 39 Loss=  0.11823468603
Iteration 40 Loss=  0.115885345148
Iteration 41 Loss=  0.11358705563
Iteration 42 Loss=  0.111338761154
Iteration 43 Loss=  0.109139425972
Iteration 44 Loss=  0.10698803366
Iteration 45 Loss=  0.104883586041
Iteration 46 Loss=  0.102825102284
Iteration 47 Loss=  0.100811618177
Iteration 48 Loss=  0.0988421855651
Iteration 49 Loss=  0.0969158719366
Iteration 50 Loss=  0.0950317601541
Iteration 51 Loss=  0.0931889483079
Iteration 52 Loss=  0.0913865496813
Iteration 53 Loss=  0.0896236928069
Iteration 54 Loss=  0.0878995215975
Iteration 55 Loss=  0.0862131955314
Iteration 56 Loss=  0.084563889871
Iteration 57 Loss=  0.0829507958958
Iteration 58 Loss=  0.0813731211303
Iteration 59 Loss=  0.079830089549
Iteration 60 Loss=  0.0783209417453
Iteration 61 Loss=  0.0768449350523
Iteration 62 Loss=  0.0754013436111
Iteration 63 Loss=  0.0739894583833
Iteration 64 Loss=  0.0726085871112
Iteration 65 Loss=  0.0712580542335
Iteration 66 Loss=  0.0699372007656
Iteration 67 Loss=  0.0686453841585
Iteration 68 Loss=  0.0673819781491
Iteration 69 Loss=  0.0661463726162
Iteration 70 Loss=  0.064937973455
Iteration 71 Loss=  0.0637562024783
Iteration 72 Loss=  0.062600497352
Iteration 73 Loss=  0.0614703115647
Iteration 74 Loss=  0.0603651144303
Iteration 75 Loss=  0.0592843911128
Iteration 76 Loss=  0.0582276426611
Iteration 77 Loss=  0.0571943860373
Iteration 78 Loss=  0.0561841541161
Iteration 79 Loss=  0.055196495635
Iteration 80 Loss=  0.0542309750713
Iteration 81 Loss=  0.0532871724269
Iteration 82 Loss=  0.0523646829014
Iteration 83 Loss=  0.0514631164428
Iteration 84 Loss=  0.0505820971681
Iteration 85 Loss=  0.0497212626538
Iteration 86 Loss=  0.0488802631055
Iteration 87 Loss=  0.0480587604178
Iteration 88 Loss=  0.0472564271478
Iteration 89 Loss=  0.0464729454233
Iteration 90 Loss=  0.0457080058164
Iteration 91 Loss=  0.0449613062078
Iteration 92 Loss=  0.0442325506715
Iteration 93 Loss=  0.043521448405
Iteration 94 Loss=  0.0428277127258
Iteration 95 Loss=  0.0421510601541
Iteration 96 Loss=  0.0414912095937
Iteration 97 Loss=  0.040847881623
Iteration 98 Loss=  0.0402207979018
Iteration 99 Loss=  0.0396096807009
Iteration 100 Loss=  0.0390142525567
[ -3.89714754e-04   1.66322229e-04  -1.80285245e-04 ...,   2.45657513e-04
  -1.57387758e-05   1.53089928e-04]
CROSS VALIDATION 11
Iteration 1 Loss=  8.01738795911
Iteration 2 Loss=  0.211619619717
Iteration 3 Loss=  0.19507806347
Iteration 4 Loss=  0.190558636534
Iteration 5 Loss=  0.186309108843
Iteration 6 Loss=  0.182248734977
Iteration 7 Loss=  0.178337129678
Iteration 8 Loss=  0.174551116971
Iteration 9 Loss=  0.170876018694
Iteration 10 Loss=  0.167301800817
Iteration 11 Loss=  0.163821165987
Iteration 12 Loss=  0.160428527263
Iteration 13 Loss=  0.157119419158
Iteration 14 Loss=  0.153890141776
Iteration 15 Loss=  0.150737536653
Iteration 16 Loss=  0.147658840619
Iteration 17 Loss=  0.144651587796
Iteration 18 Loss=  0.141713542298
Iteration 19 Loss=  0.138842651082
Iteration 20 Loss=  0.136037010317
Iteration 21 Loss=  0.133294841001
Iteration 22 Loss=  0.130614470955
Iteration 23 Loss=  0.12799432126
Iteration 24 Loss=  0.125432895781
Iteration 25 Loss=  0.122928772819
Iteration 26 Loss=  0.120480598225
Iteration 27 Loss=  0.118087079487
Iteration 28 Loss=  0.115746980468
Iteration 29 Loss=  0.113459116573
Iteration 30 Loss=  0.111222350202
Iteration 31 Loss=  0.10903558643
Iteration 32 Loss=  0.106897768869
Iteration 33 Loss=  0.104807875726
Iteration 34 Loss=  0.102764916087
Iteration 35 Loss=  0.100767926445
Iteration 36 Loss=  0.0988159675355
Iteration 37 Loss=  0.0969081214984
Iteration 38 Loss=  0.095043489403
Iteration 39 Loss=  0.0932211891549
Iteration 40 Loss=  0.0914403537892
Iteration 41 Loss=  0.0897001301457
Iteration 42 Loss=  0.0879996779061
Iteration 43 Loss=  0.0863381689635
Iteration 44 Loss=  0.0847147870846
Iteration 45 Loss=  0.0831287278176
Iteration 46 Loss=  0.0815791985929
Iteration 47 Loss=  0.0800654189621
Iteration 48 Loss=  0.0785866209178
Iteration 49 Loss=  0.0771420492412
Iteration 50 Loss=  0.0757309618255
Iteration 51 Loss=  0.0743526299298
Iteration 52 Loss=  0.0730063383272
Iteration 53 Loss=  0.0716913853157
Iteration 54 Loss=  0.0704070825749
Iteration 55 Loss=  0.0691527548596
Iteration 56 Loss=  0.0679277395328
Iteration 57 Loss=  0.0667313859523
Iteration 58 Loss=  0.0655630547323
Iteration 59 Loss=  0.0644221169127
Iteration 60 Loss=  0.0633079530725
Iteration 61 Loss=  0.0622199524283
Iteration 62 Loss=  0.0611575119622
Iteration 63 Loss=  0.0601200356182
Iteration 64 Loss=  0.0591069336075
Iteration 65 Loss=  0.0581176218542
Iteration 66 Loss=  0.0571515216063
Iteration 67 Loss=  0.0562080592278
Iteration 68 Loss=  0.0552866661799
Iteration 69 Loss=  0.054386779188
Iteration 70 Loss=  0.0535078405843
Iteration 71 Loss=  0.052649298807
Iteration 72 Loss=  0.0518106090327
Iteration 73 Loss=  0.0509912339143
Iteration 74 Loss=  0.0501906443949
Iteration 75 Loss=  0.0494083205689
Iteration 76 Loss=  0.0486437525617
Iteration 77 Loss=  0.047896441405
Iteration 78 Loss=  0.0471658998864
Iteration 79 Loss=  0.046451653356
Iteration 80 Loss=  0.0457532404785
Iteration 81 Loss=  0.0450702139207
Iteration 82 Loss=  0.0444021409698
Iteration 83 Loss=  0.0437486040777
Iteration 84 Loss=  0.0431092013293
Iteration 85 Loss=  0.0424835468359
Iteration 86 Loss=  0.0418712710505
Iteration 87 Loss=  0.041272021007
Iteration 88 Loss=  0.0406854604828
Iteration 89 Loss=  0.0401112700833
Iteration 90 Loss=  0.0395491472504
Iteration 91 Loss=  0.0389988061927
Iteration 92 Loss=  0.0384599777394
Iteration 93 Loss=  0.0379324091173
Iteration 94 Loss=  0.0374158636544
Iteration 95 Loss=  0.0369101204114
Iteration 96 Loss=  0.0364149737451
Iteration 97 Loss=  0.0359302328098
Iteration 98 Loss=  0.0354557210024
Iteration 99 Loss=  0.0349912753586
Iteration 100 Loss=  0.0345367459093
[ -4.21005626e-04   1.78048800e-04  -1.51627421e-04 ...,   1.30642137e-04
  -4.35996267e-05   1.47142149e-04]
CROSS VALIDATION 12
Iteration 1 Loss=  10.1521453937
Iteration 2 Loss=  0.182981426958
Iteration 3 Loss=  0.174206962921
Iteration 4 Loss=  0.16989516107
Iteration 5 Loss=  0.166026403573
Iteration 6 Loss=  0.162386387858
Iteration 7 Loss=  0.158902664552
Iteration 8 Loss=  0.155541842355
Iteration 9 Loss=  0.152285568491
Iteration 10 Loss=  0.149122470917
Iteration 11 Loss=  0.146044842312
Iteration 12 Loss=  0.143047077379
Iteration 13 Loss=  0.140124861038
Iteration 14 Loss=  0.137274714437
Iteration 15 Loss=  0.13449372602
Iteration 16 Loss=  0.131779384656
Iteration 17 Loss=  0.129129472048
Iteration 18 Loss=  0.126541991051
Iteration 19 Loss=  0.12401511646
Iteration 20 Loss=  0.121547160251
Iteration 21 Loss=  0.119136546302
Iteration 22 Loss=  0.116781791409
Iteration 23 Loss=  0.114481490571
Iteration 24 Loss=  0.112234305176
Iteration 25 Loss=  0.11003895322
Iteration 26 Loss=  0.107894200982
Iteration 27 Loss=  0.105798855798
Iteration 28 Loss=  0.103751759733
Iteration 29 Loss=  0.101751784028
Iteration 30 Loss=  0.099797824273
Iteration 31 Loss=  0.0978887962981
Iteration 32 Loss=  0.0960236327855
Iteration 33 Loss=  0.0942012806074
Iteration 34 Loss=  0.092420698894
Iteration 35 Loss=  0.0906808578186
Iteration 36 Loss=  0.0889807380691
Iteration 37 Loss=  0.0873193309584
Iteration 38 Loss=  0.0856956391077
Iteration 39 Loss=  0.0841086776232
Iteration 40 Loss=  0.0825574756743
Iteration 41 Loss=  0.0810410783763
Iteration 42 Loss=  0.0795585488764
Iteration 43 Loss=  0.0781089705454
Iteration 44 Loss=  0.0766914491809
Iteration 45 Loss=  0.0753051151372
Iteration 46 Loss=  0.0739491253039
Iteration 47 Loss=  0.0726226648695
Iteration 48 Loss=  0.0713249488136
Iteration 49 Loss=  0.0700552230853
Iteration 50 Loss=  0.0688127654355
Iteration 51 Loss=  0.0675968858824
Iteration 52 Loss=  0.0664069267999
Iteration 53 Loss=  0.0652422626317
Iteration 54 Loss=  0.064102299242
Iteration 55 Loss=  0.0629864729271
Iteration 56 Loss=  0.061894249121
Iteration 57 Loss=  0.0608251208358
Iteration 58 Loss=  0.0597786068883
Iteration 59 Loss=  0.058754249966
Iteration 60 Loss=  0.0577516145922
Iteration 61 Loss=  0.0567702850498
Iteration 62 Loss=  0.0558098633206
Iteration 63 Loss=  0.0548699670972
Iteration 64 Loss=  0.0539502279143
Iteration 65 Loss=  0.0530502894433
Iteration 66 Loss=  0.0521698059838
Iteration 67 Loss=  0.0513084411768
Iteration 68 Loss=  0.0504658669564
Iteration 69 Loss=  0.0496417627454
Iteration 70 Loss=  0.0488358148946
Iteration 71 Loss=  0.0480477163537
Iteration 72 Loss=  0.0472771665571
Iteration 73 Loss=  0.0465238714999
Iteration 74 Loss=  0.0457875439742
Iteration 75 Loss=  0.0450679039309
Iteration 76 Loss=  0.0443646789294
Iteration 77 Loss=  0.0436776046346
Iteration 78 Loss=  0.0430064253207
Iteration 79 Loss=  0.0423508943395
Iteration 80 Loss=  0.0417107745147
Iteration 81 Loss=  0.0410858384243
Iteration 82 Loss=  0.0404758685375
Iteration 83 Loss=  0.0398806571767
Iteration 84 Loss=  0.0393000062817
Iteration 85 Loss=  0.0387337269581
Iteration 86 Loss=  0.0381816387999
Iteration 87 Loss=  0.0376435689816
Iteration 88 Loss=  0.0371193511262
Iteration 89 Loss=  0.0366088239596
Iteration 90 Loss=  0.0361118297729
Iteration 91 Loss=  0.0356282127201
Iteration 92 Loss=  0.0351578169878
Iteration 93 Loss=  0.0347004848807
Iteration 94 Loss=  0.0342560548732
Iteration 95 Loss=  0.0338243596852
Iteration 96 Loss=  0.0334052244415
Iteration 97 Loss=  0.032998464982
Iteration 98 Loss=  0.0326038863859
Iteration 99 Loss=  0.0322212817748
Iteration 100 Loss=  0.0318504314515
[ -7.32208821e-04  -3.78860179e-05  -2.25834036e-04 ...,   6.97550916e-05
  -4.89209248e-05   8.52395147e-05]
CROSS VALIDATION 13
Iteration 1 Loss=  8.10834569578
Iteration 2 Loss=  0.246437070947
Iteration 3 Loss=  0.237502677113
Iteration 4 Loss=  0.231441181678
Iteration 5 Loss=  0.226051272916
Iteration 6 Loss=  0.220999886921
Iteration 7 Loss=  0.216172972957
Iteration 8 Loss=  0.211518572906
Iteration 9 Loss=  0.207008678802
Iteration 10 Loss=  0.202626315234
Iteration 11 Loss=  0.198360232074
Iteration 12 Loss=  0.194202419931
Iteration 13 Loss=  0.190146830634
Iteration 14 Loss=  0.186188668117
Iteration 15 Loss=  0.182323971771
Iteration 16 Loss=  0.178549359602
Iteration 17 Loss=  0.174861863433
Iteration 18 Loss=  0.171258819461
Iteration 19 Loss=  0.16773779342
Iteration 20 Loss=  0.164296528052
Iteration 21 Loss=  0.16093290542
Iteration 22 Loss=  0.157644919338
Iteration 23 Loss=  0.15443065487
Iteration 24 Loss=  0.151288272904
Iteration 25 Loss=  0.148215998439
Iteration 26 Loss=  0.145212111663
Iteration 27 Loss=  0.14227494116
Iteration 28 Loss=  0.139402858805
Iteration 29 Loss=  0.13659427599
Iteration 30 Loss=  0.133847640927
Iteration 31 Loss=  0.13116143683
Iteration 32 Loss=  0.128534180808
Iteration 33 Loss=  0.125964423319
Iteration 34 Loss=  0.123450748065
Iteration 35 Loss=  0.120991772216
Iteration 36 Loss=  0.118586146847
Iteration 37 Loss=  0.116232557508
Iteration 38 Loss=  0.113929724837
Iteration 39 Loss=  0.111676405144
Iteration 40 Loss=  0.109471390917
Iteration 41 Loss=  0.107313511199
Iteration 42 Loss=  0.105201631808
Iteration 43 Loss=  0.103134655382
Iteration 44 Loss=  0.10111152124
Iteration 45 Loss=  0.0991312050696
Iteration 46 Loss=  0.0971927184414
Iteration 47 Loss=  0.0952951081702
Iteration 48 Loss=  0.093437455546
Iteration 49 Loss=  0.0916188754497
Iteration 50 Loss=  0.08983851538
Iteration 51 Loss=  0.0880955544089
Iteration 52 Loss=  0.0863892020881
Iteration 53 Loss=  0.0847186973234
Iteration 54 Loss=  0.083083307233
Iteration 55 Loss=  0.081482326004
Iteration 56 Loss=  0.0799150737601
Iteration 57 Loss=  0.078380895449
Iteration 58 Loss=  0.0768791597596
Iteration 59 Loss=  0.075409258072
Iteration 60 Loss=  0.0739706034469
Iteration 61 Loss=  0.072562629652
Iteration 62 Loss=  0.0711847902251
Iteration 63 Loss=  0.0698365575682
Iteration 64 Loss=  0.0685174220651
Iteration 65 Loss=  0.0672268912113
Iteration 66 Loss=  0.0659644887451
Iteration 67 Loss=  0.0647297537645
Iteration 68 Loss=  0.0635222398175
Iteration 69 Loss=  0.0623415139511
Iteration 70 Loss=  0.0611871557082
Iteration 71 Loss=  0.0600587560639
Iteration 72 Loss=  0.058955916299
Iteration 73 Loss=  0.0578782468099
Iteration 74 Loss=  0.0568253658661
Iteration 75 Loss=  0.055796898328
Iteration 76 Loss=  0.0547924743465
Iteration 77 Loss=  0.0538117280725
Iteration 78 Loss=  0.0528542964067
Iteration 79 Loss=  0.0519198178248
Iteration 80 Loss=  0.051007931315
Iteration 81 Loss=  0.0501182754605
Iteration 82 Loss=  0.0492504876994
Iteration 83 Loss=  0.0484042037874
Iteration 84 Loss=  0.0475790574798
Iteration 85 Loss=  0.0467746804436
Iteration 86 Loss=  0.0459907023985
Iteration 87 Loss=  0.0452267514779
Iteration 88 Loss=  0.0444824547912
Iteration 89 Loss=  0.0437574391641
Iteration 90 Loss=  0.0430513320249
Iteration 91 Loss=  0.0423637624033
Iteration 92 Loss=  0.0416943620064
Iteration 93 Loss=  0.0410427663347
Iteration 94 Loss=  0.0404086158013
Iteration 95 Loss=  0.0397915568213
Iteration 96 Loss=  0.0391912428368
Iteration 97 Loss=  0.038607335246
Iteration 98 Loss=  0.0380395042074
Iteration 99 Loss=  0.037487429291
Iteration 100 Loss=  0.0369507999507
[ -5.81883968e-04  -1.15178216e-04  -2.67993325e-04 ...,   7.19849931e-05
   3.29708354e-05   1.29757704e-04]
CROSS VALIDATION 14
Iteration 1 Loss=  7.99743842155
Iteration 2 Loss=  0.210225488651
Iteration 3 Loss=  0.193535945662
Iteration 4 Loss=  0.189249233698
Iteration 5 Loss=  0.185154357537
Iteration 6 Loss=  0.181204357156
Iteration 7 Loss=  0.177375437104
Iteration 8 Loss=  0.173653612147
Iteration 9 Loss=  0.170029739355
Iteration 10 Loss=  0.166497332308
Iteration 11 Loss=  0.163051480679
Iteration 12 Loss=  0.159688268193
Iteration 13 Loss=  0.156404437608
Iteration 14 Loss=  0.153197187509
Iteration 15 Loss=  0.150064043786
Iteration 16 Loss=  0.147002775556
Iteration 17 Loss=  0.144011338643
Iteration 18 Loss=  0.141087836741
Iteration 19 Loss=  0.138230494235
Iteration 20 Loss=  0.135437636866
Iteration 21 Loss=  0.132707677742
Iteration 22 Loss=  0.130039107001
Iteration 23 Loss=  0.127430483957
Iteration 24 Loss=  0.124880430885
Iteration 25 Loss=  0.122387627858
Iteration 26 Loss=  0.119950808218
Iteration 27 Loss=  0.117568754371
Iteration 28 Loss=  0.115240293728
Iteration 29 Loss=  0.112964294666
Iteration 30 Loss=  0.11073966248
Iteration 31 Loss=  0.108565335299
Iteration 32 Loss=  0.106440280045
Iteration 33 Loss=  0.104363488465
Iteration 34 Loss=  0.10233397336
Iteration 35 Loss=  0.100350765083
Iteration 36 Loss=  0.0984129084114
Iteration 37 Loss=  0.0965194598889
Iteration 38 Loss=  0.094669485701
Iteration 39 Loss=  0.0928620601445
Iteration 40 Loss=  0.0910962647182
Iteration 41 Loss=  0.0893711878355
Iteration 42 Loss=  0.0876859251306
Iteration 43 Loss=  0.0860395803006
Iteration 44 Loss=  0.0844312664006
Iteration 45 Loss=  0.0828601074839
Iteration 46 Loss=  0.0813252404689
Iteration 47 Loss=  0.0798258170999
Iteration 48 Loss=  0.0783610058725
Iteration 49 Loss=  0.0769299938012
Iteration 50 Loss=  0.0755319879184
Iteration 51 Loss=  0.0741662164197
Iteration 52 Loss=  0.0728319293918
Iteration 53 Loss=  0.0715283990876
Iteration 54 Loss=  0.0702549197428
Iteration 55 Loss=  0.0690108069508
Iteration 56 Loss=  0.0677953966404
Iteration 57 Loss=  0.0666080437141
Iteration 58 Loss=  0.0654481204244
Iteration 59 Loss=  0.0643150145677
Iteration 60 Loss=  0.0632081275842
Iteration 61 Loss=  0.0621268726468
Iteration 62 Loss=  0.0610706728168
Iteration 63 Loss=  0.0600389593388
Iteration 64 Loss=  0.0590311701295
Iteration 65 Loss=  0.0580467485082
Iteration 66 Loss=  0.0570851421998
Iteration 67 Loss=  0.0561458026266
Iteration 68 Loss=  0.055228184496
Iteration 69 Loss=  0.0543317456747
Iteration 70 Loss=  0.0534559473342
Iteration 71 Loss=  0.0526002543414
Iteration 72 Loss=  0.0517641358639
Iteration 73 Loss=  0.0509470661551
Iteration 74 Loss=  0.0501485254834
Iteration 75 Loss=  0.0493680011677
Iteration 76 Loss=  0.0486049886861
Iteration 77 Loss=  0.0478589928221
Iteration 78 Loss=  0.0471295288204
Iteration 79 Loss=  0.0464161235247
Iteration 80 Loss=  0.0457183164721
Iteration 81 Loss=  0.0450356609254
Iteration 82 Loss=  0.0443677248238
Iteration 83 Loss=  0.0437140916372
Iteration 84 Loss=  0.0430743611114
Iteration 85 Loss=  0.0424481498942
Iteration 86 Loss=  0.0418350920344
Iteration 87 Loss=  0.0412348393486
Iteration 88 Loss=  0.0406470616549
Iteration 89 Loss=  0.0400714468708
Iteration 90 Loss=  0.0395077009821
Iteration 91 Loss=  0.0389555478846
Iteration 92 Loss=  0.0384147291094
Iteration 93 Loss=  0.0378850034387
Iteration 94 Loss=  0.0373661464271
Iteration 95 Loss=  0.0368579498369
Iteration 96 Loss=  0.0363602210054
Iteration 97 Loss=  0.0358727821549
Iteration 98 Loss=  0.0353954696608
Iteration 99 Loss=  0.0349281332921
Iteration 100 Loss=  0.0344706354357
[ -3.95703504e-04   1.87212067e-04  -1.48549887e-04 ...,   1.13544561e-04
  -5.90732748e-05   1.44525656e-04]
CROSS VALIDATION 15
Iteration 1 Loss=  8.0465233581
Iteration 2 Loss=  0.212120039723
Iteration 3 Loss=  0.195135045381
Iteration 4 Loss=  0.190633547569
Iteration 5 Loss=  0.186391589462
Iteration 6 Loss=  0.182334223416
Iteration 7 Loss=  0.178423268588
Iteration 8 Loss=  0.174636550707
Iteration 9 Loss=  0.170959904221
Iteration 10 Loss=  0.167383580775
Iteration 11 Loss=  0.163900452732
Iteration 12 Loss=  0.160505039084
Iteration 13 Loss=  0.157192943078
Iteration 14 Loss=  0.153960510866
Iteration 15 Loss=  0.150804615713
Iteration 16 Loss=  0.147722516966
Iteration 17 Loss=  0.14471176533
Iteration 18 Loss=  0.141770137799
Iteration 19 Loss=  0.138895592107
Iteration 20 Loss=  0.136086234318
Iteration 21 Loss=  0.133340295417
Iteration 22 Loss=  0.130656114112
Iteration 23 Loss=  0.128032123949
Iteration 24 Loss=  0.125466843409
Iteration 25 Loss=  0.122958868029
Iteration 26 Loss=  0.120506863861
Iteration 27 Loss=  0.118109561789
Iteration 28 Loss=  0.115765752358
Iteration 29 Loss=  0.113474280863
Iteration 30 Loss=  0.111234042575
Iteration 31 Loss=  0.109043978002
Iteration 32 Loss=  0.10690306816
Iteration 33 Loss=  0.104810329862
Iteration 34 Loss=  0.102764811078
Iteration 35 Loss=  0.100765586407
Iteration 36 Loss=  0.0988117527533
Iteration 37 Loss=  0.096902425294
Iteration 38 Loss=  0.0950367338065
Iteration 39 Loss=  0.0932138194542
Iteration 40 Loss=  0.0914328320911
Iteration 41 Loss=  0.0896929281428
Iteration 42 Loss=  0.087993269097
Iteration 43 Loss=  0.0863330206142
Iteration 44 Loss=  0.0847113522399
Iteration 45 Loss=  0.0831274376757
Iteration 46 Loss=  0.0815804555374
Iteration 47 Loss=  0.0800695905079
Iteration 48 Loss=  0.078594034774
Iteration 49 Loss=  0.0771529896271
Iteration 50 Loss=  0.0757456671044
Iteration 51 Loss=  0.0743712915556
Iteration 52 Loss=  0.0730291010291
Iteration 53 Loss=  0.0717183483965
Iteration 54 Loss=  0.0704383021558
Iteration 55 Loss=  0.0691882468787
Iteration 56 Loss=  0.0679674832973
Iteration 57 Loss=  0.0667753280463
Iteration 58 Loss=  0.0656111131007
Iteration 59 Loss=  0.0644741849614
Iteration 60 Loss=  0.0633639036556
Iteration 61 Loss=  0.0622796416216
Iteration 62 Loss=  0.0612207825501
Iteration 63 Loss=  0.0601867202475
Iteration 64 Loss=  0.0591768575829
Iteration 65 Loss=  0.0581906055676
Iteration 66 Loss=  0.0572273826052
Iteration 67 Loss=  0.0562866139394
Iteration 68 Loss=  0.0553677313128
Iteration 69 Loss=  0.054470172839
Iteration 70 Loss=  0.0535933830818
Iteration 71 Loss=  0.0527368133246
Iteration 72 Loss=  0.0518999220094
Iteration 73 Loss=  0.0510821753175
Iteration 74 Loss=  0.0502830478657
Iteration 75 Loss=  0.0495020234859
Iteration 76 Loss=  0.0487385960622
Iteration 77 Loss=  0.0479922703967
Iteration 78 Loss=  0.0472625630801
Iteration 79 Loss=  0.0465490033463
Iteration 80 Loss=  0.0458511338903
Iteration 81 Loss=  0.0451685116349
Iteration 82 Loss=  0.0445007084312
Iteration 83 Loss=  0.0438473116832
Iteration 84 Loss=  0.0432079248851
Iteration 85 Loss=  0.0425821680667
Iteration 86 Loss=  0.0419696781395
Iteration 87 Loss=  0.0413701091405
Iteration 88 Loss=  0.0407831323729
Iteration 89 Loss=  0.0402084364428
Iteration 90 Loss=  0.0396457271936
Iteration 91 Loss=  0.0390947275428
Iteration 92 Loss=  0.0385551772245
Iteration 93 Loss=  0.038026832446
Iteration 94 Loss=  0.0375094654639
Iteration 95 Loss=  0.0370028640903
Iteration 96 Loss=  0.0365068311373
Iteration 97 Loss=  0.0360211838103
Iteration 98 Loss=  0.0355457530593
Iteration 99 Loss=  0.0350803828996
Iteration 100 Loss=  0.034624929712
[ -4.21454549e-04   1.85234444e-04  -1.60409216e-04 ...,   1.31181151e-04
  -4.45761022e-05   1.46760651e-04]
CROSS VALIDATION 16
Iteration 1 Loss=  8.02212520354
Iteration 2 Loss=  0.197602215577
Iteration 3 Loss=  0.193158610974
Iteration 4 Loss=  0.188941871458
Iteration 5 Loss=  0.184887226644
Iteration 6 Loss=  0.18096374432
Iteration 7 Loss=  0.177153990534
Iteration 8 Loss=  0.173446940319
Iteration 9 Loss=  0.169834986226
Iteration 10 Loss=  0.166312503363
Iteration 11 Loss=  0.162875094108
Iteration 12 Loss=  0.159519161454
Iteration 13 Loss=  0.156241654264
Iteration 14 Loss=  0.153039908269
Iteration 15 Loss=  0.14991154317
Iteration 16 Loss=  0.146854394086
Iteration 17 Loss=  0.143866464762
Iteration 18 Loss=  0.140945894996
Iteration 19 Loss=  0.138090937561
Iteration 20 Loss=  0.135299941607
Iteration 21 Loss=  0.132571340492
Iteration 22 Loss=  0.129903642684
Iteration 23 Loss=  0.127295424757
Iteration 24 Loss=  0.124745325784
Iteration 25 Loss=  0.122252042646
Iteration 26 Loss=  0.119814325893
Iteration 27 Loss=  0.117430975912
Iteration 28 Loss=  0.115100839234
Iteration 29 Loss=  0.112822804875
Iteration 30 Loss=  0.110595800675
Iteration 31 Loss=  0.108418789606
Iteration 32 Loss=  0.10629076608
Iteration 33 Loss=  0.104210752309
Iteration 34 Loss=  0.102177794746
Iteration 35 Loss=  0.100190960705
Iteration 36 Loss=  0.0982493351978
Iteration 37 Loss=  0.0963520180564
Iteration 38 Loss=  0.0944981214014
Iteration 39 Loss=  0.0926867674871
Iteration 40 Loss=  0.0909170869601
Iteration 41 Loss=  0.089188217547
Iteration 42 Loss=  0.0874993031737
Iteration 43 Loss=  0.0858494935076
Iteration 44 Loss=  0.0842379438988
Iteration 45 Loss=  0.0826638156863
Iteration 46 Loss=  0.0811262768236
Iteration 47 Loss=  0.0796245027676
Iteration 48 Loss=  0.0781576775697
Iteration 49 Loss=  0.0767249950985
Iteration 50 Loss=  0.0753256603252
Iteration 51 Loss=  0.0739588905974
Iteration 52 Loss=  0.0726239168368
Iteration 53 Loss=  0.0713199845948
Iteration 54 Loss=  0.0700463549178
Iteration 55 Loss=  0.0688023049798
Iteration 56 Loss=  0.0675871284557
Iteration 57 Loss=  0.0664001356272
Iteration 58 Loss=  0.0652406532213
Iteration 59 Loss=  0.0641080240023
Iteration 60 Loss=  0.0630016061467
Iteration 61 Loss=  0.0619207724409
Iteration 62 Loss=  0.0608649093509
Iteration 63 Loss=  0.0598334160137
Iteration 64 Loss=  0.0588257032055
Iteration 65 Loss=  0.0578411923372
Iteration 66 Loss=  0.0568793145248
Iteration 67 Loss=  0.0559395097764
Iteration 68 Loss=  0.0550212263297
Iteration 69 Loss=  0.0541239201659
Iteration 70 Loss=  0.0532470547159
Iteration 71 Loss=  0.0523901007652
Iteration 72 Loss=  0.0515525365573
Iteration 73 Loss=  0.0507338480835
Iteration 74 Loss=  0.0499335295421
Iteration 75 Loss=  0.0491510839433
Iteration 76 Loss=  0.048386023831
Iteration 77 Loss=  0.0476378720893
Iteration 78 Loss=  0.0469061628009
Iteration 79 Loss=  0.0461904421233
Iteration 80 Loss=  0.0454902691503
Iteration 81 Loss=  0.0448052167314
Iteration 82 Loss=  0.0441348722196
Iteration 83 Loss=  0.0434788381307
Iteration 84 Loss=  0.0428367326938
Iteration 85 Loss=  0.0422081902843
Iteration 86 Loss=  0.0415928617317
Iteration 87 Loss=  0.0409904145014
Iteration 88 Loss=  0.0404005327517
Iteration 89 Loss=  0.0398229172739
Iteration 90 Loss=  0.0392572853214
Iteration 91 Loss=  0.0387033703419
Iteration 92 Loss=  0.0381609216215
Iteration 93 Loss=  0.0376297038563
Iteration 94 Loss=  0.0371094966627
Iteration 95 Loss=  0.03660009404
Iteration 96 Loss=  0.0361013037971
Iteration 97 Loss=  0.035612946955
Iteration 98 Loss=  0.0351348571351
Iteration 99 Loss=  0.0346668799418
Iteration 100 Loss=  0.0342088723486
[ -4.03596668e-04   1.75529651e-04  -1.53428418e-04 ...,   1.27882399e-04
  -4.54109117e-05   1.51969466e-04]
CROSS VALIDATION 17
Iteration 1 Loss=  8.01421224891
Iteration 2 Loss=  0.211536387205
Iteration 3 Loss=  0.195031174545
Iteration 4 Loss=  0.190510506187
Iteration 5 Loss=  0.186261073365
Iteration 6 Loss=  0.182201382949
Iteration 7 Loss=  0.178290767569
Iteration 8 Loss=  0.174505927525
Iteration 9 Loss=  0.170832125678
Iteration 10 Loss=  0.167259299135
Iteration 11 Loss=  0.163780137174
Iteration 12 Loss=  0.160389048186
Iteration 13 Loss=  0.157081567296
Iteration 14 Loss=  0.153853998701
Iteration 15 Loss=  0.15070319048
Iteration 16 Loss=  0.147626387854
Iteration 17 Loss=  0.144621134797
Iteration 18 Loss=  0.141685206471
Iteration 19 Loss=  0.138816561859
Iteration 20 Loss=  0.136013309956
Iteration 21 Loss=  0.133273685187
Iteration 22 Loss=  0.130596029211
Iteration 23 Loss=  0.127978777132
Iteration 24 Loss=  0.12542044677
Iteration 25 Loss=  0.122919630036
Iteration 26 Loss=  0.120474985723
Iteration 27 Loss=  0.118085233248
Iteration 28 Loss=  0.115749147005
Iteration 29 Loss=  0.113465551135
Iteration 30 Loss=  0.111233314558
Iteration 31 Loss=  0.109051346232
Iteration 32 Loss=  0.106918590605
Iteration 33 Loss=  0.104834023304
Iteration 34 Loss=  0.102796647082
Iteration 35 Loss=  0.10080548811
Iteration 36 Loss=  0.0988595926556
Iteration 37 Loss=  0.0969580242192
Iteration 38 Loss=  0.0950998611718
Iteration 39 Loss=  0.0932841949296
Iteration 40 Loss=  0.0915101286774
Iteration 41 Loss=  0.0897767766306
Iteration 42 Loss=  0.0880832638055
Iteration 43 Loss=  0.0864287262411
Iteration 44 Loss=  0.0848123115986
Iteration 45 Loss=  0.0832331800462
Iteration 46 Loss=  0.0816905053264
Iteration 47 Loss=  0.0801834758975
Iteration 48 Loss=  0.0787112960418
Iteration 49 Loss=  0.0772731868414
Iteration 50 Loss=  0.0758683869357
Iteration 51 Loss=  0.0744961529935
Iteration 52 Loss=  0.0731557598566
Iteration 53 Loss=  0.0718465003334
Iteration 54 Loss=  0.0705676846465
Iteration 55 Loss=  0.0693186395626
Iteration 56 Loss=  0.0680987072472
Iteration 57 Loss=  0.0669072439085
Iteration 58 Loss=  0.0657436182972
Iteration 59 Loss=  0.0646072101415
Iteration 60 Loss=  0.0634974085904
Iteration 61 Loss=  0.0624136107377
Iteration 62 Loss=  0.0613552202897
Iteration 63 Loss=  0.0603216464295
Iteration 64 Loss=  0.059312302917
Iteration 65 Loss=  0.0583266074509
Iteration 66 Loss=  0.0573639813052
Iteration 67 Loss=  0.0564238492387
Iteration 68 Loss=  0.0555056396643
Iteration 69 Loss=  0.0546087850565
Iteration 70 Loss=  0.0537327225639
Iteration 71 Loss=  0.052876894793
Iteration 72 Loss=  0.0520407507216
Iteration 73 Loss=  0.0512237467041
Iteration 74 Loss=  0.0504253475297
Iteration 75 Loss=  0.049645027499
Iteration 76 Loss=  0.0488822714893
Iteration 77 Loss=  0.0481365759837
Iteration 78 Loss=  0.0474074500446
Iteration 79 Loss=  0.0466944162177
Iteration 80 Loss=  0.0459970113573
Iteration 81 Loss=  0.0453147873657
Iteration 82 Loss=  0.0446473118448
Iteration 83 Loss=  0.0439941686574
Iteration 84 Loss=  0.0433549583983
Iteration 85 Loss=  0.0427292987746
Iteration 86 Loss=  0.0421168248955
Iteration 87 Loss=  0.0415171894718
Iteration 88 Loss=  0.0409300629241
Iteration 89 Loss=  0.0403551334014
Iteration 90 Loss=  0.0397921067094
Iteration 91 Loss=  0.0392407061503
Iteration 92 Loss=  0.0387006722767
Iteration 93 Loss=  0.0381717625635
Iteration 94 Loss=  0.0376537510016
Iteration 95 Loss=  0.0371464276203
Iteration 96 Loss=  0.0366495979456
Iteration 97 Loss=  0.0361630824021
Iteration 98 Loss=  0.0356867156693
Iteration 99 Loss=  0.0352203459989
Iteration 100 Loss=  0.0347638345061
[ -4.19817472e-04   1.77275221e-04  -1.55593193e-04 ...,   1.33159786e-04
  -4.70041035e-05   1.47062048e-04]
CROSS VALIDATION 18
Iteration 1 Loss=  7.13643175285
Iteration 2 Loss=  0.202723602745
Iteration 3 Loss=  0.197704865545
Iteration 4 Loss=  0.193119076331
Iteration 5 Loss=  0.188803179149
Iteration 6 Loss=  0.184684476875
Iteration 7 Loss=  0.180723527304
Iteration 8 Loss=  0.176896249095
Iteration 9 Loss=  0.173186675403
Iteration 10 Loss=  0.169583533729
Iteration 11 Loss=  0.1660784554
Iteration 12 Loss=  0.162664964494
Iteration 13 Loss=  0.159337872693
Iteration 14 Loss=  0.156092899802
Iteration 15 Loss=  0.152926426461
Iteration 16 Loss=  0.149835327646
Iteration 17 Loss=  0.146816857339
Iteration 18 Loss=  0.143868566619
Iteration 19 Loss=  0.140988244141
Iteration 20 Loss=  0.138173872
Iteration 21 Loss=  0.135423592363
Iteration 22 Loss=  0.132735681818
Iteration 23 Loss=  0.130108531347
Iteration 24 Loss=  0.127540630482
Iteration 25 Loss=  0.125030554632
Iteration 26 Loss=  0.122576954861
Iteration 27 Loss=  0.12017854959
Iteration 28 Loss=  0.117834117822
Iteration 29 Loss=  0.115542493604
Iteration 30 Loss=  0.113302561456
Iteration 31 Loss=  0.111113252573
Iteration 32 Loss=  0.108973541606
Iteration 33 Loss=  0.10688244385
Iteration 34 Loss=  0.104839012684
Iteration 35 Loss=  0.102842337104
Iteration 36 Loss=  0.10089153922
Iteration 37 Loss=  0.098985771604
Iteration 38 Loss=  0.0971242143925
Iteration 39 Loss=  0.0953060720844
Iteration 40 Loss=  0.0935305700089
Iteration 41 Loss=  0.091796950472
Iteration 42 Loss=  0.0901044686306
Iteration 43 Loss=  0.0884523881777
Iteration 44 Loss=  0.0868399769556
Iteration 45 Loss=  0.0852665026369
Iteration 46 Loss=  0.083731228631
Iteration 47 Loss=  0.0822334103824
Iteration 48 Loss=  0.0807722922186
Iteration 49 Loss=  0.0793471048964
Iteration 50 Loss=  0.0779570639676
Iteration 51 Loss=  0.0766013690523
Iteration 52 Loss=  0.0752792040688
Iteration 53 Loss=  0.073989738422
Iteration 54 Loss=  0.0727321291076
Iteration 55 Loss=  0.0715055236391
Iteration 56 Loss=  0.0703090636664
Iteration 57 Loss=  0.0691418891155
Iteration 58 Loss=  0.0680031426564
Iteration 59 Loss=  0.0668919742924
Iteration 60 Loss=  0.0658075458633
Iteration 61 Loss=  0.064749035271
Iteration 62 Loss=  0.0637156402603
Iteration 63 Loss=  0.0627065816222
Iteration 64 Loss=  0.0617211057315
Iteration 65 Loss=  0.0607584863705
Iteration 66 Loss=  0.0598180258338
Iteration 67 Loss=  0.0588990553482
Iteration 68 Loss=  0.0580009348711
Iteration 69 Loss=  0.0571230523553
Iteration 70 Loss=  0.0562648225837
Iteration 71 Loss=  0.0554256856869
Iteration 72 Loss=  0.0546051054569
Iteration 73 Loss=  0.0538025675685
Iteration 74 Loss=  0.0530175778103
Iteration 75 Loss=  0.0522496604166
Iteration 76 Loss=  0.0514983565745
Iteration 77 Loss=  0.0507632231652
Iteration 78 Loss=  0.0500438317764
Iteration 79 Loss=  0.0493397680059
Iteration 80 Loss=  0.0486506310544
Iteration 81 Loss=  0.047976033588
Iteration 82 Loss=  0.0473156018366
Iteration 83 Loss=  0.0466689758792
Iteration 84 Loss=  0.0460358100623
Iteration 85 Loss=  0.0454157734893
Iteration 86 Loss=  0.0448085505249
Iteration 87 Loss=  0.0442138412572
Iteration 88 Loss=  0.0436313618707
Iteration 89 Loss=  0.0430608448943
Iteration 90 Loss=  0.0425020392961
Iteration 91 Loss=  0.0419547104106
Iteration 92 Loss=  0.0414186396949
Iteration 93 Loss=  0.0408936243171
Iteration 94 Loss=  0.0403794765908
Iteration 95 Loss=  0.0398760232723
Iteration 96 Loss=  0.0393831047411
Iteration 97 Loss=  0.0389005740852
Iteration 98 Loss=  0.0384282961117
Iteration 99 Loss=  0.0379661463004
Iteration 100 Loss=  0.0375140097157
[ -3.53617763e-04  -1.22877250e-04  -5.15969351e-04 ...,   3.69116686e-04
  -1.58131737e-05   1.27083188e-04]
CROSS VALIDATION 19
Iteration 1 Loss=  7.8550761952
Iteration 2 Loss=  0.206699147727
Iteration 3 Loss=  0.189042627028
Iteration 4 Loss=  0.184713990349
Iteration 5 Loss=  0.180620116897
Iteration 6 Loss=  0.17669966472
Iteration 7 Loss=  0.172919573849
Iteration 8 Loss=  0.169259882203
Iteration 9 Loss=  0.165707473299
Iteration 10 Loss=  0.162253132467
Iteration 11 Loss=  0.158890020646
Iteration 12 Loss=  0.155612823221
Iteration 13 Loss=  0.152417247344
Iteration 14 Loss=  0.14929971104
Iteration 15 Loss=  0.146257143489
Iteration 16 Loss=  0.143286852573
Iteration 17 Loss=  0.1403864346
Iteration 18 Loss=  0.137553711252
Iteration 19 Loss=  0.134786684535
Iteration 20 Loss=  0.132083503855
Iteration 21 Loss=  0.129442441384
Iteration 22 Loss=  0.126861873146
Iteration 23 Loss=  0.124340264097
Iteration 24 Loss=  0.121876156006
Iteration 25 Loss=  0.119468157349
Iteration 26 Loss=  0.11711493466
Iteration 27 Loss=  0.114815205012
Iteration 28 Loss=  0.112567729415
Iteration 29 Loss=  0.110371306999
Iteration 30 Loss=  0.108224769953
Iteration 31 Loss=  0.106126979188
Iteration 32 Loss=  0.10407682073
Iteration 33 Loss=  0.102073202848
Iteration 34 Loss=  0.100115053902
Iteration 35 Loss=  0.0982013208934
Iteration 36 Loss=  0.0963309686608
Iteration 37 Loss=  0.0945029796532
Iteration 38 Loss=  0.0927163541936
Iteration 39 Loss=  0.0909701111259
Iteration 40 Loss=  0.0892632887378
Iteration 41 Loss=  0.0875949458502
Iteration 42 Loss=  0.0859641629704
Iteration 43 Loss=  0.0843700434208
Iteration 44 Loss=  0.0828117143705
Iteration 45 Loss=  0.0812883277137
Iteration 46 Loss=  0.0797990607594
Iteration 47 Loss=  0.0783431167088
Iteration 48 Loss=  0.0769197249133
Iteration 49 Loss=  0.0755281409101
Iteration 50 Loss=  0.0741676462428
Iteration 51 Loss=  0.072837548073
Iteration 52 Loss=  0.0715371785907
Iteration 53 Loss=  0.0702658942299
Iteration 54 Loss=  0.0690230746946
Iteration 55 Loss=  0.0678081217993
Iteration 56 Loss=  0.0666204581301
Iteration 57 Loss=  0.0654595255325
Iteration 58 Loss=  0.0643247834388
Iteration 59 Loss=  0.0632157070494
Iteration 60 Loss=  0.0621317853952
Iteration 61 Loss=  0.0610725193076
Iteration 62 Loss=  0.0600374193379
Iteration 63 Loss=  0.0590260036685
Iteration 64 Loss=  0.0580377960679
Iteration 65 Loss=  0.0570723239427
Iteration 66 Loss=  0.0561291165422
Iteration 67 Loss=  0.055207703371
Iteration 68 Loss=  0.054307612859
Iteration 69 Loss=  0.0534283713331
Iteration 70 Loss=  0.0525695023262
Iteration 71 Loss=  0.0517305262458
Iteration 72 Loss=  0.0509109604132
Iteration 73 Loss=  0.0501103194724
Iteration 74 Loss=  0.0493281161498
Iteration 75 Loss=  0.0485638623383
Iteration 76 Loss=  0.0478170704642
Iteration 77 Loss=  0.0470872550886
Iteration 78 Loss=  0.0463739346866
Iteration 79 Loss=  0.045676633546
Iteration 80 Loss=  0.0449948837236
Iteration 81 Loss=  0.0443282270011
Iteration 82 Loss=  0.0436762167844
Iteration 83 Loss=  0.0430384198976
Iteration 84 Loss=  0.0424144182294
Iteration 85 Loss=  0.0418038101969
Iteration 86 Loss=  0.0412062120022
Iteration 87 Loss=  0.0406212586636
Iteration 88 Loss=  0.040048604812
Iteration 89 Loss=  0.0394879252522
Iteration 90 Loss=  0.0389389152916
Iteration 91 Loss=  0.0384012908488
Iteration 92 Loss=  0.0378747883549
Iteration 93 Loss=  0.0373591644668
Iteration 94 Loss=  0.0368541956127
Iteration 95 Loss=  0.0363596773902
Iteration 96 Loss=  0.0358754238414
Iteration 97 Loss=  0.0354012666247
Iteration 98 Loss=  0.0349370541054
Iteration 99 Loss=  0.034482650385
Iteration 100 Loss=  0.0340379342863
[ -4.82173816e-04   1.76352418e-04  -1.93666351e-04 ...,   1.15707333e-04
  -5.10882434e-05   1.56326527e-04]
Accuracy (Logistic Loss):	0.95 for lmda= 1 learning rate= 0.0001
---------------------------------------------------------------------------------
lmda= 1 learning rate= 0.001
CROSS VALIDATION 0
Iteration 1 Loss=  111.654209534
Iteration 2 Loss=  18.0299416388
Iteration 3 Loss=  14.5569141631
Iteration 4 Loss=  11.7735300768
Iteration 5 Loss=  9.5223485502
Iteration 6 Loss=  7.7016087242
Iteration 7 Loss=  6.2290071463
Iteration 8 Loss=  5.03797744232
Iteration 9 Loss=  4.07468152113
Iteration 10 Loss=  3.29557660016
Iteration 11 Loss=  2.6654486109
Iteration 12 Loss=  2.15582337976
Iteration 13 Loss=  1.74368068882
Iteration 14 Loss=  1.41039925978
Iteration 15 Loss=  1.14088005942
Iteration 16 Loss=  0.922895306987
Iteration 17 Loss=  0.746633088613
Iteration 18 Loss=  0.604214757712
Iteration 19 Loss=  0.489264727697
Iteration 20 Loss=  0.39658028384
Iteration 21 Loss=  0.321901904982
Iteration 22 Loss=  0.261712289274
Iteration 23 Loss=  0.213124600036
Iteration 24 Loss=  0.173865200762
Iteration 25 Loss=  0.142151741079
Iteration 26 Loss=  0.116581870638
Iteration 27 Loss=  0.0959784327947
Iteration 28 Loss=  0.0793689303414
Iteration 29 Loss=  0.0659921856171
Iteration 30 Loss=  0.0552503431248
Iteration 31 Loss=  0.0466760969169
Iteration 32 Loss=  0.0399195692236
Iteration 33 Loss=  0.0346402668539
Iteration 34 Loss=  0.0305252508971
Iteration 35 Loss=  0.0273849571125
Iteration 36 Loss=  0.0250206843246
Iteration 37 Loss=  0.0231684191751
Iteration 38 Loss=  0.0216691842327
Iteration 39 Loss=  0.0204851399942
Iteration 40 Loss=  0.0196534443471
Iteration 41 Loss=  0.0191267246143
Iteration 42 Loss=  0.0186201881483
Iteration 43 Loss=  0.0180875627112
Iteration 44 Loss=  0.0177774380822
Iteration 45 Loss=  0.0178254427731
[ -2.77111492e-04  -9.33697146e-05   6.51868160e-06 ...,   1.22865840e-04
   8.89002370e-05   3.21742322e-05]
CROSS VALIDATION 1
Iteration 1 Loss=  81.7017894408
Iteration 2 Loss=  19.6402038928
Iteration 3 Loss=  15.8848591573
Iteration 4 Loss=  12.8475626743
Iteration 5 Loss=  10.3910185816
Iteration 6 Loss=  8.40418294898
Iteration 7 Loss=  6.79724422499
Iteration 8 Loss=  5.49756345983
Iteration 9 Loss=  4.4463907998
Iteration 10 Loss=  3.59620987166
Iteration 11 Loss=  2.90859016122
Iteration 12 Loss=  2.3524506955
Iteration 13 Loss=  1.90265727206
Iteration 14 Loss=  1.53889011496
Iteration 15 Loss=  1.24472619457
Iteration 16 Loss=  1.00688100733
Iteration 17 Loss=  0.814589717336
Iteration 18 Loss=  0.659142588931
Iteration 19 Loss=  0.533460744023
Iteration 20 Loss=  0.431807797626
Iteration 21 Loss=  0.349670034841
Iteration 22 Loss=  0.28346845045
Iteration 23 Loss=  0.230268504372
Iteration 24 Loss=  0.187564135674
Iteration 25 Loss=  0.153173618151
Iteration 26 Loss=  0.125319141665
Iteration 27 Loss=  0.102736779939
Iteration 28 Loss=  0.0845139753003
Iteration 29 Loss=  0.0699053912767
Iteration 30 Loss=  0.0582448425345
Iteration 31 Loss=  0.048976641868
Iteration 32 Loss=  0.0416242256286
Iteration 33 Loss=  0.0357582841068
Iteration 34 Loss=  0.0310651189978
Iteration 35 Loss=  0.0273775233761
Iteration 36 Loss=  0.0245662111623
Iteration 37 Loss=  0.0224002649367
Iteration 38 Loss=  0.0206737858925
Iteration 39 Loss=  0.0193338674079
Iteration 40 Loss=  0.018459980741
Iteration 41 Loss=  0.0180684176218
Iteration 42 Loss=  0.0178148009962
Iteration 43 Loss=  0.0175002987027
Iteration 44 Loss=  0.0172904600633
Iteration 45 Loss=  0.017355895293
[ -2.68677775e-04  -9.64273780e-05  -2.41922490e-05 ...,   1.09811112e-04
   8.63646262e-05   4.58481867e-05]
CROSS VALIDATION 2
Iteration 1 Loss=  354.698351936
Iteration 2 Loss=  85.2090876228
Iteration 3 Loss=  19.3302325259
Iteration 4 Loss=  15.6345422298
Iteration 5 Loss=  12.6454149527
Iteration 6 Loss=  10.2277891604
Iteration 7 Loss=  8.27242636399
Iteration 8 Loss=  6.69096303286
Iteration 9 Loss=  5.41192876466
Iteration 10 Loss=  4.37750060909
Iteration 11 Loss=  3.54088453804
Iteration 12 Loss=  2.86424119254
Iteration 13 Loss=  2.31696969094
Iteration 14 Loss=  1.87432320751
Iteration 15 Loss=  1.51630787844
Iteration 16 Loss=  1.22676150479
Iteration 17 Loss=  0.992609959307
Iteration 18 Loss=  0.803259177587
Iteration 19 Loss=  0.650110063909
Iteration 20 Loss=  0.52622570199
Iteration 21 Loss=  0.426030894366
Iteration 22 Loss=  0.345022645469
Iteration 23 Loss=  0.279566385739
Iteration 24 Loss=  0.226723066843
Iteration 25 Loss=  0.184100456537
Iteration 26 Loss=  0.149796284586
Iteration 27 Loss=  0.122331753034
Iteration 28 Loss=  0.100465760667
Iteration 29 Loss=  0.0830555759484
Iteration 30 Loss=  0.0691188071232
Iteration 31 Loss=  0.0579388316937
Iteration 32 Loss=  0.0489080984465
Iteration 33 Loss=  0.0415823310181
Iteration 34 Loss=  0.0356719889328
Iteration 35 Loss=  0.0309507795959
Iteration 36 Loss=  0.0272230385916
Iteration 37 Loss=  0.0243445660865
Iteration 38 Loss=  0.0222191195125
Iteration 39 Loss=  0.0206771350916
Iteration 40 Loss=  0.0194913106797
Iteration 41 Loss=  0.0186088844175
Iteration 42 Loss=  0.0179577562663
Iteration 43 Loss=  0.017352301919
Iteration 44 Loss=  0.0167870539189
Iteration 45 Loss=  0.0164607870794
Iteration 46 Loss=  0.0164907250415
[ -3.34277246e-04  -1.70231717e-04  -5.69727596e-05 ...,   2.18545587e-04
   6.60008518e-05   2.13055278e-05]
CROSS VALIDATION 3
Iteration 1 Loss=  81.9597226602
Iteration 2 Loss=  19.6652386277
Iteration 3 Loss=  15.9051070753
Iteration 4 Loss=  12.8639390483
Iteration 5 Loss=  10.4042636781
Iteration 6 Loss=  8.41489549011
Iteration 7 Loss=  6.80590845288
Iteration 8 Loss=  5.50457102475
Iteration 9 Loss=  4.45205845794
Iteration 10 Loss=  3.6007937774
Iteration 11 Loss=  2.91229735538
Iteration 12 Loss=  2.35544821012
Iteration 13 Loss=  1.90507914553
Iteration 14 Loss=  1.54084293802
Iteration 15 Loss=  1.24629573393
Iteration 16 Loss=  1.00814341515
Iteration 17 Loss=  0.815614608573
Iteration 18 Loss=  0.659978769515
Iteration 19 Loss=  0.534144256005
Iteration 20 Loss=  0.43237785011
Iteration 21 Loss=  0.350180828954
Iteration 22 Loss=  0.283991351228
Iteration 23 Loss=  0.230843656129
Iteration 24 Loss=  0.188118083869
Iteration 25 Loss=  0.153612654999
Iteration 26 Loss=  0.125660021171
Iteration 27 Loss=  0.10303594348
Iteration 28 Loss=  0.0847918449033
Iteration 29 Loss=  0.0701615631549
Iteration 30 Loss=  0.0584769495241
Iteration 31 Loss=  0.0491870694755
Iteration 32 Loss=  0.0418189006667
Iteration 33 Loss=  0.0359445161328
Iteration 34 Loss=  0.0312520865804
Iteration 35 Loss=  0.0275756144726
Iteration 36 Loss=  0.0247796685875
Iteration 37 Loss=  0.0226208034309
Iteration 38 Loss=  0.0208914485313
Iteration 39 Loss=  0.0195287086542
Iteration 40 Loss=  0.0186064537831
Iteration 41 Loss=  0.0181741328833
Iteration 42 Loss=  0.0179400376339
Iteration 43 Loss=  0.017650680872
Iteration 44 Loss=  0.0174685917077
Iteration 45 Loss=  0.0175958022005
Iteration 46 Loss=  0.0179478438858
Iteration 47 Loss=  0.0182739401469
Iteration 48 Loss=  0.0186016678093
Iteration 49 Loss=  0.0189707468357
Iteration 50 Loss=  0.019347348579
Iteration 51 Loss=  0.0196911998481
Iteration 52 Loss=  0.0200477959531
Iteration 53 Loss=  0.0204260984749
Iteration 54 Loss=  0.0207568018212
Iteration 55 Loss=  0.0209856305504
Iteration 56 Loss=  0.0211104906617
Iteration 57 Loss=  0.0211633066017
[ -2.99386887e-04  -1.67216617e-04  -5.83110040e-05 ...,   1.49492021e-04
   7.48484059e-05   2.48778598e-05]
CROSS VALIDATION 4
Iteration 1 Loss=  81.9597226602
Iteration 2 Loss=  19.6652386277
Iteration 3 Loss=  15.9051070753
Iteration 4 Loss=  12.8639390483
Iteration 5 Loss=  10.4042636781
Iteration 6 Loss=  8.41489549011
Iteration 7 Loss=  6.80590845288
Iteration 8 Loss=  5.50457102475
Iteration 9 Loss=  4.45205845794
Iteration 10 Loss=  3.6007937774
Iteration 11 Loss=  2.91229735538
Iteration 12 Loss=  2.35544821012
Iteration 13 Loss=  1.90507914554
Iteration 14 Loss=  1.54084293816
Iteration 15 Loss=  1.24629573535
Iteration 16 Loss=  1.00814342588
Iteration 17 Loss=  0.815614673589
Iteration 18 Loss=  0.659979090134
Iteration 19 Loss=  0.534145575384
Iteration 20 Loss=  0.432382480681
Iteration 21 Loss=  0.350194882927
Iteration 22 Loss=  0.284028247868
Iteration 23 Loss=  0.230926220853
Iteration 24 Loss=  0.188270754073
Iteration 25 Loss=  0.15383655691
Iteration 26 Loss=  0.125915157005
Iteration 27 Loss=  0.103264620883
Iteration 28 Loss=  0.0849510235447
Iteration 29 Loss=  0.0702386831392
Iteration 30 Loss=  0.0584938657191
Iteration 31 Loss=  0.0491746370431
Iteration 32 Loss=  0.0417906731728
Iteration 33 Loss=  0.0359033555178
Iteration 34 Loss=  0.031204803379
Iteration 35 Loss=  0.0275271753146
Iteration 36 Loss=  0.0247287251873
Iteration 37 Loss=  0.0225660319631
Iteration 38 Loss=  0.0208340660683
Iteration 39 Loss=  0.0194745539574
Iteration 40 Loss=  0.0185643471445
Iteration 41 Loss=  0.0181445243415
Iteration 42 Loss=  0.0179049730642
Iteration 43 Loss=  0.0176027434128
Iteration 44 Loss=  0.0173977521723
Iteration 45 Loss=  0.0174873219569
[ -2.81984044e-04  -9.13847704e-05  -3.76999279e-05 ...,   1.46876340e-04
   9.11455046e-05   4.28701367e-05]
CROSS VALIDATION 5
Iteration 1 Loss=  81.7670598125
Iteration 2 Loss=  19.6474890639
Iteration 3 Loss=  15.8907513526
Iteration 4 Loss=  12.8523282405
Iteration 5 Loss=  10.3948729381
Iteration 6 Loss=  8.4073003255
Iteration 7 Loss=  6.79976553718
Iteration 8 Loss=  5.49960267884
Iteration 9 Loss=  4.44804010221
Iteration 10 Loss=  3.59754379787
Iteration 11 Loss=  2.90966895657
Iteration 12 Loss=  2.35332295473
Iteration 13 Loss=  1.90336197227
Iteration 14 Loss=  1.53945822907
Iteration 15 Loss=  1.24518265414
Iteration 16 Loss=  1.00724787477
Iteration 17 Loss=  0.814886686238
Iteration 18 Loss=  0.659384300054
Iteration 19 Loss=  0.533661985974
Iteration 20 Loss=  0.431988421454
Iteration 21 Loss=  0.349862080116
Iteration 22 Loss=  0.283718804946
Iteration 23 Loss=  0.230590194875
Iteration 24 Loss=  0.187847976958
Iteration 25 Loss=  0.153292887042
Iteration 26 Loss=  0.12531435804
Iteration 27 Loss=  0.102689166991
Iteration 28 Loss=  0.0844431420567
Iteration 29 Loss=  0.0698137087471
Iteration 30 Loss=  0.058138835919
Iteration 31 Loss=  0.0488633215028
Iteration 32 Loss=  0.0415054839391
Iteration 33 Loss=  0.0356353740505
Iteration 34 Loss=  0.0309454836992
Iteration 35 Loss=  0.0272731307217
Iteration 36 Loss=  0.0244811912134
Iteration 37 Loss=  0.0223242547636
Iteration 38 Loss=  0.0205977515067
Iteration 39 Loss=  0.0192413641497
Iteration 40 Loss=  0.018330748817
Iteration 41 Loss=  0.0179083720487
Iteration 42 Loss=  0.0176666963289
Iteration 43 Loss=  0.0173605495284
Iteration 44 Loss=  0.0171527509549
Iteration 45 Loss=  0.017247098601
[ -2.65709562e-04  -8.99301728e-05  -2.74167557e-05 ...,   1.22529333e-04
   6.11945706e-05   4.63502301e-05]
CROSS VALIDATION 6
Iteration 1 Loss=  81.9627227214
Iteration 2 Loss=  19.6655143868
Iteration 3 Loss=  15.9053301074
Iteration 4 Loss=  12.8641194351
Iteration 5 Loss=  10.4044095736
Iteration 6 Loss=  8.41501348939
Iteration 7 Loss=  6.80600388988
Iteration 8 Loss=  5.5046482135
Iteration 9 Loss=  4.45212088756
Iteration 10 Loss=  3.60084426952
Iteration 11 Loss=  2.91233819085
Iteration 12 Loss=  2.35548122958
Iteration 13 Loss=  1.9051058272
Iteration 14 Loss=  1.54086445846
Iteration 15 Loss=  1.24631303724
Iteration 16 Loss=  1.00815733936
Iteration 17 Loss=  0.815625975241
Iteration 18 Loss=  0.65998832461
Iteration 19 Loss=  0.534153077986
Iteration 20 Loss=  0.432388574779
Iteration 21 Loss=  0.350199976472
Iteration 22 Loss=  0.284032915858
Iteration 23 Loss=  0.230931430239
Iteration 24 Loss=  0.188278470499
Iteration 25 Loss=  0.153851607065
Iteration 26 Loss=  0.125949838816
Iteration 27 Loss=  0.103339697357
Iteration 28 Loss=  0.0850857938482
Iteration 29 Loss=  0.0704353978046
Iteration 30 Loss=  0.058726343197
Iteration 31 Loss=  0.0494014091178
Iteration 32 Loss=  0.0419787642116
Iteration 33 Loss=  0.0360388774978
Iteration 34 Loss=  0.0312963237434
Iteration 35 Loss=  0.0275934624302
Iteration 36 Loss=  0.0247808870509
Iteration 37 Loss=  0.022608603335
Iteration 38 Loss=  0.020873028372
Iteration 39 Loss=  0.0195095262603
Iteration 40 Loss=  0.018585011438
Iteration 41 Loss=  0.0181457130456
Iteration 42 Loss=  0.0179013680245
Iteration 43 Loss=  0.0175993178223
Iteration 44 Loss=  0.0173882761069
Iteration 45 Loss=  0.0174640944789
[ -2.95050206e-04  -9.95630554e-05  -3.61754997e-05 ...,   1.38567525e-04
   8.40569708e-05   4.01021894e-05]
CROSS VALIDATION 7
Iteration 1 Loss=  81.9627227214
Iteration 2 Loss=  19.6655143868
Iteration 3 Loss=  15.9053301074
Iteration 4 Loss=  12.8641194351
Iteration 5 Loss=  10.4044095736
Iteration 6 Loss=  8.41501348939
Iteration 7 Loss=  6.80600388988
Iteration 8 Loss=  5.5046482135
Iteration 9 Loss=  4.45212088756
Iteration 10 Loss=  3.60084426952
Iteration 11 Loss=  2.91233819085
Iteration 12 Loss=  2.35548122957
Iteration 13 Loss=  1.90510582704
Iteration 14 Loss=  1.54086445696
Iteration 15 Loss=  1.24631302574
Iteration 16 Loss=  1.00815726764
Iteration 17 Loss=  0.815625606872
Iteration 18 Loss=  0.659986738751
Iteration 19 Loss=  0.534147255021
Iteration 20 Loss=  0.43237011279
Iteration 21 Loss=  0.350149417067
Iteration 22 Loss=  0.283915740968
Iteration 23 Loss=  0.230711118086
Iteration 24 Loss=  0.187953943791
Iteration 25 Loss=  0.15346705143
Iteration 26 Loss=  0.125550345771
Iteration 27 Loss=  0.102950638971
Iteration 28 Loss=  0.0847210512641
Iteration 29 Loss=  0.0700975528558
Iteration 30 Loss=  0.0584126416372
Iteration 31 Loss=  0.0491150188904
Iteration 32 Loss=  0.0417346860857
Iteration 33 Loss=  0.035851303213
Iteration 34 Loss=  0.0311590446356
Iteration 35 Loss=  0.0274909854965
Iteration 36 Loss=  0.0247023447747
Iteration 37 Loss=  0.0225432656299
Iteration 38 Loss=  0.0208106822897
Iteration 39 Loss=  0.0194442449553
Iteration 40 Loss=  0.0185158409384
Iteration 41 Loss=  0.0180769571508
Iteration 42 Loss=  0.0178422970223
Iteration 43 Loss=  0.0175513426369
Iteration 44 Loss=  0.0173581490827
Iteration 45 Loss=  0.0174675105432
Iteration 46 Loss=  0.017808945535
Iteration 47 Loss=  0.0181252573024
Iteration 48 Loss=  0.0184268207464
Iteration 49 Loss=  0.0187766522998
Iteration 50 Loss=  0.019150182072
Iteration 51 Loss=  0.0195149249284
Iteration 52 Loss=  0.019898502712
Iteration 53 Loss=  0.0202990425541
Iteration 54 Loss=  0.0206414323122
Iteration 55 Loss=  0.0208704813932
Iteration 56 Loss=  0.0209890008858
Iteration 57 Loss=  0.0210352718514
[ -3.08713226e-04  -1.72045176e-04  -6.04282426e-05 ...,   1.38131629e-04
   7.25301606e-05   2.57117264e-05]
CROSS VALIDATION 8
Iteration 1 Loss=  81.9627227214
Iteration 2 Loss=  19.6655143868
Iteration 3 Loss=  15.9053301074
Iteration 4 Loss=  12.8641194351
Iteration 5 Loss=  10.4044095736
Iteration 6 Loss=  8.41501348939
Iteration 7 Loss=  6.80600388988
Iteration 8 Loss=  5.5046482135
Iteration 9 Loss=  4.45212088756
Iteration 10 Loss=  3.60084426952
Iteration 11 Loss=  2.91233819085
Iteration 12 Loss=  2.35548122958
Iteration 13 Loss=  1.9051058272
Iteration 14 Loss=  1.54086445846
Iteration 15 Loss=  1.24631303724
Iteration 16 Loss=  1.00815733938
Iteration 17 Loss=  0.815625975306
Iteration 18 Loss=  0.659988324831
Iteration 19 Loss=  0.534153078263
Iteration 20 Loss=  0.432388570576
Iteration 21 Loss=  0.35019992571
Iteration 22 Loss=  0.284032587102
Iteration 23 Loss=  0.230930078066
Iteration 24 Loss=  0.188275028647
Iteration 25 Loss=  0.153845891689
Iteration 26 Loss=  0.125941955358
Iteration 27 Loss=  0.103327505456
Iteration 28 Loss=  0.0850621998653
Iteration 29 Loss=  0.0703846796224
Iteration 30 Loss=  0.0586234812623
Iteration 31 Loss=  0.0492293836845
Iteration 32 Loss=  0.041765283068
Iteration 33 Loss=  0.0358434584607
Iteration 34 Loss=  0.0311412053048
Iteration 35 Loss=  0.0274667798866
Iteration 36 Loss=  0.0246722776403
Iteration 37 Loss=  0.0225104982764
Iteration 38 Loss=  0.020778344719
Iteration 39 Loss=  0.0194101705341
Iteration 40 Loss=  0.0184723910418
Iteration 41 Loss=  0.0180167993226
Iteration 42 Loss=  0.0177666941028
Iteration 43 Loss=  0.0174632624951
Iteration 44 Loss=  0.0172540185487
Iteration 45 Loss=  0.0173458156047
[ -2.79224169e-04  -9.01601498e-05  -1.54115720e-05 ...,   1.41576519e-04
   7.70682144e-05   3.94256200e-05]
CROSS VALIDATION 9
Iteration 1 Loss=  164.837280255
Iteration 2 Loss=  185.850581238
Iteration 3 Loss=  21.0939738473
Iteration 4 Loss=  17.0606581002
Iteration 5 Loss=  13.7985406125
Iteration 6 Loss=  11.1601628681
Iteration 7 Loss=  9.02626145332
Iteration 8 Loss=  7.30037695578
Iteration 9 Loss=  5.9044936802
Iteration 10 Loss=  4.77551308579
Iteration 11 Loss=  3.86240155117
Iteration 12 Loss=  3.12388360624
Iteration 13 Loss=  2.52657657138
Iteration 14 Loss=  2.04348280281
Iteration 15 Loss=  1.65277227026
Iteration 16 Loss=  1.33680050669
Iteration 17 Loss=  1.08131065421
Iteration 18 Loss=  0.874762354001
Iteration 19 Loss=  0.707773817956
Iteration 20 Loss=  0.572755255734
Iteration 21 Loss=  0.46362294454
Iteration 22 Loss=  0.375466523519
Iteration 23 Loss=  0.304276862955
Iteration 24 Loss=  0.246774030025
Iteration 25 Loss=  0.20029100967
Iteration 26 Loss=  0.162700318573
Iteration 27 Loss=  0.132400760394
Iteration 28 Loss=  0.108088467202
Iteration 29 Loss=  0.0885950201872
Iteration 30 Loss=  0.0729592631903
Iteration 31 Loss=  0.0604439960037
Iteration 32 Loss=  0.0504924576125
Iteration 33 Loss=  0.0426703052013
Iteration 34 Loss=  0.0365970247533
Iteration 35 Loss=  0.0318883182241
Iteration 36 Loss=  0.0281606844819
Iteration 37 Loss=  0.0251439472237
Iteration 38 Loss=  0.0226697617984
Iteration 39 Loss=  0.0206545489743
Iteration 40 Loss=  0.0191148065799
Iteration 41 Loss=  0.0180824662675
Iteration 42 Loss=  0.0173505047443
Iteration 43 Loss=  0.0166200805337
Iteration 44 Loss=  0.0160847509645
Iteration 45 Loss=  0.0159323634542
Iteration 46 Loss=  0.0159889658036
[ -3.76397354e-04  -9.98160737e-05  -6.94165068e-05 ...,   2.28698411e-04
   1.15049979e-04   2.45703140e-05]
CROSS VALIDATION 10
Iteration 1 Loss=  82.0485111825
Iteration 2 Loss=  19.6785207287
Iteration 3 Loss=  15.9158495455
Iteration 4 Loss=  12.8726274828
Iteration 5 Loss=  10.4112908229
Iteration 6 Loss=  8.42057899559
Iteration 7 Loss=  6.81050523218
Iteration 8 Loss=  5.50828886702
Iteration 9 Loss=  4.45506541894
Iteration 10 Loss=  3.60322576682
Iteration 11 Loss=  2.91426424688
Iteration 12 Loss=  2.35703871035
Iteration 13 Loss=  1.90636458609
Iteration 14 Loss=  1.54188023595
Iteration 15 Loss=  1.24713049156
Iteration 16 Loss=  1.00881506925
Iteration 17 Loss=  0.816159619596
Iteration 18 Loss=  0.660423743462
Iteration 19 Loss=  0.5345065126
Iteration 20 Loss=  0.432674621816
Iteration 21 Loss=  0.350433364001
Iteration 22 Loss=  0.284223877924
Iteration 23 Loss=  0.231075562488
Iteration 24 Loss=  0.188348150963
Iteration 25 Loss=  0.153798008853
Iteration 26 Loss=  0.125723844259
Iteration 27 Loss=  0.102964773408
Iteration 28 Loss=  0.0846425861117
Iteration 29 Loss=  0.0699709159154
Iteration 30 Loss=  0.0582611740873
Iteration 31 Loss=  0.0489581564492
Iteration 32 Loss=  0.0415803886638
Iteration 33 Loss=  0.0356930971642
Iteration 34 Loss=  0.0309939628233
Iteration 35 Loss=  0.0273215584087
Iteration 36 Loss=  0.0245307040595
Iteration 37 Loss=  0.0223712742424
Iteration 38 Loss=  0.0206405697433
Iteration 39 Loss=  0.0192761771681
Iteration 40 Loss=  0.0183509948035
Iteration 41 Loss=  0.0179146244182
Iteration 42 Loss=  0.0176757699903
Iteration 43 Loss=  0.0173839161738
Iteration 44 Loss=  0.0172119622486
Iteration 45 Loss=  0.0173653931013
Iteration 46 Loss=  0.0177423707544
Iteration 47 Loss=  0.018084853594
Iteration 48 Loss=  0.0184105825203
Iteration 49 Loss=  0.0187540501843
Iteration 50 Loss=  0.0191085903538
Iteration 51 Loss=  0.0194397698994
Iteration 52 Loss=  0.0197954087749
Iteration 53 Loss=  0.0201820991118
Iteration 54 Loss=  0.0205258916031
Iteration 55 Loss=  0.0207615832692
Iteration 56 Loss=  0.0208847481488
Iteration 57 Loss=  0.0209324853666
[ -2.80266170e-04  -1.61009889e-04  -5.25460949e-05 ...,   1.40439464e-04
   6.67851654e-05   2.83504778e-05]
CROSS VALIDATION 11
Iteration 1 Loss=  82.0484086128
Iteration 2 Loss=  19.678512283
Iteration 3 Loss=  15.9158427146
Iteration 4 Loss=  12.8726219581
Iteration 5 Loss=  10.4112863546
Iteration 6 Loss=  8.42057538161
Iteration 7 Loss=  6.81050230922
Iteration 8 Loss=  5.50828650295
Iteration 9 Loss=  4.4550635069
Iteration 10 Loss=  3.60322422039
Iteration 11 Loss=  2.9142629962
Iteration 12 Loss=  2.35703769903
Iteration 13 Loss=  1.90636376886
Iteration 14 Loss=  1.54187957677
Iteration 15 Loss=  1.24712996172
Iteration 16 Loss=  1.00881464381
Iteration 17 Loss=  0.816159275644
Iteration 18 Loss=  0.660423471231
Iteration 19 Loss=  0.534506346502
Iteration 20 Loss=  0.432674770466
Iteration 21 Loss=  0.350434711632
Iteration 22 Loss=  0.284229549581
Iteration 23 Loss=  0.231095043943
Iteration 24 Loss=  0.18840580293
Iteration 25 Loss=  0.153941862026
Iteration 26 Loss=  0.126005631202
Iteration 27 Loss=  0.103367103446
Iteration 28 Loss=  0.0850767827997
Iteration 29 Loss=  0.0703688687719
Iteration 30 Loss=  0.0585856316846
Iteration 31 Loss=  0.0491988637498
Iteration 32 Loss=  0.0417641728967
Iteration 33 Loss=  0.0358592592425
Iteration 34 Loss=  0.0311553158807
Iteration 35 Loss=  0.0274697766283
Iteration 36 Loss=  0.0246609744364
Iteration 37 Loss=  0.0224879799967
Iteration 38 Loss=  0.0207486722063
Iteration 39 Loss=  0.0193872072278
Iteration 40 Loss=  0.018478307587
Iteration 41 Loss=  0.0180581466107
Iteration 42 Loss=  0.0178113669375
Iteration 43 Loss=  0.017498417018
Iteration 44 Loss=  0.0172778530089
Iteration 45 Loss=  0.0173446919219
[ -2.91724258e-04  -8.75704908e-05  -2.20468636e-05 ...,   1.42662322e-04
   8.53223246e-05   3.98685954e-05]
CROSS VALIDATION 12
Iteration 1 Loss=  130.386033022
Iteration 2 Loss=  75.3781205095
Iteration 3 Loss=  16.0556816128
Iteration 4 Loss=  12.9857226782
Iteration 5 Loss=  10.5027614237
Iteration 6 Loss=  8.49455977591
Iteration 7 Loss=  6.87034036817
Iteration 8 Loss=  5.55668310304
Iteration 9 Loss=  4.49420632064
Iteration 10 Loss=  3.63488255097
Iteration 11 Loss=  2.93986751315
Iteration 12 Loss=  2.37774422547
Iteration 13 Loss=  1.92310285531
Iteration 14 Loss=  1.55539212031
Iteration 15 Loss=  1.25799035222
Iteration 16 Loss=  1.01745434862
Iteration 17 Loss=  0.822912404553
Iteration 18 Loss=  0.665574902828
Iteration 19 Loss=  0.538341619497
Iteration 20 Loss=  0.435487392531
Iteration 21 Loss=  0.352399451005
Iteration 22 Loss=  0.285329687264
Iteration 23 Loss=  0.231209565894
Iteration 24 Loss=  0.187621105573
Iteration 25 Loss=  0.152676319517
Iteration 26 Loss=  0.124699171665
Iteration 27 Loss=  0.102209194556
Iteration 28 Loss=  0.0841434698043
Iteration 29 Loss=  0.0697199992736
Iteration 30 Loss=  0.0582810985577
Iteration 31 Loss=  0.0491504591642
Iteration 32 Loss=  0.0418190753947
Iteration 33 Loss=  0.0359913716117
Iteration 34 Loss=  0.0314233884773
Iteration 35 Loss=  0.0278045911516
Iteration 36 Loss=  0.0248683498747
Iteration 37 Loss=  0.022524123853
Iteration 38 Loss=  0.0206701241269
Iteration 39 Loss=  0.0191817459641
Iteration 40 Loss=  0.0180666666786
Iteration 41 Loss=  0.0174494913885
Iteration 42 Loss=  0.0173177947093
Iteration 43 Loss=  0.0172615065954
[ -5.27756734e-04  -1.77155709e-04  -1.20504268e-04 ...,   1.41243734e-04
   5.78458433e-05   2.12886831e-05]
CROSS VALIDATION 13
Iteration 1 Loss=  240.340965987
Iteration 2 Loss=  91.1255192557
Iteration 3 Loss=  18.664880527
Iteration 4 Loss=  15.0960244597
Iteration 5 Loss=  12.2095587035
Iteration 6 Loss=  9.87500544482
Iteration 7 Loss=  7.98683514312
Iteration 8 Loss=  6.45969624642
Iteration 9 Loss=  5.22455701933
Iteration 10 Loss=  4.2255850871
Iteration 11 Loss=  3.41762366306
Iteration 12 Loss=  2.76415045974
Iteration 13 Loss=  2.23562725624
Iteration 14 Loss=  1.80816601331
Iteration 15 Loss=  1.46245165162
Iteration 16 Loss=  1.1828703709
Iteration 17 Loss=  0.956793425909
Iteration 18 Loss=  0.773987280838
Iteration 19 Loss=  0.626179147217
Iteration 20 Loss=  0.506692474321
Iteration 21 Loss=  0.410091432859
Iteration 22 Loss=  0.332020271027
Iteration 23 Loss=  0.269051677536
Iteration 24 Loss=  0.218408272152
Iteration 25 Loss=  0.177772127151
Iteration 26 Loss=  0.14517188683
Iteration 27 Loss=  0.118981769193
Iteration 28 Loss=  0.0979783189719
Iteration 29 Loss=  0.0811848950434
Iteration 30 Loss=  0.0677169844132
Iteration 31 Loss=  0.0568156856886
Iteration 32 Loss=  0.0479501278857
Iteration 33 Loss=  0.040786156798
Iteration 34 Loss=  0.0350310218085
Iteration 35 Loss=  0.0304229134279
Iteration 36 Loss=  0.0267749795503
Iteration 37 Loss=  0.0239270879636
Iteration 38 Loss=  0.0216874717557
Iteration 39 Loss=  0.0199005256432
Iteration 40 Loss=  0.0185731105144
Iteration 41 Loss=  0.0178121875767
Iteration 42 Loss=  0.0175172001089
Iteration 43 Loss=  0.0172312832676
Iteration 44 Loss=  0.0168542854536
Iteration 45 Loss=  0.0166993841293
Iteration 46 Loss=  0.0168040521902
Iteration 47 Loss=  0.0170592897736
Iteration 48 Loss=  0.0174488806843
Iteration 49 Loss=  0.0178805976377
Iteration 50 Loss=  0.0183589638812
Iteration 51 Loss=  0.0188805545747
Iteration 52 Loss=  0.0195317318229
Iteration 53 Loss=  0.0202250412448
Iteration 54 Loss=  0.0207144413946
Iteration 55 Loss=  0.0209538046848
Iteration 56 Loss=  0.0210448881797
[ -3.09508551e-04  -1.76598204e-04  -5.08303321e-05 ...,   1.39996086e-04
   7.43909119e-05   2.12939759e-05]
CROSS VALIDATION 14
Iteration 1 Loss=  81.8177844613
Iteration 2 Loss=  19.6639449647
Iteration 3 Loss=  15.9040607698
Iteration 4 Loss=  12.8630928037
Iteration 5 Loss=  10.4035792414
Iteration 6 Loss=  8.41434192251
Iteration 7 Loss=  6.8054607314
Iteration 8 Loss=  5.50420891158
Iteration 9 Loss=  4.4517655882
Iteration 10 Loss=  3.60055692889
Iteration 11 Loss=  2.91210587595
Iteration 12 Loss=  2.35529356785
Iteration 13 Loss=  1.90495444463
Iteration 14 Loss=  1.5407416935
Iteration 15 Loss=  1.24620753324
Iteration 16 Loss=  1.00804296103
Iteration 17 Loss=  0.815452588613
Iteration 18 Loss=  0.659700187766
Iteration 19 Loss=  0.533741356583
Iteration 20 Loss=  0.431912726242
Iteration 21 Loss=  0.349708315089
Iteration 22 Loss=  0.283538582728
Iteration 23 Loss=  0.230442244142
Iteration 24 Loss=  0.187800022017
Iteration 25 Loss=  0.153377473956
Iteration 26 Loss=  0.125473709978
Iteration 27 Loss=  0.102858897455
Iteration 28 Loss=  0.0846079118645
Iteration 29 Loss=  0.0699733904794
Iteration 30 Loss=  0.0582952098494
Iteration 31 Loss=  0.0490140185881
Iteration 32 Loss=  0.0416413295111
Iteration 33 Loss=  0.0357512381039
Iteration 34 Loss=  0.0310468548333
Iteration 35 Loss=  0.0273653764922
Iteration 36 Loss=  0.02456429466
Iteration 37 Loss=  0.0223982253218
Iteration 38 Loss=  0.0206658473948
Iteration 39 Loss=  0.0193072096678
Iteration 40 Loss=  0.0183879800722
Iteration 41 Loss=  0.0179451606067
Iteration 42 Loss=  0.0176787733314
Iteration 43 Loss=  0.0173558167522
Iteration 44 Loss=  0.0171342538298
Iteration 45 Loss=  0.0172231221124
[ -2.58274832e-04  -7.78779156e-05  -1.78631168e-05 ...,   1.22178183e-04
   6.73117758e-05   3.74511309e-05]
CROSS VALIDATION 15
Iteration 1 Loss=  81.8177844613
Iteration 2 Loss=  19.6639449647
Iteration 3 Loss=  15.9040607698
Iteration 4 Loss=  12.8630928037
Iteration 5 Loss=  10.4035792414
Iteration 6 Loss=  8.41434192251
Iteration 7 Loss=  6.80546073141
Iteration 8 Loss=  5.50420891165
Iteration 9 Loss=  4.45176558894
Iteration 10 Loss=  3.60055693501
Iteration 11 Loss=  2.91210591707
Iteration 12 Loss=  2.355293796
Iteration 13 Loss=  1.90495550953
Iteration 14 Loss=  1.54074594402
Iteration 15 Loss=  1.24622221369
Iteration 16 Loss=  1.0080869263
Iteration 17 Loss=  0.815564640761
Iteration 18 Loss=  0.659930818123
Iteration 19 Loss=  0.5340990705
Iteration 20 Loss=  0.432332382033
Iteration 21 Loss=  0.350122823024
Iteration 22 Loss=  0.283902799366
Iteration 23 Loss=  0.230717514441
Iteration 24 Loss=  0.187981256435
Iteration 25 Loss=  0.153508974532
Iteration 26 Loss=  0.125600628805
Iteration 27 Loss=  0.102993255127
Iteration 28 Loss=  0.0847488932751
Iteration 29 Loss=  0.0701152603411
Iteration 30 Loss=  0.0584296714996
Iteration 31 Loss=  0.049139046925
Iteration 32 Loss=  0.0417652733252
Iteration 33 Loss=  0.0358836406237
Iteration 34 Loss=  0.0311895891939
Iteration 35 Loss=  0.0275173709747
Iteration 36 Loss=  0.0247248711066
Iteration 37 Loss=  0.0225639850357
Iteration 38 Loss=  0.020830748375
Iteration 39 Loss=  0.0194636926293
Iteration 40 Loss=  0.0185336580199
Iteration 41 Loss=  0.0180930732273
Iteration 42 Loss=  0.0178587303895
Iteration 43 Loss=  0.0175667925767
Iteration 44 Loss=  0.0173663603929
Iteration 45 Loss=  0.0174655415591
[ -2.90030067e-04  -7.57902163e-05  -3.29247633e-05 ...,   1.42820327e-04
   8.34042713e-05   3.96750823e-05]
CROSS VALIDATION 16
Iteration 1 Loss=  196.241314777
Iteration 2 Loss=  19.1110650537
Iteration 3 Loss=  15.4569026435
Iteration 4 Loss=  12.5014564011
Iteration 5 Loss=  10.1111465021
Iteration 6 Loss=  8.177939821
Iteration 7 Loss=  6.61443018512
Iteration 8 Loss=  5.34986726618
Iteration 9 Loss=  4.3270540479
Iteration 10 Loss=  3.49978914271
Iteration 11 Loss=  2.83069889089
Iteration 12 Loss=  2.28954279049
Iteration 13 Loss=  1.85185961149
Iteration 14 Loss=  1.49786526774
Iteration 15 Loss=  1.2115599964
Iteration 16 Loss=  0.980007702764
Iteration 17 Loss=  0.792756157123
Iteration 18 Loss=  0.641368992408
Iteration 19 Loss=  0.519030532552
Iteration 20 Loss=  0.42019010788
Iteration 21 Loss=  0.34033127277
Iteration 22 Loss=  0.275873212591
Iteration 23 Loss=  0.22392293727
Iteration 24 Loss=  0.182043743782
Iteration 25 Loss=  0.148309011551
Iteration 26 Loss=  0.121222990693
Iteration 27 Loss=  0.0995192167471
Iteration 28 Loss=  0.082156810338
Iteration 29 Loss=  0.0682374161155
Iteration 30 Loss=  0.057046217349
Iteration 31 Loss=  0.0480890737265
Iteration 32 Loss=  0.0409557457581
Iteration 33 Loss=  0.0352608533928
Iteration 34 Loss=  0.0307447356661
Iteration 35 Loss=  0.027257724259
Iteration 36 Loss=  0.0246136379673
Iteration 37 Loss=  0.0225401539146
Iteration 38 Loss=  0.0208568261502
Iteration 39 Loss=  0.0195397635165
Iteration 40 Loss=  0.0186852383837
Iteration 41 Loss=  0.0182925239961
Iteration 42 Loss=  0.0180223541563
Iteration 43 Loss=  0.0176955725836
Iteration 44 Loss=  0.0175067769115
Iteration 45 Loss=  0.017570876632
[ -3.16109149e-04  -1.01996907e-04  -8.30785040e-05 ...,   1.88217186e-04
   5.59190773e-05   3.98694099e-05]
CROSS VALIDATION 17
Iteration 1 Loss=  81.8396897055
Iteration 2 Loss=  19.6658277889
Iteration 3 Loss=  15.9055835848
Iteration 4 Loss=  12.8643244458
Iteration 5 Loss=  10.4045753849
Iteration 6 Loss=  8.41514759638
Iteration 7 Loss=  6.80611235476
Iteration 8 Loss=  5.5047359399
Iteration 9 Loss=  4.45219184477
Iteration 10 Loss=  3.60090168311
Iteration 11 Loss=  2.9123847275
Iteration 12 Loss=  2.35551922724
Iteration 13 Loss=  1.90513763264
Iteration 14 Loss=  1.54089275761
Iteration 15 Loss=  1.24634016309
Iteration 16 Loss=  1.00818183534
Iteration 17 Loss=  0.81564204696
Iteration 18 Loss=  0.659995037907
Iteration 19 Loss=  0.534154649323
Iteration 20 Loss=  0.432387651509
Iteration 21 Loss=  0.350194590662
Iteration 22 Loss=  0.284019457437
Iteration 23 Loss=  0.230910525107
Iteration 24 Loss=  0.188257345388
Iteration 25 Loss=  0.153835395147
Iteration 26 Loss=  0.12593755335
Iteration 27 Loss=  0.103321931861
Iteration 28 Loss=  0.0850617012513
Iteration 29 Loss=  0.0704093003483
Iteration 30 Loss=  0.0587021344541
Iteration 31 Loss=  0.0493854068765
Iteration 32 Loss=  0.0419799662353
Iteration 33 Loss=  0.0360635264571
Iteration 34 Loss=  0.0313400138516
Iteration 35 Loss=  0.0276465142573
Iteration 36 Loss=  0.0248381953806
Iteration 37 Loss=  0.0226681687714
Iteration 38 Loss=  0.0209333547851
Iteration 39 Loss=  0.0195697422501
Iteration 40 Loss=  0.0186461295972
Iteration 41 Loss=  0.0182085671107
Iteration 42 Loss=  0.0179630417982
Iteration 43 Loss=  0.0176577031928
Iteration 44 Loss=  0.0174440638394
Iteration 45 Loss=  0.0175193641888
[ -2.85906074e-04  -8.89724119e-05  -2.58239707e-05 ...,   1.46314892e-04
   8.00174993e-05   4.03522528e-05]
CROSS VALIDATION 18
Iteration 1 Loss=  134.056211557
Iteration 2 Loss=  150.929206606
Iteration 3 Loss=  18.0381627193
Iteration 4 Loss=  14.589315269
Iteration 5 Loss=  11.7999453226
Iteration 6 Loss=  9.54391028061
Iteration 7 Loss=  7.71925580442
Iteration 8 Loss=  6.2435020178
Iteration 9 Loss=  5.04990583938
Iteration 10 Loss=  4.08453443755
Iteration 11 Loss=  3.30379428804
Iteration 12 Loss=  2.67241646028
Iteration 13 Loss=  2.16182642152
Iteration 14 Loss=  1.74885772665
Iteration 15 Loss=  1.41480549138
Iteration 16 Loss=  1.14459671382
Iteration 17 Loss=  0.926046059538
Iteration 18 Loss=  0.749286613689
Iteration 19 Loss=  0.606337025146
Iteration 20 Loss=  0.49075010016
Iteration 21 Loss=  0.397322003762
Iteration 22 Loss=  0.321841084134
Iteration 23 Loss=  0.260875706722
Iteration 24 Loss=  0.211653472293
Iteration 25 Loss=  0.171986986482
Iteration 26 Loss=  0.140115128225
Iteration 27 Loss=  0.114553800013
Iteration 28 Loss=  0.094060741489
Iteration 29 Loss=  0.0775802952944
Iteration 30 Loss=  0.0642444892629
Iteration 31 Loss=  0.0534815880649
Iteration 32 Loss=  0.0449328006362
Iteration 33 Loss=  0.0382381546288
Iteration 34 Loss=  0.0329399479943
Iteration 35 Loss=  0.0287089247964
Iteration 36 Loss=  0.0254978271873
Iteration 37 Loss=  0.0231727356482
Iteration 38 Loss=  0.0213562353055
Iteration 39 Loss=  0.0198353300781
Iteration 40 Loss=  0.018722153069
Iteration 41 Loss=  0.0181306990447
Iteration 42 Loss=  0.0178102489789
Iteration 43 Loss=  0.0174042931362
Iteration 44 Loss=  0.0170562115823
Iteration 45 Loss=  0.0170246302063
[ -3.25715408e-04  -2.05917204e-04  -1.00710806e-04 ...,   2.07783187e-04
   8.33284166e-05   3.00421904e-05]
CROSS VALIDATION 19
Iteration 1 Loss=  145.563945883
Iteration 2 Loss=  40.3506784197
Iteration 3 Loss=  19.8715336632
Iteration 4 Loss=  16.0719570531
Iteration 5 Loss=  12.9988861401
Iteration 6 Loss=  10.5134079394
Iteration 7 Loss=  8.50317060318
Iteration 8 Loss=  6.87730474507
Iteration 9 Loss=  5.56231584407
Iteration 10 Loss=  4.49876205563
Iteration 11 Loss=  3.63856727869
Iteration 12 Loss=  2.94284809993
Iteration 13 Loss=  2.38015661128
Iteration 14 Loss=  1.9250601574
Iteration 15 Loss=  1.55699441664
Iteration 16 Loss=  1.25933687003
Iteration 17 Loss=  1.01864962417
Iteration 18 Loss=  0.82404356682
Iteration 19 Loss=  0.666682609664
Iteration 20 Loss=  0.539451768477
Iteration 21 Loss=  0.436600158271
Iteration 22 Loss=  0.353455538049
Iteration 23 Loss=  0.286297684687
Iteration 24 Loss=  0.23209534293
Iteration 25 Loss=  0.188327466444
Iteration 26 Loss=  0.153029929796
Iteration 27 Loss=  0.124665439738
Iteration 28 Loss=  0.101922057049
Iteration 29 Loss=  0.0837246728635
Iteration 30 Loss=  0.0691726550799
Iteration 31 Loss=  0.0575047929896
Iteration 32 Loss=  0.0481858901302
Iteration 33 Loss=  0.040804856121
Iteration 34 Loss=  0.0350038309934
Iteration 35 Loss=  0.0305168230239
Iteration 36 Loss=  0.027109086098
Iteration 37 Loss=  0.0244655820695
Iteration 38 Loss=  0.0223454897661
Iteration 39 Loss=  0.0207133119825
Iteration 40 Loss=  0.0196551695687
Iteration 41 Loss=  0.0190380792241
Iteration 42 Loss=  0.0184338782921
Iteration 43 Loss=  0.0177955503075
Iteration 44 Loss=  0.0173387042395
Iteration 45 Loss=  0.0172108190703
Iteration 46 Loss=  0.0172899630108
[ -2.96313519e-04  -1.47978384e-04  -5.63534886e-05 ...,   1.93847025e-04
   6.90617326e-05   2.43179929e-05]
Accuracy (Logistic Loss):	0.85 for lmda= 1 learning rate= 0.001
---------------------------------------------------------------------------------
lmda= 1 learning rate= 0.01
CROSS VALIDATION 0
Iteration 1 Loss=  2190.3204803
Iteration 2 Loss=  394.832584314
Iteration 3 Loss=  565.749878369
Iteration 4 Loss=  35.2333208925
Iteration 5 Loss=  4.1392113643
Iteration 6 Loss=  0.487972345341
Iteration 7 Loss=  5282.46263401
Iteration 8 Loss=  555.676200573
Iteration 9 Loss=  856.46388153
Iteration 10 Loss=  4331.95035891
Iteration 11 Loss=  1901.89492354
Iteration 12 Loss=  2709.70157228
Iteration 13 Loss=  1210.21211452
Iteration 14 Loss=  1634.29487361
Iteration 15 Loss=  2535.39793496
Iteration 16 Loss=  525.630832558
Iteration 17 Loss=  1323.620445
Iteration 18 Loss=  4346.53331171
Iteration 19 Loss=  2141.64463074
Iteration 20 Loss=  460.387601829
Iteration 21 Loss=  4971.09690108
Iteration 22 Loss=  1330.23813296
Iteration 23 Loss=  2683.00593773
Iteration 24 Loss=  3682.89622354
Iteration 25 Loss=  2425.44630954
Iteration 26 Loss=  2264.88334539
Iteration 27 Loss=  240.242483286
Iteration 28 Loss=  28.2236930774
Iteration 29 Loss=  3.32268142794
Iteration 30 Loss=  0.427940124187
Iteration 31 Loss=  3302.88929954
Iteration 32 Loss=  988.730768104
Iteration 33 Loss=  130.168527578
Iteration 34 Loss=  15.2985344528
Iteration 35 Loss=  1.81652711694
Iteration 36 Loss=  0.278000475559
Iteration 37 Loss=  6182.33350592
Iteration 38 Loss=  985.414339739
Iteration 39 Loss=  1335.97680139
Iteration 40 Loss=  5547.10859448
Iteration 41 Loss=  216.172702148
Iteration 42 Loss=  26.2292743541
Iteration 43 Loss=  4032.74600457
Iteration 44 Loss=  1171.949623
Iteration 45 Loss=  834.303655006
Iteration 46 Loss=  1303.08224673
Iteration 47 Loss=  5495.71842108
Iteration 48 Loss=  598.959681701
Iteration 49 Loss=  702.057608039
Iteration 50 Loss=  3898.47629455
Iteration 51 Loss=  1493.3445585
Iteration 52 Loss=  2346.74661788
Iteration 53 Loss=  2378.73576264
Iteration 54 Loss=  1666.35245954
Iteration 55 Loss=  569.029235033
Iteration 56 Loss=  2384.08815107
Iteration 57 Loss=  112.37595226
Iteration 58 Loss=  13.2019294723
Iteration 59 Loss=  1.55101643143
Iteration 60 Loss=  0.197189254339
Iteration 61 Loss=  5078.78929037
Iteration 62 Loss=  3274.03224386
Iteration 63 Loss=  205.08074555
Iteration 64 Loss=  3494.36589585
Iteration 65 Loss=  2174.94043372
Iteration 66 Loss=  3480.4173199
Iteration 67 Loss=  1369.43691604
Iteration 68 Loss=  2335.00859161
Iteration 69 Loss=  9090.12163959
Iteration 70 Loss=  1555.10933228
Iteration 71 Loss=  733.736334302
Iteration 72 Loss=  3511.41041711
Iteration 73 Loss=  1065.13347419
Iteration 74 Loss=  1705.4817811
Iteration 75 Loss=  3428.55032893
Iteration 76 Loss=  952.692888472
Iteration 77 Loss=  110.468820788
Iteration 78 Loss=  12.9779050464
Iteration 79 Loss=  1.58450898038
Iteration 80 Loss=  4848.40694149
Iteration 81 Loss=  524.596741559
Iteration 82 Loss=  312.849544257
Iteration 83 Loss=  36.7535717
Iteration 84 Loss=  4.31819479803
Iteration 85 Loss=  6561.27366862
Iteration 86 Loss=  1655.8694908
Iteration 87 Loss=  1261.47093427
Iteration 88 Loss=  1191.2433829
Iteration 89 Loss=  1287.17377556
Iteration 90 Loss=  2108.97369693
Iteration 91 Loss=  2832.99355245
Iteration 92 Loss=  4056.83116381
Iteration 93 Loss=  335.460898807
Iteration 94 Loss=  3032.15688909
Iteration 95 Loss=  3847.47325373
Iteration 96 Loss=  4024.05177863
Iteration 97 Loss=  276.238340968
Iteration 98 Loss=  2109.06817886
Iteration 99 Loss=  1925.66268348
Iteration 100 Loss=  1801.45991884
[-0.09682417 -0.0391092  -0.08195338 ...,  0.0699524  -0.0756923
  0.01270601]
CROSS VALIDATION 1
Iteration 1 Loss=  2736.11104953
Iteration 2 Loss=  1199.86409404
Iteration 3 Loss=  474.423782983
Iteration 4 Loss=  4265.3193603
Iteration 5 Loss=  1438.88160879
Iteration 6 Loss=  740.121030505
Iteration 7 Loss=  3130.26556232
Iteration 8 Loss=  2390.67151922
Iteration 9 Loss=  364.177817855
Iteration 10 Loss=  2010.87664977
Iteration 11 Loss=  374.450444892
Iteration 12 Loss=  43.9904862357
Iteration 13 Loss=  5.18865796137
Iteration 14 Loss=  0.624881525835
Iteration 15 Loss=  4564.28787704
Iteration 16 Loss=  3245.54821061
Iteration 17 Loss=  1347.4123201
Iteration 18 Loss=  137.774192587
Iteration 19 Loss=  1741.37574117
Iteration 20 Loss=  637.178491834
Iteration 21 Loss=  2585.97357379
Iteration 22 Loss=  4039.46326538
Iteration 23 Loss=  1877.0181035
Iteration 24 Loss=  2176.14659882
Iteration 25 Loss=  1416.81813536
Iteration 26 Loss=  3080.45176501
Iteration 27 Loss=  2138.2337999
Iteration 28 Loss=  624.190519776
Iteration 29 Loss=  1680.19361257
Iteration 30 Loss=  2219.59051254
Iteration 31 Loss=  1480.94376657
Iteration 32 Loss=  1546.18685994
Iteration 33 Loss=  130.142091318
Iteration 34 Loss=  15.2896398064
Iteration 35 Loss=  1.79636695653
Iteration 36 Loss=  0.917834510413
Iteration 37 Loss=  5219.20354397
Iteration 38 Loss=  1804.99419291
Iteration 39 Loss=  1036.70468723
Iteration 40 Loss=  2469.31138921
Iteration 41 Loss=  677.06658333
Iteration 42 Loss=  1798.67077828
Iteration 43 Loss=  199.513613222
Iteration 44 Loss=  1997.55222064
Iteration 45 Loss=  4470.16067993
Iteration 46 Loss=  1682.67609599
Iteration 47 Loss=  1722.17477661
Iteration 48 Loss=  2718.31000881
Iteration 49 Loss=  1275.19295042
Iteration 50 Loss=  1924.52306162
Iteration 51 Loss=  1386.12533766
Iteration 52 Loss=  445.284387476
Iteration 53 Loss=  1263.86288219
Iteration 54 Loss=  1533.06600495
Iteration 55 Loss=  1591.12052528
Iteration 56 Loss=  2801.9914681
Iteration 57 Loss=  6359.66275202
Iteration 58 Loss=  741.502768212
Iteration 59 Loss=  1337.7658711
Iteration 60 Loss=  1687.83985625
Iteration 61 Loss=  1381.674442
Iteration 62 Loss=  808.073118058
Iteration 63 Loss=  94.9324486119
Iteration 64 Loss=  11.1536723378
Iteration 65 Loss=  1.32033609622
Iteration 66 Loss=  1.49393310985
Iteration 67 Loss=  2222.54833145
Iteration 68 Loss=  1652.45558366
Iteration 69 Loss=  2555.02285374
Iteration 70 Loss=  1609.81658701
Iteration 71 Loss=  1490.9313095
Iteration 72 Loss=  2291.07547334
Iteration 73 Loss=  2611.84206551
Iteration 74 Loss=  2356.41807886
Iteration 75 Loss=  1824.76936923
Iteration 76 Loss=  901.230940622
Iteration 77 Loss=  2696.24070686
Iteration 78 Loss=  1330.8535164
Iteration 79 Loss=  2291.08750147
Iteration 80 Loss=  5209.09946944
Iteration 81 Loss=  430.427903829
Iteration 82 Loss=  790.590692882
Iteration 83 Loss=  2085.43366773
Iteration 84 Loss=  3058.03856059
Iteration 85 Loss=  110.967581216
Iteration 86 Loss=  13.0364740133
Iteration 87 Loss=  1.53269698481
Iteration 88 Loss=  12.008824904
Iteration 89 Loss=  2788.36459546
Iteration 90 Loss=  813.15565874
Iteration 91 Loss=  548.555820531
Iteration 92 Loss=  1040.44743965
Iteration 93 Loss=  1563.60507388
Iteration 94 Loss=  2555.92311008
Iteration 95 Loss=  1540.86548758
Iteration 96 Loss=  4664.46998571
Iteration 97 Loss=  563.389531505
Iteration 98 Loss=  1418.52058448
Iteration 99 Loss=  4093.60395428
Iteration 100 Loss=  238.963688326
[-0.00969171 -0.00069055  0.00929812 ...,  0.01703518  0.00571333
  0.00900798]
CROSS VALIDATION 2
Iteration 1 Loss=  3722.28408834
Iteration 2 Loss=  981.664140498
Iteration 3 Loss=  913.451446205
Iteration 4 Loss=  4686.75264725
Iteration 5 Loss=  1683.1959583
Iteration 6 Loss=  155.174038948
Iteration 7 Loss=  1975.36617834
Iteration 8 Loss=  283.915138164
Iteration 9 Loss=  2353.11806213
Iteration 10 Loss=  2099.09440624
Iteration 11 Loss=  228.732938949
Iteration 12 Loss=  3222.34069533
Iteration 13 Loss=  1659.25223018
Iteration 14 Loss=  1410.08027629
Iteration 15 Loss=  1079.36606509
Iteration 16 Loss=  1790.90232966
Iteration 17 Loss=  2438.12732057
Iteration 18 Loss=  2074.6155502
Iteration 19 Loss=  337.366144719
Iteration 20 Loss=  752.645004273
Iteration 21 Loss=  3228.17646275
Iteration 22 Loss=  2091.95618671
Iteration 23 Loss=  1824.09128296
Iteration 24 Loss=  1882.50448473
Iteration 25 Loss=  1255.02831593
Iteration 26 Loss=  2871.89367677
Iteration 27 Loss=  3782.92924316
Iteration 28 Loss=  288.399414668
Iteration 29 Loss=  1956.46048084
Iteration 30 Loss=  2341.92345229
Iteration 31 Loss=  2375.72684325
Iteration 32 Loss=  2388.41425844
Iteration 33 Loss=  6248.38465134
Iteration 34 Loss=  433.147509455
Iteration 35 Loss=  3933.18837176
Iteration 36 Loss=  697.856243372
Iteration 37 Loss=  1979.27318699
Iteration 38 Loss=  2326.23107952
Iteration 39 Loss=  1221.59124979
Iteration 40 Loss=  74.8925831027
Iteration 41 Loss=  8.79838974759
Iteration 42 Loss=  1.05809427539
Iteration 43 Loss=  5808.75455284
Iteration 44 Loss=  2592.44365885
Iteration 45 Loss=  1288.69850081
Iteration 46 Loss=  372.593712789
Iteration 47 Loss=  1706.04982522
Iteration 48 Loss=  2866.19776707
Iteration 49 Loss=  3615.16665038
Iteration 50 Loss=  745.237617837
Iteration 51 Loss=  1147.83785499
Iteration 52 Loss=  2893.16791819
Iteration 53 Loss=  895.7795362
Iteration 54 Loss=  310.042457781
Iteration 55 Loss=  1772.7820813
Iteration 56 Loss=  623.569265079
Iteration 57 Loss=  3065.32289707
Iteration 58 Loss=  2535.60700831
Iteration 59 Loss=  405.14665067
Iteration 60 Loss=  2493.81539852
Iteration 61 Loss=  2247.764221
Iteration 62 Loss=  1067.07579691
Iteration 63 Loss=  418.963375905
Iteration 64 Loss=  49.2198270974
Iteration 65 Loss=  5.78234645113
Iteration 66 Loss=  0.682809294522
Iteration 67 Loss=  0.115332225961
Iteration 68 Loss=  1894.52454588
Iteration 69 Loss=  3310.33785154
Iteration 70 Loss=  1433.00720821
Iteration 71 Loss=  2031.89784679
Iteration 72 Loss=  178.434886442
Iteration 73 Loss=  1485.2640968
Iteration 74 Loss=  4067.1747473
Iteration 75 Loss=  425.960640765
Iteration 76 Loss=  50.0421386642
Iteration 77 Loss=  5.94113163839
Iteration 78 Loss=  0.718541883754
Iteration 79 Loss=  0.105476566403
Iteration 80 Loss=  5005.79193197
Iteration 81 Loss=  2300.96197737
Iteration 82 Loss=  408.590576321
Iteration 83 Loss=  2741.37906294
Iteration 84 Loss=  3736.88185875
Iteration 85 Loss=  1979.23275951
Iteration 86 Loss=  2504.26046607
Iteration 87 Loss=  1657.67064439
Iteration 88 Loss=  465.551862084
Iteration 89 Loss=  54.6930493326
Iteration 90 Loss=  6.6302058547
Iteration 91 Loss=  16.8273729801
Iteration 92 Loss=  6603.48487205
Iteration 93 Loss=  1255.05758847
Iteration 94 Loss=  672.41783876
Iteration 95 Loss=  1274.03768509
Iteration 96 Loss=  1738.09257072
Iteration 97 Loss=  2441.85007903
Iteration 98 Loss=  1458.63328324
Iteration 99 Loss=  4185.97971128
Iteration 100 Loss=  639.498162624
[-0.01848257 -0.04465844 -0.05026868 ...,  0.04905098 -0.03372004
  0.00209951]
CROSS VALIDATION 3
Iteration 1 Loss=  2740.74260099
Iteration 2 Loss=  1701.86386912
Iteration 3 Loss=  661.883740935
Iteration 4 Loss=  1629.1507957
Iteration 5 Loss=  1702.14609663
Iteration 6 Loss=  505.219712567
Iteration 7 Loss=  4058.04366549
Iteration 8 Loss=  1196.97078984
Iteration 9 Loss=  2512.56678094
Iteration 10 Loss=  1353.21779988
Iteration 11 Loss=  2381.79289609
Iteration 12 Loss=  2147.78458217
Iteration 13 Loss=  2990.92187392
Iteration 14 Loss=  777.950577741
Iteration 15 Loss=  2538.40480586
Iteration 16 Loss=  2837.69615708
Iteration 17 Loss=  2193.8464996
Iteration 18 Loss=  123.881470835
Iteration 19 Loss=  14.5535988577
Iteration 20 Loss=  1.72195538541
Iteration 21 Loss=  0.324024348917
Iteration 22 Loss=  1992.52844641
Iteration 23 Loss=  1754.89094603
Iteration 24 Loss=  2438.35591725
Iteration 25 Loss=  3708.92268976
Iteration 26 Loss=  2394.61577754
Iteration 27 Loss=  3022.21761225
Iteration 28 Loss=  1905.09688204
Iteration 29 Loss=  1789.8225955
Iteration 30 Loss=  2136.67633206
Iteration 31 Loss=  1346.13901997
Iteration 32 Loss=  1089.59459068
Iteration 33 Loss=  883.651170126
Iteration 34 Loss=  233.2287872
Iteration 35 Loss=  3081.45119455
Iteration 36 Loss=  3314.46903108
Iteration 37 Loss=  929.422470427
Iteration 38 Loss=  1033.14403942
Iteration 39 Loss=  1548.94293274
Iteration 40 Loss=  916.646105444
Iteration 41 Loss=  1520.56584581
Iteration 42 Loss=  4956.43387322
Iteration 43 Loss=  2364.40318694
Iteration 44 Loss=  726.479008227
Iteration 45 Loss=  2820.76294886
Iteration 46 Loss=  1643.72101691
Iteration 47 Loss=  1164.84806978
Iteration 48 Loss=  2026.95683961
Iteration 49 Loss=  1132.57099578
Iteration 50 Loss=  2360.7155372
Iteration 51 Loss=  1108.2432921
Iteration 52 Loss=  1092.64215137
Iteration 53 Loss=  3611.02924551
Iteration 54 Loss=  784.257496388
Iteration 55 Loss=  3150.08799147
Iteration 56 Loss=  3242.80342892
Iteration 57 Loss=  697.876711096
Iteration 58 Loss=  1150.48512286
Iteration 59 Loss=  2496.26717792
Iteration 60 Loss=  520.972710015
Iteration 61 Loss=  1121.07530916
Iteration 62 Loss=  5893.92003421
Iteration 63 Loss=  1556.89174972
Iteration 64 Loss=  1570.1095107
Iteration 65 Loss=  1008.65693058
Iteration 66 Loss=  2965.08630334
Iteration 67 Loss=  1414.70884717
Iteration 68 Loss=  5114.75255081
Iteration 69 Loss=  933.554519219
Iteration 70 Loss=  1656.08260792
Iteration 71 Loss=  3360.4660758
Iteration 72 Loss=  1943.70062348
Iteration 73 Loss=  863.303264938
Iteration 74 Loss=  2300.50565416
Iteration 75 Loss=  496.370472145
Iteration 76 Loss=  2488.78193299
Iteration 77 Loss=  2765.78866048
Iteration 78 Loss=  485.683855668
Iteration 79 Loss=  2327.29816908
Iteration 80 Loss=  2860.14356606
Iteration 81 Loss=  1443.37160871
Iteration 82 Loss=  2702.37500079
Iteration 83 Loss=  2490.79039967
Iteration 84 Loss=  1467.52469221
Iteration 85 Loss=  6397.79401345
Iteration 86 Loss=  311.136038163
Iteration 87 Loss=  36.552289536
Iteration 88 Loss=  4.3150955695
Iteration 89 Loss=  0.521981846967
Iteration 90 Loss=  0.0938296570956
Iteration 91 Loss=  1859.19776285
Iteration 92 Loss=  3289.58654693
Iteration 93 Loss=  1429.34473801
Iteration 94 Loss=  2029.85237694
Iteration 95 Loss=  177.944986117
Iteration 96 Loss=  1485.21563441
Iteration 97 Loss=  4067.17536229
Iteration 98 Loss=  425.960291756
Iteration 99 Loss=  50.0420977843
Iteration 100 Loss=  5.94116756621
[  4.56174904e-03   1.56974407e-04  -5.65375007e-05 ...,  -3.25754555e-05
  -2.55563951e-03   1.96468632e-03]
CROSS VALIDATION 4
Iteration 1 Loss=  2740.74260099
Iteration 2 Loss=  1701.86386912
Iteration 3 Loss=  624.50202155
Iteration 4 Loss=  2366.92150407
Iteration 5 Loss=  2972.04312507
Iteration 6 Loss=  1475.95675917
Iteration 7 Loss=  2121.77147771
Iteration 8 Loss=  1526.86084009
Iteration 9 Loss=  159.211327595
Iteration 10 Loss=  1834.09319554
Iteration 11 Loss=  574.527641502
Iteration 12 Loss=  1803.32626355
Iteration 13 Loss=  3310.36400347
Iteration 14 Loss=  808.749702361
Iteration 15 Loss=  1818.2172474
Iteration 16 Loss=  3251.53022037
Iteration 17 Loss=  990.570295124
Iteration 18 Loss=  84.4208594197
Iteration 19 Loss=  9.91777508649
Iteration 20 Loss=  1.18773650019
Iteration 21 Loss=  10647.8243988
Iteration 22 Loss=  7354.42512795
Iteration 23 Loss=  1642.53558286
Iteration 24 Loss=  1831.99790188
Iteration 25 Loss=  151.777184714
Iteration 26 Loss=  17.8307871728
Iteration 27 Loss=  2.0952573212
Iteration 28 Loss=  0.275366685913
Iteration 29 Loss=  4758.20847204
Iteration 30 Loss=  2472.20911664
Iteration 31 Loss=  599.312983022
Iteration 32 Loss=  2587.24817435
Iteration 33 Loss=  2299.46208571
Iteration 34 Loss=  579.237494451
Iteration 35 Loss=  299.977936023
Iteration 36 Loss=  2718.15137962
Iteration 37 Loss=  4017.72197086
Iteration 38 Loss=  387.29364216
Iteration 39 Loss=  1163.91624082
Iteration 40 Loss=  3633.94345504
Iteration 41 Loss=  1604.80197903
Iteration 42 Loss=  506.886024663
Iteration 43 Loss=  2205.90394394
Iteration 44 Loss=  1780.57257049
Iteration 45 Loss=  3585.73449367
Iteration 46 Loss=  815.930237197
Iteration 47 Loss=  2473.20145805
Iteration 48 Loss=  3309.40189493
Iteration 49 Loss=  1564.32048477
Iteration 50 Loss=  1686.22601049
Iteration 51 Loss=  264.328057732
Iteration 52 Loss=  3079.38413002
Iteration 53 Loss=  3212.17041407
Iteration 54 Loss=  1178.02408647
Iteration 55 Loss=  2768.2228412
Iteration 56 Loss=  391.858242039
Iteration 57 Loss=  46.0407322303
Iteration 58 Loss=  5.40975441466
Iteration 59 Loss=  27.5459449222
Iteration 60 Loss=  4170.45140871
Iteration 61 Loss=  3634.70022592
Iteration 62 Loss=  689.96180598
Iteration 63 Loss=  4759.37515122
Iteration 64 Loss=  428.284137576
Iteration 65 Loss=  1565.38898852
Iteration 66 Loss=  4757.80883641
Iteration 67 Loss=  376.232479978
Iteration 68 Loss=  1395.47939355
Iteration 69 Loss=  1904.58382408
Iteration 70 Loss=  2849.53860078
Iteration 71 Loss=  1008.33515063
Iteration 72 Loss=  1378.12938689
Iteration 73 Loss=  2429.59938936
Iteration 74 Loss=  280.595721062
Iteration 75 Loss=  32.9827502222
Iteration 76 Loss=  3.87604076193
Iteration 77 Loss=  4963.20186662
Iteration 78 Loss=  2576.53812131
Iteration 79 Loss=  1108.44707251
Iteration 80 Loss=  2299.97585717
Iteration 81 Loss=  303.123301001
Iteration 82 Loss=  2686.75480532
Iteration 83 Loss=  2089.45447505
Iteration 84 Loss=  1708.6328835
Iteration 85 Loss=  2030.71934221
Iteration 86 Loss=  2561.51380606
Iteration 87 Loss=  2654.78347015
Iteration 88 Loss=  1872.48269785
Iteration 89 Loss=  1431.71059162
Iteration 90 Loss=  334.075636942
Iteration 91 Loss=  1622.89582636
Iteration 92 Loss=  2814.31522917
Iteration 93 Loss=  1791.20288347
Iteration 94 Loss=  3698.62981202
Iteration 95 Loss=  566.461164776
Iteration 96 Loss=  2874.7414218
Iteration 97 Loss=  3399.69610449
Iteration 98 Loss=  903.824693814
Iteration 99 Loss=  79.4510169344
Iteration 100 Loss=  9.33394656176
[-0.01072228 -0.00467269 -0.01570644 ...,  0.0082776   0.00777533
  0.00270368]
CROSS VALIDATION 5
Iteration 1 Loss=  2382.64791247
Iteration 2 Loss=  1652.83845412
Iteration 3 Loss=  235.495444097
Iteration 4 Loss=  27.6660102231
Iteration 5 Loss=  3.25100627183
Iteration 6 Loss=  0.394419335377
Iteration 7 Loss=  4.01021431346
Iteration 8 Loss=  2226.72468292
Iteration 9 Loss=  3378.8082585
Iteration 10 Loss=  599.501319369
Iteration 11 Loss=  2667.23157746
Iteration 12 Loss=  1854.70161082
Iteration 13 Loss=  1328.65696604
Iteration 14 Loss=  1749.4930643
Iteration 15 Loss=  1560.66457585
Iteration 16 Loss=  139.506425171
Iteration 17 Loss=  2473.82280989
Iteration 18 Loss=  599.950606515
Iteration 19 Loss=  3860.06260179
Iteration 20 Loss=  3658.60938238
Iteration 21 Loss=  1970.91528555
Iteration 22 Loss=  1117.74396867
Iteration 23 Loss=  1109.69052271
Iteration 24 Loss=  1425.19232393
Iteration 25 Loss=  1759.32976432
Iteration 26 Loss=  164.69766009
Iteration 27 Loss=  5688.58142176
Iteration 28 Loss=  1341.34974388
Iteration 29 Loss=  781.642715133
Iteration 30 Loss=  1696.62676634
Iteration 31 Loss=  1867.48823822
Iteration 32 Loss=  688.83882986
Iteration 33 Loss=  3338.18697965
Iteration 34 Loss=  306.90784808
Iteration 35 Loss=  1142.37896562
Iteration 36 Loss=  1606.85141278
Iteration 37 Loss=  1232.76279215
Iteration 38 Loss=  1882.46203264
Iteration 39 Loss=  5252.85225947
Iteration 40 Loss=  1622.90730193
Iteration 41 Loss=  691.676127478
Iteration 42 Loss=  325.862803141
Iteration 43 Loss=  3933.34275901
Iteration 44 Loss=  2490.67895565
Iteration 45 Loss=  437.151083162
Iteration 46 Loss=  1177.02652532
Iteration 47 Loss=  1389.03324508
Iteration 48 Loss=  1042.1325969
Iteration 49 Loss=  3306.90794356
Iteration 50 Loss=  431.186494345
Iteration 51 Loss=  3535.16504288
Iteration 52 Loss=  2991.34363046
Iteration 53 Loss=  309.943311045
Iteration 54 Loss=  6198.30034603
Iteration 55 Loss=  1117.50679313
Iteration 56 Loss=  2397.6178439
Iteration 57 Loss=  2145.22716238
Iteration 58 Loss=  241.698346043
Iteration 59 Loss=  4576.47363228
Iteration 60 Loss=  333.429438463
Iteration 61 Loss=  39.1716816473
Iteration 62 Loss=  8.68195100975
Iteration 63 Loss=  2276.49913667
Iteration 64 Loss=  1852.48886578
Iteration 65 Loss=  162.885329436
Iteration 66 Loss=  19.1370755018
Iteration 67 Loss=  2.2743872254
Iteration 68 Loss=  0.290767089845
Iteration 69 Loss=  4594.91934172
Iteration 70 Loss=  3400.90609358
Iteration 71 Loss=  579.435167254
Iteration 72 Loss=  1948.65778162
Iteration 73 Loss=  1098.29767239
Iteration 74 Loss=  1740.79187629
Iteration 75 Loss=  1207.10730353
Iteration 76 Loss=  1569.51213266
Iteration 77 Loss=  2155.67263229
Iteration 78 Loss=  2901.39969046
Iteration 79 Loss=  480.661147952
Iteration 80 Loss=  2760.20615694
Iteration 81 Loss=  1702.55071056
Iteration 82 Loss=  480.719838269
Iteration 83 Loss=  2105.09977136
Iteration 84 Loss=  680.494034017
Iteration 85 Loss=  2481.99838686
Iteration 86 Loss=  2741.04241759
Iteration 87 Loss=  1725.42715063
Iteration 88 Loss=  2197.53821103
Iteration 89 Loss=  4426.31949087
Iteration 90 Loss=  957.384627938
Iteration 91 Loss=  1799.81889886
Iteration 92 Loss=  2336.72811622
Iteration 93 Loss=  1297.34796712
Iteration 94 Loss=  800.701171772
Iteration 95 Loss=  3630.78333684
Iteration 96 Loss=  4542.53310098
Iteration 97 Loss=  262.999210084
Iteration 98 Loss=  1748.70243775
Iteration 99 Loss=  36.9588735925
Iteration 100 Loss=  4.34290934091
[-0.00958173 -0.01036301 -0.00650194 ...,  0.00698262  0.00268861
  0.00128052]
CROSS VALIDATION 6
Iteration 1 Loss=  2740.74260099
Iteration 2 Loss=  1691.57400902
Iteration 3 Loss=  658.002583267
Iteration 4 Loss=  2389.89849916
Iteration 5 Loss=  3167.88923095
Iteration 6 Loss=  540.773657526
Iteration 7 Loss=  63.5301019928
Iteration 8 Loss=  7.46846709429
Iteration 9 Loss=  0.88428749972
Iteration 10 Loss=  10535.9991729
Iteration 11 Loss=  6392.47951836
Iteration 12 Loss=  2276.53991716
Iteration 13 Loss=  490.788056793
Iteration 14 Loss=  1905.60477998
Iteration 15 Loss=  1826.60420885
Iteration 16 Loss=  2224.33570648
Iteration 17 Loss=  331.500018729
Iteration 18 Loss=  3669.95204888
Iteration 19 Loss=  3610.14318
Iteration 20 Loss=  1321.76311446
Iteration 21 Loss=  1908.08779602
Iteration 22 Loss=  1280.58968086
Iteration 23 Loss=  904.471248303
Iteration 24 Loss=  3640.13170414
Iteration 25 Loss=  2099.06477938
Iteration 26 Loss=  323.389899235
Iteration 27 Loss=  3862.24102734
Iteration 28 Loss=  1487.63903697
Iteration 29 Loss=  312.009635748
Iteration 30 Loss=  1298.22835095
Iteration 31 Loss=  3446.51210116
Iteration 32 Loss=  1908.47893004
Iteration 33 Loss=  2874.92634453
Iteration 34 Loss=  2061.96291269
Iteration 35 Loss=  1510.01579544
Iteration 36 Loss=  5056.85683948
Iteration 37 Loss=  1458.45666118
Iteration 38 Loss=  1125.71424552
Iteration 39 Loss=  2295.94456152
Iteration 40 Loss=  1807.18673811
Iteration 41 Loss=  357.734734001
Iteration 42 Loss=  3157.03036736
Iteration 43 Loss=  2255.4026024
Iteration 44 Loss=  413.097256588
Iteration 45 Loss=  1762.23782402
Iteration 46 Loss=  3124.16699441
Iteration 47 Loss=  1625.33663428
Iteration 48 Loss=  247.235190795
Iteration 49 Loss=  2638.75049184
Iteration 50 Loss=  2698.75606882
Iteration 51 Loss=  4344.28468063
Iteration 52 Loss=  3483.1262793
Iteration 53 Loss=  724.498335529
Iteration 54 Loss=  1259.01756191
Iteration 55 Loss=  2199.23805792
Iteration 56 Loss=  2480.89398935
Iteration 57 Loss=  932.148823895
Iteration 58 Loss=  1123.90898912
Iteration 59 Loss=  1554.92132848
Iteration 60 Loss=  883.80380258
Iteration 61 Loss=  2019.73849576
Iteration 62 Loss=  1946.53794455
Iteration 63 Loss=  1031.98649952
Iteration 64 Loss=  3301.37948066
Iteration 65 Loss=  886.674643389
Iteration 66 Loss=  3178.2846971
Iteration 67 Loss=  2816.01436733
Iteration 68 Loss=  456.615027985
Iteration 69 Loss=  1589.41740736
Iteration 70 Loss=  5588.38545557
Iteration 71 Loss=  6917.56893762
Iteration 72 Loss=  2131.33860517
Iteration 73 Loss=  2638.20962256
Iteration 74 Loss=  380.734564937
Iteration 75 Loss=  1474.55260599
Iteration 76 Loss=  2479.87884807
Iteration 77 Loss=  4312.35435186
Iteration 78 Loss=  1165.29067062
Iteration 79 Loss=  2232.82513903
Iteration 80 Loss=  2982.72831632
Iteration 81 Loss=  3089.19897974
Iteration 82 Loss=  290.376726207
Iteration 83 Loss=  34.113464515
Iteration 84 Loss=  4.00783428454
Iteration 85 Loss=  0.478362534433
Iteration 86 Loss=  9464.49785627
Iteration 87 Loss=  2094.73396924
Iteration 88 Loss=  1366.83690318
Iteration 89 Loss=  79.2649206968
Iteration 90 Loss=  9.31204513645
Iteration 91 Loss=  1.09516330646
Iteration 92 Loss=  0.141372805218
Iteration 93 Loss=  2509.72365333
Iteration 94 Loss=  4426.18066036
Iteration 95 Loss=  1009.26765399
Iteration 96 Loss=  1415.02331855
Iteration 97 Loss=  3508.56490587
Iteration 98 Loss=  422.152948464
Iteration 99 Loss=  49.5945381765
Iteration 100 Loss=  5.82771555856
[ -6.41488671e-04   8.96905357e-04   2.38445085e-03 ...,   2.88469839e-03
  -3.63996812e-06   2.97963016e-03]
CROSS VALIDATION 7
Iteration 1 Loss=  2740.74260099
Iteration 2 Loss=  1691.57400902
Iteration 3 Loss=  658.002583267
Iteration 4 Loss=  1637.01189742
Iteration 5 Loss=  1693.19143655
Iteration 6 Loss=  504.051367495
Iteration 7 Loss=  4052.34149074
Iteration 8 Loss=  1196.17415521
Iteration 9 Loss=  2514.82522033
Iteration 10 Loss=  1338.88452079
Iteration 11 Loss=  2240.23699451
Iteration 12 Loss=  3319.43268279
Iteration 13 Loss=  1406.84645087
Iteration 14 Loss=  2371.51639704
Iteration 15 Loss=  2725.98018999
Iteration 16 Loss=  664.027205706
Iteration 17 Loss=  3065.37313951
Iteration 18 Loss=  3284.09592877
Iteration 19 Loss=  1515.18727012
Iteration 20 Loss=  267.730188842
Iteration 21 Loss=  31.4529487996
Iteration 22 Loss=  3.69731962756
Iteration 23 Loss=  0.435634818376
Iteration 24 Loss=  0.0611911090989
Iteration 25 Loss=  5454.85933622
Iteration 26 Loss=  370.780120562
Iteration 27 Loss=  1174.28258421
Iteration 28 Loss=  2044.83524618
Iteration 29 Loss=  1762.98448966
Iteration 30 Loss=  528.380183789
Iteration 31 Loss=  2260.13953834
Iteration 32 Loss=  1313.01279704
Iteration 33 Loss=  1963.52942249
Iteration 34 Loss=  3971.12134098
Iteration 35 Loss=  1441.69919295
Iteration 36 Loss=  557.105269774
Iteration 37 Loss=  2726.23317919
Iteration 38 Loss=  1713.29488112
Iteration 39 Loss=  3311.03607913
Iteration 40 Loss=  1129.30609283
Iteration 41 Loss=  606.442004729
Iteration 42 Loss=  1799.93828492
Iteration 43 Loss=  1104.54135566
Iteration 44 Loss=  767.796962662
Iteration 45 Loss=  6761.53861973
Iteration 46 Loss=  204.78436835
Iteration 47 Loss=  24.0581534735
Iteration 48 Loss=  2.84644053393
Iteration 49 Loss=  9675.43289995
Iteration 50 Loss=  3321.19055163
Iteration 51 Loss=  1105.91402425
Iteration 52 Loss=  5182.70137967
Iteration 53 Loss=  2672.52823377
Iteration 54 Loss=  891.069399059
Iteration 55 Loss=  1960.84805978
Iteration 56 Loss=  2123.84879774
Iteration 57 Loss=  1101.37777785
Iteration 58 Loss=  1977.86135694
Iteration 59 Loss=  2981.96137264
Iteration 60 Loss=  468.508222601
Iteration 61 Loss=  1983.32476881
Iteration 62 Loss=  4548.18395874
Iteration 63 Loss=  443.47510026
Iteration 64 Loss=  1429.15229582
Iteration 65 Loss=  2369.15767316
Iteration 66 Loss=  2847.18568594
Iteration 67 Loss=  4137.65257399
Iteration 68 Loss=  1479.82780104
Iteration 69 Loss=  497.136814186
Iteration 70 Loss=  1760.50240054
Iteration 71 Loss=  1398.18204117
Iteration 72 Loss=  1934.21442183
Iteration 73 Loss=  488.512765818
Iteration 74 Loss=  2897.20152851
Iteration 75 Loss=  435.411965218
Iteration 76 Loss=  1943.33808515
Iteration 77 Loss=  320.857503096
Iteration 78 Loss=  37.6957467246
Iteration 79 Loss=  7348.11423407
Iteration 80 Loss=  3356.56525368
Iteration 81 Loss=  203.796076853
Iteration 82 Loss=  23.9419747028
Iteration 83 Loss=  2.82042801891
Iteration 84 Loss=  93.7616813455
Iteration 85 Loss=  4187.81984385
Iteration 86 Loss=  885.753439035
Iteration 87 Loss=  343.243397326
Iteration 88 Loss=  40.3242422615
Iteration 89 Loss=  4.73732986125
Iteration 90 Loss=  0.557494727534
Iteration 91 Loss=  9518.13955848
Iteration 92 Loss=  2133.29037424
Iteration 93 Loss=  1365.96426939
Iteration 94 Loss=  79.2695204598
Iteration 95 Loss=  9.31258550659
Iteration 96 Loss=  1.09529996154
Iteration 97 Loss=  0.175331559922
Iteration 98 Loss=  4658.36189127
Iteration 99 Loss=  2605.76483071
Iteration 100 Loss=  1272.51257329
[-0.119276   -0.02793353 -0.04336553 ...,  0.03609916  0.04834259
  0.01027994]
CROSS VALIDATION 8
Iteration 1 Loss=  2740.74260099
Iteration 2 Loss=  1691.57400902
Iteration 3 Loss=  658.002583267
Iteration 4 Loss=  1637.01189742
Iteration 5 Loss=  1693.19143655
Iteration 6 Loss=  504.051367495
Iteration 7 Loss=  4052.34149074
Iteration 8 Loss=  1196.17415521
Iteration 9 Loss=  2514.82522033
Iteration 10 Loss=  1338.88452079
Iteration 11 Loss=  2369.92357752
Iteration 12 Loss=  1606.19699038
Iteration 13 Loss=  2627.14940201
Iteration 14 Loss=  962.882664849
Iteration 15 Loss=  6026.69330753
Iteration 16 Loss=  1629.63499885
Iteration 17 Loss=  1037.9463968
Iteration 18 Loss=  1128.95670925
Iteration 19 Loss=  1294.60870826
Iteration 20 Loss=  393.283965129
Iteration 21 Loss=  405.021224647
Iteration 22 Loss=  2996.80424318
Iteration 23 Loss=  2825.62597566
Iteration 24 Loss=  236.499702463
Iteration 25 Loss=  2537.19398499
Iteration 26 Loss=  320.713970217
Iteration 27 Loss=  1540.97658747
Iteration 28 Loss=  4515.72103941
Iteration 29 Loss=  1087.63752315
Iteration 30 Loss=  797.519106027
Iteration 31 Loss=  1527.37061803
Iteration 32 Loss=  489.982642194
Iteration 33 Loss=  1154.57098515
Iteration 34 Loss=  339.988832629
Iteration 35 Loss=  39.9418959256
Iteration 36 Loss=  4.69237664523
Iteration 37 Loss=  0.570812087958
Iteration 38 Loss=  2331.15852397
Iteration 39 Loss=  1776.26111385
Iteration 40 Loss=  878.178262181
Iteration 41 Loss=  2126.91905207
Iteration 42 Loss=  2351.84068659
Iteration 43 Loss=  3008.87197351
Iteration 44 Loss=  1628.2741893
Iteration 45 Loss=  864.046212607
Iteration 46 Loss=  2724.79573441
Iteration 47 Loss=  3989.83083671
Iteration 48 Loss=  1079.38459993
Iteration 49 Loss=  1728.77083192
Iteration 50 Loss=  3359.10973593
Iteration 51 Loss=  788.023228832
Iteration 52 Loss=  6374.29406814
Iteration 53 Loss=  5832.44868732
Iteration 54 Loss=  453.493068875
Iteration 55 Loss=  2169.32079084
Iteration 56 Loss=  958.937798013
Iteration 57 Loss=  2242.9131421
Iteration 58 Loss=  2802.92165371
Iteration 59 Loss=  633.604717911
Iteration 60 Loss=  4369.89455674
Iteration 61 Loss=  4798.49795061
Iteration 62 Loss=  1902.37227072
Iteration 63 Loss=  1199.79898229
Iteration 64 Loss=  4106.52449663
Iteration 65 Loss=  1562.53770591
Iteration 66 Loss=  1019.21036486
Iteration 67 Loss=  1439.88351026
Iteration 68 Loss=  1889.11257456
Iteration 69 Loss=  470.19647728
Iteration 70 Loss=  1741.276339
Iteration 71 Loss=  1329.0814376
Iteration 72 Loss=  2136.46857547
Iteration 73 Loss=  1375.33413988
Iteration 74 Loss=  464.496749474
Iteration 75 Loss=  1898.81854354
Iteration 76 Loss=  1238.4404542
Iteration 77 Loss=  713.942283654
Iteration 78 Loss=  679.464931362
Iteration 79 Loss=  4172.07136852
Iteration 80 Loss=  1239.37640762
Iteration 81 Loss=  154.473643676
Iteration 82 Loss=  18.1475672786
Iteration 83 Loss=  2.13240387242
Iteration 84 Loss=  3899.38084183
Iteration 85 Loss=  4234.90608004
Iteration 86 Loss=  1067.10093291
Iteration 87 Loss=  3015.48917178
Iteration 88 Loss=  1402.98964079
Iteration 89 Loss=  2078.45816468
Iteration 90 Loss=  2266.88881078
Iteration 91 Loss=  2396.25127863
Iteration 92 Loss=  473.241207497
Iteration 93 Loss=  1848.47437345
Iteration 94 Loss=  925.107184164
Iteration 95 Loss=  3181.04898826
Iteration 96 Loss=  1960.09508475
Iteration 97 Loss=  998.909191796
Iteration 98 Loss=  409.188004698
Iteration 99 Loss=  9965.24293042
Iteration 100 Loss=  1249.92918292
[-0.05184285 -0.01251955  0.00578612 ...,  0.07473783 -0.02333107
  0.01198777]
CROSS VALIDATION 9
Iteration 1 Loss=  3496.90305443
Iteration 2 Loss=  535.285106136
Iteration 3 Loss=  62.8853746817
Iteration 4 Loss=  7.41031128032
Iteration 5 Loss=  0.886967461745
Iteration 6 Loss=  0.126981053409
Iteration 7 Loss=  7790.60412961
Iteration 8 Loss=  1040.27165042
Iteration 9 Loss=  4292.46881505
Iteration 10 Loss=  503.35516385
Iteration 11 Loss=  1549.71832666
Iteration 12 Loss=  4282.31220983
Iteration 13 Loss=  926.608567856
Iteration 14 Loss=  1637.37590989
Iteration 15 Loss=  3322.70202661
Iteration 16 Loss=  1077.43304966
Iteration 17 Loss=  1774.98111127
Iteration 18 Loss=  2519.44371207
Iteration 19 Loss=  524.541400106
Iteration 20 Loss=  61.6231673036
Iteration 21 Loss=  7.23957994104
Iteration 22 Loss=  0.852276575453
Iteration 23 Loss=  8283.37710862
Iteration 24 Loss=  5401.73428977
Iteration 25 Loss=  1970.34789947
Iteration 26 Loss=  199.033557377
Iteration 27 Loss=  2927.14619163
Iteration 28 Loss=  2062.43098112
Iteration 29 Loss=  1737.7262495
Iteration 30 Loss=  6977.9807661
Iteration 31 Loss=  1316.39819793
Iteration 32 Loss=  1753.23535175
Iteration 33 Loss=  1722.07019787
Iteration 34 Loss=  1388.37844403
Iteration 35 Loss=  922.262889465
Iteration 36 Loss=  705.409106007
Iteration 37 Loss=  2154.32172354
Iteration 38 Loss=  396.358251052
Iteration 39 Loss=  2229.44630272
Iteration 40 Loss=  4601.05150801
Iteration 41 Loss=  464.446512196
Iteration 42 Loss=  1995.78002706
Iteration 43 Loss=  3330.52655177
Iteration 44 Loss=  338.100060877
Iteration 45 Loss=  507.812930598
Iteration 46 Loss=  414.983564807
Iteration 47 Loss=  1910.52441468
Iteration 48 Loss=  3500.66871503
Iteration 49 Loss=  4074.21726486
Iteration 50 Loss=  867.755302771
Iteration 51 Loss=  1536.16165725
Iteration 52 Loss=  2040.47430791
Iteration 53 Loss=  619.556657627
Iteration 54 Loss=  112.138036193
Iteration 55 Loss=  13.1740022687
Iteration 56 Loss=  1.55328336701
Iteration 57 Loss=  0.209338407321
Iteration 58 Loss=  5467.44683595
Iteration 59 Loss=  1153.26381705
Iteration 60 Loss=  2586.07260256
Iteration 61 Loss=  69.3291828919
Iteration 62 Loss=  8.14490416287
Iteration 63 Loss=  0.968326446169
Iteration 64 Loss=  5155.23431249
Iteration 65 Loss=  1520.76485603
Iteration 66 Loss=  861.156428558
Iteration 67 Loss=  1195.37530142
Iteration 68 Loss=  5182.78520318
Iteration 69 Loss=  2636.69811583
Iteration 70 Loss=  737.876978496
Iteration 71 Loss=  1469.02171847
Iteration 72 Loss=  752.555774495
Iteration 73 Loss=  1548.88902607
Iteration 74 Loss=  2184.02413607
Iteration 75 Loss=  1921.07251258
Iteration 76 Loss=  4866.18135957
Iteration 77 Loss=  1603.59002376
Iteration 78 Loss=  2077.74551106
Iteration 79 Loss=  1590.53669548
Iteration 80 Loss=  365.486376662
Iteration 81 Loss=  2380.56516753
Iteration 82 Loss=  1559.65251838
Iteration 83 Loss=  1683.85396978
Iteration 84 Loss=  192.323770119
Iteration 85 Loss=  22.5942291908
Iteration 86 Loss=  2.65703519514
Iteration 87 Loss=  5820.67346972
Iteration 88 Loss=  1932.00517809
Iteration 89 Loss=  393.344728481
Iteration 90 Loss=  46.2101478052
Iteration 91 Loss=  5.42876923364
Iteration 92 Loss=  0.63822841881
Iteration 93 Loss=  0.131168523838
Iteration 94 Loss=  1882.68476444
Iteration 95 Loss=  2875.93065289
Iteration 96 Loss=  626.444255321
Iteration 97 Loss=  2957.83971716
Iteration 98 Loss=  2227.61557264
Iteration 99 Loss=  1463.98358295
Iteration 100 Loss=  2984.81772944
[-0.10654387 -0.03793244 -0.07798182 ...,  0.1163042   0.0067664
  0.01686361]
CROSS VALIDATION 10
Iteration 1 Loss=  2739.63021008
Iteration 2 Loss=  1099.62766002
Iteration 3 Loss=  87.6649351597
Iteration 4 Loss=  10.2988786114
Iteration 5 Loss=  1.21018322983
Iteration 6 Loss=  0.48889648999
Iteration 7 Loss=  4635.52361866
Iteration 8 Loss=  2589.57537977
Iteration 9 Loss=  1307.49950897
Iteration 10 Loss=  3545.28608966
Iteration 11 Loss=  1711.53350724
Iteration 12 Loss=  1179.8386836
Iteration 13 Loss=  3482.02119784
Iteration 14 Loss=  2097.57820076
Iteration 15 Loss=  5260.15052773
Iteration 16 Loss=  187.971864363
Iteration 17 Loss=  22.0829389758
Iteration 18 Loss=  2.59478365352
Iteration 19 Loss=  0.306680746728
Iteration 20 Loss=  7782.95463878
Iteration 21 Loss=  832.540891536
Iteration 22 Loss=  802.786956529
Iteration 23 Loss=  1783.67999888
Iteration 24 Loss=  307.437796847
Iteration 25 Loss=  36.1177994886
Iteration 26 Loss=  4.24320500639
Iteration 27 Loss=  7261.44390486
Iteration 28 Loss=  4505.78067588
Iteration 29 Loss=  250.959342332
Iteration 30 Loss=  29.4827093471
Iteration 31 Loss=  3.46463609166
Iteration 32 Loss=  0.427494048386
Iteration 33 Loss=  9677.19196355
Iteration 34 Loss=  2382.81449512
Iteration 35 Loss=  2068.64829674
Iteration 36 Loss=  3675.53335395
Iteration 37 Loss=  3364.49998405
Iteration 38 Loss=  1539.42516027
Iteration 39 Loss=  557.0539861
Iteration 40 Loss=  1487.15658467
Iteration 41 Loss=  1646.41724847
Iteration 42 Loss=  1308.16430135
Iteration 43 Loss=  1734.87327083
Iteration 44 Loss=  4482.23134779
Iteration 45 Loss=  1121.92566307
Iteration 46 Loss=  625.567034993
Iteration 47 Loss=  181.309397005
Iteration 48 Loss=  21.300240275
Iteration 49 Loss=  2.51858676441
Iteration 50 Loss=  10484.2439859
Iteration 51 Loss=  2021.16584224
Iteration 52 Loss=  720.076123212
Iteration 53 Loss=  354.232129023
Iteration 54 Loss=  5194.9501948
Iteration 55 Loss=  1375.72496326
Iteration 56 Loss=  52.4323776286
Iteration 57 Loss=  6.16119229512
Iteration 58 Loss=  0.74706064717
Iteration 59 Loss=  8251.82857392
Iteration 60 Loss=  4645.77959389
Iteration 61 Loss=  273.432888416
Iteration 62 Loss=  32.1229020637
Iteration 63 Loss=  3.775211558
Iteration 64 Loss=  0.451091253184
Iteration 65 Loss=  5208.74047369
Iteration 66 Loss=  7485.72859259
Iteration 67 Loss=  485.190853332
Iteration 68 Loss=  876.734702236
Iteration 69 Loss=  2709.49993102
Iteration 70 Loss=  1327.30298156
Iteration 71 Loss=  1766.89753549
Iteration 72 Loss=  1045.4058517
Iteration 73 Loss=  3000.33188814
Iteration 74 Loss=  4935.91091187
Iteration 75 Loss=  2099.8193572
Iteration 76 Loss=  129.463577431
Iteration 77 Loss=  15.2093840728
Iteration 78 Loss=  1.78704133608
Iteration 79 Loss=  31.1513459998
Iteration 80 Loss=  2684.74411558
Iteration 81 Loss=  405.055270415
Iteration 82 Loss=  2617.51679409
Iteration 83 Loss=  5132.13146963
Iteration 84 Loss=  2163.71319786
Iteration 85 Loss=  3402.47522532
Iteration 86 Loss=  1241.82571085
Iteration 87 Loss=  4674.47132117
Iteration 88 Loss=  797.849022612
Iteration 89 Loss=  1344.22544635
Iteration 90 Loss=  2655.78828957
Iteration 91 Loss=  343.453276208
Iteration 92 Loss=  40.3513347929
Iteration 93 Loss=  4.81798159245
Iteration 94 Loss=  4911.06173452
Iteration 95 Loss=  497.720069462
Iteration 96 Loss=  1675.99260955
Iteration 97 Loss=  2133.87397356
Iteration 98 Loss=  650.320243344
Iteration 99 Loss=  1008.61292256
Iteration 100 Loss=  1022.32275699
[-0.09511708  0.0101098  -0.10032784 ...,  0.04619208 -0.06283868
  0.0220068 ]
CROSS VALIDATION 11
Iteration 1 Loss=  2739.63021008
Iteration 2 Loss=  1416.90163024
Iteration 3 Loss=  443.006568539
Iteration 4 Loss=  1635.11120943
Iteration 5 Loss=  1678.35198416
Iteration 6 Loss=  503.257528986
Iteration 7 Loss=  2997.57323418
Iteration 8 Loss=  1781.43666909
Iteration 9 Loss=  888.801980463
Iteration 10 Loss=  1845.2715576
Iteration 11 Loss=  1060.52199115
Iteration 12 Loss=  1482.96805478
Iteration 13 Loss=  3524.40799217
Iteration 14 Loss=  289.688622887
Iteration 15 Loss=  34.032626121
Iteration 16 Loss=  3.99819045386
Iteration 17 Loss=  0.484597946054
Iteration 18 Loss=  0.327829979598
Iteration 19 Loss=  4700.99465519
Iteration 20 Loss=  2361.30678798
Iteration 21 Loss=  527.793542183
Iteration 22 Loss=  2154.37503185
Iteration 23 Loss=  1814.63919874
Iteration 24 Loss=  322.685052727
Iteration 25 Loss=  2017.94584373
Iteration 26 Loss=  1679.52472629
Iteration 27 Loss=  2179.43009337
Iteration 28 Loss=  1287.72120204
Iteration 29 Loss=  1504.16076866
Iteration 30 Loss=  877.393019818
Iteration 31 Loss=  2313.47995725
Iteration 32 Loss=  3006.78713985
Iteration 33 Loss=  255.590159757
Iteration 34 Loss=  30.0272601003
Iteration 35 Loss=  21.0563703615
Iteration 36 Loss=  3332.31481432
Iteration 37 Loss=  1462.27579901
Iteration 38 Loss=  900.208459058
Iteration 39 Loss=  923.316406836
Iteration 40 Loss=  1400.55353337
Iteration 41 Loss=  922.284531826
Iteration 42 Loss=  1538.40131132
Iteration 43 Loss=  128.779938621
Iteration 44 Loss=  15.1290701708
Iteration 45 Loss=  1.77831585522
Iteration 46 Loss=  0.217055947679
Iteration 47 Loss=  0.648982726513
Iteration 48 Loss=  3761.25758968
Iteration 49 Loss=  2088.82581343
Iteration 50 Loss=  343.634070411
Iteration 51 Loss=  40.4028740856
Iteration 52 Loss=  4.74674830297
Iteration 53 Loss=  27.3167257071
Iteration 54 Loss=  3763.23369287
Iteration 55 Loss=  2727.8074849
Iteration 56 Loss=  2299.12861751
Iteration 57 Loss=  1509.89171137
Iteration 58 Loss=  2199.42111611
Iteration 59 Loss=  1052.31916952
Iteration 60 Loss=  3582.55572339
Iteration 61 Loss=  1763.058755
Iteration 62 Loss=  2769.6157104
Iteration 63 Loss=  379.27044536
Iteration 64 Loss=  1521.05755825
Iteration 65 Loss=  2002.08062211
Iteration 66 Loss=  1914.67775233
Iteration 67 Loss=  3946.92554074
Iteration 68 Loss=  1235.41482349
Iteration 69 Loss=  1814.91856075
Iteration 70 Loss=  1956.35465462
Iteration 71 Loss=  2519.28858849
Iteration 72 Loss=  2526.43547658
Iteration 73 Loss=  2805.49996512
Iteration 74 Loss=  1067.16887646
Iteration 75 Loss=  2313.89866954
Iteration 76 Loss=  919.950655474
Iteration 77 Loss=  1889.77554392
Iteration 78 Loss=  784.683670086
Iteration 79 Loss=  2564.05890014
Iteration 80 Loss=  1748.93248824
Iteration 81 Loss=  649.437871387
Iteration 82 Loss=  438.995795172
Iteration 83 Loss=  2677.23844801
Iteration 84 Loss=  4612.20865498
Iteration 85 Loss=  6021.94895184
Iteration 86 Loss=  2479.28482868
Iteration 87 Loss=  162.373462444
Iteration 88 Loss=  3012.64902939
Iteration 89 Loss=  871.535323176
Iteration 90 Loss=  2152.67832308
Iteration 91 Loss=  6730.41303569
Iteration 92 Loss=  929.146816684
Iteration 93 Loss=  4088.765904
Iteration 94 Loss=  3989.70294552
Iteration 95 Loss=  1112.52573432
Iteration 96 Loss=  2782.89361537
Iteration 97 Loss=  1414.85055863
Iteration 98 Loss=  441.408241103
Iteration 99 Loss=  370.129949735
Iteration 100 Loss=  3057.37497933
[-0.04159219 -0.01640474 -0.06048375 ...,  0.02528431 -0.03386807
  0.01311976]
CROSS VALIDATION 12
Iteration 1 Loss=  2853.48756222
Iteration 2 Loss=  838.188190035
Iteration 3 Loss=  1022.06485842
Iteration 4 Loss=  1204.45533216
Iteration 5 Loss=  1206.36797026
Iteration 6 Loss=  1523.29239541
Iteration 7 Loss=  431.660024963
Iteration 8 Loss=  50.7668797575
Iteration 9 Loss=  5.96410456648
Iteration 10 Loss=  0.70623630156
Iteration 11 Loss=  0.126661273914
Iteration 12 Loss=  1821.15476455
Iteration 13 Loss=  5567.91212609
Iteration 14 Loss=  200.469250945
Iteration 15 Loss=  23.5583820957
Iteration 16 Loss=  2.78364745162
Iteration 17 Loss=  0.331503407486
Iteration 18 Loss=  0.0687217195791
Iteration 19 Loss=  3052.20121672
Iteration 20 Loss=  1696.76343962
Iteration 21 Loss=  6776.23849218
Iteration 22 Loss=  415.550376478
Iteration 23 Loss=  243.836905133
Iteration 24 Loss=  28.6459652587
Iteration 25 Loss=  3.36607185652
Iteration 26 Loss=  0.406150244252
Iteration 27 Loss=  9308.81033678
Iteration 28 Loss=  7946.77147963
Iteration 29 Loss=  342.4982819
Iteration 30 Loss=  3351.45847664
Iteration 31 Loss=  2186.2899607
Iteration 32 Loss=  128.325281767
Iteration 33 Loss=  15.0756570718
Iteration 34 Loss=  1.77108867501
Iteration 35 Loss=  0.214564660768
Iteration 36 Loss=  4500.69984372
Iteration 37 Loss=  1754.19531216
Iteration 38 Loss=  323.989008682
Iteration 39 Loss=  39.7528618679
Iteration 40 Loss=  4.67016721653
Iteration 41 Loss=  0.549021988864
Iteration 42 Loss=  837.481678695
Iteration 43 Loss=  1878.34386579
Iteration 44 Loss=  2025.11697688
Iteration 45 Loss=  409.142722434
Iteration 46 Loss=  3266.87626133
Iteration 47 Loss=  2129.44096284
Iteration 48 Loss=  3336.88536644
Iteration 49 Loss=  882.421460488
Iteration 50 Loss=  2220.41757703
Iteration 51 Loss=  3435.71767466
Iteration 52 Loss=  213.213704051
Iteration 53 Loss=  25.0483508872
Iteration 54 Loss=  2.94300293395
Iteration 55 Loss=  0.370001189808
Iteration 56 Loss=  0.800458970908
Iteration 57 Loss=  3328.36784203
Iteration 58 Loss=  460.699758392
Iteration 59 Loss=  354.999579807
Iteration 60 Loss=  2694.76098772
Iteration 61 Loss=  3160.26562182
Iteration 62 Loss=  751.347173636
Iteration 63 Loss=  1627.20995418
Iteration 64 Loss=  1860.86859408
Iteration 65 Loss=  499.505650439
Iteration 66 Loss=  3987.49866497
Iteration 67 Loss=  1907.00919154
Iteration 68 Loss=  493.160713492
Iteration 69 Loss=  1536.95880781
Iteration 70 Loss=  1226.97805542
Iteration 71 Loss=  2868.87941136
Iteration 72 Loss=  941.275258568
Iteration 73 Loss=  5880.09294558
Iteration 74 Loss=  2025.66432292
Iteration 75 Loss=  1317.96083771
Iteration 76 Loss=  1482.72051002
Iteration 77 Loss=  2017.05158668
Iteration 78 Loss=  3727.60396397
Iteration 79 Loss=  4960.82381903
Iteration 80 Loss=  1497.34926209
Iteration 81 Loss=  1439.66900387
Iteration 82 Loss=  4676.90896173
Iteration 83 Loss=  1678.63572865
Iteration 84 Loss=  2884.50354232
Iteration 85 Loss=  674.329650351
Iteration 86 Loss=  254.806585488
Iteration 87 Loss=  2676.8116433
Iteration 88 Loss=  2764.52809389
Iteration 89 Loss=  2376.70886411
Iteration 90 Loss=  4107.39658064
Iteration 91 Loss=  222.597266832
Iteration 92 Loss=  1070.03859413
Iteration 93 Loss=  1132.38633199
Iteration 94 Loss=  2636.61580352
Iteration 95 Loss=  2358.59010352
Iteration 96 Loss=  477.884976109
Iteration 97 Loss=  5746.70586516
Iteration 98 Loss=  923.901996897
Iteration 99 Loss=  2544.72356996
Iteration 100 Loss=  6688.48277123
[-0.13620212 -0.06381226 -0.07027701 ...,  0.05645556 -0.06740081
  0.00886394]
CROSS VALIDATION 13
Iteration 1 Loss=  4223.94918738
Iteration 2 Loss=  713.192192288
Iteration 3 Loss=  1963.91518357
Iteration 4 Loss=  1943.02567771
Iteration 5 Loss=  1739.70943908
Iteration 6 Loss=  607.121580267
Iteration 7 Loss=  1405.44026648
Iteration 8 Loss=  3396.3097263
Iteration 9 Loss=  2292.27407051
Iteration 10 Loss=  1419.0643272
Iteration 11 Loss=  2853.24635948
Iteration 12 Loss=  2449.6569097
Iteration 13 Loss=  481.282530105
Iteration 14 Loss=  1158.80473611
Iteration 15 Loss=  2495.13871813
Iteration 16 Loss=  190.647546617
Iteration 17 Loss=  22.3972781887
Iteration 18 Loss=  2.63125439656
Iteration 19 Loss=  0.328448116593
Iteration 20 Loss=  5693.66494361
Iteration 21 Loss=  951.62261629
Iteration 22 Loss=  247.341276135
Iteration 23 Loss=  1090.85057092
Iteration 24 Loss=  3925.50768736
Iteration 25 Loss=  725.904719237
Iteration 26 Loss=  4426.92391071
Iteration 27 Loss=  382.020709382
Iteration 28 Loss=  44.8799475475
Iteration 29 Loss=  5.37543725343
Iteration 30 Loss=  4572.85136007
Iteration 31 Loss=  829.974565728
Iteration 32 Loss=  162.723169458
Iteration 33 Loss=  19.136765827
Iteration 34 Loss=  2.24943922801
Iteration 35 Loss=  0.621076105487
Iteration 36 Loss=  2148.42671164
Iteration 37 Loss=  2370.57352285
Iteration 38 Loss=  334.381216085
Iteration 39 Loss=  39.2831130079
Iteration 40 Loss=  4.61642671246
Iteration 41 Loss=  6864.62825845
Iteration 42 Loss=  3607.19470514
Iteration 43 Loss=  1381.58234787
Iteration 44 Loss=  108.914039077
Iteration 45 Loss=  1578.62289453
Iteration 46 Loss=  1647.38079868
Iteration 47 Loss=  1148.75375297
Iteration 48 Loss=  1549.46534528
Iteration 49 Loss=  3452.96048596
Iteration 50 Loss=  1136.6642502
Iteration 51 Loss=  2919.19253011
Iteration 52 Loss=  4138.09891909
Iteration 53 Loss=  1614.46016332
Iteration 54 Loss=  331.209375456
Iteration 55 Loss=  3146.34459695
Iteration 56 Loss=  1385.9901683
Iteration 57 Loss=  940.390631783
Iteration 58 Loss=  3918.29248046
Iteration 59 Loss=  634.723427292
Iteration 60 Loss=  1875.33076787
Iteration 61 Loss=  3799.57083972
Iteration 62 Loss=  6767.36245176
Iteration 63 Loss=  754.644682542
Iteration 64 Loss=  3017.31756314
Iteration 65 Loss=  3939.87015921
Iteration 66 Loss=  514.349359702
Iteration 67 Loss=  96.2237964521
Iteration 68 Loss=  11.3043738569
Iteration 69 Loss=  1.32985222047
Iteration 70 Loss=  7611.20650198
Iteration 71 Loss=  4567.69593755
Iteration 72 Loss=  2678.56714093
Iteration 73 Loss=  846.049136633
Iteration 74 Loss=  277.657149936
Iteration 75 Loss=  2677.9206233
Iteration 76 Loss=  1269.87922058
Iteration 77 Loss=  116.614211298
Iteration 78 Loss=  13.700068592
Iteration 79 Loss=  1.61359828463
Iteration 80 Loss=  0.23135177296
Iteration 81 Loss=  4559.42921966
Iteration 82 Loss=  1412.12412137
Iteration 83 Loss=  1068.45420218
Iteration 84 Loss=  8404.79525176
Iteration 85 Loss=  3280.94611987
Iteration 86 Loss=  836.479111679
Iteration 87 Loss=  511.146681607
Iteration 88 Loss=  5220.2780007
Iteration 89 Loss=  2643.67082358
Iteration 90 Loss=  3350.11994637
Iteration 91 Loss=  580.730584084
Iteration 92 Loss=  973.269662315
Iteration 93 Loss=  4028.17624169
Iteration 94 Loss=  1661.27839961
Iteration 95 Loss=  1108.45755335
Iteration 96 Loss=  2577.81707275
Iteration 97 Loss=  1918.53262195
Iteration 98 Loss=  2674.3405265
Iteration 99 Loss=  6014.60540486
Iteration 100 Loss=  1658.20877993
[-0.02868107 -0.00571244  0.02958802 ...,  0.04533541  0.02177672
  0.0166264 ]
CROSS VALIDATION 14
Iteration 1 Loss=  2739.11406951
Iteration 2 Loss=  1703.07918814
Iteration 3 Loss=  661.349307271
Iteration 4 Loss=  1581.66794527
Iteration 5 Loss=  1185.43304171
Iteration 6 Loss=  1690.48022306
Iteration 7 Loss=  1639.61160529
Iteration 8 Loss=  1651.12080019
Iteration 9 Loss=  2892.81091136
Iteration 10 Loss=  1748.02953043
Iteration 11 Loss=  3413.62245249
Iteration 12 Loss=  1541.51400387
Iteration 13 Loss=  753.594120151
Iteration 14 Loss=  1595.07541996
Iteration 15 Loss=  1934.75443648
Iteration 16 Loss=  1723.79896805
Iteration 17 Loss=  1800.01483269
Iteration 18 Loss=  2510.89581644
Iteration 19 Loss=  230.604663702
Iteration 20 Loss=  4147.0325781
Iteration 21 Loss=  1966.18121225
Iteration 22 Loss=  1633.92626124
Iteration 23 Loss=  4295.72276853
Iteration 24 Loss=  1186.43954467
Iteration 25 Loss=  1405.71977062
Iteration 26 Loss=  715.704611797
Iteration 27 Loss=  1566.85203022
Iteration 28 Loss=  1570.3160825
Iteration 29 Loss=  1229.28182919
Iteration 30 Loss=  4171.52587474
Iteration 31 Loss=  1757.03611789
Iteration 32 Loss=  115.433361382
Iteration 33 Loss=  2195.61700777
Iteration 34 Loss=  624.954933507
Iteration 35 Loss=  1290.30651249
Iteration 36 Loss=  2642.02503063
Iteration 37 Loss=  4448.48483949
Iteration 38 Loss=  1875.25630065
Iteration 39 Loss=  139.628103945
Iteration 40 Loss=  16.4055355075
Iteration 41 Loss=  1.92855514069
Iteration 42 Loss=  0.244520351638
Iteration 43 Loss=  5418.05625945
Iteration 44 Loss=  1232.77887186
Iteration 45 Loss=  473.58431485
Iteration 46 Loss=  2324.16482428
Iteration 47 Loss=  645.839639346
Iteration 48 Loss=  1215.94093547
Iteration 49 Loss=  2507.98500068
Iteration 50 Loss=  182.54700526
Iteration 51 Loss=  21.4481804733
Iteration 52 Loss=  8570.2605829
Iteration 53 Loss=  1218.19341364
Iteration 54 Loss=  2239.93854328
Iteration 55 Loss=  1796.79592955
Iteration 56 Loss=  3019.75891945
Iteration 57 Loss=  1660.64121769
Iteration 58 Loss=  580.560940283
Iteration 59 Loss=  62.1555850893
Iteration 60 Loss=  7.30203986746
Iteration 61 Loss=  0.860484515709
Iteration 62 Loss=  7859.91476274
Iteration 63 Loss=  1588.13633192
Iteration 64 Loss=  1057.18746829
Iteration 65 Loss=  2077.2296752
Iteration 66 Loss=  344.253074309
Iteration 67 Loss=  977.60386727
Iteration 68 Loss=  75.0664200684
Iteration 69 Loss=  8.81880477966
Iteration 70 Loss=  1.03615502803
Iteration 71 Loss=  0.12539326191
Iteration 72 Loss=  5478.89164985
Iteration 73 Loss=  1284.08278484
Iteration 74 Loss=  447.25594491
Iteration 75 Loss=  2706.99915842
Iteration 76 Loss=  1422.70277157
Iteration 77 Loss=  1184.79474325
Iteration 78 Loss=  225.857655433
Iteration 79 Loss=  4114.39302904
Iteration 80 Loss=  1854.00859381
Iteration 81 Loss=  918.971894976
Iteration 82 Loss=  3460.19747946
Iteration 83 Loss=  230.083386557
Iteration 84 Loss=  3055.21188732
Iteration 85 Loss=  2342.52874822
Iteration 86 Loss=  667.923104176
Iteration 87 Loss=  3899.40957439
Iteration 88 Loss=  496.567966266
Iteration 89 Loss=  1189.6294541
Iteration 90 Loss=  3227.11960675
Iteration 91 Loss=  5010.79113074
Iteration 92 Loss=  3596.03951825
Iteration 93 Loss=  2580.84194024
Iteration 94 Loss=  278.552013302
Iteration 95 Loss=  2492.85352861
Iteration 96 Loss=  1128.45340707
Iteration 97 Loss=  2445.35913027
Iteration 98 Loss=  2063.14692604
Iteration 99 Loss=  864.801482158
Iteration 100 Loss=  3488.33518589
[-0.08587144  0.0205718  -0.06480441 ...,  0.06677188 -0.03023623
  0.0082784 ]
CROSS VALIDATION 15
Iteration 1 Loss=  2739.11406951
Iteration 2 Loss=  1703.07918814
Iteration 3 Loss=  661.349307271
Iteration 4 Loss=  1630.16370677
Iteration 5 Loss=  1683.96819375
Iteration 6 Loss=  476.582882319
Iteration 7 Loss=  2155.72575934
Iteration 8 Loss=  1904.04012317
Iteration 9 Loss=  2816.16635661
Iteration 10 Loss=  1686.0181684
Iteration 11 Loss=  1191.53515368
Iteration 12 Loss=  1438.90793892
Iteration 13 Loss=  757.61477162
Iteration 14 Loss=  2013.46525833
Iteration 15 Loss=  1972.7140327
Iteration 16 Loss=  1626.96798377
Iteration 17 Loss=  691.373220523
Iteration 18 Loss=  65.9649874277
Iteration 19 Loss=  7.75077000373
Iteration 20 Loss=  0.912021967592
Iteration 21 Loss=  7591.61277335
Iteration 22 Loss=  1668.94261172
Iteration 23 Loss=  4846.37471909
Iteration 24 Loss=  1303.25685633
Iteration 25 Loss=  4402.92496413
Iteration 26 Loss=  1451.02611603
Iteration 27 Loss=  2729.75389294
Iteration 28 Loss=  826.491890182
Iteration 29 Loss=  2822.94436487
Iteration 30 Loss=  2133.08761379
Iteration 31 Loss=  2429.14100485
Iteration 32 Loss=  2332.69249811
Iteration 33 Loss=  1302.02637538
Iteration 34 Loss=  1776.38475925
Iteration 35 Loss=  1425.12946776
Iteration 36 Loss=  4380.55194486
Iteration 37 Loss=  488.864724282
Iteration 38 Loss=  3314.71092348
Iteration 39 Loss=  536.243572322
Iteration 40 Loss=  1107.67218147
Iteration 41 Loss=  2932.13363664
Iteration 42 Loss=  1494.25766359
Iteration 43 Loss=  706.623376993
Iteration 44 Loss=  1552.73913769
Iteration 45 Loss=  2174.98130088
Iteration 46 Loss=  431.144167998
Iteration 47 Loss=  4128.1676268
Iteration 48 Loss=  339.163420424
Iteration 49 Loss=  39.8449264883
Iteration 50 Loss=  4.6826332167
Iteration 51 Loss=  0.661058723301
Iteration 52 Loss=  8048.66972597
Iteration 53 Loss=  2556.92249701
Iteration 54 Loss=  451.99023446
Iteration 55 Loss=  2209.37970489
Iteration 56 Loss=  1658.72112848
Iteration 57 Loss=  977.987119864
Iteration 58 Loss=  5816.072799
Iteration 59 Loss=  1646.49013004
Iteration 60 Loss=  2778.21516322
Iteration 61 Loss=  2013.43493808
Iteration 62 Loss=  2455.38710425
Iteration 63 Loss=  374.916915709
Iteration 64 Loss=  5158.82220553
Iteration 65 Loss=  1380.37150101
Iteration 66 Loss=  1057.60006157
Iteration 67 Loss=  2747.0242189
Iteration 68 Loss=  2025.09851602
Iteration 69 Loss=  708.528211745
Iteration 70 Loss=  98.1887262431
Iteration 71 Loss=  5505.32482277
Iteration 72 Loss=  1729.57318973
Iteration 73 Loss=  536.289563565
Iteration 74 Loss=  2303.86467805
Iteration 75 Loss=  1206.90970188
Iteration 76 Loss=  207.443881112
Iteration 77 Loss=  2085.47732704
Iteration 78 Loss=  4098.27779986
Iteration 79 Loss=  504.285120764
Iteration 80 Loss=  59.2434276579
Iteration 81 Loss=  6.95991926009
Iteration 82 Loss=  0.819347900056
Iteration 83 Loss=  7020.39888077
Iteration 84 Loss=  2195.59147288
Iteration 85 Loss=  169.247646499
Iteration 86 Loss=  19.8832175501
Iteration 87 Loss=  2.34038179006
Iteration 88 Loss=  0.321638675671
Iteration 89 Loss=  4617.58521555
Iteration 90 Loss=  1352.12296236
Iteration 91 Loss=  2075.29615283
Iteration 92 Loss=  2940.99953419
Iteration 93 Loss=  1697.64248195
Iteration 94 Loss=  623.916183347
Iteration 95 Loss=  1234.51218931
Iteration 96 Loss=  1705.47349212
Iteration 97 Loss=  4376.25222324
Iteration 98 Loss=  462.401104271
Iteration 99 Loss=  95.1575441626
Iteration 100 Loss=  11.1791192094
[ -2.18158038e-02  -7.83832055e-03   2.45651272e-05 ...,   1.04920508e-02
   2.14287745e-03   2.04009074e-03]
CROSS VALIDATION 16
Iteration 1 Loss=  2739.11406951
Iteration 2 Loss=  1703.07918814
Iteration 3 Loss=  77.1520559235
Iteration 4 Loss=  9.06480684989
Iteration 5 Loss=  1.07883988213
Iteration 6 Loss=  0.15768694239
Iteration 7 Loss=  5851.25799768
Iteration 8 Loss=  2726.94740805
Iteration 9 Loss=  390.934325687
Iteration 10 Loss=  45.9269774861
Iteration 11 Loss=  5.39922828894
Iteration 12 Loss=  0.637419781974
Iteration 13 Loss=  8641.62290281
Iteration 14 Loss=  3487.50418167
Iteration 15 Loss=  1261.14868599
Iteration 16 Loss=  3364.65628555
Iteration 17 Loss=  1124.01927886
Iteration 18 Loss=  1379.20608604
Iteration 19 Loss=  1847.72892147
Iteration 20 Loss=  4161.89413231
Iteration 21 Loss=  995.415243057
Iteration 22 Loss=  1269.52186747
Iteration 23 Loss=  3245.39056787
Iteration 24 Loss=  764.170233399
Iteration 25 Loss=  1638.07976145
Iteration 26 Loss=  1775.59365591
Iteration 27 Loss=  1080.09621653
Iteration 28 Loss=  1335.32612932
Iteration 29 Loss=  3226.7653126
Iteration 30 Loss=  947.347934573
Iteration 31 Loss=  387.764978564
Iteration 32 Loss=  2748.95863104
Iteration 33 Loss=  1742.02501414
Iteration 34 Loss=  1483.10712542
Iteration 35 Loss=  1713.55598782
Iteration 36 Loss=  4918.5212531
Iteration 37 Loss=  2252.06128235
Iteration 38 Loss=  1346.59888945
Iteration 39 Loss=  1225.23054464
Iteration 40 Loss=  1293.9513711
Iteration 41 Loss=  1163.56310661
Iteration 42 Loss=  2350.17555914
Iteration 43 Loss=  562.837728829
Iteration 44 Loss=  1069.23082013
Iteration 45 Loss=  4775.61344398
Iteration 46 Loss=  6194.72836179
Iteration 47 Loss=  1002.01905036
Iteration 48 Loss=  1411.46986471
Iteration 49 Loss=  2961.46141374
Iteration 50 Loss=  1574.54083562
Iteration 51 Loss=  2714.54084772
Iteration 52 Loss=  4613.60129096
Iteration 53 Loss=  2172.21183047
Iteration 54 Loss=  1546.49804943
Iteration 55 Loss=  2767.68890173
Iteration 56 Loss=  1676.86551128
Iteration 57 Loss=  856.542663487
Iteration 58 Loss=  2173.31977318
Iteration 59 Loss=  278.393824952
Iteration 60 Loss=  653.278738877
Iteration 61 Loss=  2185.30127509
Iteration 62 Loss=  1144.68351747
Iteration 63 Loss=  1525.58031628
Iteration 64 Loss=  875.338097692
Iteration 65 Loss=  1446.89987645
Iteration 66 Loss=  3067.7933218
Iteration 67 Loss=  331.907279934
Iteration 68 Loss=  38.9924749279
Iteration 69 Loss=  4.58083690361
Iteration 70 Loss=  0.542033609711
Iteration 71 Loss=  4574.90227611
Iteration 72 Loss=  706.758506055
Iteration 73 Loss=  558.432720652
Iteration 74 Loss=  6593.47515851
Iteration 75 Loss=  1649.4456436
Iteration 76 Loss=  462.665755983
Iteration 77 Loss=  893.851429199
Iteration 78 Loss=  1921.52285983
Iteration 79 Loss=  3344.00051547
Iteration 80 Loss=  620.393624476
Iteration 81 Loss=  980.216879767
Iteration 82 Loss=  3725.46060791
Iteration 83 Loss=  1137.72298152
Iteration 84 Loss=  1087.6426294
Iteration 85 Loss=  1558.89002516
Iteration 86 Loss=  1405.69703594
Iteration 87 Loss=  6910.56344638
Iteration 88 Loss=  3626.48948049
Iteration 89 Loss=  333.736021725
Iteration 90 Loss=  1355.59266346
Iteration 91 Loss=  3274.22942909
Iteration 92 Loss=  1195.03104318
Iteration 93 Loss=  2613.59382061
Iteration 94 Loss=  2018.41868533
Iteration 95 Loss=  362.236829591
Iteration 96 Loss=  306.023586925
Iteration 97 Loss=  35.951658076
Iteration 98 Loss=  4.22407307896
Iteration 99 Loss=  8397.40787484
Iteration 100 Loss=  7923.47219455
[-0.0368581  -0.03082378 -0.00894535 ...,  0.06306294  0.02306978
  0.03676247]
CROSS VALIDATION 17
Iteration 1 Loss=  2739.11406951
Iteration 2 Loss=  1703.07918814
Iteration 3 Loss=  683.602678833
Iteration 4 Loss=  1633.33538156
Iteration 5 Loss=  1671.42965893
Iteration 6 Loss=  501.724055068
Iteration 7 Loss=  4022.18402967
Iteration 8 Loss=  724.253823948
Iteration 9 Loss=  2037.33604015
Iteration 10 Loss=  3024.10463816
Iteration 11 Loss=  688.322059527
Iteration 12 Loss=  2576.57561771
Iteration 13 Loss=  2729.00234768
Iteration 14 Loss=  807.67123852
Iteration 15 Loss=  794.664909199
Iteration 16 Loss=  2096.58199833
Iteration 17 Loss=  424.210377619
Iteration 18 Loss=  638.063795513
Iteration 19 Loss=  3807.40471796
Iteration 20 Loss=  1949.5070317
Iteration 21 Loss=  955.801526001
Iteration 22 Loss=  2755.8981245
Iteration 23 Loss=  3699.46279772
Iteration 24 Loss=  2998.59960343
Iteration 25 Loss=  154.593301156
Iteration 26 Loss=  1586.50035261
Iteration 27 Loss=  2276.0832156
Iteration 28 Loss=  1041.74291849
Iteration 29 Loss=  4390.44188403
Iteration 30 Loss=  471.937782457
Iteration 31 Loss=  1034.40881999
Iteration 32 Loss=  2553.96614708
Iteration 33 Loss=  2393.55934148
Iteration 34 Loss=  760.958742201
Iteration 35 Loss=  1318.73754784
Iteration 36 Loss=  3114.49164554
Iteration 37 Loss=  1583.06309016
Iteration 38 Loss=  145.195126116
Iteration 39 Loss=  3070.33785489
Iteration 40 Loss=  3184.90565022
Iteration 41 Loss=  4250.07647606
Iteration 42 Loss=  349.507404772
Iteration 43 Loss=  2921.79664343
Iteration 44 Loss=  1640.21761883
Iteration 45 Loss=  509.568016482
Iteration 46 Loss=  3545.45874207
Iteration 47 Loss=  2237.76263455
Iteration 48 Loss=  523.673963497
Iteration 49 Loss=  962.769676199
Iteration 50 Loss=  2675.89370176
Iteration 51 Loss=  2722.48846038
Iteration 52 Loss=  1863.47529415
Iteration 53 Loss=  2469.97965973
Iteration 54 Loss=  2117.57903138
Iteration 55 Loss=  1725.13805741
Iteration 56 Loss=  544.252911142
Iteration 57 Loss=  1452.99029334
Iteration 58 Loss=  3122.85879482
Iteration 59 Loss=  1466.43004216
Iteration 60 Loss=  1842.13455083
Iteration 61 Loss=  188.846151508
Iteration 62 Loss=  22.187119072
Iteration 63 Loss=  2.63676193991
Iteration 64 Loss=  10028.4715374
Iteration 65 Loss=  4346.69710183
Iteration 66 Loss=  2873.77172689
Iteration 67 Loss=  290.021547019
Iteration 68 Loss=  4577.64885064
Iteration 69 Loss=  2002.97258239
Iteration 70 Loss=  2898.42863497
Iteration 71 Loss=  1129.0953244
Iteration 72 Loss=  3085.63990148
Iteration 73 Loss=  933.203192291
Iteration 74 Loss=  2432.96785423
Iteration 75 Loss=  900.278517973
Iteration 76 Loss=  1667.91390337
Iteration 77 Loss=  885.293817513
Iteration 78 Loss=  2108.92211318
Iteration 79 Loss=  266.708257309
Iteration 80 Loss=  1911.70157843
Iteration 81 Loss=  1100.27174853
Iteration 82 Loss=  1023.11837481
Iteration 83 Loss=  5964.72665658
Iteration 84 Loss=  4513.79290781
Iteration 85 Loss=  2188.80776347
Iteration 86 Loss=  799.355634069
Iteration 87 Loss=  1822.59531599
Iteration 88 Loss=  2550.92090811
Iteration 89 Loss=  701.352805545
Iteration 90 Loss=  1364.14290641
Iteration 91 Loss=  1159.1036912
Iteration 92 Loss=  977.014390877
Iteration 93 Loss=  3083.23839688
Iteration 94 Loss=  624.324282378
Iteration 95 Loss=  1717.749914
Iteration 96 Loss=  3815.35336971
Iteration 97 Loss=  1660.20546559
Iteration 98 Loss=  240.965462243
Iteration 99 Loss=  226.586208036
Iteration 100 Loss=  1715.22497192
[-0.04404147 -0.05293645  0.03135205 ...,  0.01191035 -0.00426469
 -0.00168163]
CROSS VALIDATION 18
Iteration 1 Loss=  2368.56738647
Iteration 2 Loss=  459.627774627
Iteration 3 Loss=  334.237908333
Iteration 4 Loss=  1116.40281675
Iteration 5 Loss=  1040.19107211
Iteration 6 Loss=  2092.41276157
Iteration 7 Loss=  928.99865378
Iteration 8 Loss=  679.561522034
Iteration 9 Loss=  2417.81541247
Iteration 10 Loss=  5121.9930912
Iteration 11 Loss=  553.112728226
Iteration 12 Loss=  1463.49849277
Iteration 13 Loss=  3668.30152089
Iteration 14 Loss=  770.47413249
Iteration 15 Loss=  309.146880635
Iteration 16 Loss=  36.3185826915
Iteration 17 Loss=  4.26670793517
Iteration 18 Loss=  0.501552542948
Iteration 19 Loss=  6804.18589011
Iteration 20 Loss=  7568.65414547
Iteration 21 Loss=  2552.81170082
Iteration 22 Loss=  2085.10591018
Iteration 23 Loss=  2011.80765578
Iteration 24 Loss=  1929.50653246
Iteration 25 Loss=  2883.50751417
Iteration 26 Loss=  3696.75428834
Iteration 27 Loss=  1594.75788772
Iteration 28 Loss=  312.1586491
Iteration 29 Loss=  36.6751289566
Iteration 30 Loss=  4.31088630157
Iteration 31 Loss=  0.527929127089
Iteration 32 Loss=  2658.87218715
Iteration 33 Loss=  3152.59050503
Iteration 34 Loss=  176.842530256
Iteration 35 Loss=  20.7756774215
Iteration 36 Loss=  2.44121927463
Iteration 37 Loss=  0.51326420859
Iteration 38 Loss=  6095.11019593
Iteration 39 Loss=  2390.75969195
Iteration 40 Loss=  4500.87784029
Iteration 41 Loss=  1347.32881316
Iteration 42 Loss=  326.048105971
Iteration 43 Loss=  242.712891024
Iteration 44 Loss=  1828.05774038
Iteration 45 Loss=  690.114065469
Iteration 46 Loss=  683.819791284
Iteration 47 Loss=  1596.77636286
Iteration 48 Loss=  1473.88148641
Iteration 49 Loss=  887.749443771
Iteration 50 Loss=  1768.59661862
Iteration 51 Loss=  1520.11726212
Iteration 52 Loss=  1103.02781529
Iteration 53 Loss=  2703.72626693
Iteration 54 Loss=  1263.293696
Iteration 55 Loss=  2745.87506659
Iteration 56 Loss=  1158.30616941
Iteration 57 Loss=  2911.15361206
Iteration 58 Loss=  2679.54196031
Iteration 59 Loss=  3404.57432784
Iteration 60 Loss=  459.081725573
Iteration 61 Loss=  1782.24148369
Iteration 62 Loss=  2648.1625961
Iteration 63 Loss=  916.255047916
Iteration 64 Loss=  2898.01944555
Iteration 65 Loss=  947.351247325
Iteration 66 Loss=  74.8049726498
Iteration 67 Loss=  8.7880899196
Iteration 68 Loss=  1.03361808036
Iteration 69 Loss=  0.810347816182
Iteration 70 Loss=  4199.83719494
Iteration 71 Loss=  1009.45468619
Iteration 72 Loss=  2258.46156229
Iteration 73 Loss=  3214.65463781
Iteration 74 Loss=  1931.31158216
Iteration 75 Loss=  187.933928926
Iteration 76 Loss=  1607.97505426
Iteration 77 Loss=  4547.40008866
Iteration 78 Loss=  307.867084681
Iteration 79 Loss=  2029.67256111
Iteration 80 Loss=  3159.3612057
Iteration 81 Loss=  1049.81887434
Iteration 82 Loss=  3640.39811724
Iteration 83 Loss=  3151.66910677
Iteration 84 Loss=  1234.25004324
Iteration 85 Loss=  1798.63526651
Iteration 86 Loss=  2862.64266943
Iteration 87 Loss=  2083.33225976
Iteration 88 Loss=  1387.55519288
Iteration 89 Loss=  1152.41647152
Iteration 90 Loss=  1177.82841287
Iteration 91 Loss=  2263.15302145
Iteration 92 Loss=  1132.97151181
Iteration 93 Loss=  1196.90718789
Iteration 94 Loss=  2311.14996763
Iteration 95 Loss=  4099.82744707
Iteration 96 Loss=  2797.10700437
Iteration 97 Loss=  2240.04759094
Iteration 98 Loss=  1518.63968719
Iteration 99 Loss=  248.754366627
Iteration 100 Loss=  29.2236689205
[ 0.0065695  -0.01908603  0.00516369 ...,  0.00375283  0.00313534
  0.00136157]
CROSS VALIDATION 19
Iteration 1 Loss=  2731.69490482
Iteration 2 Loss=  1699.89623596
Iteration 3 Loss=  492.800434278
Iteration 4 Loss=  1371.96365033
Iteration 5 Loss=  1371.845007
Iteration 6 Loss=  1049.45930939
Iteration 7 Loss=  3250.06478457
Iteration 8 Loss=  1536.74908954
Iteration 9 Loss=  361.244477683
Iteration 10 Loss=  2756.28635319
Iteration 11 Loss=  263.334504669
Iteration 12 Loss=  1881.34008857
Iteration 13 Loss=  4627.84842114
Iteration 14 Loss=  334.112943352
Iteration 15 Loss=  39.2523755389
Iteration 16 Loss=  4.61346136125
Iteration 17 Loss=  0.547022482992
Iteration 18 Loss=  0.166524663187
Iteration 19 Loss=  4784.10110796
Iteration 20 Loss=  1151.34618293
Iteration 21 Loss=  2934.17651338
Iteration 22 Loss=  601.699281861
Iteration 23 Loss=  2779.34876745
Iteration 24 Loss=  872.651739867
Iteration 25 Loss=  1279.4717322
Iteration 26 Loss=  1655.93325059
Iteration 27 Loss=  1563.09102779
Iteration 28 Loss=  301.080901868
Iteration 29 Loss=  2244.60188886
Iteration 30 Loss=  966.733595694
Iteration 31 Loss=  4699.39492935
Iteration 32 Loss=  1096.71540654
Iteration 33 Loss=  3818.24833134
Iteration 34 Loss=  1354.46754159
Iteration 35 Loss=  3894.05894828
Iteration 36 Loss=  1486.8424486
Iteration 37 Loss=  1173.11635502
Iteration 38 Loss=  1843.00088092
Iteration 39 Loss=  905.523764058
Iteration 40 Loss=  599.928823342
Iteration 41 Loss=  1437.44184095
Iteration 42 Loss=  1696.15826574
Iteration 43 Loss=  1053.28235244
Iteration 44 Loss=  1563.39744315
Iteration 45 Loss=  1212.16419958
Iteration 46 Loss=  2552.21640522
Iteration 47 Loss=  2236.70141614
Iteration 48 Loss=  355.516532993
Iteration 49 Loss=  4238.1470497
Iteration 50 Loss=  1450.1071409
Iteration 51 Loss=  1387.20570116
Iteration 52 Loss=  2532.8869593
Iteration 53 Loss=  1314.46282164
Iteration 54 Loss=  1062.55557729
Iteration 55 Loss=  331.116746101
Iteration 56 Loss=  38.908420085
Iteration 57 Loss=  5396.37215042
Iteration 58 Loss=  5784.87144672
Iteration 59 Loss=  526.328869534
Iteration 60 Loss=  481.546569983
Iteration 61 Loss=  1644.09302022
Iteration 62 Loss=  2223.94899415
Iteration 63 Loss=  1167.51802152
Iteration 64 Loss=  1287.91634557
Iteration 65 Loss=  1063.08318141
Iteration 66 Loss=  735.387868855
Iteration 67 Loss=  1718.99472696
Iteration 68 Loss=  1691.36493907
Iteration 69 Loss=  2264.44762807
Iteration 70 Loss=  776.850831444
Iteration 71 Loss=  1472.43493938
Iteration 72 Loss=  1414.98704941
Iteration 73 Loss=  1711.93900137
Iteration 74 Loss=  1512.12641737
Iteration 75 Loss=  2220.0206671
Iteration 76 Loss=  294.320744963
Iteration 77 Loss=  2580.82532519
Iteration 78 Loss=  1783.06583194
Iteration 79 Loss=  1544.92335241
Iteration 80 Loss=  1119.73075545
Iteration 81 Loss=  3879.46737166
Iteration 82 Loss=  2118.95409186
Iteration 83 Loss=  335.453565262
Iteration 84 Loss=  3416.54087904
Iteration 85 Loss=  3359.98583486
Iteration 86 Loss=  626.987444378
Iteration 87 Loss=  3039.63501515
Iteration 88 Loss=  3416.56731231
Iteration 89 Loss=  952.195023843
Iteration 90 Loss=  4153.42931311
Iteration 91 Loss=  558.400458819
Iteration 92 Loss=  1885.65316354
Iteration 93 Loss=  2831.36208037
Iteration 94 Loss=  612.239811696
Iteration 95 Loss=  2151.13992731
Iteration 96 Loss=  1875.66028383
Iteration 97 Loss=  1288.49694313
Iteration 98 Loss=  1599.66373612
Iteration 99 Loss=  2485.72820716
Iteration 100 Loss=  361.015961457
[-0.0809987  -0.06098917 -0.05165221 ...,  0.02652988  0.0277708
  0.00763971]
Accuracy (Logistic Loss):	0.7 for lmda= 1 learning rate= 0.01
---------------------------------------------------------------------------------
lmda= 1 learning rate= 0.1
CROSS VALIDATION 0
Iteration 1 Loss=  75856.3977165
Iteration 2 Loss=  75852.7464519
Iteration 3 Loss=  75852.7464252
[-0.07024048 -0.51245781  0.12728471 ...,  0.19160851 -0.19982005
 -0.10075717]
CROSS VALIDATION 1
Iteration 1 Loss=  83901.6194552
Iteration 2 Loss=  75852.7391614
Iteration 3 Loss=  75852.7464252
Iteration 4 Loss=  75852.7464252
[-0.07024048 -0.51245781  0.12728471 ...,  0.19160851 -0.19982005
 -0.10075717]
CROSS VALIDATION 2
Iteration 1 Loss=  76302.6825956
Iteration 2 Loss=  75852.7497075
Iteration 3 Loss=  75852.7464252
Iteration 4 Loss=  75852.7464252
[-0.07024048 -0.51245781  0.12728471 ...,  0.19160851 -0.19982005
 -0.10075717]
CROSS VALIDATION 3
Iteration 1 Loss=  75860.6348988
Iteration 2 Loss=  75852.746483
Iteration 3 Loss=  75852.7464252
[-0.07024048 -0.51245781  0.12728471 ...,  0.19160851 -0.19982005
 -0.10075717]
CROSS VALIDATION 4
Iteration 1 Loss=  75860.6348988
Iteration 2 Loss=  75852.746483
Iteration 3 Loss=  75852.7464252
[-0.07024048 -0.51245781  0.12728471 ...,  0.19160851 -0.19982005
 -0.10075717]
CROSS VALIDATION 5
Iteration 1 Loss=  75860.6348988
Iteration 2 Loss=  75852.746483
Iteration 3 Loss=  75852.7464252
[-0.07024048 -0.51245781  0.12728471 ...,  0.19160851 -0.19982005
 -0.10075717]
CROSS VALIDATION 6
Iteration 1 Loss=  72870.6344482
Iteration 2 Loss=  83271.9809597
Iteration 3 Loss=  83272.2182603
Iteration 4 Loss=  83272.218262
[-0.21508333 -0.47275411 -0.10479216 ...,  0.16639644 -0.18896458
 -0.10756397]
CROSS VALIDATION 7
Iteration 1 Loss=  75860.6348988
Iteration 2 Loss=  75848.9794238
Iteration 3 Loss=  75848.9793386
[-0.07025055 -0.51245995  0.12727476 ...,  0.19160269 -0.19982083
 -0.10075299]
CROSS VALIDATION 8
Iteration 1 Loss=  75279.8576132
Iteration 2 Loss=  74476.702503
Iteration 3 Loss=  74476.9600962
Iteration 4 Loss=  74476.9547719
Iteration 5 Loss=  74476.9548789
Iteration 6 Loss=  74476.9548767
[-0.06300272 -0.5156361   0.14916036 ...,  0.19294299 -0.19681788
 -0.09876445]
CROSS VALIDATION 9
Iteration 1 Loss=  74659.6556522
Iteration 2 Loss=  73958.2651242
Iteration 3 Loss=  73958.6805808
Iteration 4 Loss=  73958.6720796
Iteration 5 Loss=  73958.6722504
Iteration 6 Loss=  73958.672247
[-0.06300272 -0.5156361   0.14916036 ...,  0.19294299 -0.19681788
 -0.09876445]
CROSS VALIDATION 10
Iteration 1 Loss=  73916.4646112
Iteration 2 Loss=  73915.4579311
Iteration 3 Loss=  73915.4579237
[-0.07021865 -0.51243399  0.12730971 ...,  0.19160667 -0.19983086
 -0.10075054]
CROSS VALIDATION 11
Iteration 1 Loss=  75859.8899136
Iteration 2 Loss=  75844.0646611
Iteration 3 Loss=  75844.0645455
Iteration 4 Loss=  75844.0645455
[-0.07024468 -0.5124418   0.12731737 ...,  0.19161237 -0.19981566
 -0.10075904]
CROSS VALIDATION 12
Iteration 1 Loss=  72244.0044224
Iteration 2 Loss=  72233.5760185
Iteration 3 Loss=  72233.5759423
[-0.08801267 -0.51658407  0.11705607 ...,  0.20797454 -0.19339498
 -0.09960365]
CROSS VALIDATION 13
Iteration 1 Loss=  75004.2702526
Iteration 2 Loss=  83740.8468278
Iteration 3 Loss=  83741.0689884
Iteration 4 Loss=  83741.06899
[-0.19661941 -0.44548754 -0.10690041 ...,  0.18979865 -0.20011079
 -0.10064335]
CROSS VALIDATION 14
Iteration 1 Loss=  83897.0235771
Iteration 2 Loss=  79631.0660693
Iteration 3 Loss=  79631.1041029
Iteration 4 Loss=  79631.1041027
[-0.09408417 -0.53872172  0.11708975 ...,  0.18674852 -0.18378593
 -0.10624049]
CROSS VALIDATION 15
Iteration 1 Loss=  83897.0235771
Iteration 2 Loss=  79631.0660693
Iteration 3 Loss=  79631.1041029
Iteration 4 Loss=  79631.1041027
[-0.09408417 -0.53872172  0.11708975 ...,  0.18674852 -0.18378593
 -0.10624049]
CROSS VALIDATION 16
Iteration 1 Loss=  80611.7426559
Iteration 2 Loss=  77255.9533047
Iteration 3 Loss=  77255.9973332
Iteration 4 Loss=  77255.9973331
[-0.09408417 -0.53872172  0.11708975 ...,  0.18674852 -0.18378593
 -0.10624049]
CROSS VALIDATION 17
Iteration 1 Loss=  79263.7503119
Iteration 2 Loss=  73960.9924451
Iteration 3 Loss=  73961.0229165
Iteration 4 Loss=  73961.0229162
[-0.09408417 -0.53872172  0.11708975 ...,  0.18674852 -0.18378593
 -0.10624049]
CROSS VALIDATION 18
Iteration 1 Loss=  72927.8753246
Iteration 2 Loss=  74464.9796715
Iteration 3 Loss=  74464.9914725
Iteration 4 Loss=  74464.9914726
[-0.21504898 -0.4726451  -0.10488968 ...,  0.16627498 -0.1890239
 -0.10752102]
CROSS VALIDATION 19
Iteration 1 Loss=  83897.0235771
Iteration 2 Loss=  79610.8008456
Iteration 3 Loss=  79610.8342382
Iteration 4 Loss=  79610.8342384
[-0.09410774 -0.5387073   0.1171062  ...,  0.18672626 -0.18383132
 -0.10623035]
Accuracy (Logistic Loss):	0.6 for lmda= 1 learning rate= 0.1
---------------------------------------------------------------------------------

